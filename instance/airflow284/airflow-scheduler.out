[2026-02-25T08:45:11.765+0800] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2026-02-25T08:45:12.313+0800] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2026-02-25T08:45:12.314+0800] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2026-02-25T08:45:12.319+0800] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 1487
[2026-02-25T08:45:12.325+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T08:45:14.314+0800] {settings.py:63} INFO - Configured default timezone Asia/Shanghai
[2026-02-25T08:45:14.372+0800] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-02-25T08:45:14.665+0800] {core.py:50} INFO - Starting log server on http://[::]:8793
[2026-02-25T08:50:14.555+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T08:55:16.808+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:00:20.117+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:01:13.146+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:01:11.694331+00:00 [scheduled]>
[2026-02-25T09:01:13.147+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T09:01:13.148+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:01:11.694331+00:00 [scheduled]>
[2026-02-25T09:01:13.151+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:01:11.694331+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T09:01:13.152+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:01:11.694331+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T09:01:13.152+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:01:11.694331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:01:13.155+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:01:11.694331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:01:15.284+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T09:01:16.927+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:01:11.694331+00:00 [queued]> on host localhost-2.local
[2026-02-25T09:01:18.175+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:01:11.694331+00:00', try_number=1, map_index=-1)
[2026-02-25T09:01:18.190+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T01:01:11.694331+00:00, map_index=-1, run_start_date=2026-02-25 01:01:16.998370+00:00, run_end_date=2026-02-25 01:01:17.490608+00:00, run_duration=0.492238, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=341, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:01:13.149594+00:00, queued_by_job_id=340, pid=2096
[2026-02-25T09:01:21.679+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 01:01:11.694331+00:00: manual__2026-02-25T01:01:11.694331+00:00, state:running, queued_at: 2026-02-25 01:01:11.725299+00:00. externally triggered: True> successful
[2026-02-25T09:01:21.681+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 01:01:11.694331+00:00, run_id=manual__2026-02-25T01:01:11.694331+00:00, run_start_date=2026-02-25 01:01:13.113741+00:00, run_end_date=2026-02-25 01:01:21.681438+00:00, run_duration=8.567697, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 01:01:11.694331+00:00, data_interval_end=2026-02-25 01:01:11.694331+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T09:01:21.694+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:01:17.507944+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:01:17.509548+00:00 [scheduled]>
[2026-02-25T09:01:21.695+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T09:01:21.696+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T09:01:21.697+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:01:17.507944+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:01:17.509548+00:00 [scheduled]>
[2026-02-25T09:01:21.700+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:01:17.507944+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:01:17.509548+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T09:01:21.701+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:01:17.507944+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T09:01:21.702+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:01:17.507944+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:01:21.705+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:01:17.509548+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T09:01:21.706+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:01:17.509548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:01:21.715+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:01:17.507944+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:01:24.035+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T09:01:25.694+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:01:17.507944+00:00 [queued]> on host localhost-2.local
[2026-02-25T09:01:34.747+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:01:17.509548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:01:37.135+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T09:01:38.594+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:01:17.509548+00:00 [queued]> on host localhost-2.local
[2026-02-25T09:01:46.935+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:01:17.507944+00:00', try_number=1, map_index=-1)
[2026-02-25T09:01:46.941+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:01:17.509548+00:00', try_number=1, map_index=-1)
[2026-02-25T09:01:46.953+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T01:01:17.507944+00:00, map_index=-1, run_start_date=2026-02-25 01:01:25.769215+00:00, run_end_date=2026-02-25 01:01:34.065145+00:00, run_duration=8.29593, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=342, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:01:21.698613+00:00, queued_by_job_id=340, pid=2102
[2026-02-25T09:01:46.955+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T01:01:17.509548+00:00, map_index=-1, run_start_date=2026-02-25 01:01:38.662529+00:00, run_end_date=2026-02-25 01:01:46.239032+00:00, run_duration=7.576503, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=343, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:01:21.698613+00:00, queued_by_job_id=340, pid=2134
[2026-02-25T09:01:50.714+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 01:01:17.507944+00:00: dataset_triggered__2026-02-25T01:01:17.507944+00:00, state:running, queued_at: 2026-02-25 01:01:21.645233+00:00. externally triggered: False> successful
[2026-02-25T09:01:50.715+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 01:01:17.507944+00:00, run_id=dataset_triggered__2026-02-25T01:01:17.507944+00:00, run_start_date=2026-02-25 01:01:21.659727+00:00, run_end_date=2026-02-25 01:01:50.715367+00:00, run_duration=29.05564, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:01:11.694331+00:00, data_interval_end=2026-02-25 01:01:11.694331+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T09:01:50.720+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 01:01:17.509548+00:00: dataset_triggered__2026-02-25T01:01:17.509548+00:00, state:running, queued_at: 2026-02-25 01:01:21.630949+00:00. externally triggered: False> successful
[2026-02-25T09:01:50.720+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 01:01:17.509548+00:00, run_id=dataset_triggered__2026-02-25T01:01:17.509548+00:00, run_start_date=2026-02-25 01:01:21.659837+00:00, run_end_date=2026-02-25 01:01:50.720949+00:00, run_duration=29.061112, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:01:11.694331+00:00, data_interval_end=2026-02-25 01:01:11.694331+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T09:25:24.933+0800] {job.py:229} INFO - Heartbeat recovered after 1282.81 seconds
[2026-02-25T09:25:46.507+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:25:43.764450+00:00 [scheduled]>
[2026-02-25T09:25:46.508+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T09:25:46.509+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:25:43.764450+00:00 [scheduled]>
[2026-02-25T09:25:46.511+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:25:43.764450+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T09:25:46.512+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:25:43.764450+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T09:25:46.513+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:25:43.764450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:25:46.516+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:25:43.764450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:25:48.533+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T09:25:49.880+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:25:43.764450+00:00 [queued]> on host localhost-2.local
[2026-02-25T09:25:51.163+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:25:43.764450+00:00', try_number=1, map_index=-1)
[2026-02-25T09:25:51.175+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T01:25:43.764450+00:00, map_index=-1, run_start_date=2026-02-25 01:25:49.947155+00:00, run_end_date=2026-02-25 01:25:50.436660+00:00, run_duration=0.489505, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=344, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:25:46.510503+00:00, queued_by_job_id=340, pid=2325
[2026-02-25T09:25:54.883+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 01:25:43.764450+00:00: manual__2026-02-25T01:25:43.764450+00:00, state:running, queued_at: 2026-02-25 01:25:43.787031+00:00. externally triggered: True> successful
[2026-02-25T09:25:54.883+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 01:25:43.764450+00:00, run_id=manual__2026-02-25T01:25:43.764450+00:00, run_start_date=2026-02-25 01:25:46.485532+00:00, run_end_date=2026-02-25 01:25:54.883909+00:00, run_duration=8.398377, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 01:25:43.764450+00:00, data_interval_end=2026-02-25 01:25:43.764450+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T09:25:54.895+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:25:50.455089+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:25:50.457171+00:00 [scheduled]>
[2026-02-25T09:25:54.896+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T09:25:54.897+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T09:25:54.898+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:25:50.455089+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:25:50.457171+00:00 [scheduled]>
[2026-02-25T09:25:54.901+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:25:50.455089+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:25:50.457171+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T09:25:54.902+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:25:50.455089+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T09:25:54.903+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:25:50.455089+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:25:54.904+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:25:50.457171+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T09:25:54.904+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:25:50.457171+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:25:54.907+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:25:50.455089+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:25:56.981+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T09:25:58.402+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:25:50.455089+00:00 [queued]> on host localhost-2.local
[2026-02-25T09:26:07.970+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:25:50.457171+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T09:26:10.214+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T09:26:11.576+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:25:50.457171+00:00 [queued]> on host localhost-2.local
[2026-02-25T09:26:17.442+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:25:50.455089+00:00', try_number=1, map_index=-1)
[2026-02-25T09:26:17.446+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:25:50.457171+00:00', try_number=1, map_index=-1)
[2026-02-25T09:26:17.456+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T01:25:50.457171+00:00, map_index=-1, run_start_date=2026-02-25 01:26:11.641318+00:00, run_end_date=2026-02-25 01:26:16.742618+00:00, run_duration=5.1013, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=346, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:25:54.899699+00:00, queued_by_job_id=340, pid=2352
[2026-02-25T09:26:17.458+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T01:25:50.455089+00:00, map_index=-1, run_start_date=2026-02-25 01:25:58.470298+00:00, run_end_date=2026-02-25 01:26:07.250876+00:00, run_duration=8.780578, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=345, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:25:54.899699+00:00, queued_by_job_id=340, pid=2328
[2026-02-25T09:26:19.847+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 01:25:50.455089+00:00: dataset_triggered__2026-02-25T01:25:50.455089+00:00, state:running, queued_at: 2026-02-25 01:25:54.846237+00:00. externally triggered: False> successful
[2026-02-25T09:26:19.849+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 01:25:50.455089+00:00, run_id=dataset_triggered__2026-02-25T01:25:50.455089+00:00, run_start_date=2026-02-25 01:25:54.865207+00:00, run_end_date=2026-02-25 01:26:19.848938+00:00, run_duration=24.983731, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:25:43.764450+00:00, data_interval_end=2026-02-25 01:25:43.764450+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T09:26:19.853+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 01:25:50.457171+00:00: dataset_triggered__2026-02-25T01:25:50.457171+00:00, state:running, queued_at: 2026-02-25 01:25:54.853354+00:00. externally triggered: False> successful
[2026-02-25T09:26:19.854+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 01:25:50.457171+00:00, run_id=dataset_triggered__2026-02-25T01:25:50.457171+00:00, run_start_date=2026-02-25 01:25:54.865751+00:00, run_end_date=2026-02-25 01:26:19.854812+00:00, run_duration=24.989061, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:25:43.764450+00:00, data_interval_end=2026-02-25 01:25:43.764450+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T09:26:37.877+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:31:38.573+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:36:38.581+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:41:41.878+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:46:44.316+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:51:46.002+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T09:56:48.551+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:01:49.059+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:06:50.824+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:11:53.456+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:16:55.655+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:21:56.620+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:26:58.038+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:32:01.062+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:37:02.573+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:42:04.202+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:47:05.021+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:52:07.135+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T10:57:09.668+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:02:11.934+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:07:12.860+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:07:38.029+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:07:34.728947+00:00 [scheduled]>
[2026-02-25T11:07:38.030+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:07:38.031+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:07:34.728947+00:00 [scheduled]>
[2026-02-25T11:07:38.034+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:07:34.728947+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:07:38.035+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:07:34.728947+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:07:38.036+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:07:34.728947+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:07:38.039+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:07:34.728947+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:07:40.102+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:07:41.870+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:07:34.728947+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:07:43.206+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:07:34.728947+00:00', try_number=1, map_index=-1)
[2026-02-25T11:07:43.216+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:07:34.728947+00:00, map_index=-1, run_start_date=2026-02-25 03:07:41.944928+00:00, run_end_date=2026-02-25 03:07:42.449445+00:00, run_duration=0.504517, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=347, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:07:38.032902+00:00, queued_by_job_id=340, pid=6127
[2026-02-25T11:07:46.650+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:07:34.728947+00:00: manual__2026-02-25T03:07:34.728947+00:00, state:running, queued_at: 2026-02-25 03:07:34.748821+00:00. externally triggered: True> successful
[2026-02-25T11:07:46.651+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:07:34.728947+00:00, run_id=manual__2026-02-25T03:07:34.728947+00:00, run_start_date=2026-02-25 03:07:38.004296+00:00, run_end_date=2026-02-25 03:07:46.651867+00:00, run_duration=8.647571, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:07:34.728947+00:00, data_interval_end=2026-02-25 03:07:34.728947+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:07:46.663+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:07:42.467888+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:07:42.469399+00:00 [scheduled]>
[2026-02-25T11:07:46.664+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:07:46.665+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:07:46.666+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:07:42.467888+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:07:42.469399+00:00 [scheduled]>
[2026-02-25T11:07:46.669+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:07:42.467888+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:07:42.469399+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:07:46.670+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:07:42.467888+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:07:46.671+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:07:42.467888+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:07:46.672+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:07:42.469399+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:07:46.672+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:07:42.469399+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:07:46.675+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:07:42.467888+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:07:48.981+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:07:50.629+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:07:42.467888+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:08:00.692+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:07:42.469399+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:08:03.227+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:08:04.808+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:07:42.469399+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:08:10.923+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:07:42.467888+00:00', try_number=1, map_index=-1)
[2026-02-25T11:08:10.927+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:07:42.469399+00:00', try_number=1, map_index=-1)
[2026-02-25T11:08:10.938+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:07:42.469399+00:00, map_index=-1, run_start_date=2026-02-25 03:08:04.885747+00:00, run_end_date=2026-02-25 03:08:10.196140+00:00, run_duration=5.310393, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=349, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:07:46.667792+00:00, queued_by_job_id=340, pid=6167
[2026-02-25T11:08:10.939+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:07:42.467888+00:00, map_index=-1, run_start_date=2026-02-25 03:07:50.702051+00:00, run_end_date=2026-02-25 03:07:59.938761+00:00, run_duration=9.23671, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=348, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:07:46.667792+00:00, queued_by_job_id=340, pid=6136
[2026-02-25T11:08:14.307+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:07:42.467888+00:00: dataset_triggered__2026-02-25T03:07:42.467888+00:00, state:running, queued_at: 2026-02-25 03:07:46.609861+00:00. externally triggered: False> successful
[2026-02-25T11:08:14.308+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:07:42.467888+00:00, run_id=dataset_triggered__2026-02-25T03:07:42.467888+00:00, run_start_date=2026-02-25 03:07:46.632375+00:00, run_end_date=2026-02-25 03:08:14.308557+00:00, run_duration=27.676182, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:07:34.728947+00:00, data_interval_end=2026-02-25 03:07:34.728947+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:08:14.313+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:07:42.469399+00:00: dataset_triggered__2026-02-25T03:07:42.469399+00:00, state:running, queued_at: 2026-02-25 03:07:46.621234+00:00. externally triggered: False> successful
[2026-02-25T11:08:14.315+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:07:42.469399+00:00, run_id=dataset_triggered__2026-02-25T03:07:42.469399+00:00, run_start_date=2026-02-25 03:07:46.632474+00:00, run_end_date=2026-02-25 03:08:14.314959+00:00, run_duration=27.682485, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:07:34.728947+00:00, data_interval_end=2026-02-25 03:07:34.728947+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:10:40.110+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:10:39.916905+00:00 [scheduled]>
[2026-02-25T11:10:40.111+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:10:40.112+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:10:39.916905+00:00 [scheduled]>
[2026-02-25T11:10:40.114+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:10:39.916905+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:10:40.116+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:10:39.916905+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:10:40.116+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:10:39.916905+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:10:40.119+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:10:39.916905+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:10:42.453+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:10:44.243+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:10:39.916905+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:10:45.525+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:10:39.916905+00:00', try_number=1, map_index=-1)
[2026-02-25T11:10:45.533+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:10:39.916905+00:00, map_index=-1, run_start_date=2026-02-25 03:10:44.316756+00:00, run_end_date=2026-02-25 03:10:44.782850+00:00, run_duration=0.466094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=350, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:10:40.113753+00:00, queued_by_job_id=340, pid=6280
[2026-02-25T11:10:48.314+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:10:39.916905+00:00: manual__2026-02-25T03:10:39.916905+00:00, state:running, queued_at: 2026-02-25 03:10:39.930048+00:00. externally triggered: True> successful
[2026-02-25T11:10:48.315+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:10:39.916905+00:00, run_id=manual__2026-02-25T03:10:39.916905+00:00, run_start_date=2026-02-25 03:10:40.085485+00:00, run_end_date=2026-02-25 03:10:48.315620+00:00, run_duration=8.230135, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:10:39.916905+00:00, data_interval_end=2026-02-25 03:10:39.916905+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:10:48.325+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:10:44.800451+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:10:44.801967+00:00 [scheduled]>
[2026-02-25T11:10:48.326+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:10:48.327+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:10:48.328+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:10:44.800451+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:10:44.801967+00:00 [scheduled]>
[2026-02-25T11:10:48.330+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:10:44.800451+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:10:44.801967+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:10:48.331+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:10:44.800451+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:10:48.332+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:10:44.800451+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:10:48.333+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:10:44.801967+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:10:48.333+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:10:44.801967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:10:48.336+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:10:44.800451+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:10:50.369+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:10:51.952+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:10:44.800451+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:11:02.761+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:10:44.801967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:11:05.678+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:11:07.216+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:10:44.801967+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:11:13.875+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:10:44.800451+00:00', try_number=1, map_index=-1)
[2026-02-25T11:11:13.877+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:10:44.801967+00:00', try_number=1, map_index=-1)
[2026-02-25T11:11:13.886+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:10:44.801967+00:00, map_index=-1, run_start_date=2026-02-25 03:11:07.293195+00:00, run_end_date=2026-02-25 03:11:13.153313+00:00, run_duration=5.860118, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=352, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:10:48.329251+00:00, queued_by_job_id=340, pid=6308
[2026-02-25T11:11:13.887+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:10:44.800451+00:00, map_index=-1, run_start_date=2026-02-25 03:10:52.030643+00:00, run_end_date=2026-02-25 03:11:01.809133+00:00, run_duration=9.77849, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=351, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:10:48.329251+00:00, queued_by_job_id=340, pid=6284
[2026-02-25T11:11:16.816+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:10:44.800451+00:00: dataset_triggered__2026-02-25T03:10:44.800451+00:00, state:running, queued_at: 2026-02-25 03:10:48.285576+00:00. externally triggered: False> successful
[2026-02-25T11:11:16.818+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:10:44.800451+00:00, run_id=dataset_triggered__2026-02-25T03:10:44.800451+00:00, run_start_date=2026-02-25 03:10:48.298002+00:00, run_end_date=2026-02-25 03:11:16.818094+00:00, run_duration=28.520092, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:10:39.916905+00:00, data_interval_end=2026-02-25 03:10:39.916905+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:11:16.823+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:10:44.801967+00:00: dataset_triggered__2026-02-25T03:10:44.801967+00:00, state:running, queued_at: 2026-02-25 03:10:48.276034+00:00. externally triggered: False> successful
[2026-02-25T11:11:16.824+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:10:44.801967+00:00, run_id=dataset_triggered__2026-02-25T03:10:44.801967+00:00, run_start_date=2026-02-25 03:10:48.298117+00:00, run_end_date=2026-02-25 03:11:16.824602+00:00, run_duration=28.526485, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:10:39.916905+00:00, data_interval_end=2026-02-25 03:10:39.916905+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:12:15.081+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:14:51.790+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:14:48.801353+00:00 [scheduled]>
[2026-02-25T11:14:51.791+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:14:51.791+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:14:48.801353+00:00 [scheduled]>
[2026-02-25T11:14:51.793+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:14:48.801353+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:14:51.794+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:14:48.801353+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:14:51.795+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:14:48.801353+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:14:51.798+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:14:48.801353+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:14:53.839+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:14:55.447+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:14:48.801353+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:14:56.672+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:14:48.801353+00:00', try_number=1, map_index=-1)
[2026-02-25T11:14:56.683+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:14:48.801353+00:00, map_index=-1, run_start_date=2026-02-25 03:14:55.522804+00:00, run_end_date=2026-02-25 03:14:56.030288+00:00, run_duration=0.507484, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=353, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:14:51.792727+00:00, queued_by_job_id=340, pid=6432
[2026-02-25T11:15:01.089+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:14:48.801353+00:00: manual__2026-02-25T03:14:48.801353+00:00, state:running, queued_at: 2026-02-25 03:14:48.823204+00:00. externally triggered: True> successful
[2026-02-25T11:15:01.091+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:14:48.801353+00:00, run_id=manual__2026-02-25T03:14:48.801353+00:00, run_start_date=2026-02-25 03:14:51.768314+00:00, run_end_date=2026-02-25 03:15:01.091443+00:00, run_duration=9.323129, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:14:48.801353+00:00, data_interval_end=2026-02-25 03:14:48.801353+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:15:01.110+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:14:56.048887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:14:56.051599+00:00 [scheduled]>
[2026-02-25T11:15:01.111+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:15:01.112+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:15:01.113+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:14:56.048887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:14:56.051599+00:00 [scheduled]>
[2026-02-25T11:15:01.117+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:14:56.048887+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:14:56.051599+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:15:01.119+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:14:56.048887+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:15:01.121+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:14:56.048887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:15:01.123+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:14:56.051599+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:15:01.124+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:14:56.051599+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:15:01.128+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:14:56.048887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:15:03.482+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:15:05.200+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:14:56.048887+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:15:12.890+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:14:56.051599+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:15:15.510+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:15:16.934+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:14:56.051599+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:15:25.583+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:14:56.048887+00:00', try_number=1, map_index=-1)
[2026-02-25T11:15:25.585+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:14:56.051599+00:00', try_number=1, map_index=-1)
[2026-02-25T11:15:25.598+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:14:56.048887+00:00, map_index=-1, run_start_date=2026-02-25 03:15:05.275409+00:00, run_end_date=2026-02-25 03:15:12.028191+00:00, run_duration=6.752782, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=354, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:15:01.115810+00:00, queued_by_job_id=340, pid=6438
[2026-02-25T11:15:25.600+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:14:56.051599+00:00, map_index=-1, run_start_date=2026-02-25 03:15:17.009581+00:00, run_end_date=2026-02-25 03:15:24.866876+00:00, run_duration=7.857295, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=355, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:15:01.115810+00:00, queued_by_job_id=340, pid=6452
[2026-02-25T11:15:28.324+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:14:56.048887+00:00: dataset_triggered__2026-02-25T03:14:56.048887+00:00, state:running, queued_at: 2026-02-25 03:15:01.026212+00:00. externally triggered: False> successful
[2026-02-25T11:15:28.325+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:14:56.048887+00:00, run_id=dataset_triggered__2026-02-25T03:14:56.048887+00:00, run_start_date=2026-02-25 03:15:01.057165+00:00, run_end_date=2026-02-25 03:15:28.325727+00:00, run_duration=27.268562, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:14:48.801353+00:00, data_interval_end=2026-02-25 03:14:48.801353+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:15:28.331+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:14:56.051599+00:00: dataset_triggered__2026-02-25T03:14:56.051599+00:00, state:running, queued_at: 2026-02-25 03:15:01.038549+00:00. externally triggered: False> successful
[2026-02-25T11:15:28.332+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:14:56.051599+00:00, run_id=dataset_triggered__2026-02-25T03:14:56.051599+00:00, run_start_date=2026-02-25 03:15:01.057294+00:00, run_end_date=2026-02-25 03:15:28.332381+00:00, run_duration=27.275087, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:14:48.801353+00:00, data_interval_end=2026-02-25 03:14:48.801353+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:17:19.308+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:20:41.010+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:20:37.356853+00:00 [scheduled]>
[2026-02-25T11:20:41.011+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:20:41.012+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:20:37.356853+00:00 [scheduled]>
[2026-02-25T11:20:41.014+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:20:37.356853+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:20:41.016+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:20:37.356853+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:20:41.016+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:20:37.356853+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:20:41.019+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:20:37.356853+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:20:43.699+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:20:45.273+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:20:37.356853+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:20:46.821+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:20:37.356853+00:00', try_number=1, map_index=-1)
[2026-02-25T11:20:46.837+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:20:37.356853+00:00, map_index=-1, run_start_date=2026-02-25 03:20:45.361879+00:00, run_end_date=2026-02-25 03:20:46.095836+00:00, run_duration=0.733957, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=356, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:20:41.013702+00:00, queued_by_job_id=340, pid=6673
[2026-02-25T11:20:49.796+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:20:37.356853+00:00: manual__2026-02-25T03:20:37.356853+00:00, state:running, queued_at: 2026-02-25 03:20:37.380706+00:00. externally triggered: True> successful
[2026-02-25T11:20:49.798+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:20:37.356853+00:00, run_id=manual__2026-02-25T03:20:37.356853+00:00, run_start_date=2026-02-25 03:20:40.977948+00:00, run_end_date=2026-02-25 03:20:49.797934+00:00, run_duration=8.819986, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:20:37.356853+00:00, data_interval_end=2026-02-25 03:20:37.356853+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:20:49.809+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:20:46.124517+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:20:46.128384+00:00 [scheduled]>
[2026-02-25T11:20:49.810+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:20:49.810+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:20:49.812+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:20:46.124517+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:20:46.128384+00:00 [scheduled]>
[2026-02-25T11:20:49.815+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:20:46.124517+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:20:46.128384+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:20:49.816+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:20:46.124517+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:20:49.817+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:20:46.124517+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:20:49.817+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:20:46.128384+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:20:49.818+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:20:46.128384+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:20:49.821+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:20:46.124517+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:20:52.133+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:20:53.644+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:20:46.124517+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:21:03.565+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:20:46.128384+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:21:05.796+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:21:07.201+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:20:46.128384+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:21:13.144+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:20:46.124517+00:00', try_number=1, map_index=-1)
[2026-02-25T11:21:13.147+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:20:46.128384+00:00', try_number=1, map_index=-1)
[2026-02-25T11:21:13.159+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:20:46.128384+00:00, map_index=-1, run_start_date=2026-02-25 03:21:07.270001+00:00, run_end_date=2026-02-25 03:21:12.447695+00:00, run_duration=5.177694, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=358, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:20:49.813875+00:00, queued_by_job_id=340, pid=6702
[2026-02-25T11:21:13.162+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:20:46.124517+00:00, map_index=-1, run_start_date=2026-02-25 03:20:53.742434+00:00, run_end_date=2026-02-25 03:21:02.793104+00:00, run_duration=9.05067, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=357, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:20:49.813875+00:00, queued_by_job_id=340, pid=6676
[2026-02-25T11:21:16.123+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:20:46.124517+00:00: dataset_triggered__2026-02-25T03:20:46.124517+00:00, state:running, queued_at: 2026-02-25 03:20:49.755793+00:00. externally triggered: False> successful
[2026-02-25T11:21:16.124+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:20:46.124517+00:00, run_id=dataset_triggered__2026-02-25T03:20:46.124517+00:00, run_start_date=2026-02-25 03:20:49.777783+00:00, run_end_date=2026-02-25 03:21:16.124325+00:00, run_duration=26.346542, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:20:37.356853+00:00, data_interval_end=2026-02-25 03:20:37.356853+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:21:16.130+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:20:46.128384+00:00: dataset_triggered__2026-02-25T03:20:46.128384+00:00, state:running, queued_at: 2026-02-25 03:20:49.765664+00:00. externally triggered: False> successful
[2026-02-25T11:21:16.131+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:20:46.128384+00:00, run_id=dataset_triggered__2026-02-25T03:20:46.128384+00:00, run_start_date=2026-02-25 03:20:49.777931+00:00, run_end_date=2026-02-25 03:21:16.131091+00:00, run_duration=26.35316, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:20:37.356853+00:00, data_interval_end=2026-02-25 03:20:37.356853+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:22:03.887+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:22:00.163492+00:00 [scheduled]>
[2026-02-25T11:22:03.889+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:22:03.889+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:22:00.163492+00:00 [scheduled]>
[2026-02-25T11:22:03.892+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:22:00.163492+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:22:03.892+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:22:00.163492+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:22:03.893+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:22:00.163492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:22:03.896+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:22:00.163492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:22:06.024+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:22:08.267+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:22:00.163492+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:22:09.630+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:22:00.163492+00:00', try_number=1, map_index=-1)
[2026-02-25T11:22:09.639+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:22:00.163492+00:00, map_index=-1, run_start_date=2026-02-25 03:22:08.343219+00:00, run_end_date=2026-02-25 03:22:08.852087+00:00, run_duration=0.508868, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=359, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:22:03.890844+00:00, queued_by_job_id=340, pid=6740
[2026-02-25T11:22:12.300+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:22:00.163492+00:00: manual__2026-02-25T03:22:00.163492+00:00, state:running, queued_at: 2026-02-25 03:22:00.181593+00:00. externally triggered: True> successful
[2026-02-25T11:22:12.301+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:22:00.163492+00:00, run_id=manual__2026-02-25T03:22:00.163492+00:00, run_start_date=2026-02-25 03:22:03.866961+00:00, run_end_date=2026-02-25 03:22:12.301202+00:00, run_duration=8.434241, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:22:00.163492+00:00, data_interval_end=2026-02-25 03:22:00.163492+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:22:12.311+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:22:08.871256+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:22:08.872657+00:00 [scheduled]>
[2026-02-25T11:22:12.312+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:22:12.313+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:22:12.313+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:22:08.871256+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:22:08.872657+00:00 [scheduled]>
[2026-02-25T11:22:12.316+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:22:08.871256+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:22:08.872657+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:22:12.318+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:22:08.871256+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:22:12.318+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:22:08.871256+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:22:12.319+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:22:08.872657+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:22:12.320+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:22:08.872657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:22:12.322+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:22:08.871256+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:22:14.497+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:22:15.874+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:22:08.871256+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:22:23.799+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:22:08.872657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:22:26.200+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:22:27.613+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:22:08.872657+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:22:33.466+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:22:08.871256+00:00', try_number=1, map_index=-1)
[2026-02-25T11:22:33.470+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:22:08.872657+00:00', try_number=1, map_index=-1)
[2026-02-25T11:22:33.479+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:22:08.872657+00:00, map_index=-1, run_start_date=2026-02-25 03:22:27.685576+00:00, run_end_date=2026-02-25 03:22:32.768850+00:00, run_duration=5.083274, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=361, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:22:12.315382+00:00, queued_by_job_id=340, pid=6764
[2026-02-25T11:22:33.480+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:22:08.871256+00:00, map_index=-1, run_start_date=2026-02-25 03:22:15.942734+00:00, run_end_date=2026-02-25 03:22:23.073454+00:00, run_duration=7.13072, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=360, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:22:12.315382+00:00, queued_by_job_id=340, pid=6743
[2026-02-25T11:22:33.514+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:22:36.509+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:22:08.871256+00:00: dataset_triggered__2026-02-25T03:22:08.871256+00:00, state:running, queued_at: 2026-02-25 03:22:12.270831+00:00. externally triggered: False> successful
[2026-02-25T11:22:36.510+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:22:08.871256+00:00, run_id=dataset_triggered__2026-02-25T03:22:08.871256+00:00, run_start_date=2026-02-25 03:22:12.283418+00:00, run_end_date=2026-02-25 03:22:36.510567+00:00, run_duration=24.227149, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:22:00.163492+00:00, data_interval_end=2026-02-25 03:22:00.163492+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:22:36.517+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:22:08.872657+00:00: dataset_triggered__2026-02-25T03:22:08.872657+00:00, state:running, queued_at: 2026-02-25 03:22:12.261248+00:00. externally triggered: False> successful
[2026-02-25T11:22:36.518+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:22:08.872657+00:00, run_id=dataset_triggered__2026-02-25T03:22:08.872657+00:00, run_start_date=2026-02-25 03:22:12.283522+00:00, run_end_date=2026-02-25 03:22:36.518534+00:00, run_duration=24.235012, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:22:00.163492+00:00, data_interval_end=2026-02-25 03:22:00.163492+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:26:11.274+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:26:09.850421+00:00 [scheduled]>
[2026-02-25T11:26:11.275+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:26:11.276+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:26:09.850421+00:00 [scheduled]>
[2026-02-25T11:26:11.279+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:26:09.850421+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:26:11.280+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:26:09.850421+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:26:11.281+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:26:09.850421+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:26:11.284+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:26:09.850421+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:26:13.956+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:26:15.927+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:26:09.850421+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:26:17.478+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:26:09.850421+00:00', try_number=1, map_index=-1)
[2026-02-25T11:26:17.495+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:26:09.850421+00:00, map_index=-1, run_start_date=2026-02-25 03:26:16.001177+00:00, run_end_date=2026-02-25 03:26:16.524172+00:00, run_duration=0.522995, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=362, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:26:11.278018+00:00, queued_by_job_id=340, pid=6940
[2026-02-25T11:26:20.858+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:26:09.850421+00:00: manual__2026-02-25T03:26:09.850421+00:00, state:running, queued_at: 2026-02-25 03:26:09.862864+00:00. externally triggered: True> successful
[2026-02-25T11:26:20.859+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:26:09.850421+00:00, run_id=manual__2026-02-25T03:26:09.850421+00:00, run_start_date=2026-02-25 03:26:11.253916+00:00, run_end_date=2026-02-25 03:26:20.859703+00:00, run_duration=9.605787, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:26:09.850421+00:00, data_interval_end=2026-02-25 03:26:09.850421+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:26:20.870+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:26:16.544495+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:26:16.546239+00:00 [scheduled]>
[2026-02-25T11:26:20.871+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:26:20.871+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:26:20.872+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:26:16.544495+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:26:16.546239+00:00 [scheduled]>
[2026-02-25T11:26:20.875+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:26:16.544495+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:26:16.546239+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:26:20.876+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:26:16.544495+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:26:20.877+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:26:16.544495+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:26:20.878+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:26:16.546239+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:26:20.879+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:26:16.546239+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:26:20.882+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:26:16.544495+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:26:23.402+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:26:25.242+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:26:16.544495+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:26:33.409+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:26:16.546239+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:26:36.188+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:26:37.724+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:26:16.546239+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:26:47.080+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:26:16.544495+00:00', try_number=1, map_index=-1)
[2026-02-25T11:26:47.083+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:26:16.546239+00:00', try_number=1, map_index=-1)
[2026-02-25T11:26:47.095+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:26:16.544495+00:00, map_index=-1, run_start_date=2026-02-25 03:26:25.313998+00:00, run_end_date=2026-02-25 03:26:32.500993+00:00, run_duration=7.186995, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=363, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:26:20.873822+00:00, queued_by_job_id=340, pid=6943
[2026-02-25T11:26:47.097+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:26:16.546239+00:00, map_index=-1, run_start_date=2026-02-25 03:26:37.829846+00:00, run_end_date=2026-02-25 03:26:46.134546+00:00, run_duration=8.3047, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=364, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:26:20.873822+00:00, queued_by_job_id=340, pid=6957
[2026-02-25T11:26:50.576+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:26:16.544495+00:00: dataset_triggered__2026-02-25T03:26:16.544495+00:00, state:running, queued_at: 2026-02-25 03:26:20.828761+00:00. externally triggered: False> successful
[2026-02-25T11:26:50.577+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:26:16.544495+00:00, run_id=dataset_triggered__2026-02-25T03:26:16.544495+00:00, run_start_date=2026-02-25 03:26:20.840013+00:00, run_end_date=2026-02-25 03:26:50.577235+00:00, run_duration=29.737222, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:26:09.850421+00:00, data_interval_end=2026-02-25 03:26:09.850421+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:26:50.581+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:26:16.546239+00:00: dataset_triggered__2026-02-25T03:26:16.546239+00:00, state:running, queued_at: 2026-02-25 03:26:20.819568+00:00. externally triggered: False> failed
[2026-02-25T11:26:50.582+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:26:16.546239+00:00, run_id=dataset_triggered__2026-02-25T03:26:16.546239+00:00, run_start_date=2026-02-25 03:26:20.840120+00:00, run_end_date=2026-02-25 03:26:50.582656+00:00, run_duration=29.742536, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:26:09.850421+00:00, data_interval_end=2026-02-25 03:26:09.850421+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:27:26.545+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:27:24.112471+00:00 [scheduled]>
[2026-02-25T11:27:26.546+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:27:26.547+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:27:24.112471+00:00 [scheduled]>
[2026-02-25T11:27:26.549+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:27:24.112471+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:27:26.551+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:27:24.112471+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:27:26.551+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:27:24.112471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:27:26.554+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:27:24.112471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:27:28.702+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:27:30.111+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:27:24.112471+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:27:31.347+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:27:24.112471+00:00', try_number=1, map_index=-1)
[2026-02-25T11:27:31.356+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:27:24.112471+00:00, map_index=-1, run_start_date=2026-02-25 03:27:30.182772+00:00, run_end_date=2026-02-25 03:27:30.668907+00:00, run_duration=0.486135, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=365, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:27:26.548550+00:00, queued_by_job_id=340, pid=7008
[2026-02-25T11:27:34.316+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:27:24.112471+00:00: manual__2026-02-25T03:27:24.112471+00:00, state:running, queued_at: 2026-02-25 03:27:24.128029+00:00. externally triggered: True> successful
[2026-02-25T11:27:34.317+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:27:24.112471+00:00, run_id=manual__2026-02-25T03:27:24.112471+00:00, run_start_date=2026-02-25 03:27:26.524056+00:00, run_end_date=2026-02-25 03:27:34.317822+00:00, run_duration=7.793766, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:27:24.112471+00:00, data_interval_end=2026-02-25 03:27:24.112471+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:27:34.328+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:27:30.687416+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:27:30.688841+00:00 [scheduled]>
[2026-02-25T11:27:34.329+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:27:34.330+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:27:34.331+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:27:30.687416+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:27:30.688841+00:00 [scheduled]>
[2026-02-25T11:27:34.333+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:27:30.687416+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:27:30.688841+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:27:34.334+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:27:30.687416+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:27:34.335+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:27:30.687416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:27:34.336+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:27:30.688841+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:27:34.337+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:27:30.688841+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:27:34.340+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:27:30.687416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:27:36.877+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:27:38.363+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:27:30.687416+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:27:44.500+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:27:30.688841+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:27:46.715+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:27:49.108+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:27:30.688841+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:27:57.628+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:27:30.687416+00:00', try_number=1, map_index=-1)
[2026-02-25T11:27:57.633+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:27:30.688841+00:00', try_number=1, map_index=-1)
[2026-02-25T11:27:57.656+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:27:30.687416+00:00, map_index=-1, run_start_date=2026-02-25 03:27:38.438131+00:00, run_end_date=2026-02-25 03:27:43.793043+00:00, run_duration=5.354912, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=366, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:27:34.332376+00:00, queued_by_job_id=340, pid=7020
[2026-02-25T11:27:57.659+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:27:30.688841+00:00, map_index=-1, run_start_date=2026-02-25 03:27:49.199191+00:00, run_end_date=2026-02-25 03:27:56.922496+00:00, run_duration=7.723305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=367, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:27:34.332376+00:00, queued_by_job_id=340, pid=7035
[2026-02-25T11:27:57.687+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:28:01.296+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:27:30.687416+00:00: dataset_triggered__2026-02-25T03:27:30.687416+00:00, state:running, queued_at: 2026-02-25 03:27:34.285772+00:00. externally triggered: False> successful
[2026-02-25T11:28:01.298+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:27:30.687416+00:00, run_id=dataset_triggered__2026-02-25T03:27:30.687416+00:00, run_start_date=2026-02-25 03:27:34.298863+00:00, run_end_date=2026-02-25 03:28:01.297779+00:00, run_duration=26.998916, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:27:24.112471+00:00, data_interval_end=2026-02-25 03:27:24.112471+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:28:01.304+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:27:30.688841+00:00: dataset_triggered__2026-02-25T03:27:30.688841+00:00, state:running, queued_at: 2026-02-25 03:27:34.270908+00:00. externally triggered: False> successful
[2026-02-25T11:28:01.305+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:27:30.688841+00:00, run_id=dataset_triggered__2026-02-25T03:27:30.688841+00:00, run_start_date=2026-02-25 03:27:34.298965+00:00, run_end_date=2026-02-25 03:28:01.305152+00:00, run_duration=27.006187, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:27:24.112471+00:00, data_interval_end=2026-02-25 03:27:24.112471+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:32:57.985+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:33:06.774+0800] {manager.py:537} INFO - DAG p_cdrd_all is missing and will be deactivated.
[2026-02-25T11:33:06.777+0800] {manager.py:537} INFO - DAG c_cdrd_DAG2 is missing and will be deactivated.
[2026-02-25T11:33:06.778+0800] {manager.py:537} INFO - DAG c_cdrd_DAG1 is missing and will be deactivated.
[2026-02-25T11:33:06.787+0800] {manager.py:549} INFO - Deactivated 3 DAGs which are no longer present in file.
[2026-02-25T11:33:06.793+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG1 in serialized_dag table
[2026-02-25T11:33:06.798+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG2 in serialized_dag table
[2026-02-25T11:33:06.805+0800] {manager.py:553} INFO - Deleted DAG p_cdrd_all in serialized_dag table
[2026-02-25T11:34:03.438+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:33:58.872489+00:00 [scheduled]>
[2026-02-25T11:34:03.439+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:34:03.440+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:33:58.872489+00:00 [scheduled]>
[2026-02-25T11:34:03.444+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:33:58.872489+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:34:03.446+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:33:58.872489+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:34:03.447+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:33:58.872489+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:34:03.452+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:33:58.872489+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:34:06.156+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:34:08.729+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:33:58.872489+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:34:09.957+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:33:58.872489+00:00', try_number=1, map_index=-1)
[2026-02-25T11:34:09.968+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:33:58.872489+00:00, map_index=-1, run_start_date=2026-02-25 03:34:08.837032+00:00, run_end_date=2026-02-25 03:34:09.098897+00:00, run_duration=0.261865, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=368, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:34:03.442608+00:00, queued_by_job_id=340, pid=7335
[2026-02-25T11:34:14.068+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:33:58.872489+00:00: manual__2026-02-25T03:33:58.872489+00:00, state:running, queued_at: 2026-02-25 03:33:58.887058+00:00. externally triggered: True> successful
[2026-02-25T11:34:14.069+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:33:58.872489+00:00, run_id=manual__2026-02-25T03:33:58.872489+00:00, run_start_date=2026-02-25 03:34:03.410775+00:00, run_end_date=2026-02-25 03:34:14.069862+00:00, run_duration=10.659087, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:33:58.872489+00:00, data_interval_end=2026-02-25 03:33:58.872489+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:34:14.086+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:34:09.176444+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:34:09.182989+00:00 [scheduled]>
[2026-02-25T11:34:14.087+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:34:14.088+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:34:14.088+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:34:09.176444+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:34:09.182989+00:00 [scheduled]>
[2026-02-25T11:34:14.091+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:34:09.176444+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:34:09.182989+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:34:14.092+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:34:09.176444+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:34:14.093+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:34:09.176444+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:34:14.094+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:34:09.182989+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:34:14.096+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:34:09.182989+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:34:14.098+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:34:09.176444+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:34:16.174+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:34:17.822+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:34:09.176444+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:34:24.672+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:34:09.182989+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:34:26.922+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:34:28.560+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:34:09.182989+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:34:36.390+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:34:09.176444+00:00', try_number=1, map_index=-1)
[2026-02-25T11:34:36.394+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:34:09.182989+00:00', try_number=1, map_index=-1)
[2026-02-25T11:34:36.403+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:34:09.176444+00:00, map_index=-1, run_start_date=2026-02-25 03:34:17.892178+00:00, run_end_date=2026-02-25 03:34:23.964117+00:00, run_duration=6.071939, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=369, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:34:14.090063+00:00, queued_by_job_id=340, pid=7345
[2026-02-25T11:34:36.404+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:34:09.182989+00:00, map_index=-1, run_start_date=2026-02-25 03:34:28.629040+00:00, run_end_date=2026-02-25 03:34:35.673743+00:00, run_duration=7.044703, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=370, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:34:14.090063+00:00, queued_by_job_id=340, pid=7359
[2026-02-25T11:34:39.869+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:34:09.176444+00:00: dataset_triggered__2026-02-25T03:34:09.176444+00:00, state:running, queued_at: 2026-02-25 03:34:14.028689+00:00. externally triggered: False> successful
[2026-02-25T11:34:39.870+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:34:09.176444+00:00, run_id=dataset_triggered__2026-02-25T03:34:09.176444+00:00, run_start_date=2026-02-25 03:34:14.050993+00:00, run_end_date=2026-02-25 03:34:39.870861+00:00, run_duration=25.819868, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:33:58.872489+00:00, data_interval_end=2026-02-25 03:33:58.872489+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:34:39.875+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:34:09.182989+00:00: dataset_triggered__2026-02-25T03:34:09.182989+00:00, state:running, queued_at: 2026-02-25 03:34:14.039068+00:00. externally triggered: False> failed
[2026-02-25T11:34:39.876+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:34:09.182989+00:00, run_id=dataset_triggered__2026-02-25T03:34:09.182989+00:00, run_start_date=2026-02-25 03:34:14.051223+00:00, run_end_date=2026-02-25 03:34:39.876310+00:00, run_duration=25.825087, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:33:58.872489+00:00, data_interval_end=2026-02-25 03:33:58.872489+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:36:11.600+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:36:10.000295+00:00 [scheduled]>
[2026-02-25T11:36:11.601+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T11:36:11.602+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:36:10.000295+00:00 [scheduled]>
[2026-02-25T11:36:11.604+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:36:10.000295+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:36:11.605+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:36:10.000295+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:36:11.606+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:36:10.000295+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:36:11.608+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:36:10.000295+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:36:13.614+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:36:15.628+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:36:10.000295+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:36:16.613+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:36:10.000295+00:00', try_number=1, map_index=-1)
[2026-02-25T11:36:16.622+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:36:10.000295+00:00, map_index=-1, run_start_date=2026-02-25 03:36:15.699537+00:00, run_end_date=2026-02-25 03:36:15.908250+00:00, run_duration=0.208713, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=371, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:36:11.603347+00:00, queued_by_job_id=340, pid=7441
[2026-02-25T11:36:20.846+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:36:10.000295+00:00: manual__2026-02-25T03:36:10.000295+00:00, state:running, queued_at: 2026-02-25 03:36:10.016365+00:00. externally triggered: True> successful
[2026-02-25T11:36:20.847+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:36:10.000295+00:00, run_id=manual__2026-02-25T03:36:10.000295+00:00, run_start_date=2026-02-25 03:36:11.578105+00:00, run_end_date=2026-02-25 03:36:20.847711+00:00, run_duration=9.269606, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:36:10.000295+00:00, data_interval_end=2026-02-25 03:36:10.000295+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-25T11:36:20.857+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:36:15.925389+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:36:15.926751+00:00 [scheduled]>
[2026-02-25T11:36:20.858+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T11:36:20.859+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T11:36:20.859+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:36:15.925389+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:36:15.926751+00:00 [scheduled]>
[2026-02-25T11:36:20.862+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:36:15.925389+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:36:15.926751+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T11:36:20.863+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:36:15.925389+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:36:20.864+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:36:15.925389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:36:20.864+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:36:15.926751+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T11:36:20.865+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:36:15.926751+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:36:20.868+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:36:15.925389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:36:22.899+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:36:24.559+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:36:15.925389+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:36:34.420+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:36:15.926751+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T11:36:36.874+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T11:36:38.492+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:36:15.926751+00:00 [queued]> on host localhost-2.local
[2026-02-25T11:36:44.130+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:36:15.925389+00:00', try_number=1, map_index=-1)
[2026-02-25T11:36:44.133+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:36:15.926751+00:00', try_number=1, map_index=-1)
[2026-02-25T11:36:44.142+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:36:15.926751+00:00, map_index=-1, run_start_date=2026-02-25 03:36:38.557973+00:00, run_end_date=2026-02-25 03:36:43.440008+00:00, run_duration=4.882035, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=373, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:36:20.860796+00:00, queued_by_job_id=340, pid=7487
[2026-02-25T11:36:44.143+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:36:15.925389+00:00, map_index=-1, run_start_date=2026-02-25 03:36:24.625087+00:00, run_end_date=2026-02-25 03:36:33.150885+00:00, run_duration=8.525798, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=372, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:36:20.860796+00:00, queued_by_job_id=340, pid=7452
[2026-02-25T11:36:47.485+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:36:15.925389+00:00: dataset_triggered__2026-02-25T03:36:15.925389+00:00, state:running, queued_at: 2026-02-25 03:36:20.817535+00:00. externally triggered: False> successful
[2026-02-25T11:36:47.486+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:36:15.925389+00:00, run_id=dataset_triggered__2026-02-25T03:36:15.925389+00:00, run_start_date=2026-02-25 03:36:20.829430+00:00, run_end_date=2026-02-25 03:36:47.486219+00:00, run_duration=26.656789, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:36:10.000295+00:00, data_interval_end=2026-02-25 03:36:10.000295+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T11:36:47.492+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:36:15.926751+00:00: dataset_triggered__2026-02-25T03:36:15.926751+00:00, state:running, queued_at: 2026-02-25 03:36:20.809946+00:00. externally triggered: False> successful
[2026-02-25T11:36:47.493+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:36:15.926751+00:00, run_id=dataset_triggered__2026-02-25T03:36:15.926751+00:00, run_start_date=2026-02-25 03:36:20.829536+00:00, run_end_date=2026-02-25 03:36:47.493270+00:00, run_duration=26.663734, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:36:10.000295+00:00, data_interval_end=2026-02-25 03:36:10.000295+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T11:37:58.883+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:43:00.997+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:48:03.396+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:53:06.722+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T11:58:06.987+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:03:09.765+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:08:13.208+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:13:13.295+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:17:38.020+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:17:34.239273+00:00 [scheduled]>
[2026-02-25T12:17:38.023+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T12:17:38.024+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:17:34.239273+00:00 [scheduled]>
[2026-02-25T12:17:38.026+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:17:34.239273+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:17:38.027+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:17:34.239273+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:17:38.028+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:17:34.239273+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:17:38.031+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:17:34.239273+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:17:40.125+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:17:42.733+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:17:34.239273+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:17:43.822+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:17:34.239273+00:00', try_number=1, map_index=-1)
[2026-02-25T12:17:43.834+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:17:34.239273+00:00, map_index=-1, run_start_date=2026-02-25 04:17:42.806076+00:00, run_end_date=2026-02-25 04:17:43.033202+00:00, run_duration=0.227126, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=374, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:17:38.025389+00:00, queued_by_job_id=340, pid=8828
[2026-02-25T12:17:47.459+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:17:34.239273+00:00: manual__2026-02-25T04:17:34.239273+00:00, state:running, queued_at: 2026-02-25 04:17:34.264781+00:00. externally triggered: True> successful
[2026-02-25T12:17:47.460+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:17:34.239273+00:00, run_id=manual__2026-02-25T04:17:34.239273+00:00, run_start_date=2026-02-25 04:17:37.999345+00:00, run_end_date=2026-02-25 04:17:47.460417+00:00, run_duration=9.461072, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:17:34.239273+00:00, data_interval_end=2026-02-25 04:17:34.239273+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T12:17:47.471+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:17:43.056324+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:17:43.058196+00:00 [scheduled]>
[2026-02-25T12:17:47.472+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T12:17:47.473+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T12:17:47.473+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:17:43.056324+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:17:43.058196+00:00 [scheduled]>
[2026-02-25T12:17:47.476+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:17:43.056324+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:17:43.058196+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:17:47.477+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:17:43.056324+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:17:47.478+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:17:43.056324+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:17:47.479+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:17:43.058196+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:17:47.479+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:17:43.058196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:17:47.482+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:17:43.056324+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:17:49.615+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:17:51.263+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:17:43.056324+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:17:52.275+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:17:43.058196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:17:54.497+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:17:56.166+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:17:43.058196+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:17:57.192+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:17:43.056324+00:00', try_number=1, map_index=-1)
[2026-02-25T12:17:57.195+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:17:43.058196+00:00', try_number=1, map_index=-1)
[2026-02-25T12:17:57.206+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:17:43.056324+00:00, map_index=-1, run_start_date=2026-02-25 04:17:51.331291+00:00, run_end_date=2026-02-25 04:17:51.561712+00:00, run_duration=0.230421, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=375, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:17:47.474807+00:00, queued_by_job_id=340, pid=8831
[2026-02-25T12:17:57.207+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:17:43.058196+00:00, map_index=-1, run_start_date=2026-02-25 04:17:56.233040+00:00, run_end_date=2026-02-25 04:17:56.466871+00:00, run_duration=0.233831, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=376, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:17:47.474807+00:00, queued_by_job_id=340, pid=8833
[2026-02-25T12:18:00.800+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:17:43.056324+00:00: dataset_triggered__2026-02-25T04:17:43.056324+00:00, state:running, queued_at: 2026-02-25 04:17:47.427183+00:00. externally triggered: False> successful
[2026-02-25T12:18:00.801+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:17:43.056324+00:00, run_id=dataset_triggered__2026-02-25T04:17:43.056324+00:00, run_start_date=2026-02-25 04:17:47.441367+00:00, run_end_date=2026-02-25 04:18:00.801097+00:00, run_duration=13.35973, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:17:34.239273+00:00, data_interval_end=2026-02-25 04:17:34.239273+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T12:18:00.806+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:17:43.058196+00:00: dataset_triggered__2026-02-25T04:17:43.058196+00:00, state:running, queued_at: 2026-02-25 04:17:47.416909+00:00. externally triggered: False> successful
[2026-02-25T12:18:00.807+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:17:43.058196+00:00, run_id=dataset_triggered__2026-02-25T04:17:43.058196+00:00, run_start_date=2026-02-25 04:17:47.441488+00:00, run_end_date=2026-02-25 04:18:00.807577+00:00, run_duration=13.366089, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:17:34.239273+00:00, data_interval_end=2026-02-25 04:17:34.239273+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T12:18:16.228+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:20:55.906+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:20:52.685960+00:00 [scheduled]>
[2026-02-25T12:20:55.907+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T12:20:55.908+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:20:52.685960+00:00 [scheduled]>
[2026-02-25T12:20:55.911+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:20:52.685960+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:20:55.912+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:20:52.685960+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:20:55.913+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:20:52.685960+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:20:55.915+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:20:52.685960+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:20:57.972+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:20:59.908+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:20:52.685960+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:21:00.902+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:20:52.685960+00:00', try_number=1, map_index=-1)
[2026-02-25T12:21:00.911+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:20:52.685960+00:00, map_index=-1, run_start_date=2026-02-25 04:20:59.977453+00:00, run_end_date=2026-02-25 04:21:00.190301+00:00, run_duration=0.212848, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=377, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:20:55.909843+00:00, queued_by_job_id=340, pid=8936
[2026-02-25T12:21:03.567+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:20:52.685960+00:00: manual__2026-02-25T04:20:52.685960+00:00, state:running, queued_at: 2026-02-25 04:20:52.704806+00:00. externally triggered: True> successful
[2026-02-25T12:21:03.568+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:20:52.685960+00:00, run_id=manual__2026-02-25T04:20:52.685960+00:00, run_start_date=2026-02-25 04:20:55.888785+00:00, run_end_date=2026-02-25 04:21:03.568843+00:00, run_duration=7.680058, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:20:52.685960+00:00, data_interval_end=2026-02-25 04:20:52.685960+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T12:21:03.579+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:21:00.208815+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:21:00.210341+00:00 [scheduled]>
[2026-02-25T12:21:03.580+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T12:21:03.581+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T12:21:03.582+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:21:00.208815+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:21:00.210341+00:00 [scheduled]>
[2026-02-25T12:21:03.585+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:21:00.208815+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:21:00.210341+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:21:03.586+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:21:00.208815+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:21:03.587+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:21:00.208815+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:21:03.587+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:21:00.210341+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:21:03.588+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:21:00.210341+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:21:03.591+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:21:00.208815+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:21:06.004+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:21:07.719+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:21:00.208815+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:21:17.299+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:21:00.210341+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:21:19.691+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:21:21.338+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:21:00.210341+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:21:27.278+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:21:00.208815+00:00', try_number=1, map_index=-1)
[2026-02-25T12:21:27.280+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:21:00.210341+00:00', try_number=1, map_index=-1)
[2026-02-25T12:21:27.288+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:21:00.210341+00:00, map_index=-1, run_start_date=2026-02-25 04:21:21.403258+00:00, run_end_date=2026-02-25 04:21:26.640914+00:00, run_duration=5.237656, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=379, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:21:03.583722+00:00, queued_by_job_id=340, pid=8970
[2026-02-25T12:21:27.290+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:21:00.208815+00:00, map_index=-1, run_start_date=2026-02-25 04:21:07.789874+00:00, run_end_date=2026-02-25 04:21:16.549902+00:00, run_duration=8.760028, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=378, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:21:03.583722+00:00, queued_by_job_id=340, pid=8945
[2026-02-25T12:21:30.173+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:21:00.208815+00:00: dataset_triggered__2026-02-25T04:21:00.208815+00:00, state:running, queued_at: 2026-02-25 04:21:03.537491+00:00. externally triggered: False> failed
[2026-02-25T12:21:30.174+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:21:00.208815+00:00, run_id=dataset_triggered__2026-02-25T04:21:00.208815+00:00, run_start_date=2026-02-25 04:21:03.550414+00:00, run_end_date=2026-02-25 04:21:30.174400+00:00, run_duration=26.623986, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:20:52.685960+00:00, data_interval_end=2026-02-25 04:20:52.685960+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T12:21:30.179+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:21:00.210341+00:00: dataset_triggered__2026-02-25T04:21:00.210341+00:00, state:running, queued_at: 2026-02-25 04:21:03.527933+00:00. externally triggered: False> successful
[2026-02-25T12:21:30.180+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:21:00.210341+00:00, run_id=dataset_triggered__2026-02-25T04:21:00.210341+00:00, run_start_date=2026-02-25 04:21:03.550542+00:00, run_end_date=2026-02-25 04:21:30.180698+00:00, run_duration=26.630156, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:20:52.685960+00:00, data_interval_end=2026-02-25 04:20:52.685960+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T12:23:17.978+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:23:45.455+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:23:44.062963+00:00 [scheduled]>
[2026-02-25T12:23:45.456+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T12:23:45.456+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:23:44.062963+00:00 [scheduled]>
[2026-02-25T12:23:45.460+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:23:44.062963+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:23:45.461+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:23:44.062963+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:23:45.461+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:23:44.062963+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:23:45.463+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:23:44.062963+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:23:47.519+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:23:49.308+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:23:44.062963+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:23:50.330+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:23:44.062963+00:00', try_number=1, map_index=-1)
[2026-02-25T12:23:50.339+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:23:44.062963+00:00, map_index=-1, run_start_date=2026-02-25 04:23:49.379807+00:00, run_end_date=2026-02-25 04:23:49.578240+00:00, run_duration=0.198433, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=380, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:23:45.459114+00:00, queued_by_job_id=340, pid=9065
[2026-02-25T12:23:54.230+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:23:44.062963+00:00: manual__2026-02-25T04:23:44.062963+00:00, state:running, queued_at: 2026-02-25 04:23:44.075441+00:00. externally triggered: True> successful
[2026-02-25T12:23:54.231+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:23:44.062963+00:00, run_id=manual__2026-02-25T04:23:44.062963+00:00, run_start_date=2026-02-25 04:23:45.434783+00:00, run_end_date=2026-02-25 04:23:54.231727+00:00, run_duration=8.796944, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:23:44.062963+00:00, data_interval_end=2026-02-25 04:23:44.062963+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T12:23:54.241+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:23:49.597392+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:23:49.598752+00:00 [scheduled]>
[2026-02-25T12:23:54.242+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T12:23:54.243+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T12:23:54.243+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:23:49.597392+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:23:49.598752+00:00 [scheduled]>
[2026-02-25T12:23:54.246+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:23:49.597392+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:23:49.598752+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:23:54.247+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:23:49.597392+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:23:54.247+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:23:49.597392+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:23:54.248+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:23:49.598752+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:23:54.249+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:23:49.598752+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:23:54.252+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:23:49.597392+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:23:56.275+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:23:57.970+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:23:49.597392+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:24:05.633+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:23:49.598752+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:24:07.854+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:24:09.578+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:23:49.598752+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:24:15.596+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:23:49.597392+00:00', try_number=1, map_index=-1)
[2026-02-25T12:24:15.598+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:23:49.598752+00:00', try_number=1, map_index=-1)
[2026-02-25T12:24:15.608+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:23:49.598752+00:00, map_index=-1, run_start_date=2026-02-25 04:24:09.649692+00:00, run_end_date=2026-02-25 04:24:14.885375+00:00, run_duration=5.235683, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=382, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:23:54.244758+00:00, queued_by_job_id=340, pid=9092
[2026-02-25T12:24:15.609+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:23:49.597392+00:00, map_index=-1, run_start_date=2026-02-25 04:23:58.043111+00:00, run_end_date=2026-02-25 04:24:04.931981+00:00, run_duration=6.88887, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=381, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:23:54.244758+00:00, queued_by_job_id=340, pid=9068
[2026-02-25T12:24:18.215+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:23:49.597392+00:00: dataset_triggered__2026-02-25T04:23:49.597392+00:00, state:running, queued_at: 2026-02-25 04:23:54.192303+00:00. externally triggered: False> failed
[2026-02-25T12:24:18.216+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:23:49.597392+00:00, run_id=dataset_triggered__2026-02-25T04:23:49.597392+00:00, run_start_date=2026-02-25 04:23:54.213197+00:00, run_end_date=2026-02-25 04:24:18.216076+00:00, run_duration=24.002879, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:23:44.062963+00:00, data_interval_end=2026-02-25 04:23:44.062963+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T12:24:18.221+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:23:49.598752+00:00: dataset_triggered__2026-02-25T04:23:49.598752+00:00, state:running, queued_at: 2026-02-25 04:23:54.200981+00:00. externally triggered: False> successful
[2026-02-25T12:24:18.223+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:23:49.598752+00:00, run_id=dataset_triggered__2026-02-25T04:23:49.598752+00:00, run_start_date=2026-02-25 04:23:54.213305+00:00, run_end_date=2026-02-25 04:24:18.223156+00:00, run_duration=24.009851, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:23:44.062963+00:00, data_interval_end=2026-02-25 04:23:44.062963+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T12:27:23.206+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:27:21.133814+00:00 [scheduled]>
[2026-02-25T12:27:23.207+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T12:27:23.207+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:27:21.133814+00:00 [scheduled]>
[2026-02-25T12:27:23.209+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:27:21.133814+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:27:23.210+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:27:21.133814+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:27:23.211+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:27:21.133814+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:27:23.214+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:27:21.133814+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:27:25.274+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:27:27.082+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:27:21.133814+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:27:28.085+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:27:21.133814+00:00', try_number=1, map_index=-1)
[2026-02-25T12:27:28.094+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:27:21.133814+00:00, map_index=-1, run_start_date=2026-02-25 04:27:27.153146+00:00, run_end_date=2026-02-25 04:27:27.351238+00:00, run_duration=0.198092, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=383, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:27:23.208780+00:00, queued_by_job_id=340, pid=9200
[2026-02-25T12:27:30.771+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:27:21.133814+00:00: manual__2026-02-25T04:27:21.133814+00:00, state:running, queued_at: 2026-02-25 04:27:21.146615+00:00. externally triggered: True> successful
[2026-02-25T12:27:30.772+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:27:21.133814+00:00, run_id=manual__2026-02-25T04:27:21.133814+00:00, run_start_date=2026-02-25 04:27:23.184864+00:00, run_end_date=2026-02-25 04:27:30.772671+00:00, run_duration=7.587807, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:27:21.133814+00:00, data_interval_end=2026-02-25 04:27:21.133814+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T12:27:30.781+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:27:27.369878+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:27:27.371258+00:00 [scheduled]>
[2026-02-25T12:27:30.782+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T12:27:30.783+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T12:27:30.784+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:27:27.369878+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:27:27.371258+00:00 [scheduled]>
[2026-02-25T12:27:30.787+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:27:27.369878+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:27:27.371258+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T12:27:30.788+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:27:27.369878+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:27:30.789+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:27:27.369878+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:27:30.789+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:27:27.371258+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T12:27:30.790+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:27:27.371258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:27:30.793+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:27:27.369878+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:27:32.874+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:27:34.537+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:27:27.369878+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:27:40.493+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:27:27.371258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T12:27:42.729+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T12:27:44.367+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:27:27.371258+00:00 [queued]> on host localhost-2.local
[2026-02-25T12:27:52.008+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:27:27.369878+00:00', try_number=1, map_index=-1)
[2026-02-25T12:27:52.010+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:27:27.371258+00:00', try_number=1, map_index=-1)
[2026-02-25T12:27:52.020+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:27:27.369878+00:00, map_index=-1, run_start_date=2026-02-25 04:27:34.607613+00:00, run_end_date=2026-02-25 04:27:39.747657+00:00, run_duration=5.140044, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=384, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:27:30.785476+00:00, queued_by_job_id=340, pid=9203
[2026-02-25T12:27:52.021+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:27:27.371258+00:00, map_index=-1, run_start_date=2026-02-25 04:27:44.432197+00:00, run_end_date=2026-02-25 04:27:51.282790+00:00, run_duration=6.850593, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=385, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:27:30.785476+00:00, queued_by_job_id=340, pid=9221
[2026-02-25T12:27:54.915+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:27:27.369878+00:00: dataset_triggered__2026-02-25T04:27:27.369878+00:00, state:running, queued_at: 2026-02-25 04:27:30.740866+00:00. externally triggered: False> successful
[2026-02-25T12:27:54.916+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:27:27.369878+00:00, run_id=dataset_triggered__2026-02-25T04:27:27.369878+00:00, run_start_date=2026-02-25 04:27:30.754186+00:00, run_end_date=2026-02-25 04:27:54.916594+00:00, run_duration=24.162408, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:27:21.133814+00:00, data_interval_end=2026-02-25 04:27:21.133814+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T12:27:54.922+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:27:27.371258+00:00: dataset_triggered__2026-02-25T04:27:27.371258+00:00, state:running, queued_at: 2026-02-25 04:27:30.731574+00:00. externally triggered: False> successful
[2026-02-25T12:27:54.922+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:27:27.371258+00:00, run_id=dataset_triggered__2026-02-25T04:27:27.371258+00:00, run_start_date=2026-02-25 04:27:30.754293+00:00, run_end_date=2026-02-25 04:27:54.922935+00:00, run_duration=24.168642, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:27:21.133814+00:00, data_interval_end=2026-02-25 04:27:21.133814+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T12:28:20.431+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:30:54.723+0800] {job.py:229} INFO - Heartbeat recovered after 36.60 seconds
[2026-02-25T12:33:43.194+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:39:06.184+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:47:31.153+0800] {job.py:229} INFO - Heartbeat recovered after 269.29 seconds
[2026-02-25T12:48:32.029+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T12:55:49.974+0800] {job.py:229} INFO - Heartbeat recovered after 237.89 seconds
[2026-02-25T12:57:22.497+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:02:23.026+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:07:25.073+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:12:27.685+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:17:29.969+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:22:31.167+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:26:24.163+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:26:21.543429+00:00 [scheduled]>
[2026-02-25T13:26:24.164+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T13:26:24.165+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:26:21.543429+00:00 [scheduled]>
[2026-02-25T13:26:24.167+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:26:21.543429+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:26:24.169+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:26:21.543429+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:26:24.170+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:26:21.543429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:26:24.173+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:26:21.543429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:26:26.383+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:26:28.554+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:26:21.543429+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:26:29.624+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:26:21.543429+00:00', try_number=1, map_index=-1)
[2026-02-25T13:26:29.635+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:26:21.543429+00:00, map_index=-1, run_start_date=2026-02-25 05:26:28.626199+00:00, run_end_date=2026-02-25 05:26:28.862994+00:00, run_duration=0.236795, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=386, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:26:24.166533+00:00, queued_by_job_id=340, pid=11639
[2026-02-25T13:26:33.621+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:26:21.543429+00:00: manual__2026-02-25T05:26:21.543429+00:00, state:running, queued_at: 2026-02-25 05:26:21.569156+00:00. externally triggered: True> successful
[2026-02-25T13:26:33.622+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:26:21.543429+00:00, run_id=manual__2026-02-25T05:26:21.543429+00:00, run_start_date=2026-02-25 05:26:24.136338+00:00, run_end_date=2026-02-25 05:26:33.622495+00:00, run_duration=9.486157, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:26:21.543429+00:00, data_interval_end=2026-02-25 05:26:21.543429+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T13:26:33.633+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:26:28.886219+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:26:28.887851+00:00 [scheduled]>
[2026-02-25T13:26:33.634+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T13:26:33.634+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T13:26:33.635+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:26:28.886219+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:26:28.887851+00:00 [scheduled]>
[2026-02-25T13:26:33.638+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:26:28.886219+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:26:28.887851+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:26:33.639+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:26:28.886219+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:26:33.640+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:26:28.886219+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:26:33.641+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:26:28.887851+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:26:33.641+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:26:28.887851+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:26:33.644+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:26:28.886219+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:26:36.019+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:26:37.727+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:26:28.886219+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:26:46.088+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:26:28.887851+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:26:48.426+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:26:50.200+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:26:28.887851+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:26:58.097+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:26:28.886219+00:00', try_number=1, map_index=-1)
[2026-02-25T13:26:58.100+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:26:28.887851+00:00', try_number=1, map_index=-1)
[2026-02-25T13:26:58.110+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:26:28.886219+00:00, map_index=-1, run_start_date=2026-02-25 05:26:37.797963+00:00, run_end_date=2026-02-25 05:26:45.341653+00:00, run_duration=7.54369, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=387, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:26:33.636941+00:00, queued_by_job_id=340, pid=11644
[2026-02-25T13:26:58.111+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:26:28.887851+00:00, map_index=-1, run_start_date=2026-02-25 05:26:50.269714+00:00, run_end_date=2026-02-25 05:26:57.350280+00:00, run_duration=7.080566, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=388, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:26:33.636941+00:00, queued_by_job_id=340, pid=11669
[2026-02-25T13:27:00.779+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:26:28.886219+00:00: dataset_triggered__2026-02-25T05:26:28.886219+00:00, state:running, queued_at: 2026-02-25 05:26:33.578523+00:00. externally triggered: False> successful
[2026-02-25T13:27:00.780+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:26:28.886219+00:00, run_id=dataset_triggered__2026-02-25T05:26:28.886219+00:00, run_start_date=2026-02-25 05:26:33.603105+00:00, run_end_date=2026-02-25 05:27:00.779955+00:00, run_duration=27.17685, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:26:21.543429+00:00, data_interval_end=2026-02-25 05:26:21.543429+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T13:27:00.785+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:26:28.887851+00:00: dataset_triggered__2026-02-25T05:26:28.887851+00:00, state:running, queued_at: 2026-02-25 05:26:33.589893+00:00. externally triggered: False> successful
[2026-02-25T13:27:00.786+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:26:28.887851+00:00, run_id=dataset_triggered__2026-02-25T05:26:28.887851+00:00, run_start_date=2026-02-25 05:26:33.603213+00:00, run_end_date=2026-02-25 05:27:00.786817+00:00, run_duration=27.183604, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:26:21.543429+00:00, data_interval_end=2026-02-25 05:26:21.543429+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T13:27:31.636+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:32:32.443+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:37:35.732+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:38:59.315+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:38:56.276937+00:00 [scheduled]>
[2026-02-25T13:38:59.316+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T13:38:59.317+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:38:56.276937+00:00 [scheduled]>
[2026-02-25T13:38:59.319+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:38:56.276937+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:38:59.320+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:38:56.276937+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:38:59.321+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:38:56.276937+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:38:59.325+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:38:56.276937+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:39:01.700+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:39:04.148+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:38:56.276937+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:39:05.241+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:38:56.276937+00:00', try_number=1, map_index=-1)
[2026-02-25T13:39:05.251+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:38:56.276937+00:00, map_index=-1, run_start_date=2026-02-25 05:39:04.221836+00:00, run_end_date=2026-02-25 05:39:04.458798+00:00, run_duration=0.236962, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=389, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:38:59.318679+00:00, queued_by_job_id=340, pid=12044
[2026-02-25T13:39:08.028+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:38:56.276937+00:00: manual__2026-02-25T05:38:56.276937+00:00, state:running, queued_at: 2026-02-25 05:38:56.311253+00:00. externally triggered: True> successful
[2026-02-25T13:39:08.029+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:38:56.276937+00:00, run_id=manual__2026-02-25T05:38:56.276937+00:00, run_start_date=2026-02-25 05:38:59.293437+00:00, run_end_date=2026-02-25 05:39:08.029545+00:00, run_duration=8.736108, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:38:56.276937+00:00, data_interval_end=2026-02-25 05:38:56.276937+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T13:39:08.041+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:39:04.478327+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [scheduled]>
[2026-02-25T13:39:08.043+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T13:39:08.043+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T13:39:08.044+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:39:04.478327+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [scheduled]>
[2026-02-25T13:39:08.047+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:39:04.478327+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:39:08.048+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:39:04.478327+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:39:08.049+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:39:04.478327+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:39:08.049+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:39:04.479998+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:39:08.050+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:39:04.479998+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:39:08.053+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:39:04.478327+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:39:10.335+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:39:12.134+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:39:04.478327+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:40:03.704+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:39:04.479998+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:40:06.570+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:40:08.363+0800] {dagbag.py:387} ERROR - Failed to import: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Traceback (most recent call last):
  File "src/pymssql/_pymssql.pyx", line 651, in pymssql._pymssql.connect
  File "src/pymssql/_mssql.pyx", line 2189, in pymssql._mssql.connect
  File "src/pymssql/_mssql.pyx", line 722, in pymssql._mssql.MSSQLConnection.__init__
  File "src/pymssql/_mssql.pyx", line 1915, in pymssql._mssql.maybe_raise_MSSQLDatabaseException
  File "src/pymssql/_mssql.pyx", line 1932, in pymssql._mssql.raise_MSSQLDatabaseException
pymssql._mssql.MSSQLDatabaseException: (20009, b'DB-Lib error message 20009, severity 9:\nUnable to connect: Adaptive Server is unavailable or does not exist (192.168.0.234:1433)\nNet-Lib error during Network is unreachable (51)\n')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py", line 48, in <module>
    Sqlserver_PO = SqlserverPO("192.168.0.234", "sa", "Zy_123456789", "CDRD_TEST", "GBK")
  File "/Users/linghuchong/Downloads/51/Python/project/PO/SqlserverPO.py", line 201, in __init__
    self.conn = pymssql.connect(
  File "src/pymssql/_pymssql.pyx", line 660, in pymssql._pymssql.connect
pymssql.exceptions.OperationalError: (20009, b'DB-Lib error message 20009, severity 9:\nUnable to connect: Adaptive Server is unavailable or does not exist (192.168.0.234:1433)\nNet-Lib error during Network is unreachable (51)\n')
[2026-02-25T13:40:08.372+0800] {cli.py:251} WARNING - Dag 'c_cdrd_DAG1' not found in path /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py; trying path /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-25T13:40:08.372+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:40:08.423+0800] {dagbag.py:387} ERROR - Failed to import: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Traceback (most recent call last):
  File "src/pymssql/_pymssql.pyx", line 651, in pymssql._pymssql.connect
  File "src/pymssql/_mssql.pyx", line 2189, in pymssql._mssql.connect
  File "src/pymssql/_mssql.pyx", line 722, in pymssql._mssql.MSSQLConnection.__init__
  File "src/pymssql/_mssql.pyx", line 1915, in pymssql._mssql.maybe_raise_MSSQLDatabaseException
  File "src/pymssql/_mssql.pyx", line 1932, in pymssql._mssql.raise_MSSQLDatabaseException
pymssql._mssql.MSSQLDatabaseException: (20009, b'DB-Lib error message 20009, severity 9:\nUnable to connect: Adaptive Server is unavailable or does not exist (192.168.0.234:1433)\nNet-Lib error during Network is unreachable (51)\n')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py", line 48, in <module>
    Sqlserver_PO = SqlserverPO("192.168.0.234", "sa", "Zy_123456789", "CDRD_TEST", "GBK")
  File "/Users/linghuchong/Downloads/51/Python/project/PO/SqlserverPO.py", line 201, in __init__
    self.conn = pymssql.connect(
  File "src/pymssql/_pymssql.pyx", line 660, in pymssql._pymssql.connect
pymssql.exceptions.OperationalError: (20009, b'DB-Lib error message 20009, severity 9:\nUnable to connect: Adaptive Server is unavailable or does not exist (192.168.0.234:1433)\nNet-Lib error during Network is unreachable (51)\n')
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:40:08.755+0800] {dagbag.py:387} ERROR - Failed to import: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Traceback (most recent call last):
  File "src/pymssql/_pymssql.pyx", line 651, in pymssql._pymssql.connect
  File "src/pymssql/_mssql.pyx", line 2189, in pymssql._mssql.connect
  File "src/pymssql/_mssql.pyx", line 722, in pymssql._mssql.MSSQLConnection.__init__
  File "src/pymssql/_mssql.pyx", line 1915, in pymssql._mssql.maybe_raise_MSSQLDatabaseException
  File "src/pymssql/_mssql.pyx", line 1932, in pymssql._mssql.raise_MSSQLDatabaseException
pymssql._mssql.MSSQLDatabaseException: (20009, b'DB-Lib error message 20009, severity 9:\nUnable to connect: Adaptive Server is unavailable or does not exist (192.168.0.234:1433)\nNet-Lib error during Network is unreachable (51)\n')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py", line 48, in <module>
    Sqlserver_PO = SqlserverPO("192.168.0.234", "sa", "Zy_123456789", "CDRD_TEST", "GBK")
  File "/Users/linghuchong/Downloads/51/Python/project/PO/SqlserverPO.py", line 201, in __init__
    self.conn = pymssql.connect(
  File "src/pymssql/_pymssql.pyx", line 660, in pymssql._pymssql.connect
pymssql.exceptions.OperationalError: (20009, b'DB-Lib error message 20009, severity 9:\nUnable to connect: Adaptive Server is unavailable or does not exist (192.168.0.234:1433)\nNet-Lib error during Network is unreachable (51)\n')
[2026-02-25T13:40:09.351+0800] {sequential_executor.py:91} ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:39:04.479998+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']' returned non-zero exit status 1..
[2026-02-25T13:40:09.356+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:39:04.478327+00:00', try_number=1, map_index=-1)
[2026-02-25T13:40:09.357+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:39:04.479998+00:00', try_number=1, map_index=-1)
[2026-02-25T13:40:09.365+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:39:04.478327+00:00, map_index=-1, run_start_date=2026-02-25 05:39:12.201148+00:00, run_end_date=2026-02-25 05:40:02.969638+00:00, run_duration=50.76849, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=390, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:39:08.045662+00:00, queued_by_job_id=340, pid=12047
[2026-02-25T13:40:09.367+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:39:04.479998+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:39:08.045662+00:00, queued_by_job_id=340, pid=None
[2026-02-25T13:40:09.368+0800] {scheduler_job_runner.py:922} ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2026-02-25T13:40:09.377+0800] {taskinstance.py:3338} ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
[2026-02-25T13:40:09.414+0800] {taskinstance.py:1242} INFO - Marking task as FAILED. dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:39:04.479998+00:00, execution_date=20260225T053904, start_date=, end_date=20260225T054009
[2026-02-25T13:40:09.450+0800] {manager.py:293} ERROR - DagFileProcessorManager (PID=1487) last sent a heartbeat 61.48 seconds ago! Restarting it
[2026-02-25T13:40:09.466+0800] {process_utils.py:132} INFO - Sending Signals.SIGTERM to group 1487. PIDs of all processes in the group: [1487]
[2026-02-25T13:40:09.467+0800] {process_utils.py:87} INFO - Sending the signal Signals.SIGTERM to group 1487
[2026-02-25T13:40:10.295+0800] {process_utils.py:80} INFO - Process psutil.Process(pid=1487, status='terminated', exitcode=0, started='08:45:12') (1487) terminated with exit code 0
[2026-02-25T13:40:10.303+0800] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 12093
[2026-02-25T13:40:10.315+0800] {job.py:229} INFO - Heartbeat recovered after 65.05 seconds
[2026-02-25T13:40:12.264+0800] {settings.py:63} INFO - Configured default timezone Asia/Shanghai
[2026-02-25T13:40:12.311+0800] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-02-25T13:40:16.284+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:39:04.478327+00:00: dataset_triggered__2026-02-25T05:39:04.478327+00:00, state:running, queued_at: 2026-02-25 05:39:07.997238+00:00. externally triggered: False> successful
[2026-02-25T13:40:16.285+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:39:04.478327+00:00, run_id=dataset_triggered__2026-02-25T05:39:04.478327+00:00, run_start_date=2026-02-25 05:39:08.009638+00:00, run_end_date=2026-02-25 05:40:16.285178+00:00, run_duration=68.27554, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:38:56.276937+00:00, data_interval_end=2026-02-25 05:38:56.276937+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T13:40:16.290+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:39:04.479998+00:00: dataset_triggered__2026-02-25T05:39:04.479998+00:00, state:running, queued_at: 2026-02-25 05:39:07.985482+00:00. externally triggered: False> failed
[2026-02-25T13:40:16.291+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:39:04.479998+00:00, run_id=dataset_triggered__2026-02-25T05:39:04.479998+00:00, run_start_date=2026-02-25 05:39:08.009751+00:00, run_end_date=2026-02-25 05:40:16.291670+00:00, run_duration=68.281919, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:38:56.276937+00:00, data_interval_end=2026-02-25 05:38:56.276937+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T13:41:14.945+0800] {manager.py:537} INFO - DAG p_cdrd_all is missing and will be deactivated.
[2026-02-25T13:41:14.947+0800] {manager.py:537} INFO - DAG c_cdrd_DAG2 is missing and will be deactivated.
[2026-02-25T13:41:14.947+0800] {manager.py:537} INFO - DAG c_cdrd_DAG1 is missing and will be deactivated.
[2026-02-25T13:41:14.953+0800] {manager.py:549} INFO - Deactivated 3 DAGs which are no longer present in file.
[2026-02-25T13:41:14.956+0800] {manager.py:553} INFO - Deleted DAG p_cdrd_all in serialized_dag table
[2026-02-25T13:41:14.958+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG1 in serialized_dag table
[2026-02-25T13:41:14.959+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG2 in serialized_dag table
[2026-02-25T13:42:27.889+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:42:23.956346+00:00 [scheduled]>
[2026-02-25T13:42:27.892+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T13:42:27.893+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:42:23.956346+00:00 [scheduled]>
[2026-02-25T13:42:27.895+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:42:23.956346+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:42:27.896+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:42:23.956346+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:42:27.897+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:42:23.956346+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:42:27.900+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:42:23.956346+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:42:30.071+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:42:34.623+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:42:23.956346+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:42:35.687+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:42:23.956346+00:00', try_number=1, map_index=-1)
[2026-02-25T13:42:35.698+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:42:23.956346+00:00, map_index=-1, run_start_date=2026-02-25 05:42:34.694030+00:00, run_end_date=2026-02-25 05:42:34.912154+00:00, run_duration=0.218124, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=391, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:42:27.894160+00:00, queued_by_job_id=340, pid=12220
[2026-02-25T13:42:35.728+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:42:38.975+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:42:23.956346+00:00: manual__2026-02-25T05:42:23.956346+00:00, state:running, queued_at: 2026-02-25 05:42:23.977501+00:00. externally triggered: True> successful
[2026-02-25T13:42:38.977+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:42:23.956346+00:00, run_id=manual__2026-02-25T05:42:23.956346+00:00, run_start_date=2026-02-25 05:42:27.868460+00:00, run_end_date=2026-02-25 05:42:38.976897+00:00, run_duration=11.108437, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:42:23.956346+00:00, data_interval_end=2026-02-25 05:42:23.956346+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T13:42:38.989+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:42:34.930730+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:42:34.932463+00:00 [scheduled]>
[2026-02-25T13:42:38.990+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T13:42:38.991+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T13:42:38.991+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:42:34.930730+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:42:34.932463+00:00 [scheduled]>
[2026-02-25T13:42:38.994+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:42:34.930730+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:42:34.932463+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:42:38.995+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:42:34.930730+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:42:38.995+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:42:34.930730+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:42:38.996+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:42:34.932463+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:42:38.997+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:42:34.932463+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:42:39.000+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:42:34.930730+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:42:41.222+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:42:43.674+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:42:34.930730+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:43:18.863+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:42:34.932463+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:43:21.702+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:43:24.958+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:42:34.932463+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:43:58.607+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:42:34.930730+00:00', try_number=1, map_index=-1)
[2026-02-25T13:43:58.609+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:42:34.932463+00:00', try_number=1, map_index=-1)
[2026-02-25T13:43:58.619+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:42:34.932463+00:00, map_index=-1, run_start_date=2026-02-25 05:43:25.042171+00:00, run_end_date=2026-02-25 05:43:57.834442+00:00, run_duration=32.792271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=393, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:42:38.992951+00:00, queued_by_job_id=340, pid=12249
[2026-02-25T13:43:58.620+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:42:34.930730+00:00, map_index=-1, run_start_date=2026-02-25 05:42:43.788446+00:00, run_end_date=2026-02-25 05:43:18.119512+00:00, run_duration=34.331066, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=392, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:42:38.992951+00:00, queued_by_job_id=340, pid=12226
[2026-02-25T13:43:58.633+0800] {manager.py:293} ERROR - DagFileProcessorManager (PID=12093) last sent a heartbeat 79.72 seconds ago! Restarting it
[2026-02-25T13:43:58.643+0800] {process_utils.py:132} INFO - Sending Signals.SIGTERM to group 12093. PIDs of all processes in the group: [12093]
[2026-02-25T13:43:58.644+0800] {process_utils.py:87} INFO - Sending the signal Signals.SIGTERM to group 12093
[2026-02-25T13:43:59.264+0800] {process_utils.py:80} INFO - Process psutil.Process(pid=12093, status='terminated', exitcode=0, started='13:40:10') (12093) terminated with exit code 0
[2026-02-25T13:43:59.273+0800] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 12277
[2026-02-25T13:43:59.286+0800] {job.py:229} INFO - Heartbeat recovered after 83.57 seconds
[2026-02-25T13:44:02.136+0800] {settings.py:63} INFO - Configured default timezone Asia/Shanghai
[2026-02-25T13:44:02.196+0800] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-02-25T13:44:06.767+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:42:34.930730+00:00: dataset_triggered__2026-02-25T05:42:34.930730+00:00, state:running, queued_at: 2026-02-25 05:42:38.934784+00:00. externally triggered: False> successful
[2026-02-25T13:44:06.768+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:42:34.930730+00:00, run_id=dataset_triggered__2026-02-25T05:42:34.930730+00:00, run_start_date=2026-02-25 05:42:38.957247+00:00, run_end_date=2026-02-25 05:44:06.768459+00:00, run_duration=87.811212, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:42:23.956346+00:00, data_interval_end=2026-02-25 05:42:23.956346+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T13:44:06.774+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:42:34.932463+00:00: dataset_triggered__2026-02-25T05:42:34.932463+00:00, state:running, queued_at: 2026-02-25 05:42:38.944600+00:00. externally triggered: False> successful
[2026-02-25T13:44:06.775+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:42:34.932463+00:00, run_id=dataset_triggered__2026-02-25T05:42:34.932463+00:00, run_start_date=2026-02-25 05:42:38.957354+00:00, run_end_date=2026-02-25 05:44:06.775397+00:00, run_duration=87.818043, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:42:23.956346+00:00, data_interval_end=2026-02-25 05:42:23.956346+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T13:44:59.723+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:44:55.308652+00:00 [scheduled]>
[2026-02-25T13:44:59.724+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T13:44:59.725+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:44:55.308652+00:00 [scheduled]>
[2026-02-25T13:44:59.728+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:44:55.308652+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:44:59.729+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:44:55.308652+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:44:59.729+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:44:55.308652+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:44:59.732+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:44:55.308652+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:45:02.228+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:45:04.787+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:44:55.308652+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:45:05.812+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:44:55.308652+00:00', try_number=1, map_index=-1)
[2026-02-25T13:45:05.823+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:44:55.308652+00:00, map_index=-1, run_start_date=2026-02-25 05:45:04.880399+00:00, run_end_date=2026-02-25 05:45:05.090857+00:00, run_duration=0.210458, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=394, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:44:59.726482+00:00, queued_by_job_id=340, pid=12308
[2026-02-25T13:45:08.819+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:44:55.308652+00:00: manual__2026-02-25T05:44:55.308652+00:00, state:running, queued_at: 2026-02-25 05:44:55.345816+00:00. externally triggered: True> successful
[2026-02-25T13:45:08.820+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:44:55.308652+00:00, run_id=manual__2026-02-25T05:44:55.308652+00:00, run_start_date=2026-02-25 05:44:59.703230+00:00, run_end_date=2026-02-25 05:45:08.820443+00:00, run_duration=9.117213, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:44:55.308652+00:00, data_interval_end=2026-02-25 05:44:55.308652+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T13:45:08.832+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:45:05.110303+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:45:05.111774+00:00 [scheduled]>
[2026-02-25T13:45:08.833+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T13:45:08.834+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T13:45:08.835+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:45:05.110303+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:45:05.111774+00:00 [scheduled]>
[2026-02-25T13:45:08.838+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:45:05.110303+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:45:05.111774+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:45:08.839+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:45:05.110303+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:45:08.840+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:45:05.110303+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:45:08.841+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:45:05.111774+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:45:08.842+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:45:05.111774+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:45:08.845+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:45:05.110303+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:45:11.040+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:45:12.734+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:45:05.110303+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:45:21.480+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:45:05.111774+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:45:24.286+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:45:26.059+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:45:05.111774+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:45:35.752+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:45:05.110303+00:00', try_number=1, map_index=-1)
[2026-02-25T13:45:35.756+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:45:05.111774+00:00', try_number=1, map_index=-1)
[2026-02-25T13:45:35.765+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:45:05.110303+00:00, map_index=-1, run_start_date=2026-02-25 05:45:12.803845+00:00, run_end_date=2026-02-25 05:45:20.750452+00:00, run_duration=7.946607, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=395, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:45:08.837001+00:00, queued_by_job_id=340, pid=12312
[2026-02-25T13:45:35.766+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:45:05.111774+00:00, map_index=-1, run_start_date=2026-02-25 05:45:26.133810+00:00, run_end_date=2026-02-25 05:45:35.042004+00:00, run_duration=8.908194, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=396, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:45:08.837001+00:00, queued_by_job_id=340, pid=12336
[2026-02-25T13:45:39.148+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:45:05.110303+00:00: dataset_triggered__2026-02-25T05:45:05.110303+00:00, state:running, queued_at: 2026-02-25 05:45:08.787257+00:00. externally triggered: False> successful
[2026-02-25T13:45:39.149+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:45:05.110303+00:00, run_id=dataset_triggered__2026-02-25T05:45:05.110303+00:00, run_start_date=2026-02-25 05:45:08.799124+00:00, run_end_date=2026-02-25 05:45:39.149421+00:00, run_duration=30.350297, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:44:55.308652+00:00, data_interval_end=2026-02-25 05:44:55.308652+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T13:45:39.154+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:45:05.111774+00:00: dataset_triggered__2026-02-25T05:45:05.111774+00:00, state:running, queued_at: 2026-02-25 05:45:08.776795+00:00. externally triggered: False> successful
[2026-02-25T13:45:39.156+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:45:05.111774+00:00, run_id=dataset_triggered__2026-02-25T05:45:05.111774+00:00, run_start_date=2026-02-25 05:45:08.799737+00:00, run_end_date=2026-02-25 05:45:39.155951+00:00, run_duration=30.356214, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:44:55.308652+00:00, data_interval_end=2026-02-25 05:44:55.308652+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T13:47:36.640+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:52:40.568+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T13:55:26.396+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:55:25.245471+00:00 [scheduled]>
[2026-02-25T13:55:26.397+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T13:55:26.398+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:55:25.245471+00:00 [scheduled]>
[2026-02-25T13:55:26.401+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:55:25.245471+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:55:26.403+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:55:25.245471+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:55:26.403+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:55:25.245471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:55:26.406+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:55:25.245471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:55:28.628+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:55:30.754+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:55:25.245471+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:55:31.791+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:55:25.245471+00:00', try_number=1, map_index=-1)
[2026-02-25T13:55:31.801+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:55:25.245471+00:00, map_index=-1, run_start_date=2026-02-25 05:55:30.828799+00:00, run_end_date=2026-02-25 05:55:31.040616+00:00, run_duration=0.211817, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=397, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:55:26.400042+00:00, queued_by_job_id=340, pid=12759
[2026-02-25T13:55:35.443+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:55:25.245471+00:00: manual__2026-02-25T05:55:25.245471+00:00, state:running, queued_at: 2026-02-25 05:55:25.272091+00:00. externally triggered: True> successful
[2026-02-25T13:55:35.444+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:55:25.245471+00:00, run_id=manual__2026-02-25T05:55:25.245471+00:00, run_start_date=2026-02-25 05:55:26.370562+00:00, run_end_date=2026-02-25 05:55:35.444594+00:00, run_duration=9.074032, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:55:25.245471+00:00, data_interval_end=2026-02-25 05:55:25.245471+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
[2026-02-25T13:55:35.455+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:55:31.060883+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:55:31.062285+00:00 [scheduled]>
[2026-02-25T13:55:35.456+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T13:55:35.456+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T13:55:35.458+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:55:31.060883+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:55:31.062285+00:00 [scheduled]>
[2026-02-25T13:55:35.460+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:55:31.060883+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:55:31.062285+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T13:55:35.461+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:55:31.060883+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:55:35.462+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:55:31.060883+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:55:35.463+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:55:31.062285+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T13:55:35.463+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:55:31.062285+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:55:35.466+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:55:31.060883+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:55:37.601+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:55:39.367+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:55:31.060883+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:55:47.754+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:55:31.062285+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T13:55:50.152+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T13:55:51.974+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:55:31.062285+00:00 [queued]> on host localhost-2.local
[2026-02-25T13:56:00.109+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:55:31.060883+00:00', try_number=1, map_index=-1)
[2026-02-25T13:56:00.111+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:55:31.062285+00:00', try_number=1, map_index=-1)
[2026-02-25T13:56:00.119+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:55:31.060883+00:00, map_index=-1, run_start_date=2026-02-25 05:55:39.436999+00:00, run_end_date=2026-02-25 05:55:47.025018+00:00, run_duration=7.588019, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=398, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:55:35.459239+00:00, queued_by_job_id=340, pid=12763
[2026-02-25T13:56:00.121+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:55:31.062285+00:00, map_index=-1, run_start_date=2026-02-25 05:55:52.047720+00:00, run_end_date=2026-02-25 05:55:59.410537+00:00, run_duration=7.362817, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=399, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:55:35.459239+00:00, queued_by_job_id=340, pid=12793
[2026-02-25T13:56:03.192+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:55:31.060883+00:00: dataset_triggered__2026-02-25T05:55:31.060883+00:00, state:running, queued_at: 2026-02-25 05:55:35.399686+00:00. externally triggered: False> successful
[2026-02-25T13:56:03.193+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:55:31.060883+00:00, run_id=dataset_triggered__2026-02-25T05:55:31.060883+00:00, run_start_date=2026-02-25 05:55:35.424378+00:00, run_end_date=2026-02-25 05:56:03.193195+00:00, run_duration=27.768817, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:55:25.245471+00:00, data_interval_end=2026-02-25 05:55:25.245471+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-25T13:56:03.199+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:55:31.062285+00:00: dataset_triggered__2026-02-25T05:55:31.062285+00:00, state:running, queued_at: 2026-02-25 05:55:35.411051+00:00. externally triggered: False> successful
[2026-02-25T13:56:03.200+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:55:31.062285+00:00, run_id=dataset_triggered__2026-02-25T05:55:31.062285+00:00, run_start_date=2026-02-25 05:55:35.424513+00:00, run_end_date=2026-02-25 05:56:03.200755+00:00, run_duration=27.776242, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:55:25.245471+00:00, data_interval_end=2026-02-25 05:55:25.245471+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-25T13:57:40.959+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:02:44.046+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:07:44.627+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:12:47.127+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:17:48.293+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:22:52.495+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:27:54.651+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:32:58.573+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:38:01.001+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:43:02.553+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:48:02.688+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:53:05.479+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T14:58:07.557+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:03:10.360+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:08:12.422+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:13:15.086+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:18:17.681+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:23:20.359+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:28:22.325+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:33:25.113+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:38:26.324+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:43:26.297+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:48:27.030+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:53:29.868+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T15:58:30.270+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:03:32.206+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:08:33.579+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:13:37.617+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:18:38.538+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:23:41.363+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:28:44.289+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:33:46.006+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:38:46.449+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:43:46.789+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:48:50.956+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:53:51.971+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T16:58:53.508+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:03:56.190+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:08:58.490+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:12:53.556+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:12:50.009957+00:00 [scheduled]>
[2026-02-25T17:12:53.557+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T17:12:53.557+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:12:50.009957+00:00 [scheduled]>
[2026-02-25T17:12:53.560+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:12:50.009957+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T17:12:53.563+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:12:50.009957+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T17:12:53.564+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:12:50.009957+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:12:53.566+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:12:50.009957+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:12:55.705+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T17:12:57.642+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:12:50.009957+00:00 [queued]> on host localhost-2.local
[2026-02-25T17:12:58.690+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:12:50.009957+00:00', try_number=1, map_index=-1)
[2026-02-25T17:12:58.699+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T09:12:50.009957+00:00, map_index=-1, run_start_date=2026-02-25 09:12:57.718217+00:00, run_end_date=2026-02-25 09:12:57.936050+00:00, run_duration=0.217833, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=400, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:12:53.559562+00:00, queued_by_job_id=340, pid=19192
[2026-02-25T17:13:01.727+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 09:12:50.009957+00:00: manual__2026-02-25T09:12:50.009957+00:00, state:running, queued_at: 2026-02-25 09:12:50.033363+00:00. externally triggered: True> successful
[2026-02-25T17:13:01.728+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 09:12:50.009957+00:00, run_id=manual__2026-02-25T09:12:50.009957+00:00, run_start_date=2026-02-25 09:12:53.530985+00:00, run_end_date=2026-02-25 09:13:01.728490+00:00, run_duration=8.197505, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 09:12:50.009957+00:00, data_interval_end=2026-02-25 09:12:50.009957+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
[2026-02-25T17:13:01.738+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:12:57.956329+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:12:57.958123+00:00 [scheduled]>
[2026-02-25T17:13:01.739+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T17:13:01.740+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T17:13:01.741+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:12:57.956329+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:12:57.958123+00:00 [scheduled]>
[2026-02-25T17:13:01.746+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:12:57.956329+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:12:57.958123+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T17:13:01.747+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:12:57.956329+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T17:13:01.748+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:12:57.956329+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:13:01.749+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:12:57.958123+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T17:13:01.750+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:12:57.958123+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:13:01.753+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:12:57.956329+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:13:04.018+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T17:13:05.775+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:12:57.956329+00:00 [queued]> on host localhost-2.local
[2026-02-25T17:13:14.043+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:12:57.958123+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:13:16.477+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T17:13:18.183+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:12:57.958123+00:00 [queued]> on host localhost-2.local
[2026-02-25T17:13:24.886+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:12:57.956329+00:00', try_number=1, map_index=-1)
[2026-02-25T17:13:24.888+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:12:57.958123+00:00', try_number=1, map_index=-1)
[2026-02-25T17:13:24.896+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T09:12:57.958123+00:00, map_index=-1, run_start_date=2026-02-25 09:13:18.252143+00:00, run_end_date=2026-02-25 09:13:24.186909+00:00, run_duration=5.934766, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=402, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:13:01.744683+00:00, queued_by_job_id=340, pid=19220
[2026-02-25T17:13:24.897+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T09:12:57.956329+00:00, map_index=-1, run_start_date=2026-02-25 09:13:05.840199+00:00, run_end_date=2026-02-25 09:13:13.296947+00:00, run_duration=7.456748, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=401, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:13:01.744683+00:00, queued_by_job_id=340, pid=19198
[2026-02-25T17:13:27.898+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 09:12:57.956329+00:00: dataset_triggered__2026-02-25T09:12:57.956329+00:00, state:running, queued_at: 2026-02-25 09:13:01.680697+00:00. externally triggered: False> successful
[2026-02-25T17:13:27.899+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 09:12:57.956329+00:00, run_id=dataset_triggered__2026-02-25T09:12:57.956329+00:00, run_start_date=2026-02-25 09:13:01.707694+00:00, run_end_date=2026-02-25 09:13:27.899860+00:00, run_duration=26.192166, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:12:50.009957+00:00, data_interval_end=2026-02-25 09:12:50.009957+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
[2026-02-25T17:13:27.906+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 09:12:57.958123+00:00: dataset_triggered__2026-02-25T09:12:57.958123+00:00, state:running, queued_at: 2026-02-25 09:13:01.695599+00:00. externally triggered: False> successful
[2026-02-25T17:13:27.907+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 09:12:57.958123+00:00, run_id=dataset_triggered__2026-02-25T09:12:57.958123+00:00, run_start_date=2026-02-25 09:13:01.707803+00:00, run_end_date=2026-02-25 09:13:27.907252+00:00, run_duration=26.199449, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:12:50.009957+00:00, data_interval_end=2026-02-25 09:12:50.009957+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
[2026-02-25T17:13:59.330+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:19:01.622+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:24:02.316+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:29:04.771+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:34:06.330+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:34:20.152+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:34:19.119387+00:00 [scheduled]>
[2026-02-25T17:34:20.153+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-25T17:34:20.154+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:34:19.119387+00:00 [scheduled]>
[2026-02-25T17:34:20.156+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:34:19.119387+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T17:34:20.159+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:34:19.119387+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T17:34:20.160+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:34:19.119387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:34:20.164+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:34:19.119387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:34:22.431+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T17:34:26.108+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:34:19.119387+00:00 [queued]> on host localhost-2.local
[2026-02-25T17:34:27.227+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:34:19.119387+00:00', try_number=1, map_index=-1)
[2026-02-25T17:34:27.238+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T09:34:19.119387+00:00, map_index=-1, run_start_date=2026-02-25 09:34:26.189678+00:00, run_end_date=2026-02-25 09:34:26.419055+00:00, run_duration=0.229377, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=403, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:34:20.155327+00:00, queued_by_job_id=340, pid=19950
[2026-02-25T17:34:30.910+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 09:34:19.119387+00:00: manual__2026-02-25T09:34:19.119387+00:00, state:running, queued_at: 2026-02-25 09:34:19.155536+00:00. externally triggered: True> successful
[2026-02-25T17:34:30.912+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 09:34:19.119387+00:00, run_id=manual__2026-02-25T09:34:19.119387+00:00, run_start_date=2026-02-25 09:34:20.127745+00:00, run_end_date=2026-02-25 09:34:30.912020+00:00, run_duration=10.784275, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 09:34:19.119387+00:00, data_interval_end=2026-02-25 09:34:19.119387+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
[2026-02-25T17:34:30.923+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:34:26.439432+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:34:26.440909+00:00 [scheduled]>
[2026-02-25T17:34:30.924+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-25T17:34:30.924+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-25T17:34:30.925+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:34:26.439432+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:34:26.440909+00:00 [scheduled]>
[2026-02-25T17:34:30.928+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:34:26.439432+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:34:26.440909+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-25T17:34:30.929+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:34:26.439432+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T17:34:30.930+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:34:26.439432+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:34:30.930+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:34:26.440909+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-25T17:34:30.931+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:34:26.440909+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:34:30.934+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:34:26.439432+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:34:33.141+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T17:34:39.128+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:34:26.439432+00:00 [queued]> on host localhost-2.local
[2026-02-25T17:35:18.025+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:34:26.440909+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-25T17:35:20.861+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-25T17:35:22.949+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:34:26.440909+00:00 [queued]> on host localhost-2.local
[2026-02-25T17:35:58.276+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:34:26.439432+00:00', try_number=1, map_index=-1)
[2026-02-25T17:35:58.280+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:34:26.440909+00:00', try_number=1, map_index=-1)
[2026-02-25T17:35:58.289+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T09:34:26.440909+00:00, map_index=-1, run_start_date=2026-02-25 09:35:23.015913+00:00, run_end_date=2026-02-25 09:35:57.565079+00:00, run_duration=34.549166, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=405, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:34:30.926918+00:00, queued_by_job_id=340, pid=20000
[2026-02-25T17:35:58.291+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T09:34:26.439432+00:00, map_index=-1, run_start_date=2026-02-25 09:34:39.201040+00:00, run_end_date=2026-02-25 09:35:17.280205+00:00, run_duration=38.079165, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=404, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:34:30.926918+00:00, queued_by_job_id=340, pid=19953
[2026-02-25T17:35:58.304+0800] {manager.py:293} ERROR - DagFileProcessorManager (PID=12277) last sent a heartbeat 87.46 seconds ago! Restarting it
[2026-02-25T17:35:58.320+0800] {process_utils.py:132} INFO - Sending Signals.SIGTERM to group 12277. PIDs of all processes in the group: [12277]
[2026-02-25T17:35:58.322+0800] {process_utils.py:87} INFO - Sending the signal Signals.SIGTERM to group 12277
[2026-02-25T17:35:59.031+0800] {process_utils.py:80} INFO - Process psutil.Process(pid=12277, status='terminated', exitcode=0, started='13:43:59') (12277) terminated with exit code 0
[2026-02-25T17:35:59.046+0800] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 20023
[2026-02-25T17:35:59.059+0800] {job.py:229} INFO - Heartbeat recovered after 91.80 seconds
[2026-02-25T17:36:01.736+0800] {settings.py:63} INFO - Configured default timezone Asia/Shanghai
[2026-02-25T17:36:01.786+0800] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-02-25T17:36:06.023+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 09:34:26.439432+00:00: dataset_triggered__2026-02-25T09:34:26.439432+00:00, state:running, queued_at: 2026-02-25 09:34:30.880046+00:00. externally triggered: False> successful
[2026-02-25T17:36:06.024+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 09:34:26.439432+00:00, run_id=dataset_triggered__2026-02-25T09:34:26.439432+00:00, run_start_date=2026-02-25 09:34:30.891967+00:00, run_end_date=2026-02-25 09:36:06.024620+00:00, run_duration=95.132653, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:34:19.119387+00:00, data_interval_end=2026-02-25 09:34:19.119387+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
[2026-02-25T17:36:06.031+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 09:34:26.440909+00:00: dataset_triggered__2026-02-25T09:34:26.440909+00:00, state:running, queued_at: 2026-02-25 09:34:30.870486+00:00. externally triggered: False> successful
[2026-02-25T17:36:06.032+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 09:34:26.440909+00:00, run_id=dataset_triggered__2026-02-25T09:34:26.440909+00:00, run_start_date=2026-02-25 09:34:30.892070+00:00, run_end_date=2026-02-25 09:36:06.032485+00:00, run_duration=95.140415, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:34:19.119387+00:00, data_interval_end=2026-02-25 09:34:19.119387+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
[2026-02-25T17:39:07.583+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:47:14.630+0800] {job.py:229} INFO - Heartbeat recovered after 206.63 seconds
[2026-02-25T17:47:22.897+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:50:31.812+0800] {job.py:229} INFO - Heartbeat recovered after 52.42 seconds
[2026-02-25T17:53:24.854+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T17:58:26.731+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-25T18:03:27.594+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
