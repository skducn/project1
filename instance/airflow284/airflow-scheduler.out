[2026-02-24T09:52:37.402+0800] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2026-02-24T09:52:38.078+0800] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2026-02-24T09:52:38.081+0800] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2026-02-24T09:52:38.092+0800] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 3447
[2026-02-24T09:52:38.100+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T09:52:41.162+0800] {settings.py:63} INFO - Configured default timezone Asia/Shanghai
[2026-02-24T09:52:41.214+0800] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-02-24T09:52:41.544+0800] {core.py:50} INFO - Starting log server on http://[::]:8793
[2026-02-24T09:53:41.903+0800] {manager.py:537} INFO - DAG p_1p2n_DAGs is missing and will be deactivated.
[2026-02-24T09:53:41.906+0800] {manager.py:537} INFO - DAG c_1p2n_DAG1 is missing and will be deactivated.
[2026-02-24T09:53:41.906+0800] {manager.py:537} INFO - DAG c_1p2n_DAG2 is missing and will be deactivated.
[2026-02-24T09:53:41.911+0800] {manager.py:549} INFO - Deactivated 3 DAGs which are no longer present in file.
[2026-02-24T09:53:41.915+0800] {manager.py:553} INFO - Deleted DAG c_1p2n_DAG1 in serialized_dag table
[2026-02-24T09:53:41.919+0800] {manager.py:553} INFO - Deleted DAG p_1p2n_DAGs in serialized_dag table
[2026-02-24T09:53:41.923+0800] {manager.py:553} INFO - Deleted DAG c_1p2n_DAG2 in serialized_dag table
[2026-02-24T09:57:39.321+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:02:41.861+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:07:44.445+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:12:45.205+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:15:41.378+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T02:15:38.592389+00:00 [scheduled]>
[2026-02-24T10:15:41.379+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
[2026-02-24T10:15:41.380+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T02:15:38.592389+00:00 [scheduled]>
[2026-02-24T10:15:41.383+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T02:15:38.592389+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:15:41.384+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T02:15:38.592389+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:15:41.385+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T02:15:38.592389+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T10:15:41.387+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T02:15:38.592389+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T10:15:43.495+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p2n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
Successfully imported PO.TimePO
[2026-02-24T10:15:45.107+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T02:15:38.592389+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:15:46.050+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T02:15:38.592389+00:00', try_number=1, map_index=-1)
[2026-02-24T10:15:46.067+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-24T02:15:38.592389+00:00, map_index=-1, run_start_date=2026-02-24 02:15:45.185232+00:00, run_end_date=2026-02-24 02:15:45.404882+00:00, run_duration=0.21965, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=209, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:15:41.381883+00:00, queued_by_job_id=208, pid=4653
[2026-02-24T10:15:48.882+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-24 02:15:38.592389+00:00: manual__2026-02-24T02:15:38.592389+00:00, state:running, queued_at: 2026-02-24 02:15:38.624858+00:00. externally triggered: True> successful
[2026-02-24T10:15:48.884+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-24 02:15:38.592389+00:00, run_id=manual__2026-02-24T02:15:38.592389+00:00, run_start_date=2026-02-24 02:15:41.342270+00:00, run_end_date=2026-02-24 02:15:48.884184+00:00, run_duration=7.541914, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:15:38.592389+00:00, data_interval_end=2026-02-24 02:15:38.592389+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
[2026-02-24T10:15:48.896+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-24T02:15:45.425754+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-24T02:15:45.427353+00:00 [scheduled]>
[2026-02-24T10:15:48.897+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p2n_DAG2 has 0/16 running and queued tasks
[2026-02-24T10:15:48.898+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p2n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:15:48.899+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-24T02:15:45.425754+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-24T02:15:45.427353+00:00 [scheduled]>
[2026-02-24T10:15:48.902+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-24T02:15:45.425754+00:00 [scheduled]>, <TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-24T02:15:45.427353+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:15:48.903+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-24T02:15:45.425754+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:15:48.904+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-24T02:15:45.425754+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T10:15:48.904+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-24T02:15:45.427353+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:15:48.905+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-24T02:15:45.427353+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T10:15:48.909+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-24T02:15:45.425754+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T10:15:50.998+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p2n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
Successfully imported PO.TimePO
[2026-02-24T10:15:52.284+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-24T02:15:45.425754+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:15:53.243+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-24T02:15:45.427353+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T10:15:55.389+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p2n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
Successfully imported PO.TimePO
[2026-02-24T10:15:56.680+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-24T02:15:45.427353+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:15:57.642+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-24T02:15:45.425754+00:00', try_number=1, map_index=-1)
[2026-02-24T10:15:57.645+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-24T02:15:45.427353+00:00', try_number=1, map_index=-1)
[2026-02-24T10:15:57.661+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p2n_DAG2, task_id=c_1p2n_TASK2, run_id=dataset_triggered__2026-02-24T02:15:45.425754+00:00, map_index=-1, run_start_date=2026-02-24 02:15:52.357179+00:00, run_end_date=2026-02-24 02:15:52.585118+00:00, run_duration=0.227939, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=210, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:15:48.900774+00:00, queued_by_job_id=208, pid=4656
[2026-02-24T10:15:57.662+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p2n_DAG1, task_id=c_1p2n_TASK1, run_id=dataset_triggered__2026-02-24T02:15:45.427353+00:00, map_index=-1, run_start_date=2026-02-24 02:15:56.749072+00:00, run_end_date=2026-02-24 02:15:56.972493+00:00, run_duration=0.223421, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=211, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:15:48.900774+00:00, queued_by_job_id=208, pid=4658
[2026-02-24T10:16:00.739+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p2n_DAG2 @ 2026-02-24 02:15:45.425754+00:00: dataset_triggered__2026-02-24T02:15:45.425754+00:00, state:running, queued_at: 2026-02-24 02:15:48.834997+00:00. externally triggered: False> successful
[2026-02-24T10:16:00.740+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p2n_DAG2, execution_date=2026-02-24 02:15:45.425754+00:00, run_id=dataset_triggered__2026-02-24T02:15:45.425754+00:00, run_start_date=2026-02-24 02:15:48.864141+00:00, run_end_date=2026-02-24 02:16:00.740398+00:00, run_duration=11.876257, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:15:38.592389+00:00, data_interval_end=2026-02-24 02:15:38.592389+00:00, dag_hash=f0222c6725e6517a46dc479b0aa002a2
[2026-02-24T10:16:00.746+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p2n_DAG1 @ 2026-02-24 02:15:45.427353+00:00: dataset_triggered__2026-02-24T02:15:45.427353+00:00, state:running, queued_at: 2026-02-24 02:15:48.850142+00:00. externally triggered: False> successful
[2026-02-24T10:16:00.748+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p2n_DAG1, execution_date=2026-02-24 02:15:45.427353+00:00, run_id=dataset_triggered__2026-02-24T02:15:45.427353+00:00, run_start_date=2026-02-24 02:15:48.864236+00:00, run_end_date=2026-02-24 02:16:00.748251+00:00, run_duration=11.884015, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:15:38.592389+00:00, data_interval_end=2026-02-24 02:15:38.592389+00:00, dag_hash=4a31cc71e5398c53fad0c9cea1feb380
[2026-02-24T10:17:47.677+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:22:50.393+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:24:00.028+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:23:56.268900+00:00 [scheduled]>
[2026-02-24T10:24:00.030+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
[2026-02-24T10:24:00.031+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:23:56.268900+00:00 [scheduled]>
[2026-02-24T10:24:00.033+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:23:56.268900+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:24:00.035+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:23:56.268900+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:24:00.035+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:23:56.268900+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:24:00.038+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:23:56.268900+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:24:02.099+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:24:03.528+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:23:56.268900+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:24:04.451+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:23:56.268900+00:00', try_number=1, map_index=-1)
[2026-02-24T10:24:04.462+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:23:56.268900+00:00, map_index=-1, run_start_date=2026-02-24 02:24:03.605108+00:00, run_end_date=2026-02-24 02:24:03.816128+00:00, run_duration=0.21102, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=212, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:24:00.032260+00:00, queued_by_job_id=208, pid=4931
[2026-02-24T10:24:07.836+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:23:56.268900+00:00: manual__2026-02-24T02:23:56.268900+00:00, state:running, queued_at: 2026-02-24 02:23:56.287475+00:00. externally triggered: True> successful
[2026-02-24T10:24:07.837+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:23:56.268900+00:00, run_id=manual__2026-02-24T02:23:56.268900+00:00, run_start_date=2026-02-24 02:24:00.005427+00:00, run_end_date=2026-02-24 02:24:07.837296+00:00, run_duration=7.831869, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:23:56.268900+00:00, data_interval_end=2026-02-24 02:23:56.268900+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
[2026-02-24T10:24:07.847+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-24T02:24:03.837397+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:24:03.838921+00:00 [scheduled]>
[2026-02-24T10:24:07.848+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
[2026-02-24T10:24:07.848+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:24:07.849+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-24T02:24:03.837397+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:24:03.838921+00:00 [scheduled]>
[2026-02-24T10:24:07.852+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-24T02:24:03.837397+00:00 [scheduled]>, <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:24:03.838921+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:24:07.853+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-24T02:24:03.837397+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:24:07.854+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-24T02:24:03.837397+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:24:07.855+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:24:03.838921+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:24:07.855+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:24:03.838921+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:24:07.858+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-24T02:24:03.837397+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:24:10.045+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:24:11.309+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-24T02:24:03.837397+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:24:12.253+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:24:03.838921+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:24:14.635+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:24:16.226+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:24:03.838921+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:24:17.299+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-24T02:24:03.837397+00:00', try_number=1, map_index=-1)
[2026-02-24T10:24:17.305+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:24:03.838921+00:00', try_number=1, map_index=-1)
[2026-02-24T10:24:17.315+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-24T02:24:03.838921+00:00, map_index=-1, run_start_date=2026-02-24 02:24:16.305519+00:00, run_end_date=2026-02-24 02:24:16.606146+00:00, run_duration=0.300627, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=214, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:24:07.850675+00:00, queued_by_job_id=208, pid=4936
[2026-02-24T10:24:17.317+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=dataset_triggered__2026-02-24T02:24:03.837397+00:00, map_index=-1, run_start_date=2026-02-24 02:24:11.378194+00:00, run_end_date=2026-02-24 02:24:11.604727+00:00, run_duration=0.226533, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=213, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:24:07.850675+00:00, queued_by_job_id=208, pid=4934
[2026-02-24T10:24:20.734+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-24 02:24:03.837397+00:00: dataset_triggered__2026-02-24T02:24:03.837397+00:00, state:running, queued_at: 2026-02-24 02:24:07.804984+00:00. externally triggered: False> successful
[2026-02-24T10:24:20.735+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-24 02:24:03.837397+00:00, run_id=dataset_triggered__2026-02-24T02:24:03.837397+00:00, run_start_date=2026-02-24 02:24:07.818788+00:00, run_end_date=2026-02-24 02:24:20.735600+00:00, run_duration=12.916812, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:23:56.268900+00:00, data_interval_end=2026-02-24 02:23:56.268900+00:00, dag_hash=0a3439ce80be51d3a7ac788a7442a9b6
[2026-02-24T10:24:20.741+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-24 02:24:03.838921+00:00: dataset_triggered__2026-02-24T02:24:03.838921+00:00, state:running, queued_at: 2026-02-24 02:24:07.796259+00:00. externally triggered: False> successful
[2026-02-24T10:24:20.742+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-24 02:24:03.838921+00:00, run_id=dataset_triggered__2026-02-24T02:24:03.838921+00:00, run_start_date=2026-02-24 02:24:07.818925+00:00, run_end_date=2026-02-24 02:24:20.742770+00:00, run_duration=12.923845, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:23:56.268900+00:00, data_interval_end=2026-02-24 02:23:56.268900+00:00, dag_hash=c3144e87e37f9ff1a9f0e648fbb0f19d
[2026-02-24T10:27:51.203+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:31:26.711+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:31:24.359252+00:00 [scheduled]>
[2026-02-24T10:31:26.713+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
[2026-02-24T10:31:26.713+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:31:24.359252+00:00 [scheduled]>
[2026-02-24T10:31:26.716+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:31:24.359252+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:31:26.717+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:31:24.359252+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:31:26.718+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:31:24.359252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:31:26.720+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:31:24.359252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:31:28.845+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:31:30.221+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:31:24.359252+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:31:31.133+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:31:24.359252+00:00', try_number=1, map_index=-1)
[2026-02-24T10:31:31.145+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:31:24.359252+00:00, map_index=-1, run_start_date=2026-02-24 02:31:30.295385+00:00, run_end_date=2026-02-24 02:31:30.496544+00:00, run_duration=0.201159, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=215, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:31:26.714763+00:00, queued_by_job_id=208, pid=5197
[2026-02-24T10:31:33.929+0800] {providers_manager.py:296} WARNING - Exception when importing 'airflow.providers.standard.operators.trigger_dagrun.TriggerDagRunLink' from 'apache-airflow-providers-standard' package
Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers_manager.py", line 327, in _correctness_check
    imported_class = import_string(class_name)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/standard/operators/trigger_dagrun.py", line 35, in <module>
    from airflow.providers.common.compat.sdk import (
ImportError: cannot import name 'AirflowException' from 'airflow.providers.common.compat.sdk' (/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/common/compat/sdk.py)
[2026-02-24T10:31:33.934+0800] {providers_manager.py:296} WARNING - Exception when importing 'airflow.providers.standard.sensors.external_task.ExternalDagLink' from 'apache-airflow-providers-standard' package
Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers_manager.py", line 327, in _correctness_check
    imported_class = import_string(class_name)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/standard/sensors/external_task.py", line 27, in <module>
    from airflow.providers.common.compat.sdk import (
ImportError: cannot import name 'AirflowSkipException' from 'airflow.providers.common.compat.sdk' (/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/common/compat/sdk.py)
[2026-02-24T10:31:33.995+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:31:24.359252+00:00: manual__2026-02-24T02:31:24.359252+00:00, state:running, queued_at: 2026-02-24 02:31:24.372587+00:00. externally triggered: True> successful
[2026-02-24T10:31:33.996+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:31:24.359252+00:00, run_id=manual__2026-02-24T02:31:24.359252+00:00, run_start_date=2026-02-24 02:31:26.691889+00:00, run_end_date=2026-02-24 02:31:33.996646+00:00, run_duration=7.304757, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:31:24.359252+00:00, data_interval_end=2026-02-24 02:31:24.359252+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
[2026-02-24T10:31:34.008+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.wait_for_consumer1 dataset_triggered__2026-02-24T02:31:30.518493+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:31:30.520347+00:00 [scheduled]>
[2026-02-24T10:31:34.008+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
[2026-02-24T10:31:34.009+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:31:34.010+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.wait_for_consumer1 dataset_triggered__2026-02-24T02:31:30.518493+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:31:30.520347+00:00 [scheduled]>
[2026-02-24T10:31:34.013+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.wait_for_consumer1 dataset_triggered__2026-02-24T02:31:30.518493+00:00 [scheduled]>, <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:31:30.520347+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:31:34.015+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='wait_for_consumer1', run_id='dataset_triggered__2026-02-24T02:31:30.518493+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T10:31:34.015+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'wait_for_consumer1', 'dataset_triggered__2026-02-24T02:31:30.518493+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:31:34.016+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:31:30.520347+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:31:34.017+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:31:30.520347+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:31:34.020+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'wait_for_consumer1', 'dataset_triggered__2026-02-24T02:31:30.518493+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:31:36.139+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:31:37.509+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG2.wait_for_consumer1 dataset_triggered__2026-02-24T02:31:30.518493+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:38:41.519+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:31:30.520347+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:38:43.820+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:38:45.845+0800] {sequential_executor.py:91} ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:31:30.520347+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']' returned non-zero exit status 1..
[2026-02-24T10:38:45.852+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='wait_for_consumer1', run_id='dataset_triggered__2026-02-24T02:31:30.518493+00:00', try_number=1, map_index=-1)
[2026-02-24T10:38:45.853+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:31:30.520347+00:00', try_number=1, map_index=-1)
[2026-02-24T10:38:45.871+0800] {manager.py:293} ERROR - DagFileProcessorManager (PID=3447) last sent a heartbeat 431.96 seconds ago! Restarting it
[2026-02-24T10:38:45.882+0800] {process_utils.py:132} INFO - Sending Signals.SIGTERM to group 3447. PIDs of all processes in the group: [3447]
[2026-02-24T10:38:45.883+0800] {process_utils.py:87} INFO - Sending the signal Signals.SIGTERM to group 3447
[2026-02-24T10:38:46.429+0800] {process_utils.py:80} INFO - Process psutil.Process(pid=3447, status='terminated', exitcode=0, started='09:52:38') (3447) terminated with exit code 0
[2026-02-24T10:38:46.436+0800] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 5320
[2026-02-24T10:38:46.453+0800] {job.py:229} INFO - Heartbeat recovered after 435.29 seconds
[2026-02-24T10:38:46.472+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:38:48.383+0800] {settings.py:63} INFO - Configured default timezone Asia/Shanghai
[2026-02-24T10:38:48.432+0800] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-02-24T10:38:52.080+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:38:44.096710+00:00 [scheduled]>
[2026-02-24T10:38:52.081+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
[2026-02-24T10:38:52.082+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:38:44.096710+00:00 [scheduled]>
[2026-02-24T10:38:52.084+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:38:44.096710+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:38:52.086+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:38:44.096710+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:38:52.087+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:38:44.096710+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:38:52.089+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:38:44.096710+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:38:54.194+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:38:55.595+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:38:44.096710+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:38:56.563+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:38:44.096710+00:00', try_number=1, map_index=-1)
[2026-02-24T10:38:56.574+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:38:44.096710+00:00, map_index=-1, run_start_date=2026-02-24 02:38:55.666271+00:00, run_end_date=2026-02-24 02:38:55.858686+00:00, run_duration=0.192415, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=217, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:38:52.083287+00:00, queued_by_job_id=208, pid=5323
[2026-02-24T10:39:00.153+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:38:44.096710+00:00: manual__2026-02-24T02:38:44.096710+00:00, state:running, queued_at: 2026-02-24 02:38:44.111189+00:00. externally triggered: True> successful
[2026-02-24T10:39:00.154+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:38:44.096710+00:00, run_id=manual__2026-02-24T02:38:44.096710+00:00, run_start_date=2026-02-24 02:38:52.057556+00:00, run_end_date=2026-02-24 02:39:00.154204+00:00, run_duration=8.096648, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:38:44.096710+00:00, data_interval_end=2026-02-24 02:38:44.096710+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
[2026-02-24T10:39:00.164+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
[2026-02-24T10:39:00.165+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:39:00.166+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
[2026-02-24T10:39:00.168+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:39:00.169+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T10:39:00.170+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:39:00.173+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:39:02.261+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:39:03.552+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:39:04.525+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1)
[2026-02-24T10:39:04.535+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-24T02:38:55.878244+00:00, map_index=-1, run_start_date=2026-02-24 02:39:03.621683+00:00, run_end_date=2026-02-24 02:39:03.835379+00:00, run_duration=0.213696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=218, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:39:00.167525+00:00, queued_by_job_id=208, pid=5329
[2026-02-24T10:39:07.153+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
[2026-02-24T10:39:07.154+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:39:07.155+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
[2026-02-24T10:39:07.157+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:39:07.159+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:39:07.159+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:39:07.162+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:39:09.308+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:39:10.591+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:39:11.558+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1)
[2026-02-24T10:39:11.569+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=trigger_consumer2, run_id=dataset_triggered__2026-02-24T02:38:55.878244+00:00, map_index=-1, run_start_date=2026-02-24 02:39:10.658067+00:00, run_end_date=2026-02-24 02:39:10.878931+00:00, run_duration=0.220864, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=219, pool=default_pool, queue=default, priority_weight=1, operator=TriggerDagRunOperator, queued_dttm=2026-02-24 02:39:07.156601+00:00, queued_by_job_id=208, pid=5332
[2026-02-24T10:39:14.490+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-24 02:38:55.878244+00:00: dataset_triggered__2026-02-24T02:38:55.878244+00:00, state:running, queued_at: 2026-02-24 02:39:00.118569+00:00. externally triggered: False> successful
[2026-02-24T10:39:14.491+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-24 02:38:55.878244+00:00, run_id=dataset_triggered__2026-02-24T02:38:55.878244+00:00, run_start_date=2026-02-24 02:39:00.136804+00:00, run_end_date=2026-02-24 02:39:14.491524+00:00, run_duration=14.35472, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-24 02:38:44.096710+00:00, dag_hash=1e5120c8d126ef18ce6c14bf6e8820e1
[2026-02-24T10:39:14.503+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:39:10.827985+00:00 [scheduled]>
[2026-02-24T10:39:14.504+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
[2026-02-24T10:39:14.505+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:39:10.827985+00:00 [scheduled]>
[2026-02-24T10:39:14.509+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:39:10.827985+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:39:14.510+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:39:10.827985+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:39:14.511+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:39:10.827985+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:39:14.513+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:39:10.827985+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:39:16.743+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:39:17.928+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:39:10.827985+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:39:18.813+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:39:10.827985+00:00', try_number=1, map_index=-1)
[2026-02-24T10:39:18.825+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=manual__2026-02-24T02:39:10.827985+00:00, map_index=-1, run_start_date=2026-02-24 02:39:17.994893+00:00, run_end_date=2026-02-24 02:39:18.199075+00:00, run_duration=0.204182, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=220, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:39:14.507283+00:00, queued_by_job_id=208, pid=5335
[2026-02-24T10:39:21.677+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-24 02:39:10.827985+00:00: manual__2026-02-24T02:39:10.827985+00:00, state:running, queued_at: 2026-02-24 02:39:10.844540+00:00. externally triggered: True> successful
[2026-02-24T10:39:21.678+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-24 02:39:10.827985+00:00, run_id=manual__2026-02-24T02:39:10.827985+00:00, run_start_date=2026-02-24 02:39:14.466997+00:00, run_end_date=2026-02-24 02:39:21.678646+00:00, run_duration=7.211649, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:39:10.827985+00:00, data_interval_end=2026-02-24 02:39:10.827985+00:00, dag_hash=3db0a33148c3d6ae46448fe2fe476bd0
[2026-02-24T10:43:47.478+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:46:42.488+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:46:41.375756+00:00 [scheduled]>
[2026-02-24T10:46:42.488+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
[2026-02-24T10:46:42.489+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:46:41.375756+00:00 [scheduled]>
[2026-02-24T10:46:42.491+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:46:41.375756+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:46:42.493+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:46:41.375756+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:46:42.494+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:46:41.375756+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:46:42.496+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:46:41.375756+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:46:44.690+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:46:46.108+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:46:41.375756+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:46:47.129+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:46:41.375756+00:00', try_number=1, map_index=-1)
[2026-02-24T10:46:47.141+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:46:41.375756+00:00, map_index=-1, run_start_date=2026-02-24 02:46:46.194789+00:00, run_end_date=2026-02-24 02:46:46.440884+00:00, run_duration=0.246095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=221, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:46:42.490744+00:00, queued_by_job_id=208, pid=5566
[2026-02-24T10:46:49.917+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:46:41.375756+00:00: manual__2026-02-24T02:46:41.375756+00:00, state:running, queued_at: 2026-02-24 02:46:41.390828+00:00. externally triggered: True> successful
[2026-02-24T10:46:49.918+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:46:41.375756+00:00, run_id=manual__2026-02-24T02:46:41.375756+00:00, run_start_date=2026-02-24 02:46:42.465033+00:00, run_end_date=2026-02-24 02:46:49.918687+00:00, run_duration=7.453654, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:46:41.375756+00:00, data_interval_end=2026-02-24 02:46:41.375756+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
[2026-02-24T10:46:49.929+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
[2026-02-24T10:46:49.930+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:46:49.931+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
[2026-02-24T10:46:49.933+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:46:49.934+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T10:46:49.935+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:46:49.938+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:46:52.063+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:46:53.324+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:46:54.236+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1)
[2026-02-24T10:46:54.247+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-24T02:46:46.462237+00:00, map_index=-1, run_start_date=2026-02-24 02:46:53.397409+00:00, run_end_date=2026-02-24 02:46:53.608585+00:00, run_duration=0.211176, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=222, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:46:49.932553+00:00, queued_by_job_id=208, pid=5569
[2026-02-24T10:46:57.228+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
[2026-02-24T10:46:57.229+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:46:57.230+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
[2026-02-24T10:46:57.233+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:46:57.234+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:46:57.234+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:46:57.237+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:46:59.467+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:47:00.808+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:47:01.771+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1)
[2026-02-24T10:47:01.784+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=trigger_consumer2, run_id=dataset_triggered__2026-02-24T02:46:46.462237+00:00, map_index=-1, run_start_date=2026-02-24 02:47:00.883385+00:00, run_end_date=2026-02-24 02:47:01.130534+00:00, run_duration=0.247149, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=223, pool=default_pool, queue=default, priority_weight=1, operator=TriggerDagRunOperator, queued_dttm=2026-02-24 02:46:57.231701+00:00, queued_by_job_id=208, pid=5577
[2026-02-24T10:47:04.665+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-24 02:46:46.462237+00:00: dataset_triggered__2026-02-24T02:46:46.462237+00:00, state:running, queued_at: 2026-02-24 02:46:49.888066+00:00. externally triggered: False> successful
[2026-02-24T10:47:04.666+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-24 02:46:46.462237+00:00, run_id=dataset_triggered__2026-02-24T02:46:46.462237+00:00, run_start_date=2026-02-24 02:46:49.901810+00:00, run_end_date=2026-02-24 02:47:04.666253+00:00, run_duration=14.764443, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:46:41.375756+00:00, data_interval_end=2026-02-24 02:46:41.375756+00:00, dag_hash=1e5120c8d126ef18ce6c14bf6e8820e1
[2026-02-24T10:47:04.677+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
[2026-02-24T10:47:04.678+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
[2026-02-24T10:47:04.679+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
[2026-02-24T10:47:04.681+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:47:04.682+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T10:47:04.683+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:47:04.686+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:47:06.843+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:47:08.114+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:47:01.072084+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:47:09.064+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1)
[2026-02-24T10:47:09.076+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=manual__2026-02-24T02:47:01.072084+00:00, map_index=-1, run_start_date=2026-02-24 02:47:08.184985+00:00, run_end_date=2026-02-24 02:47:08.397610+00:00, run_duration=0.212625, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=224, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:47:04.680532+00:00, queued_by_job_id=208, pid=5580
[2026-02-24T10:47:11.974+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.trigger_consumer3 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
[2026-02-24T10:47:11.975+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
[2026-02-24T10:47:11.976+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.trigger_consumer3 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
[2026-02-24T10:47:11.978+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.trigger_consumer3 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:47:11.979+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='trigger_consumer3', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:47:11.980+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'trigger_consumer3', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:47:11.982+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'trigger_consumer3', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:47:14.126+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:47:15.342+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG2.trigger_consumer3 manual__2026-02-24T02:47:01.072084+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:47:16.316+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='trigger_consumer3', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1)
[2026-02-24T10:47:16.326+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=trigger_consumer3, run_id=manual__2026-02-24T02:47:01.072084+00:00, map_index=-1, run_start_date=2026-02-24 02:47:15.418680+00:00, run_end_date=2026-02-24 02:47:15.644727+00:00, run_duration=0.226047, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=225, pool=default_pool, queue=default, priority_weight=1, operator=TriggerDagRunOperator, queued_dttm=2026-02-24 02:47:11.977155+00:00, queued_by_job_id=208, pid=5583
[2026-02-24T10:47:19.273+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-24 02:47:01.072084+00:00: manual__2026-02-24T02:47:01.072084+00:00, state:running, queued_at: 2026-02-24 02:47:01.095124+00:00. externally triggered: True> successful
[2026-02-24T10:47:19.274+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-24 02:47:01.072084+00:00, run_id=manual__2026-02-24T02:47:01.072084+00:00, run_start_date=2026-02-24 02:47:04.644252+00:00, run_end_date=2026-02-24 02:47:19.274880+00:00, run_duration=14.630628, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:47:01.072084+00:00, data_interval_end=2026-02-24 02:47:01.072084+00:00, dag_hash=2432b578155b6ddfdba45496256889cf
[2026-02-24T10:47:19.286+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG3.c_1p1n1n_TASK3 manual__2026-02-24T02:47:15.592938+00:00 [scheduled]>
[2026-02-24T10:47:19.287+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n1n_DAG3 has 0/16 running and queued tasks
[2026-02-24T10:47:19.288+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG3.c_1p1n1n_TASK3 manual__2026-02-24T02:47:15.592938+00:00 [scheduled]>
[2026-02-24T10:47:19.290+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG3.c_1p1n1n_TASK3 manual__2026-02-24T02:47:15.592938+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:47:19.291+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG3', task_id='c_1p1n1n_TASK3', run_id='manual__2026-02-24T02:47:15.592938+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:47:19.292+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG3', 'c_1p1n1n_TASK3', 'manual__2026-02-24T02:47:15.592938+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:47:19.295+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG3', 'c_1p1n1n_TASK3', 'manual__2026-02-24T02:47:15.592938+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
[2026-02-24T10:47:21.364+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:47:22.570+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n1n_DAG3.c_1p1n1n_TASK3 manual__2026-02-24T02:47:15.592938+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:47:23.517+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG3', task_id='c_1p1n1n_TASK3', run_id='manual__2026-02-24T02:47:15.592938+00:00', try_number=1, map_index=-1)
[2026-02-24T10:47:23.528+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG3, task_id=c_1p1n1n_TASK3, run_id=manual__2026-02-24T02:47:15.592938+00:00, map_index=-1, run_start_date=2026-02-24 02:47:22.636064+00:00, run_end_date=2026-02-24 02:47:22.839282+00:00, run_duration=0.203218, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=226, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:47:19.289274+00:00, queued_by_job_id=208, pid=5586
[2026-02-24T10:47:26.214+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n1n_DAG3 @ 2026-02-24 02:47:15.592938+00:00: manual__2026-02-24T02:47:15.592938+00:00, state:running, queued_at: 2026-02-24 02:47:15.609141+00:00. externally triggered: True> successful
[2026-02-24T10:47:26.216+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n1n_DAG3, execution_date=2026-02-24 02:47:15.592938+00:00, run_id=manual__2026-02-24T02:47:15.592938+00:00, run_start_date=2026-02-24 02:47:19.259742+00:00, run_end_date=2026-02-24 02:47:26.215942+00:00, run_duration=6.9562, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:47:15.592938+00:00, data_interval_end=2026-02-24 02:47:15.592938+00:00, dag_hash=6d824235d565eea177e2112d44bf1810
[2026-02-24T10:48:49.119+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:53:49.161+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T10:54:19.239+0800] {scheduler_job_runner.py:2168} INFO - Orphaning unreferenced dataset 'dataset://1p1n/'
[2026-02-24T10:58:18.526+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T02:58:15.047252+00:00 [scheduled]>
[2026-02-24T10:58:18.527+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
[2026-02-24T10:58:18.528+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T02:58:15.047252+00:00 [scheduled]>
[2026-02-24T10:58:18.531+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T02:58:15.047252+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:58:18.532+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T02:58:15.047252+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:58:18.533+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T02:58:15.047252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T10:58:18.535+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T02:58:15.047252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T10:58:20.706+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:58:22.209+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T02:58:15.047252+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:58:23.121+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T02:58:15.047252+00:00', try_number=1, map_index=-1)
[2026-02-24T10:58:23.134+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T02:58:15.047252+00:00, map_index=-1, run_start_date=2026-02-24 02:58:22.279604+00:00, run_end_date=2026-02-24 02:58:22.488864+00:00, run_duration=0.20926, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=227, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:58:18.529949+00:00, queued_by_job_id=208, pid=5930
[2026-02-24T10:58:26.802+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 02:58:15.047252+00:00: manual__2026-02-24T02:58:15.047252+00:00, state:running, queued_at: 2026-02-24 02:58:15.057739+00:00. externally triggered: True> successful
[2026-02-24T10:58:26.803+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 02:58:15.047252+00:00, run_id=manual__2026-02-24T02:58:15.047252+00:00, run_start_date=2026-02-24 02:58:18.501752+00:00, run_end_date=2026-02-24 02:58:26.803419+00:00, run_duration=8.301667, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 02:58:15.047252+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
[2026-02-24T10:58:26.814+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
[2026-02-24T10:58:26.814+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:58:26.815+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
[2026-02-24T10:58:26.818+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:58:26.819+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T10:58:26.821+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T10:58:26.824+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T10:58:29.107+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:58:30.350+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:58:31.326+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1)
[2026-02-24T10:58:31.337+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_DAG1, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T02:58:22.508864+00:00, map_index=-1, run_start_date=2026-02-24 02:58:30.415840+00:00, run_end_date=2026-02-24 02:58:30.623561+00:00, run_duration=0.207721, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=228, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:58:26.817109+00:00, queued_by_job_id=208, pid=5933
[2026-02-24T10:58:35.149+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK2 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
[2026-02-24T10:58:35.150+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T10:58:35.151+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK2 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
[2026-02-24T10:58:35.154+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK2 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T10:58:35.156+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T10:58:35.157+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T10:58:35.159+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T10:58:38.209+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T10:58:39.521+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_DAG1.c_1p1n_TASK2 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [queued]> on host localhost-2.local
[2026-02-24T10:58:40.462+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1)
[2026-02-24T10:58:40.474+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_DAG1, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T02:58:22.508864+00:00, map_index=-1, run_start_date=2026-02-24 02:58:39.592972+00:00, run_end_date=2026-02-24 02:58:39.815558+00:00, run_duration=0.222586, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=229, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:58:35.152989+00:00, queued_by_job_id=208, pid=5942
[2026-02-24T10:58:44.410+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n_DAG1 @ 2026-02-24 02:58:22.508864+00:00: dataset_triggered__2026-02-24T02:58:22.508864+00:00, state:running, queued_at: 2026-02-24 02:58:26.770174+00:00. externally triggered: False> successful
[2026-02-24T10:58:44.411+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n_DAG1, execution_date=2026-02-24 02:58:22.508864+00:00, run_id=dataset_triggered__2026-02-24T02:58:22.508864+00:00, run_start_date=2026-02-24 02:58:26.787601+00:00, run_end_date=2026-02-24 02:58:44.411574+00:00, run_duration=17.623973, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 02:58:15.047252+00:00, dag_hash=85fbbd816b13cfbff4860f745427d6cc
[2026-02-24T10:58:51.951+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:03:53.521+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:04:58.669+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:04:55.254749+00:00 [scheduled]>
[2026-02-24T11:04:58.670+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
[2026-02-24T11:04:58.670+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:04:55.254749+00:00 [scheduled]>
[2026-02-24T11:04:58.672+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:04:55.254749+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:04:58.673+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:04:55.254749+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:04:58.674+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:04:55.254749+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:04:58.676+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:04:55.254749+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:05:00.796+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:05:02.040+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:04:55.254749+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:05:02.959+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:04:55.254749+00:00', try_number=1, map_index=-1)
[2026-02-24T11:05:02.971+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:04:55.254749+00:00, map_index=-1, run_start_date=2026-02-24 03:05:02.112795+00:00, run_end_date=2026-02-24 03:05:02.314182+00:00, run_duration=0.201387, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=230, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:04:58.671850+00:00, queued_by_job_id=208, pid=6236
[2026-02-24T11:05:05.651+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:04:55.254749+00:00: manual__2026-02-24T03:04:55.254749+00:00, state:running, queued_at: 2026-02-24 03:04:55.274143+00:00. externally triggered: True> successful
[2026-02-24T11:05:05.653+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:04:55.254749+00:00, run_id=manual__2026-02-24T03:04:55.254749+00:00, run_start_date=2026-02-24 03:04:58.645593+00:00, run_end_date=2026-02-24 03:05:05.653062+00:00, run_duration=7.007469, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:04:55.254749+00:00, data_interval_end=2026-02-24 03:04:55.254749+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
[2026-02-24T11:05:05.663+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:05:02.335454+00:00 [scheduled]>
[2026-02-24T11:05:05.664+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_DAG1 has 0/16 running and queued tasks
[2026-02-24T11:05:05.664+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:05:02.335454+00:00 [scheduled]>
[2026-02-24T11:05:05.667+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:05:02.335454+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:05:05.668+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:05:02.335454+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T11:05:05.669+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:05:02.335454+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:05:05.671+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:05:02.335454+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:05:07.764+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:05:09.011+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:05:02.335454+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:05:09.998+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:05:02.335454+00:00', try_number=1, map_index=-1)
[2026-02-24T11:05:10.011+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_DAG1, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:05:02.335454+00:00, map_index=-1, run_start_date=2026-02-24 03:05:09.087275+00:00, run_end_date=2026-02-24 03:05:09.292617+00:00, run_duration=0.205342, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=231, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:05:05.666441+00:00, queued_by_job_id=208, pid=6239
[2026-02-24T11:05:12.589+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_1p1n_DAG1 @ 2026-02-24 03:05:02.335454+00:00: dataset_triggered__2026-02-24T03:05:02.335454+00:00, state:running, queued_at: 2026-02-24 03:05:05.620892+00:00. externally triggered: False> failed
[2026-02-24T11:05:12.590+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n_DAG1, execution_date=2026-02-24 03:05:02.335454+00:00, run_id=dataset_triggered__2026-02-24T03:05:02.335454+00:00, run_start_date=2026-02-24 03:05:05.636691+00:00, run_end_date=2026-02-24 03:05:12.590700+00:00, run_duration=6.954009, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:04:55.254749+00:00, data_interval_end=2026-02-24 03:04:55.254749+00:00, dag_hash=85fbbd816b13cfbff4860f745427d6cc
[2026-02-24T11:07:49.418+0800] {manager.py:537} INFO - DAG c_1p1n_DAG1 is missing and will be deactivated.
[2026-02-24T11:07:49.423+0800] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2026-02-24T11:07:49.427+0800] {manager.py:553} INFO - Deleted DAG c_1p1n_DAG1 in serialized_dag table
[2026-02-24T11:08:51.647+0800] {manager.py:537} INFO - DAG c_1p1n_2T_DAG1 is missing and will be deactivated.
[2026-02-24T11:08:51.650+0800] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2026-02-24T11:08:51.653+0800] {manager.py:553} INFO - Deleted DAG c_1p1n_2T_DAG1 in serialized_dag table
[2026-02-24T11:08:54.405+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:08:51.230534+00:00 [scheduled]>
[2026-02-24T11:08:54.406+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
[2026-02-24T11:08:54.407+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:08:51.230534+00:00 [scheduled]>
[2026-02-24T11:08:54.409+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:08:51.230534+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:08:54.410+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:08:51.230534+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:08:54.411+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:08:51.230534+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:08:54.413+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:08:51.230534+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:08:56.506+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:08:58.196+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:08:51.230534+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:08:59.133+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:08:51.230534+00:00', try_number=1, map_index=-1)
[2026-02-24T11:08:59.143+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:08:51.230534+00:00, map_index=-1, run_start_date=2026-02-24 03:08:58.272417+00:00, run_end_date=2026-02-24 03:08:58.479888+00:00, run_duration=0.207471, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=232, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:08:54.408134+00:00, queued_by_job_id=208, pid=6378
[2026-02-24T11:08:59.170+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:09:01.710+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:08:51.230534+00:00: manual__2026-02-24T03:08:51.230534+00:00, state:running, queued_at: 2026-02-24 03:08:51.246154+00:00. externally triggered: True> successful
[2026-02-24T11:09:01.711+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:08:51.230534+00:00, run_id=manual__2026-02-24T03:08:51.230534+00:00, run_start_date=2026-02-24 03:08:54.384340+00:00, run_end_date=2026-02-24 03:09:01.711557+00:00, run_duration=7.327217, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:08:51.230534+00:00, data_interval_end=2026-02-24 03:08:51.230534+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
[2026-02-24T11:09:01.721+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
[2026-02-24T11:09:01.721+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
[2026-02-24T11:09:01.722+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
[2026-02-24T11:09:01.724+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:09:01.725+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T11:09:01.726+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:09:01.728+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:09:03.816+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:09:05.086+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:09:06.054+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1)
[2026-02-24T11:09:06.065+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:08:58.500559+00:00, map_index=-1, run_start_date=2026-02-24 03:09:05.153623+00:00, run_end_date=2026-02-24 03:09:05.363846+00:00, run_duration=0.210223, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=233, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:09:01.723619+00:00, queued_by_job_id=208, pid=6384
[2026-02-24T11:09:08.689+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
[2026-02-24T11:09:08.690+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
[2026-02-24T11:09:08.691+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
[2026-02-24T11:09:08.693+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:09:08.694+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:09:08.695+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:09:08.697+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:09:10.981+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:09:12.221+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:09:13.194+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1)
[2026-02-24T11:09:13.204+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T03:08:58.500559+00:00, map_index=-1, run_start_date=2026-02-24 03:09:12.289618+00:00, run_end_date=2026-02-24 03:09:12.500226+00:00, run_duration=0.210608, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=234, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:09:08.692190+00:00, queued_by_job_id=208, pid=6387
[2026-02-24T11:09:16.730+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n_2t @ 2026-02-24 03:08:58.500559+00:00: dataset_triggered__2026-02-24T03:08:58.500559+00:00, state:running, queued_at: 2026-02-24 03:09:01.682094+00:00. externally triggered: False> successful
[2026-02-24T11:09:16.731+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n_2t, execution_date=2026-02-24 03:08:58.500559+00:00, run_id=dataset_triggered__2026-02-24T03:08:58.500559+00:00, run_start_date=2026-02-24 03:09:01.696303+00:00, run_end_date=2026-02-24 03:09:16.731463+00:00, run_duration=15.03516, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 03:08:51.230534+00:00, dag_hash=91e76cce63cbec992d6382966ab78e6d
[2026-02-24T11:11:01.790+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:10:57.126854+00:00 [scheduled]>
[2026-02-24T11:11:01.792+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
[2026-02-24T11:11:01.793+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:10:57.126854+00:00 [scheduled]>
[2026-02-24T11:11:01.797+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:10:57.126854+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:11:01.800+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:10:57.126854+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:11:01.801+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:10:57.126854+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:11:01.805+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:10:57.126854+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:11:04.197+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:11:05.894+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:10:57.126854+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:11:06.826+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:10:57.126854+00:00', try_number=1, map_index=-1)
[2026-02-24T11:11:06.837+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:10:57.126854+00:00, map_index=-1, run_start_date=2026-02-24 03:11:05.969069+00:00, run_end_date=2026-02-24 03:11:06.179247+00:00, run_duration=0.210178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=235, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:11:01.795610+00:00, queued_by_job_id=208, pid=6444
[2026-02-24T11:11:09.902+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:10:57.126854+00:00: manual__2026-02-24T03:10:57.126854+00:00, state:running, queued_at: 2026-02-24 03:10:57.139887+00:00. externally triggered: True> successful
[2026-02-24T11:11:09.903+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:10:57.126854+00:00, run_id=manual__2026-02-24T03:10:57.126854+00:00, run_start_date=2026-02-24 03:11:01.756573+00:00, run_end_date=2026-02-24 03:11:09.903004+00:00, run_duration=8.146431, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:10:57.126854+00:00, data_interval_end=2026-02-24 03:10:57.126854+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
[2026-02-24T11:11:09.913+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
[2026-02-24T11:11:09.914+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
[2026-02-24T11:11:09.915+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
[2026-02-24T11:11:09.917+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:11:09.919+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T11:11:09.919+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:11:09.922+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:11:12.313+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:11:13.671+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:11:14.655+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1)
[2026-02-24T11:11:14.668+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:11:06.198605+00:00, map_index=-1, run_start_date=2026-02-24 03:11:13.747223+00:00, run_end_date=2026-02-24 03:11:13.984757+00:00, run_duration=0.237534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=236, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:11:09.916261+00:00, queued_by_job_id=208, pid=6447
[2026-02-24T11:11:17.629+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
[2026-02-24T11:11:17.630+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
[2026-02-24T11:11:17.632+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
[2026-02-24T11:11:17.635+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:11:17.636+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:11:17.637+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:11:17.639+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:11:19.912+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:11:21.289+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:11:22.222+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1)
[2026-02-24T11:11:22.235+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T03:11:06.198605+00:00, map_index=-1, run_start_date=2026-02-24 03:11:21.368567+00:00, run_end_date=2026-02-24 03:11:21.575473+00:00, run_duration=0.206906, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=237, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:11:17.633669+00:00, queued_by_job_id=208, pid=6456
[2026-02-24T11:11:25.355+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_1p1n_2t @ 2026-02-24 03:11:06.198605+00:00: dataset_triggered__2026-02-24T03:11:06.198605+00:00, state:running, queued_at: 2026-02-24 03:11:09.870512+00:00. externally triggered: False> failed
[2026-02-24T11:11:25.356+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n_2t, execution_date=2026-02-24 03:11:06.198605+00:00, run_id=dataset_triggered__2026-02-24T03:11:06.198605+00:00, run_start_date=2026-02-24 03:11:09.885451+00:00, run_end_date=2026-02-24 03:11:25.356031+00:00, run_duration=15.47058, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:10:57.126854+00:00, data_interval_end=2026-02-24 03:10:57.126854+00:00, dag_hash=91e76cce63cbec992d6382966ab78e6d
[2026-02-24T11:14:02.349+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:15:26.821+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:15:22.633791+00:00 [scheduled]>
[2026-02-24T11:15:26.822+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
[2026-02-24T11:15:26.823+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:15:22.633791+00:00 [scheduled]>
[2026-02-24T11:15:26.825+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:15:22.633791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:15:26.826+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:15:22.633791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:15:26.827+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:15:22.633791+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:15:26.830+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:15:22.633791+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:15:29.102+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:15:30.805+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:15:22.633791+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:15:32.047+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:15:22.633791+00:00', try_number=1, map_index=-1)
[2026-02-24T11:15:32.073+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:15:22.633791+00:00, map_index=-1, run_start_date=2026-02-24 03:15:30.882783+00:00, run_end_date=2026-02-24 03:15:31.157893+00:00, run_duration=0.27511, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=238, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:15:26.824556+00:00, queued_by_job_id=208, pid=6609
[2026-02-24T11:15:36.278+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:15:22.633791+00:00: manual__2026-02-24T03:15:22.633791+00:00, state:running, queued_at: 2026-02-24 03:15:22.646096+00:00. externally triggered: True> successful
[2026-02-24T11:15:36.279+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:15:22.633791+00:00, run_id=manual__2026-02-24T03:15:22.633791+00:00, run_start_date=2026-02-24 03:15:26.799878+00:00, run_end_date=2026-02-24 03:15:36.279276+00:00, run_duration=9.479398, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:15:22.633791+00:00, data_interval_end=2026-02-24 03:15:22.633791+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
[2026-02-24T11:15:36.289+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
[2026-02-24T11:15:36.291+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
[2026-02-24T11:15:36.291+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
[2026-02-24T11:15:36.294+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:15:36.295+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T11:15:36.296+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:15:36.299+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:15:38.654+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:15:39.995+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:15:41.058+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1)
[2026-02-24T11:15:41.069+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:15:31.176510+00:00, map_index=-1, run_start_date=2026-02-24 03:15:40.070398+00:00, run_end_date=2026-02-24 03:15:40.291483+00:00, run_duration=0.221085, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=239, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:15:36.293235+00:00, queued_by_job_id=208, pid=6612
[2026-02-24T11:15:44.641+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
[2026-02-24T11:15:44.643+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
[2026-02-24T11:15:44.644+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
[2026-02-24T11:15:44.646+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:15:44.647+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:15:44.648+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:15:44.651+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T11:15:46.869+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:15:48.142+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:15:49.169+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1)
[2026-02-24T11:15:49.180+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T03:15:31.176510+00:00, map_index=-1, run_start_date=2026-02-24 03:15:48.232112+00:00, run_end_date=2026-02-24 03:15:48.442896+00:00, run_duration=0.210784, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=240, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:15:44.645572+00:00, queued_by_job_id=208, pid=6615
[2026-02-24T11:15:52.313+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n_2t @ 2026-02-24 03:15:31.176510+00:00: dataset_triggered__2026-02-24T03:15:31.176510+00:00, state:running, queued_at: 2026-02-24 03:15:36.247564+00:00. externally triggered: False> successful
[2026-02-24T11:15:52.314+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n_2t, execution_date=2026-02-24 03:15:31.176510+00:00, run_id=dataset_triggered__2026-02-24T03:15:31.176510+00:00, run_start_date=2026-02-24 03:15:36.263605+00:00, run_end_date=2026-02-24 03:15:52.314839+00:00, run_duration=16.051234, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:15:22.633791+00:00, data_interval_end=2026-02-24 03:15:22.633791+00:00, dag_hash=91e76cce63cbec992d6382966ab78e6d
[2026-02-24T11:19:05.480+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:24:08.422+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:26:26.154+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:26:24.274565+00:00 [scheduled]>
[2026-02-24T11:26:26.155+0800] {scheduler_job_runner.py:507} INFO - DAG p_2p1n_dw_user_sync has 0/16 running and queued tasks
[2026-02-24T11:26:26.155+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:26:24.274565+00:00 [scheduled]>
[2026-02-24T11:26:26.158+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:26:24.274565+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:26:26.159+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:26:24.274565+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:26:26.160+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:26:24.274565+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:26:26.163+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:26:24.274565+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:26:28.445+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /2p1n.py
[2026-02-24T11:26:29.473+0800] {task_command.py:467} INFO - Running <TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:26:24.274565+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:26:30.451+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:26:24.274565+00:00', try_number=1, map_index=-1)
[2026-02-24T11:26:30.463+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_2p1n_dw_user_sync, task_id=sync_user_data, run_id=manual__2026-02-24T03:26:24.274565+00:00, map_index=-1, run_start_date=2026-02-24 03:26:29.549835+00:00, run_end_date=2026-02-24 03:26:29.931646+00:00, run_duration=0.381811, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=241, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:26:26.157102+00:00, queued_by_job_id=208, pid=6937
[2026-02-24T11:26:30.503+0800] {manager.py:537} INFO - DAG producer_N_1_dw_user_sync is missing and will be deactivated.
[2026-02-24T11:26:30.504+0800] {manager.py:537} INFO - DAG producer_N_1_dw_order_sync is missing and will be deactivated.
[2026-02-24T11:26:30.504+0800] {manager.py:537} INFO - DAG consumer_N_1_order_user_analysis is missing and will be deactivated.
[2026-02-24T11:26:30.506+0800] {manager.py:549} INFO - Deactivated 3 DAGs which are no longer present in file.
[2026-02-24T11:26:30.508+0800] {manager.py:553} INFO - Deleted DAG producer_N_1_dw_user_sync in serialized_dag table
[2026-02-24T11:26:30.510+0800] {manager.py:553} INFO - Deleted DAG producer_N_1_dw_order_sync in serialized_dag table
[2026-02-24T11:26:30.512+0800] {manager.py:553} INFO - Deleted DAG consumer_N_1_order_user_analysis in serialized_dag table
[2026-02-24T11:26:33.807+0800] {dagrun.py:854} INFO - Marking run <DagRun p_2p1n_dw_user_sync @ 2026-02-24 03:26:24.274565+00:00: manual__2026-02-24T03:26:24.274565+00:00, state:running, queued_at: 2026-02-24 03:26:24.295081+00:00. externally triggered: True> successful
[2026-02-24T11:26:33.808+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_2p1n_dw_user_sync, execution_date=2026-02-24 03:26:24.274565+00:00, run_id=manual__2026-02-24T03:26:24.274565+00:00, run_start_date=2026-02-24 03:26:26.132724+00:00, run_end_date=2026-02-24 03:26:33.808412+00:00, run_duration=7.675688, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:26:24.274565+00:00, data_interval_end=2026-02-24 03:26:24.274565+00:00, dag_hash=be49d27b980a51dd9a3ddd841863cbd6
[2026-02-24T11:26:33.818+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:26:32.522691+00:00 [scheduled]>
[2026-02-24T11:26:33.820+0800] {scheduler_job_runner.py:507} INFO - DAG p_2p1n_dw_order_sync has 0/16 running and queued tasks
[2026-02-24T11:26:33.821+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:26:32.522691+00:00 [scheduled]>
[2026-02-24T11:26:33.823+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:26:32.522691+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:26:33.824+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:26:32.522691+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:26:33.825+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:26:32.522691+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:26:33.828+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:26:32.522691+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:26:35.937+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /2p1n.py
[2026-02-24T11:26:36.552+0800] {task_command.py:467} INFO - Running <TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:26:32.522691+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:26:37.594+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:26:32.522691+00:00', try_number=1, map_index=-1)
[2026-02-24T11:26:37.605+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_2p1n_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-24T03:26:32.522691+00:00, map_index=-1, run_start_date=2026-02-24 03:26:36.620475+00:00, run_end_date=2026-02-24 03:26:37.000651+00:00, run_duration=0.380176, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=242, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:26:33.822622+00:00, queued_by_job_id=208, pid=6941
[2026-02-24T11:26:40.555+0800] {dagrun.py:854} INFO - Marking run <DagRun p_2p1n_dw_order_sync @ 2026-02-24 03:26:32.522691+00:00: manual__2026-02-24T03:26:32.522691+00:00, state:running, queued_at: 2026-02-24 03:26:32.543836+00:00. externally triggered: True> successful
[2026-02-24T11:26:40.556+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_2p1n_dw_order_sync, execution_date=2026-02-24 03:26:32.522691+00:00, run_id=manual__2026-02-24T03:26:32.522691+00:00, run_start_date=2026-02-24 03:26:33.791747+00:00, run_end_date=2026-02-24 03:26:40.556842+00:00, run_duration=6.765095, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:26:32.522691+00:00, data_interval_end=2026-02-24 03:26:32.522691+00:00, dag_hash=a1f7ed216d49cad639f28b36f1b0251d
[2026-02-24T11:29:11.370+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:31:31.467+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:31:27.744326+00:00 [scheduled]>
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:31:30.764172+00:00 [scheduled]>
[2026-02-24T11:31:31.468+0800] {scheduler_job_runner.py:507} INFO - DAG p_2p1n_dw_user_sync has 0/16 running and queued tasks
[2026-02-24T11:31:31.469+0800] {scheduler_job_runner.py:507} INFO - DAG p_2p1n_dw_order_sync has 0/16 running and queued tasks
[2026-02-24T11:31:31.469+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:31:27.744326+00:00 [scheduled]>
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:31:30.764172+00:00 [scheduled]>
[2026-02-24T11:31:31.472+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:31:27.744326+00:00 [scheduled]>, <TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:31:30.764172+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:31:31.473+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:31:27.744326+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:31:31.474+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:31:27.744326+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:31:31.475+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:31:30.764172+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:31:31.476+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:31:30.764172+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:31:31.478+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:31:27.744326+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:31:33.654+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /2p1n.py
[2026-02-24T11:31:34.626+0800] {task_command.py:467} INFO - Running <TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:31:27.744326+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:31:35.699+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:31:30.764172+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:31:37.857+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /2p1n.py
[2026-02-24T11:31:38.488+0800] {task_command.py:467} INFO - Running <TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:31:30.764172+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:31:39.524+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:31:27.744326+00:00', try_number=1, map_index=-1)
[2026-02-24T11:31:39.527+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:31:30.764172+00:00', try_number=1, map_index=-1)
[2026-02-24T11:31:39.536+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_2p1n_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-24T03:31:30.764172+00:00, map_index=-1, run_start_date=2026-02-24 03:31:38.565512+00:00, run_end_date=2026-02-24 03:31:38.933381+00:00, run_duration=0.367869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=244, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:31:31.471151+00:00, queued_by_job_id=208, pid=7106
[2026-02-24T11:31:39.538+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_2p1n_dw_user_sync, task_id=sync_user_data, run_id=manual__2026-02-24T03:31:27.744326+00:00, map_index=-1, run_start_date=2026-02-24 03:31:34.699792+00:00, run_end_date=2026-02-24 03:31:35.080248+00:00, run_duration=0.380456, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=243, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:31:31.471151+00:00, queued_by_job_id=208, pid=7104
[2026-02-24T11:31:42.975+0800] {dagrun.py:854} INFO - Marking run <DagRun p_2p1n_dw_user_sync @ 2026-02-24 03:31:27.744326+00:00: manual__2026-02-24T03:31:27.744326+00:00, state:running, queued_at: 2026-02-24 03:31:27.755996+00:00. externally triggered: True> successful
[2026-02-24T11:31:42.976+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_2p1n_dw_user_sync, execution_date=2026-02-24 03:31:27.744326+00:00, run_id=manual__2026-02-24T03:31:27.744326+00:00, run_start_date=2026-02-24 03:31:31.437969+00:00, run_end_date=2026-02-24 03:31:42.976688+00:00, run_duration=11.538719, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:31:27.744326+00:00, data_interval_end=2026-02-24 03:31:27.744326+00:00, dag_hash=be49d27b980a51dd9a3ddd841863cbd6
[2026-02-24T11:31:42.981+0800] {dagrun.py:854} INFO - Marking run <DagRun p_2p1n_dw_order_sync @ 2026-02-24 03:31:30.764172+00:00: manual__2026-02-24T03:31:30.764172+00:00, state:running, queued_at: 2026-02-24 03:31:30.778284+00:00. externally triggered: True> successful
[2026-02-24T11:31:42.982+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_2p1n_dw_order_sync, execution_date=2026-02-24 03:31:30.764172+00:00, run_id=manual__2026-02-24T03:31:30.764172+00:00, run_start_date=2026-02-24 03:31:31.440412+00:00, run_end_date=2026-02-24 03:31:42.982286+00:00, run_duration=11.541874, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:31:30.764172+00:00, data_interval_end=2026-02-24 03:31:30.764172+00:00, dag_hash=a1f7ed216d49cad639f28b36f1b0251d
[2026-02-24T11:31:42.993+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_2p1n_order_user_analysis.analyze_order_user dataset_triggered__2026-02-24T03:31:38.953370+00:00 [scheduled]>
[2026-02-24T11:31:42.994+0800] {scheduler_job_runner.py:507} INFO - DAG c_2p1n_order_user_analysis has 0/16 running and queued tasks
[2026-02-24T11:31:42.995+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_2p1n_order_user_analysis.analyze_order_user dataset_triggered__2026-02-24T03:31:38.953370+00:00 [scheduled]>
[2026-02-24T11:31:42.997+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_2p1n_order_user_analysis.analyze_order_user dataset_triggered__2026-02-24T03:31:38.953370+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:31:42.998+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_2p1n_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-24T03:31:38.953370+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:31:42.999+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_2p1n_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-24T03:31:38.953370+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:31:43.002+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_2p1n_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-24T03:31:38.953370+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
[2026-02-24T11:31:45.480+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /2p1n.py
[2026-02-24T11:31:46.166+0800] {task_command.py:467} INFO - Running <TaskInstance: c_2p1n_order_user_analysis.analyze_order_user dataset_triggered__2026-02-24T03:31:38.953370+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:31:47.236+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_2p1n_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-24T03:31:38.953370+00:00', try_number=1, map_index=-1)
[2026-02-24T11:31:47.246+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_2p1n_order_user_analysis, task_id=analyze_order_user, run_id=dataset_triggered__2026-02-24T03:31:38.953370+00:00, map_index=-1, run_start_date=2026-02-24 03:31:46.235523+00:00, run_end_date=2026-02-24 03:31:46.652691+00:00, run_duration=0.417168, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=245, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:31:42.996296+00:00, queued_by_job_id=208, pid=7109
[2026-02-24T11:31:50.529+0800] {dagrun.py:854} INFO - Marking run <DagRun c_2p1n_order_user_analysis @ 2026-02-24 03:31:38.953370+00:00: dataset_triggered__2026-02-24T03:31:38.953370+00:00, state:running, queued_at: 2026-02-24 03:31:42.936350+00:00. externally triggered: False> successful
[2026-02-24T11:31:50.530+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_2p1n_order_user_analysis, execution_date=2026-02-24 03:31:38.953370+00:00, run_id=dataset_triggered__2026-02-24T03:31:38.953370+00:00, run_start_date=2026-02-24 03:31:42.960563+00:00, run_end_date=2026-02-24 03:31:50.530768+00:00, run_duration=7.570205, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-14 03:36:00.776536+00:00, data_interval_end=2026-02-24 03:31:30.764172+00:00, dag_hash=c0431e4500d4b89e73ba3af5030b2402
[2026-02-24T11:34:12.301+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:39:13.143+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:44:15.862+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:49:19.153+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:50:43.410+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T03:50:42.943391+00:00 [scheduled]>
[2026-02-24T11:50:43.412+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
[2026-02-24T11:50:43.414+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T03:50:42.943391+00:00 [scheduled]>
[2026-02-24T11:50:43.417+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T03:50:42.943391+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:50:43.419+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T03:50:42.943391+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:50:43.420+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T03:50:42.943391+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T11:50:43.428+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T03:50:42.943391+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T11:50:45.870+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p2n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:50:47.612+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T03:50:42.943391+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:50:48.731+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T03:50:42.943391+00:00', try_number=1, map_index=-1)
[2026-02-24T11:50:48.742+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-24T03:50:42.943391+00:00, map_index=-1, run_start_date=2026-02-24 03:50:47.690668+00:00, run_end_date=2026-02-24 03:50:47.933070+00:00, run_duration=0.242402, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=246, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:50:43.415677+00:00, queued_by_job_id=208, pid=7734
[2026-02-24T11:50:51.617+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-24 03:50:42.943391+00:00: manual__2026-02-24T03:50:42.943391+00:00, state:running, queued_at: 2026-02-24 03:50:42.955287+00:00. externally triggered: True> successful
[2026-02-24T11:50:51.618+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-24 03:50:42.943391+00:00, run_id=manual__2026-02-24T03:50:42.943391+00:00, run_start_date=2026-02-24 03:50:43.387147+00:00, run_end_date=2026-02-24 03:50:51.618208+00:00, run_duration=8.231061, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:50:42.943391+00:00, data_interval_end=2026-02-24 03:50:42.943391+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
[2026-02-24T11:50:51.629+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_DAG2_TASK1 dataset_triggered__2026-02-24T03:50:47.957041+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_DAG1_TASK1 dataset_triggered__2026-02-24T03:50:47.958959+00:00 [scheduled]>
[2026-02-24T11:50:51.630+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p2n_DAG2 has 0/16 running and queued tasks
[2026-02-24T11:50:51.630+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p2n_DAG1 has 0/16 running and queued tasks
[2026-02-24T11:50:51.631+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_DAG2_TASK1 dataset_triggered__2026-02-24T03:50:47.957041+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_DAG1_TASK1 dataset_triggered__2026-02-24T03:50:47.958959+00:00 [scheduled]>
[2026-02-24T11:50:51.634+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG2.c_1p2n_DAG2_TASK1 dataset_triggered__2026-02-24T03:50:47.957041+00:00 [scheduled]>, <TaskInstance: c_1p2n_DAG1.c_1p2n_DAG1_TASK1 dataset_triggered__2026-02-24T03:50:47.958959+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T11:50:51.635+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_DAG2_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.957041+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:50:51.636+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_DAG2_TASK1', 'dataset_triggered__2026-02-24T03:50:47.957041+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T11:50:51.637+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_DAG1_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.958959+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T11:50:51.637+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_DAG1_TASK1', 'dataset_triggered__2026-02-24T03:50:47.958959+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T11:50:51.640+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_DAG2_TASK1', 'dataset_triggered__2026-02-24T03:50:47.957041+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T11:50:53.724+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p2n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:50:54.986+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p2n_DAG2.c_1p2n_DAG2_TASK1 dataset_triggered__2026-02-24T03:50:47.957041+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:50:55.915+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_DAG1_TASK1', 'dataset_triggered__2026-02-24T03:50:47.958959+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
[2026-02-24T11:50:58.103+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p2n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T11:50:59.314+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p2n_DAG1.c_1p2n_DAG1_TASK1 dataset_triggered__2026-02-24T03:50:47.958959+00:00 [queued]> on host localhost-2.local
[2026-02-24T11:51:00.281+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_DAG2_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.957041+00:00', try_number=1, map_index=-1)
[2026-02-24T11:51:00.283+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_DAG1_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.958959+00:00', try_number=1, map_index=-1)
[2026-02-24T11:51:00.293+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p2n_DAG2, task_id=c_1p2n_DAG2_TASK1, run_id=dataset_triggered__2026-02-24T03:50:47.957041+00:00, map_index=-1, run_start_date=2026-02-24 03:50:55.058578+00:00, run_end_date=2026-02-24 03:50:55.273166+00:00, run_duration=0.214588, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=247, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:50:51.632952+00:00, queued_by_job_id=208, pid=7739
[2026-02-24T11:51:00.295+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p2n_DAG1, task_id=c_1p2n_DAG1_TASK1, run_id=dataset_triggered__2026-02-24T03:50:47.958959+00:00, map_index=-1, run_start_date=2026-02-24 03:50:59.385135+00:00, run_end_date=2026-02-24 03:50:59.601145+00:00, run_duration=0.21601, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=248, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:50:51.632952+00:00, queued_by_job_id=208, pid=7741
[2026-02-24T11:51:03.217+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p2n_DAG2 @ 2026-02-24 03:50:47.957041+00:00: dataset_triggered__2026-02-24T03:50:47.957041+00:00, state:running, queued_at: 2026-02-24 03:50:51.587139+00:00. externally triggered: False> successful
[2026-02-24T11:51:03.218+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p2n_DAG2, execution_date=2026-02-24 03:50:47.957041+00:00, run_id=dataset_triggered__2026-02-24T03:50:47.957041+00:00, run_start_date=2026-02-24 03:50:51.600394+00:00, run_end_date=2026-02-24 03:51:03.218415+00:00, run_duration=11.618021, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:50:42.943391+00:00, data_interval_end=2026-02-24 03:50:42.943391+00:00, dag_hash=98275d99bdc42b085c239e856f4230f4
[2026-02-24T11:51:03.224+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p2n_DAG1 @ 2026-02-24 03:50:47.958959+00:00: dataset_triggered__2026-02-24T03:50:47.958959+00:00, state:running, queued_at: 2026-02-24 03:50:51.576980+00:00. externally triggered: False> successful
[2026-02-24T11:51:03.225+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p2n_DAG1, execution_date=2026-02-24 03:50:47.958959+00:00, run_id=dataset_triggered__2026-02-24T03:50:47.958959+00:00, run_start_date=2026-02-24 03:50:51.600498+00:00, run_end_date=2026-02-24 03:51:03.225059+00:00, run_duration=11.624561, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:50:42.943391+00:00, data_interval_end=2026-02-24 03:50:42.943391+00:00, dag_hash=5a65660f9e489d59e87932edad18febb
[2026-02-24T11:54:19.775+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T11:54:32.597+0800] {scheduler_job_runner.py:2168} INFO - Orphaning unreferenced dataset 'dataset://1p1n2t/'
[2026-02-24T11:57:39.449+0800] {manager.py:537} INFO - DAG c_1p1n is missing and will be deactivated.
[2026-02-24T11:57:39.453+0800] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2026-02-24T11:57:39.454+0800] {manager.py:553} INFO - Deleted DAG c_1p1n in serialized_dag table
[2026-02-24T11:59:21.680+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:00:31.790+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T04:00:27.880872+00:00 [scheduled]>
[2026-02-24T12:00:31.791+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
[2026-02-24T12:00:31.792+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T04:00:27.880872+00:00 [scheduled]>
[2026-02-24T12:00:31.794+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T04:00:27.880872+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T12:00:31.795+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T04:00:27.880872+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T12:00:31.795+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T04:00:27.880872+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T12:00:31.798+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T04:00:27.880872+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T12:00:34.337+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T12:00:35.924+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T04:00:27.880872+00:00 [queued]> on host localhost-2.local
[2026-02-24T12:00:36.874+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T04:00:27.880872+00:00', try_number=1, map_index=-1)
[2026-02-24T12:00:36.883+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T04:00:27.880872+00:00, map_index=-1, run_start_date=2026-02-24 04:00:36.000200+00:00, run_end_date=2026-02-24 04:00:36.208573+00:00, run_duration=0.208373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=249, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:00:31.793298+00:00, queued_by_job_id=208, pid=8080
[2026-02-24T12:00:39.879+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 04:00:27.880872+00:00: manual__2026-02-24T04:00:27.880872+00:00, state:running, queued_at: 2026-02-24 04:00:27.893270+00:00. externally triggered: True> successful
[2026-02-24T12:00:39.880+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 04:00:27.880872+00:00, run_id=manual__2026-02-24T04:00:27.880872+00:00, run_start_date=2026-02-24 04:00:31.771790+00:00, run_end_date=2026-02-24 04:00:39.880652+00:00, run_duration=8.108862, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 04:00:27.880872+00:00, data_interval_end=2026-02-24 04:00:27.880872+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
[2026-02-24T12:00:39.890+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n.c_1p1n_TASK1 dataset_triggered__2026-02-24T04:00:36.228926+00:00 [scheduled]>
[2026-02-24T12:00:39.891+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n has 0/16 running and queued tasks
[2026-02-24T12:00:39.891+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n.c_1p1n_TASK1 dataset_triggered__2026-02-24T04:00:36.228926+00:00 [scheduled]>
[2026-02-24T12:00:39.894+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n.c_1p1n_TASK1 dataset_triggered__2026-02-24T04:00:36.228926+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T12:00:39.895+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T04:00:36.228926+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T12:00:39.896+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T04:00:36.228926+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T12:00:39.898+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T04:00:36.228926+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
[2026-02-24T12:00:42.143+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T12:00:43.425+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n.c_1p1n_TASK1 dataset_triggered__2026-02-24T04:00:36.228926+00:00 [queued]> on host localhost-2.local
[2026-02-24T12:00:44.453+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T04:00:36.228926+00:00', try_number=1, map_index=-1)
[2026-02-24T12:00:44.463+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T04:00:36.228926+00:00, map_index=-1, run_start_date=2026-02-24 04:00:43.493721+00:00, run_end_date=2026-02-24 04:00:43.707552+00:00, run_duration=0.213831, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=250, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:00:39.892958+00:00, queued_by_job_id=208, pid=8094
[2026-02-24T12:00:44.495+0800] {scheduler_job_runner.py:2168} INFO - Orphaning unreferenced dataset 'dataset://1p1n2t/'
[2026-02-24T12:00:47.342+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n @ 2026-02-24 04:00:36.228926+00:00: dataset_triggered__2026-02-24T04:00:36.228926+00:00, state:running, queued_at: 2026-02-24 04:00:39.852048+00:00. externally triggered: False> successful
[2026-02-24T12:00:47.343+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n, execution_date=2026-02-24 04:00:36.228926+00:00, run_id=dataset_triggered__2026-02-24T04:00:36.228926+00:00, run_start_date=2026-02-24 04:00:39.865712+00:00, run_end_date=2026-02-24 04:00:47.343345+00:00, run_duration=7.477633, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 04:00:27.880872+00:00, dag_hash=2232c17af953533597ba3e1a46132e55
[2026-02-24T12:02:17.376+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:02:16.315580+00:00 [scheduled]>
[2026-02-24T12:02:17.377+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n2t_DAGs has 0/16 running and queued tasks
[2026-02-24T12:02:17.379+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:02:16.315580+00:00 [scheduled]>
[2026-02-24T12:02:17.381+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:02:16.315580+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T12:02:17.382+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:02:16.315580+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T12:02:17.383+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:02:16.315580+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:02:17.386+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:02:16.315580+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:02:19.577+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T12:02:21.037+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:02:16.315580+00:00 [queued]> on host localhost-2.local
[2026-02-24T12:02:22.017+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:02:16.315580+00:00', try_number=1, map_index=-1)
[2026-02-24T12:02:22.027+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n2t_DAGs, task_id=p_1p1n2t_TASK, run_id=manual__2026-02-24T04:02:16.315580+00:00, map_index=-1, run_start_date=2026-02-24 04:02:21.104590+00:00, run_end_date=2026-02-24 04:02:21.307444+00:00, run_duration=0.202854, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=251, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:02:17.380417+00:00, queued_by_job_id=208, pid=8179
[2026-02-24T12:02:24.769+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n2t_DAGs @ 2026-02-24 04:02:16.315580+00:00: manual__2026-02-24T04:02:16.315580+00:00, state:running, queued_at: 2026-02-24 04:02:16.335974+00:00. externally triggered: True> successful
[2026-02-24T12:02:24.770+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n2t_DAGs, execution_date=2026-02-24 04:02:16.315580+00:00, run_id=manual__2026-02-24T04:02:16.315580+00:00, run_start_date=2026-02-24 04:02:17.350390+00:00, run_end_date=2026-02-24 04:02:24.770434+00:00, run_duration=7.420044, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 04:02:16.315580+00:00, data_interval_end=2026-02-24 04:02:16.315580+00:00, dag_hash=a270c45e740615b98a97f7f70d3a8a7b
[2026-02-24T12:04:10.573+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:04:07.825997+00:00 [scheduled]>
[2026-02-24T12:04:10.574+0800] {scheduler_job_runner.py:507} INFO - DAG p_1p1n2t_DAGs has 0/16 running and queued tasks
[2026-02-24T12:04:10.575+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:04:07.825997+00:00 [scheduled]>
[2026-02-24T12:04:10.577+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:04:07.825997+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T12:04:10.578+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:04:07.825997+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T12:04:10.579+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:04:07.825997+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:04:10.581+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:04:07.825997+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:04:12.602+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T12:04:14.183+0800] {task_command.py:467} INFO - Running <TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:04:07.825997+00:00 [queued]> on host localhost-2.local
[2026-02-24T12:04:15.124+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:04:07.825997+00:00', try_number=1, map_index=-1)
[2026-02-24T12:04:15.133+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_1p1n2t_DAGs, task_id=p_1p1n2t_TASK, run_id=manual__2026-02-24T04:04:07.825997+00:00, map_index=-1, run_start_date=2026-02-24 04:04:14.261320+00:00, run_end_date=2026-02-24 04:04:14.469966+00:00, run_duration=0.208646, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=252, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:04:10.576335+00:00, queued_by_job_id=208, pid=8233
[2026-02-24T12:04:17.684+0800] {dagrun.py:854} INFO - Marking run <DagRun p_1p1n2t_DAGs @ 2026-02-24 04:04:07.825997+00:00: manual__2026-02-24T04:04:07.825997+00:00, state:running, queued_at: 2026-02-24 04:04:07.839352+00:00. externally triggered: True> successful
[2026-02-24T12:04:17.685+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_1p1n2t_DAGs, execution_date=2026-02-24 04:04:07.825997+00:00, run_id=manual__2026-02-24T04:04:07.825997+00:00, run_start_date=2026-02-24 04:04:10.551499+00:00, run_end_date=2026-02-24 04:04:17.685145+00:00, run_duration=7.133646, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 04:04:07.825997+00:00, data_interval_end=2026-02-24 04:04:07.825997+00:00, dag_hash=a270c45e740615b98a97f7f70d3a8a7b
[2026-02-24T12:04:17.694+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK1 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
[2026-02-24T12:04:17.695+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n2t has 0/16 running and queued tasks
[2026-02-24T12:04:17.696+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK1 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
[2026-02-24T12:04:17.698+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n2t.c_1p1n2t_TASK1 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T12:04:17.698+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK1', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T12:04:17.699+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK1', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:04:17.701+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK1', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:04:19.733+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T12:04:20.993+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n2t.c_1p1n2t_TASK1 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [queued]> on host localhost-2.local
[2026-02-24T12:04:21.903+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK1', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1)
[2026-02-24T12:04:21.912+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n2t, task_id=c_1p1n2t_TASK1, run_id=dataset_triggered__2026-02-24T04:04:14.489596+00:00, map_index=-1, run_start_date=2026-02-24 04:04:21.062298+00:00, run_end_date=2026-02-24 04:04:21.267076+00:00, run_duration=0.204778, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=253, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 04:04:17.696953+00:00, queued_by_job_id=208, pid=8236
[2026-02-24T12:04:21.939+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:04:25.290+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK2 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
[2026-02-24T12:04:25.292+0800] {scheduler_job_runner.py:507} INFO - DAG c_1p1n2t has 0/16 running and queued tasks
[2026-02-24T12:04:25.292+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK2 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
[2026-02-24T12:04:25.295+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n2t.c_1p1n2t_TASK2 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T12:04:25.296+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK2', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T12:04:25.296+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK2', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:04:25.298+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK2', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
[2026-02-24T12:04:27.425+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer /1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/producer_consumer 
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T12:04:28.634+0800] {task_command.py:467} INFO - Running <TaskInstance: c_1p1n2t.c_1p1n2t_TASK2 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [queued]> on host localhost-2.local
[2026-02-24T12:04:29.516+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK2', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1)
[2026-02-24T12:04:29.525+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_1p1n2t, task_id=c_1p1n2t_TASK2, run_id=dataset_triggered__2026-02-24T04:04:14.489596+00:00, map_index=-1, run_start_date=2026-02-24 04:04:28.702307+00:00, run_end_date=2026-02-24 04:04:28.894827+00:00, run_duration=0.19252, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=254, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:04:25.293823+00:00, queued_by_job_id=208, pid=8240
[2026-02-24T12:04:33.027+0800] {dagrun.py:854} INFO - Marking run <DagRun c_1p1n2t @ 2026-02-24 04:04:14.489596+00:00: dataset_triggered__2026-02-24T04:04:14.489596+00:00, state:running, queued_at: 2026-02-24 04:04:17.654551+00:00. externally triggered: False> successful
[2026-02-24T12:04:33.028+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_1p1n2t, execution_date=2026-02-24 04:04:14.489596+00:00, run_id=dataset_triggered__2026-02-24T04:04:14.489596+00:00, run_start_date=2026-02-24 04:04:17.670611+00:00, run_end_date=2026-02-24 04:04:33.028516+00:00, run_duration=15.357905, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 04:02:16.315580+00:00, data_interval_end=2026-02-24 04:04:07.825997+00:00, dag_hash=62e8b6b36b717686055a70f697d10f6c
[2026-02-24T12:09:23.268+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:14:23.918+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:19:24.332+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:24:25.149+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:29:27.380+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:34:28.330+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:39:29.665+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:44:30.724+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:49:33.793+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:54:34.154+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T12:59:35.533+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:04:41.355+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:09:45.521+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:14:46.906+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:19:49.991+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:24:50.022+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:29:52.125+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:34:54.223+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:39:55.041+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:44:57.944+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:49:58.885+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T13:55:02.336+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:00:04.637+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:05:06.947+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:10:08.203+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:15:09.735+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:20:10.030+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:25:12.605+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:29:28.837+0800] {manager.py:537} INFO - DAG p_cdrd_newUser is missing and will be deactivated.
[2026-02-24T14:29:28.840+0800] {manager.py:549} INFO - Deactivated 1 DAGs which are no longer present in file.
[2026-02-24T14:29:28.845+0800] {manager.py:553} INFO - Deleted DAG p_cdrd_newUser in serialized_dag table
[2026-02-24T14:30:17.539+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:35:19.722+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:40:20.919+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:45:22.276+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:50:25.234+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T14:55:28.035+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:00:29.450+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:05:31.893+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:10:33.880+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:15:35.044+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:20:38.097+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:25:39.251+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:27:02.518+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_1p1n2t_TASK manual__2026-02-24T07:26:58.766819+00:00 [scheduled]>
[2026-02-24T15:27:02.519+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T15:27:02.520+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_1p1n2t_TASK manual__2026-02-24T07:26:58.766819+00:00 [scheduled]>
[2026-02-24T15:27:02.522+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_1p1n2t_TASK manual__2026-02-24T07:26:58.766819+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:27:02.526+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T07:26:58.766819+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:27:02.527+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_1p1n2t_TASK', 'manual__2026-02-24T07:26:58.766819+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:27:02.530+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_1p1n2t_TASK', 'manual__2026-02-24T07:26:58.766819+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:27:04.743+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:27:07.161+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_1p1n2t_TASK manual__2026-02-24T07:26:58.766819+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:27:08.594+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T07:26:58.766819+00:00', try_number=1, map_index=-1)
[2026-02-24T15:27:08.604+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_1p1n2t_TASK, run_id=manual__2026-02-24T07:26:58.766819+00:00, map_index=-1, run_start_date=2026-02-24 07:27:07.233635+00:00, run_end_date=2026-02-24 07:27:07.797169+00:00, run_duration=0.563534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=255, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:27:02.521515+00:00, queued_by_job_id=208, pid=16080
[2026-02-24T15:27:11.520+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:26:58.766819+00:00: manual__2026-02-24T07:26:58.766819+00:00, state:running, queued_at: 2026-02-24 07:26:58.793392+00:00. externally triggered: True> successful
[2026-02-24T15:27:11.521+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:26:58.766819+00:00, run_id=manual__2026-02-24T07:26:58.766819+00:00, run_start_date=2026-02-24 07:27:02.493335+00:00, run_end_date=2026-02-24 07:27:11.521801+00:00, run_duration=9.028466, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 07:26:58.766819+00:00, dag_hash=98f4e7056a3b8e0f8abf30ba6b4eceb0
[2026-02-24T15:28:52.424+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:28:51.102548+00:00 [scheduled]>
[2026-02-24T15:28:52.425+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T15:28:52.426+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:28:51.102548+00:00 [scheduled]>
[2026-02-24T15:28:52.428+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:28:51.102548+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:28:52.431+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:28:51.102548+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:28:52.431+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:28:51.102548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:28:52.435+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:28:51.102548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:28:54.606+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:28:56.291+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:28:51.102548+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:28:57.585+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:28:51.102548+00:00', try_number=1, map_index=-1)
[2026-02-24T15:28:57.595+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:28:51.102548+00:00, map_index=-1, run_start_date=2026-02-24 07:28:56.363371+00:00, run_end_date=2026-02-24 07:28:56.878627+00:00, run_duration=0.515256, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=256, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:28:52.427520+00:00, queued_by_job_id=208, pid=16134
[2026-02-24T15:29:00.274+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:28:51.102548+00:00: manual__2026-02-24T07:28:51.102548+00:00, state:running, queued_at: 2026-02-24 07:28:51.115567+00:00. externally triggered: True> successful
[2026-02-24T15:29:00.275+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:28:51.102548+00:00, run_id=manual__2026-02-24T07:28:51.102548+00:00, run_start_date=2026-02-24 07:28:52.404965+00:00, run_end_date=2026-02-24 07:29:00.275519+00:00, run_duration=7.870554, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:28:51.102548+00:00, data_interval_end=2026-02-24 07:28:51.102548+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T15:30:40.231+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:30:44.105+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:30:40.865017+00:00 [scheduled]>
[2026-02-24T15:30:44.106+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T15:30:44.106+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:30:40.865017+00:00 [scheduled]>
[2026-02-24T15:30:44.109+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:30:40.865017+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:30:44.110+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:30:40.865017+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:30:44.111+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:30:40.865017+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:30:44.114+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:30:40.865017+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:30:46.261+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:30:48.154+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:30:40.865017+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:30:49.497+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:30:40.865017+00:00', try_number=1, map_index=-1)
[2026-02-24T15:30:49.506+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:30:40.865017+00:00, map_index=-1, run_start_date=2026-02-24 07:30:48.233106+00:00, run_end_date=2026-02-24 07:30:48.764702+00:00, run_duration=0.531596, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=257, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:30:44.108033+00:00, queued_by_job_id=208, pid=16195
[2026-02-24T15:30:52.111+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:30:40.865017+00:00: manual__2026-02-24T07:30:40.865017+00:00, state:running, queued_at: 2026-02-24 07:30:40.885388+00:00. externally triggered: True> successful
[2026-02-24T15:30:52.112+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:30:40.865017+00:00, run_id=manual__2026-02-24T07:30:40.865017+00:00, run_start_date=2026-02-24 07:30:44.084649+00:00, run_end_date=2026-02-24 07:30:52.112860+00:00, run_duration=8.028211, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:30:40.865017+00:00, data_interval_end=2026-02-24 07:30:40.865017+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T15:30:52.124+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
[2026-02-24T15:30:52.125+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:30:52.125+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
[2026-02-24T15:30:52.128+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:30:52.131+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T15:30:52.132+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:30:52.135+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:30:54.490+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:30:55.953+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:30:57.245+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1)
[2026-02-24T15:30:57.257+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:30:48.784706+00:00, map_index=-1, run_start_date=2026-02-24 07:30:56.021572+00:00, run_end_date=2026-02-24 07:30:56.488053+00:00, run_duration=0.466481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=258, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:30:52.126931+00:00, queued_by_job_id=208, pid=16198
[2026-02-24T15:31:00.096+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
[2026-02-24T15:31:00.097+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:31:00.098+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
[2026-02-24T15:31:00.100+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:31:00.102+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:31:00.103+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:31:00.106+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:31:02.344+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:31:03.880+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:31:05.141+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1)
[2026-02-24T15:31:05.150+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:30:48.784706+00:00, map_index=-1, run_start_date=2026-02-24 07:31:03.955956+00:00, run_end_date=2026-02-24 07:31:04.421463+00:00, run_duration=0.465507, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=259, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:31:00.099572+00:00, queued_by_job_id=208, pid=16207
[2026-02-24T15:31:08.191+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:30:48.784706+00:00: dataset_triggered__2026-02-24T07:30:48.784706+00:00, state:running, queued_at: 2026-02-24 07:30:52.077306+00:00. externally triggered: False> successful
[2026-02-24T15:31:08.192+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:30:48.784706+00:00, run_id=dataset_triggered__2026-02-24T07:30:48.784706+00:00, run_start_date=2026-02-24 07:30:52.095279+00:00, run_end_date=2026-02-24 07:31:08.192022+00:00, run_duration=16.096743, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 07:30:40.865017+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T15:33:16.333+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:33:14.106948+00:00 [scheduled]>
[2026-02-24T15:33:16.335+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T15:33:16.336+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:33:14.106948+00:00 [scheduled]>
[2026-02-24T15:33:16.338+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:33:14.106948+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:33:16.339+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:33:14.106948+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:33:16.340+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:33:14.106948+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:33:16.343+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:33:14.106948+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:33:18.484+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:33:20.318+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:33:14.106948+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:33:21.797+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:33:14.106948+00:00', try_number=1, map_index=-1)
[2026-02-24T15:33:21.807+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:33:14.106948+00:00, map_index=-1, run_start_date=2026-02-24 07:33:20.402141+00:00, run_end_date=2026-02-24 07:33:21.021691+00:00, run_duration=0.61955, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=260, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:33:16.337594+00:00, queued_by_job_id=208, pid=16290
[2026-02-24T15:33:24.557+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:33:14.106948+00:00: manual__2026-02-24T07:33:14.106948+00:00, state:running, queued_at: 2026-02-24 07:33:14.119261+00:00. externally triggered: True> successful
[2026-02-24T15:33:24.558+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:33:14.106948+00:00, run_id=manual__2026-02-24T07:33:14.106948+00:00, run_start_date=2026-02-24 07:33:16.312795+00:00, run_end_date=2026-02-24 07:33:24.558238+00:00, run_duration=8.245443, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:33:14.106948+00:00, data_interval_end=2026-02-24 07:33:14.106948+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T15:33:24.569+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
[2026-02-24T15:33:24.570+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:33:24.570+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
[2026-02-24T15:33:24.573+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:33:24.574+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T15:33:24.575+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:33:24.578+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:33:26.731+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:33:28.368+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:33:29.980+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1)
[2026-02-24T15:33:29.991+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:33:21.044248+00:00, map_index=-1, run_start_date=2026-02-24 07:33:28.447381+00:00, run_end_date=2026-02-24 07:33:29.089560+00:00, run_duration=0.642179, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=261, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:33:24.572057+00:00, queued_by_job_id=208, pid=16293
[2026-02-24T15:33:32.867+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
[2026-02-24T15:33:32.868+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:33:32.869+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
[2026-02-24T15:33:32.871+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:33:32.873+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:33:32.875+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:33:32.878+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:33:35.398+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:33:36.986+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:33:38.318+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1)
[2026-02-24T15:33:38.328+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:33:21.044248+00:00, map_index=-1, run_start_date=2026-02-24 07:33:37.072577+00:00, run_end_date=2026-02-24 07:33:37.537020+00:00, run_duration=0.464443, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=262, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:33:32.870313+00:00, queued_by_job_id=208, pid=16301
[2026-02-24T15:33:41.733+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:33:21.044248+00:00: dataset_triggered__2026-02-24T07:33:21.044248+00:00, state:running, queued_at: 2026-02-24 07:33:24.523761+00:00. externally triggered: False> successful
[2026-02-24T15:33:41.734+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:33:21.044248+00:00, run_id=dataset_triggered__2026-02-24T07:33:21.044248+00:00, run_start_date=2026-02-24 07:33:24.541524+00:00, run_end_date=2026-02-24 07:33:41.734797+00:00, run_duration=17.193273, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:33:14.106948+00:00, data_interval_end=2026-02-24 07:33:14.106948+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T15:34:36.551+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:34:32.175427+00:00 [scheduled]>
[2026-02-24T15:34:36.552+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T15:34:36.553+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:34:32.175427+00:00 [scheduled]>
[2026-02-24T15:34:36.556+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:34:32.175427+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:34:36.557+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:34:32.175427+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:34:36.558+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:34:32.175427+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:34:36.561+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:34:32.175427+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:34:38.746+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:34:40.362+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:34:32.175427+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:34:41.766+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:34:32.175427+00:00', try_number=1, map_index=-1)
[2026-02-24T15:34:41.776+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:34:32.175427+00:00, map_index=-1, run_start_date=2026-02-24 07:34:40.440703+00:00, run_end_date=2026-02-24 07:34:40.977232+00:00, run_duration=0.536529, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=263, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:34:36.555298+00:00, queued_by_job_id=208, pid=16333
[2026-02-24T15:34:44.909+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:34:32.175427+00:00: manual__2026-02-24T07:34:32.175427+00:00, state:running, queued_at: 2026-02-24 07:34:32.194969+00:00. externally triggered: True> successful
[2026-02-24T15:34:44.910+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:34:32.175427+00:00, run_id=manual__2026-02-24T07:34:32.175427+00:00, run_start_date=2026-02-24 07:34:36.529825+00:00, run_end_date=2026-02-24 07:34:44.910730+00:00, run_duration=8.380905, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:34:32.175427+00:00, data_interval_end=2026-02-24 07:34:32.175427+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T15:34:44.923+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
[2026-02-24T15:34:44.924+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:34:44.925+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
[2026-02-24T15:34:44.927+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:34:44.928+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T15:34:44.929+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:34:44.932+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:34:47.188+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:34:48.694+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:34:50.052+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1)
[2026-02-24T15:34:50.061+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:34:40.995967+00:00, map_index=-1, run_start_date=2026-02-24 07:34:48.766215+00:00, run_end_date=2026-02-24 07:34:49.297215+00:00, run_duration=0.531, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=264, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:34:44.926045+00:00, queued_by_job_id=208, pid=16337
[2026-02-24T15:34:53.197+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
[2026-02-24T15:34:53.198+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:34:53.199+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
[2026-02-24T15:34:53.201+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:34:53.202+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:34:53.203+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:34:53.205+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:34:55.377+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:34:56.886+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:34:58.181+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1)
[2026-02-24T15:34:58.191+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:34:40.995967+00:00, map_index=-1, run_start_date=2026-02-24 07:34:56.964234+00:00, run_end_date=2026-02-24 07:34:57.415604+00:00, run_duration=0.45137, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=265, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:34:53.199925+00:00, queued_by_job_id=208, pid=16340
[2026-02-24T15:35:01.239+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:34:40.995967+00:00: dataset_triggered__2026-02-24T07:34:40.995967+00:00, state:running, queued_at: 2026-02-24 07:34:44.875512+00:00. externally triggered: False> successful
[2026-02-24T15:35:01.240+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:34:40.995967+00:00, run_id=dataset_triggered__2026-02-24T07:34:40.995967+00:00, run_start_date=2026-02-24 07:34:44.893469+00:00, run_end_date=2026-02-24 07:35:01.240410+00:00, run_duration=16.346941, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:34:32.175427+00:00, data_interval_end=2026-02-24 07:34:32.175427+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T15:35:42.865+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:40:45.347+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:45:46.840+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:50:50.213+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:55:53.010+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T15:58:04.728+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:03.932405+00:00 [scheduled]>
[2026-02-24T15:58:04.729+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T15:58:04.730+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:03.932405+00:00 [scheduled]>
[2026-02-24T15:58:04.734+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:03.932405+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:58:04.735+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:03.932405+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:58:04.735+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:03.932405+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:58:04.738+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:03.932405+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:58:07.015+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:58:08.861+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:03.932405+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:58:10.188+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:03.932405+00:00', try_number=1, map_index=-1)
[2026-02-24T15:58:10.201+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:58:03.932405+00:00, map_index=-1, run_start_date=2026-02-24 07:58:08.937943+00:00, run_end_date=2026-02-24 07:58:09.455877+00:00, run_duration=0.517934, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=266, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:58:04.731400+00:00, queued_by_job_id=208, pid=17039
[2026-02-24T15:58:13.890+0800] {dagrun.py:823} ERROR - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:58:03.932405+00:00: manual__2026-02-24T07:58:03.932405+00:00, state:running, queued_at: 2026-02-24 07:58:03.946906+00:00. externally triggered: True> failed
[2026-02-24T15:58:13.892+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:58:03.932405+00:00, run_id=manual__2026-02-24T07:58:03.932405+00:00, run_start_date=2026-02-24 07:58:04.701436+00:00, run_end_date=2026-02-24 07:58:13.891966+00:00, run_duration=9.19053, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:58:03.932405+00:00, data_interval_end=2026-02-24 07:58:03.932405+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T15:59:01.370+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:58.235400+00:00 [scheduled]>
[2026-02-24T15:59:01.371+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T15:59:01.371+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:58.235400+00:00 [scheduled]>
[2026-02-24T15:59:01.373+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:58.235400+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:59:01.375+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:58.235400+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:59:01.375+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:58.235400+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:59:01.378+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:58.235400+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:59:03.783+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:59:05.576+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:58.235400+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:59:06.947+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:58.235400+00:00', try_number=1, map_index=-1)
[2026-02-24T15:59:06.959+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:58:58.235400+00:00, map_index=-1, run_start_date=2026-02-24 07:59:05.651614+00:00, run_end_date=2026-02-24 07:59:06.203149+00:00, run_duration=0.551535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=267, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:59:01.372870+00:00, queued_by_job_id=208, pid=17074
[2026-02-24T15:59:09.591+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:58:58.235400+00:00: manual__2026-02-24T07:58:58.235400+00:00, state:running, queued_at: 2026-02-24 07:58:58.252017+00:00. externally triggered: True> successful
[2026-02-24T15:59:09.592+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:58:58.235400+00:00, run_id=manual__2026-02-24T07:58:58.235400+00:00, run_start_date=2026-02-24 07:59:01.346713+00:00, run_end_date=2026-02-24 07:59:09.592034+00:00, run_duration=8.245321, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:58:58.235400+00:00, data_interval_end=2026-02-24 07:58:58.235400+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T15:59:09.603+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
[2026-02-24T15:59:09.604+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:59:09.605+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
[2026-02-24T15:59:09.607+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:59:09.608+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T15:59:09.609+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:59:09.611+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:59:11.868+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:59:13.358+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:59:14.680+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1)
[2026-02-24T15:59:14.691+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:59:06.225233+00:00, map_index=-1, run_start_date=2026-02-24 07:59:13.430306+00:00, run_end_date=2026-02-24 07:59:13.938778+00:00, run_duration=0.508472, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=268, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:59:09.606273+00:00, queued_by_job_id=208, pid=17077
[2026-02-24T15:59:18.241+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
[2026-02-24T15:59:18.242+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T15:59:18.243+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
[2026-02-24T15:59:18.246+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T15:59:18.247+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T15:59:18.248+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:59:18.251+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T15:59:20.590+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T15:59:22.129+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [queued]> on host localhost-2.local
[2026-02-24T15:59:23.476+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1)
[2026-02-24T15:59:23.488+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:59:06.225233+00:00, map_index=-1, run_start_date=2026-02-24 07:59:22.209780+00:00, run_end_date=2026-02-24 07:59:22.758051+00:00, run_duration=0.548271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=269, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:59:18.244739+00:00, queued_by_job_id=208, pid=17080
[2026-02-24T15:59:27.360+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:59:06.225233+00:00: dataset_triggered__2026-02-24T07:59:06.225233+00:00, state:running, queued_at: 2026-02-24 07:59:09.559120+00:00. externally triggered: False> successful
[2026-02-24T15:59:27.361+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:59:06.225233+00:00, run_id=dataset_triggered__2026-02-24T07:59:06.225233+00:00, run_start_date=2026-02-24 07:59:09.575809+00:00, run_end_date=2026-02-24 07:59:27.361109+00:00, run_duration=17.7853, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:58:58.235400+00:00, data_interval_end=2026-02-24 07:58:58.235400+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:00:55.503+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:02:13.974+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:02:10.947235+00:00 [scheduled]>
[2026-02-24T16:02:13.975+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:02:13.976+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:02:10.947235+00:00 [scheduled]>
[2026-02-24T16:02:13.978+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:02:10.947235+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:02:13.979+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:02:10.947235+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:02:13.980+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:02:10.947235+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:02:13.982+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:02:10.947235+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:02:16.137+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:02:18.090+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:02:10.947235+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:02:19.460+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:02:10.947235+00:00', try_number=1, map_index=-1)
[2026-02-24T16:02:19.471+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:02:10.947235+00:00, map_index=-1, run_start_date=2026-02-24 08:02:18.166064+00:00, run_end_date=2026-02-24 08:02:18.709079+00:00, run_duration=0.543015, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=270, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:02:13.977253+00:00, queued_by_job_id=208, pid=17235
[2026-02-24T16:02:23.065+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:02:10.947235+00:00: manual__2026-02-24T08:02:10.947235+00:00, state:running, queued_at: 2026-02-24 08:02:10.965773+00:00. externally triggered: True> successful
[2026-02-24T16:02:23.066+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:02:10.947235+00:00, run_id=manual__2026-02-24T08:02:10.947235+00:00, run_start_date=2026-02-24 08:02:13.951841+00:00, run_end_date=2026-02-24 08:02:23.066827+00:00, run_duration=9.114986, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:02:10.947235+00:00, data_interval_end=2026-02-24 08:02:10.947235+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:02:23.077+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
[2026-02-24T16:02:23.078+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:02:23.078+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
[2026-02-24T16:02:23.081+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:02:23.082+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:02:23.082+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:02:23.085+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:02:25.336+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:02:26.779+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:02:28.049+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1)
[2026-02-24T16:02:28.062+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:02:18.727987+00:00, map_index=-1, run_start_date=2026-02-24 08:02:26.848805+00:00, run_end_date=2026-02-24 08:02:27.297173+00:00, run_duration=0.448368, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=271, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:02:23.079906+00:00, queued_by_job_id=208, pid=17240
[2026-02-24T16:02:31.606+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
[2026-02-24T16:02:31.607+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:02:31.608+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
[2026-02-24T16:02:31.610+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:02:31.612+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:02:31.612+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:02:31.615+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:02:33.825+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:02:35.270+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:02:36.564+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1)
[2026-02-24T16:02:36.576+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:02:18.727987+00:00, map_index=-1, run_start_date=2026-02-24 08:02:35.363016+00:00, run_end_date=2026-02-24 08:02:35.813831+00:00, run_duration=0.450815, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=272, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:02:31.609709+00:00, queued_by_job_id=208, pid=17244
[2026-02-24T16:02:40.298+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:02:18.727987+00:00: dataset_triggered__2026-02-24T08:02:18.727987+00:00, state:running, queued_at: 2026-02-24 08:02:23.033576+00:00. externally triggered: False> successful
[2026-02-24T16:02:40.299+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:02:18.727987+00:00, run_id=dataset_triggered__2026-02-24T08:02:18.727987+00:00, run_start_date=2026-02-24 08:02:23.050961+00:00, run_end_date=2026-02-24 08:02:40.299417+00:00, run_duration=17.248456, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:02:10.947235+00:00, data_interval_end=2026-02-24 08:02:10.947235+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:03:27.857+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:03:25.307661+00:00 [scheduled]>
[2026-02-24T16:03:27.859+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:03:27.859+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:03:25.307661+00:00 [scheduled]>
[2026-02-24T16:03:27.862+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:03:25.307661+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:03:27.863+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:03:25.307661+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:03:27.864+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:03:25.307661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:03:27.866+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:03:25.307661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:03:30.063+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:03:31.763+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:03:25.307661+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:03:33.093+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:03:25.307661+00:00', try_number=1, map_index=-1)
[2026-02-24T16:03:33.105+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:03:25.307661+00:00, map_index=-1, run_start_date=2026-02-24 08:03:31.839974+00:00, run_end_date=2026-02-24 08:03:32.378739+00:00, run_duration=0.538765, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=273, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:03:27.861085+00:00, queued_by_job_id=208, pid=17283
[2026-02-24T16:03:36.678+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:03:25.307661+00:00: manual__2026-02-24T08:03:25.307661+00:00, state:running, queued_at: 2026-02-24 08:03:25.320183+00:00. externally triggered: True> successful
[2026-02-24T16:03:36.679+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:03:25.307661+00:00, run_id=manual__2026-02-24T08:03:25.307661+00:00, run_start_date=2026-02-24 08:03:27.831856+00:00, run_end_date=2026-02-24 08:03:36.679587+00:00, run_duration=8.847731, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:03:25.307661+00:00, data_interval_end=2026-02-24 08:03:25.307661+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:03:36.690+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
[2026-02-24T16:03:36.691+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:03:36.692+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
[2026-02-24T16:03:36.694+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:03:36.695+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:03:36.696+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:03:36.699+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:03:38.988+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:03:40.499+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:03:41.703+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1)
[2026-02-24T16:03:41.713+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:03:32.398970+00:00, map_index=-1, run_start_date=2026-02-24 08:03:40.578448+00:00, run_end_date=2026-02-24 08:03:41.024692+00:00, run_duration=0.446244, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=274, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:03:36.693088+00:00, queued_by_job_id=208, pid=17293
[2026-02-24T16:03:44.713+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
[2026-02-24T16:03:44.715+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:03:44.715+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
[2026-02-24T16:03:44.718+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:03:44.720+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:03:44.721+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:03:44.723+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:03:47.027+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:03:48.765+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:03:50.140+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1)
[2026-02-24T16:03:50.153+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:03:32.398970+00:00, map_index=-1, run_start_date=2026-02-24 08:03:48.867388+00:00, run_end_date=2026-02-24 08:03:49.406526+00:00, run_duration=0.539138, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=275, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:03:44.717014+00:00, queued_by_job_id=208, pid=17297
[2026-02-24T16:03:53.437+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:03:32.398970+00:00: dataset_triggered__2026-02-24T08:03:32.398970+00:00, state:running, queued_at: 2026-02-24 08:03:36.649314+00:00. externally triggered: False> successful
[2026-02-24T16:03:53.439+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:03:32.398970+00:00, run_id=dataset_triggered__2026-02-24T08:03:32.398970+00:00, run_start_date=2026-02-24 08:03:36.664224+00:00, run_end_date=2026-02-24 08:03:53.438939+00:00, run_duration=16.774715, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:03:25.307661+00:00, data_interval_end=2026-02-24 08:03:25.307661+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:05:57.671+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:06:16.963+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:06:14.548837+00:00 [scheduled]>
[2026-02-24T16:06:16.964+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:06:16.965+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:06:14.548837+00:00 [scheduled]>
[2026-02-24T16:06:16.968+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:06:14.548837+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:06:16.969+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:06:14.548837+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:06:16.970+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:06:14.548837+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:06:16.975+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:06:14.548837+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:06:19.752+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:06:21.942+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:06:14.548837+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:06:23.392+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:06:14.548837+00:00', try_number=1, map_index=-1)
[2026-02-24T16:06:23.404+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:06:14.548837+00:00, map_index=-1, run_start_date=2026-02-24 08:06:22.039945+00:00, run_end_date=2026-02-24 08:06:22.627789+00:00, run_duration=0.587844, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=276, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:06:16.967061+00:00, queued_by_job_id=208, pid=17409
[2026-02-24T16:06:27.077+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:06:14.548837+00:00: manual__2026-02-24T08:06:14.548837+00:00, state:running, queued_at: 2026-02-24 08:06:14.561606+00:00. externally triggered: True> successful
[2026-02-24T16:06:27.078+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:06:14.548837+00:00, run_id=manual__2026-02-24T08:06:14.548837+00:00, run_start_date=2026-02-24 08:06:16.939065+00:00, run_end_date=2026-02-24 08:06:27.078682+00:00, run_duration=10.139617, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:06:14.548837+00:00, data_interval_end=2026-02-24 08:06:14.548837+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:06:27.090+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
[2026-02-24T16:06:27.091+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:06:27.092+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
[2026-02-24T16:06:27.094+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:06:27.095+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:06:27.097+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:06:27.099+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:06:29.353+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:06:30.811+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:06:32.058+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1)
[2026-02-24T16:06:32.069+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:06:22.647848+00:00, map_index=-1, run_start_date=2026-02-24 08:06:30.883685+00:00, run_end_date=2026-02-24 08:06:31.335049+00:00, run_duration=0.451364, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:06:27.093400+00:00, queued_by_job_id=208, pid=17419
[2026-02-24T16:06:35.817+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
[2026-02-24T16:06:35.819+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:06:35.820+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
[2026-02-24T16:06:35.822+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:06:35.823+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:06:35.824+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:06:35.827+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:06:37.984+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:06:39.536+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:06:40.750+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1)
[2026-02-24T16:06:40.761+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:06:22.647848+00:00, map_index=-1, run_start_date=2026-02-24 08:06:39.614460+00:00, run_end_date=2026-02-24 08:06:40.058741+00:00, run_duration=0.444281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=278, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:06:35.821078+00:00, queued_by_job_id=208, pid=17425
[2026-02-24T16:06:44.545+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:06:22.647848+00:00: dataset_triggered__2026-02-24T08:06:22.647848+00:00, state:running, queued_at: 2026-02-24 08:06:27.042280+00:00. externally triggered: False> successful
[2026-02-24T16:06:44.547+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:06:22.647848+00:00, run_id=dataset_triggered__2026-02-24T08:06:22.647848+00:00, run_start_date=2026-02-24 08:06:27.061167+00:00, run_end_date=2026-02-24 08:06:44.546906+00:00, run_duration=17.485739, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:06:14.548837+00:00, data_interval_end=2026-02-24 08:06:14.548837+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:09:26.701+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:09:24.784213+00:00 [scheduled]>
[2026-02-24T16:09:26.702+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:09:26.703+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:09:24.784213+00:00 [scheduled]>
[2026-02-24T16:09:26.705+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:09:24.784213+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:09:26.706+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:09:24.784213+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:09:26.707+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:09:24.784213+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:09:26.709+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:09:24.784213+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:09:28.989+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:09:30.815+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:09:24.784213+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:09:32.206+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:09:24.784213+00:00', try_number=1, map_index=-1)
[2026-02-24T16:09:32.217+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:09:24.784213+00:00, map_index=-1, run_start_date=2026-02-24 08:09:30.892087+00:00, run_end_date=2026-02-24 08:09:31.459780+00:00, run_duration=0.567693, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=279, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:09:26.704245+00:00, queued_by_job_id=208, pid=17522
[2026-02-24T16:09:35.111+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:09:24.784213+00:00: manual__2026-02-24T08:09:24.784213+00:00, state:running, queued_at: 2026-02-24 08:09:24.797695+00:00. externally triggered: True> successful
[2026-02-24T16:09:35.113+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:09:24.784213+00:00, run_id=manual__2026-02-24T08:09:24.784213+00:00, run_start_date=2026-02-24 08:09:26.683092+00:00, run_end_date=2026-02-24 08:09:35.112938+00:00, run_duration=8.429846, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:09:24.784213+00:00, data_interval_end=2026-02-24 08:09:24.784213+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:09:35.123+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
[2026-02-24T16:09:35.124+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:09:35.125+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
[2026-02-24T16:09:35.128+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:09:35.129+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:09:35.130+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:09:35.133+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:09:37.338+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:09:38.887+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:09:40.133+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1)
[2026-02-24T16:09:40.144+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:09:31.479340+00:00, map_index=-1, run_start_date=2026-02-24 08:09:38.960696+00:00, run_end_date=2026-02-24 08:09:39.417156+00:00, run_duration=0.45646, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=280, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:09:35.126788+00:00, queued_by_job_id=208, pid=17525
[2026-02-24T16:09:42.793+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
[2026-02-24T16:09:42.794+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:09:42.795+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
[2026-02-24T16:09:42.798+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:09:42.799+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:09:42.800+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:09:42.803+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:09:45.219+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:09:46.669+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:09:47.909+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1)
[2026-02-24T16:09:47.921+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:09:31.479340+00:00, map_index=-1, run_start_date=2026-02-24 08:09:46.746106+00:00, run_end_date=2026-02-24 08:09:47.184585+00:00, run_duration=0.438479, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=281, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:09:42.797214+00:00, queued_by_job_id=208, pid=17541
[2026-02-24T16:09:50.703+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:09:31.479340+00:00: dataset_triggered__2026-02-24T08:09:31.479340+00:00, state:running, queued_at: 2026-02-24 08:09:35.079081+00:00. externally triggered: False> successful
[2026-02-24T16:09:50.704+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:09:31.479340+00:00, run_id=dataset_triggered__2026-02-24T08:09:31.479340+00:00, run_start_date=2026-02-24 08:09:35.096215+00:00, run_end_date=2026-02-24 08:09:50.704602+00:00, run_duration=15.608387, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:09:24.784213+00:00, data_interval_end=2026-02-24 08:09:24.784213+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:11:00.843+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:11:48.528+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:11:46.761729+00:00 [scheduled]>
[2026-02-24T16:11:48.529+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:11:48.530+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:11:46.761729+00:00 [scheduled]>
[2026-02-24T16:11:48.532+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:11:46.761729+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:11:48.533+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:11:46.761729+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:11:48.534+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:11:46.761729+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:11:48.536+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:11:46.761729+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:11:50.720+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:11:52.384+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:11:46.761729+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:11:53.762+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:11:46.761729+00:00', try_number=1, map_index=-1)
[2026-02-24T16:11:53.773+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:11:46.761729+00:00, map_index=-1, run_start_date=2026-02-24 08:11:52.454928+00:00, run_end_date=2026-02-24 08:11:52.988042+00:00, run_duration=0.533114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=282, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:11:48.530968+00:00, queued_by_job_id=208, pid=17642
[2026-02-24T16:11:56.425+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:11:46.761729+00:00: manual__2026-02-24T08:11:46.761729+00:00, state:running, queued_at: 2026-02-24 08:11:46.774015+00:00. externally triggered: True> successful
[2026-02-24T16:11:56.426+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:11:46.761729+00:00, run_id=manual__2026-02-24T08:11:46.761729+00:00, run_start_date=2026-02-24 08:11:48.506455+00:00, run_end_date=2026-02-24 08:11:56.426195+00:00, run_duration=7.91974, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:11:46.761729+00:00, data_interval_end=2026-02-24 08:11:46.761729+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:11:56.437+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
[2026-02-24T16:11:56.438+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:11:56.439+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
[2026-02-24T16:11:56.441+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:11:56.443+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:11:56.443+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:11:56.447+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:11:58.631+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:12:00.152+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:12:01.424+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1)
[2026-02-24T16:12:01.434+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:11:53.008824+00:00, map_index=-1, run_start_date=2026-02-24 08:12:00.228846+00:00, run_end_date=2026-02-24 08:12:00.686924+00:00, run_duration=0.458078, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=283, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:11:56.440337+00:00, queued_by_job_id=208, pid=17645
[2026-02-24T16:12:04.247+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
[2026-02-24T16:12:04.248+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:12:04.249+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
[2026-02-24T16:12:04.252+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:12:04.254+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:12:04.255+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:12:04.257+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:12:06.573+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:12:08.317+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:12:09.750+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1)
[2026-02-24T16:12:09.762+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:11:53.008824+00:00, map_index=-1, run_start_date=2026-02-24 08:12:08.397985+00:00, run_end_date=2026-02-24 08:12:08.882569+00:00, run_duration=0.484584, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=284, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:12:04.250987+00:00, queued_by_job_id=208, pid=17651
[2026-02-24T16:12:12.658+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:11:53.008824+00:00: dataset_triggered__2026-02-24T08:11:53.008824+00:00, state:running, queued_at: 2026-02-24 08:11:56.393171+00:00. externally triggered: False> successful
[2026-02-24T16:12:12.660+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:11:53.008824+00:00, run_id=dataset_triggered__2026-02-24T08:11:53.008824+00:00, run_start_date=2026-02-24 08:11:56.409780+00:00, run_end_date=2026-02-24 08:12:12.659934+00:00, run_duration=16.250154, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:11:46.761729+00:00, data_interval_end=2026-02-24 08:11:46.761729+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:16:04.769+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:18:02.612+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:18:00.484964+00:00 [scheduled]>
[2026-02-24T16:18:02.614+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:18:02.615+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:18:00.484964+00:00 [scheduled]>
[2026-02-24T16:18:02.617+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:18:00.484964+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:18:02.619+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:18:00.484964+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:18:02.619+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:18:00.484964+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:18:02.622+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:18:00.484964+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:18:04.976+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:18:06.821+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:18:00.484964+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:18:08.159+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:18:00.484964+00:00', try_number=1, map_index=-1)
[2026-02-24T16:18:08.170+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:18:00.484964+00:00, map_index=-1, run_start_date=2026-02-24 08:18:06.895003+00:00, run_end_date=2026-02-24 08:18:07.427383+00:00, run_duration=0.53238, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=285, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:18:02.616347+00:00, queued_by_job_id=208, pid=17836
[2026-02-24T16:18:10.931+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:18:00.484964+00:00: manual__2026-02-24T08:18:00.484964+00:00, state:running, queued_at: 2026-02-24 08:18:00.497863+00:00. externally triggered: True> successful
[2026-02-24T16:18:10.932+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:18:00.484964+00:00, run_id=manual__2026-02-24T08:18:00.484964+00:00, run_start_date=2026-02-24 08:18:02.592841+00:00, run_end_date=2026-02-24 08:18:10.932201+00:00, run_duration=8.33936, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:18:00.484964+00:00, data_interval_end=2026-02-24 08:18:00.484964+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:18:10.943+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
[2026-02-24T16:18:10.944+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:18:10.944+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
[2026-02-24T16:18:10.947+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:18:10.948+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:18:10.948+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:18:10.951+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:18:13.345+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:18:14.860+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:18:16.154+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1)
[2026-02-24T16:18:16.164+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:18:07.446791+00:00, map_index=-1, run_start_date=2026-02-24 08:18:14.932685+00:00, run_end_date=2026-02-24 08:18:15.374382+00:00, run_duration=0.441697, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=286, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:18:10.945981+00:00, queued_by_job_id=208, pid=17839
[2026-02-24T16:18:19.009+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
[2026-02-24T16:18:19.010+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:18:19.011+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
[2026-02-24T16:18:19.013+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:18:19.014+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:18:19.015+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:18:19.018+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:18:21.709+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:18:23.382+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:18:24.737+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1)
[2026-02-24T16:18:24.749+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:18:07.446791+00:00, map_index=-1, run_start_date=2026-02-24 08:18:23.502102+00:00, run_end_date=2026-02-24 08:18:23.969578+00:00, run_duration=0.467476, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=287, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:18:19.012487+00:00, queued_by_job_id=208, pid=17843
[2026-02-24T16:18:27.913+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:18:07.446791+00:00: dataset_triggered__2026-02-24T08:18:07.446791+00:00, state:running, queued_at: 2026-02-24 08:18:10.901465+00:00. externally triggered: False> successful
[2026-02-24T16:18:27.914+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:18:07.446791+00:00, run_id=dataset_triggered__2026-02-24T08:18:07.446791+00:00, run_start_date=2026-02-24 08:18:10.916664+00:00, run_end_date=2026-02-24 08:18:27.914094+00:00, run_duration=16.99743, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:18:00.484964+00:00, data_interval_end=2026-02-24 08:18:00.484964+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:20:41.264+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:20:38.481972+00:00 [scheduled]>
[2026-02-24T16:20:41.265+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:20:41.266+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:20:38.481972+00:00 [scheduled]>
[2026-02-24T16:20:41.268+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:20:38.481972+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:20:41.269+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:20:38.481972+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:20:41.270+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:20:38.481972+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:20:41.272+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:20:38.481972+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:20:43.681+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:20:45.650+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:20:38.481972+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:20:47.049+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:20:38.481972+00:00', try_number=1, map_index=-1)
[2026-02-24T16:20:47.061+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:20:38.481972+00:00, map_index=-1, run_start_date=2026-02-24 08:20:45.729342+00:00, run_end_date=2026-02-24 08:20:46.329463+00:00, run_duration=0.600121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=288, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:20:41.267413+00:00, queued_by_job_id=208, pid=17939
[2026-02-24T16:20:49.772+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:20:38.481972+00:00: manual__2026-02-24T08:20:38.481972+00:00, state:running, queued_at: 2026-02-24 08:20:38.494859+00:00. externally triggered: True> successful
[2026-02-24T16:20:49.773+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:20:38.481972+00:00, run_id=manual__2026-02-24T08:20:38.481972+00:00, run_start_date=2026-02-24 08:20:41.242794+00:00, run_end_date=2026-02-24 08:20:49.773133+00:00, run_duration=8.530339, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:20:38.481972+00:00, data_interval_end=2026-02-24 08:20:38.481972+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:20:49.784+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
[2026-02-24T16:20:49.785+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:20:49.786+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
[2026-02-24T16:20:49.788+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:20:49.789+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:20:49.790+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:20:49.792+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:20:52.057+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:20:53.610+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:20:54.792+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1)
[2026-02-24T16:20:54.802+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:20:46.350292+00:00, map_index=-1, run_start_date=2026-02-24 08:20:53.678735+00:00, run_end_date=2026-02-24 08:20:54.125303+00:00, run_duration=0.446568, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=289, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:20:49.787151+00:00, queued_by_job_id=208, pid=17942
[2026-02-24T16:20:58.916+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
[2026-02-24T16:20:58.917+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:20:58.918+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
[2026-02-24T16:20:58.920+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:20:58.922+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:20:58.923+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:20:58.925+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:21:01.660+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:21:03.405+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:21:04.680+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1)
[2026-02-24T16:21:04.691+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:20:46.350292+00:00, map_index=-1, run_start_date=2026-02-24 08:21:03.481684+00:00, run_end_date=2026-02-24 08:21:03.927989+00:00, run_duration=0.446305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=290, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:20:58.919687+00:00, queued_by_job_id=208, pid=17949
[2026-02-24T16:21:07.547+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:20:46.350292+00:00: dataset_triggered__2026-02-24T08:20:46.350292+00:00, state:running, queued_at: 2026-02-24 08:20:49.738139+00:00. externally triggered: False> successful
[2026-02-24T16:21:07.548+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:20:46.350292+00:00, run_id=dataset_triggered__2026-02-24T08:20:46.350292+00:00, run_start_date=2026-02-24 08:20:49.755264+00:00, run_end_date=2026-02-24 08:21:07.548578+00:00, run_duration=17.793314, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:20:38.481972+00:00, data_interval_end=2026-02-24 08:20:38.481972+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:21:07.571+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:26:10.553+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:26:46.736+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:26:42.181391+00:00 [scheduled]>
[2026-02-24T16:26:46.737+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:26:46.738+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:26:42.181391+00:00 [scheduled]>
[2026-02-24T16:26:46.740+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:26:42.181391+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:26:46.741+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:26:42.181391+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:26:46.742+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:26:42.181391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:26:46.745+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:26:42.181391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:26:48.971+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:26:50.886+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:26:42.181391+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:26:52.230+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:26:42.181391+00:00', try_number=1, map_index=-1)
[2026-02-24T16:26:52.239+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:26:42.181391+00:00, map_index=-1, run_start_date=2026-02-24 08:26:50.964642+00:00, run_end_date=2026-02-24 08:26:51.473880+00:00, run_duration=0.509238, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=291, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:26:46.739693+00:00, queued_by_job_id=208, pid=18191
[2026-02-24T16:26:55.850+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:26:42.181391+00:00: manual__2026-02-24T08:26:42.181391+00:00, state:running, queued_at: 2026-02-24 08:26:42.193726+00:00. externally triggered: True> successful
[2026-02-24T16:26:55.851+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:26:42.181391+00:00, run_id=manual__2026-02-24T08:26:42.181391+00:00, run_start_date=2026-02-24 08:26:46.714246+00:00, run_end_date=2026-02-24 08:26:55.851232+00:00, run_duration=9.136986, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:26:42.181391+00:00, data_interval_end=2026-02-24 08:26:42.181391+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:26:55.864+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
[2026-02-24T16:26:55.866+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:26:55.866+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
[2026-02-24T16:26:55.869+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:26:55.871+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-24T16:26:55.872+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:26:55.874+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:26:58.255+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:26:59.722+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:27:00.965+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1)
[2026-02-24T16:27:00.977+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:26:51.493847+00:00, map_index=-1, run_start_date=2026-02-24 08:26:59.792283+00:00, run_end_date=2026-02-24 08:27:00.257898+00:00, run_duration=0.465615, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=292, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:26:55.868126+00:00, queued_by_job_id=208, pid=18199
[2026-02-24T16:27:03.797+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
[2026-02-24T16:27:03.798+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd has 0/16 running and queued tasks
[2026-02-24T16:27:03.799+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
[2026-02-24T16:27:03.801+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:27:03.802+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:27:03.803+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:27:03.806+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:27:05.961+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:27:07.493+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:27:08.779+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1)
[2026-02-24T16:27:08.788+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:26:51.493847+00:00, map_index=-1, run_start_date=2026-02-24 08:27:07.574829+00:00, run_end_date=2026-02-24 08:27:08.032543+00:00, run_duration=0.457714, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=293, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:27:03.800346+00:00, queued_by_job_id=208, pid=18206
[2026-02-24T16:27:11.881+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:26:51.493847+00:00: dataset_triggered__2026-02-24T08:26:51.493847+00:00, state:running, queued_at: 2026-02-24 08:26:55.813998+00:00. externally triggered: False> successful
[2026-02-24T16:27:11.882+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:26:51.493847+00:00, run_id=dataset_triggered__2026-02-24T08:26:51.493847+00:00, run_start_date=2026-02-24 08:26:55.832119+00:00, run_end_date=2026-02-24 08:27:11.882249+00:00, run_duration=16.05013, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:26:42.181391+00:00, data_interval_end=2026-02-24 08:26:42.181391+00:00, dag_hash=353648209cc11795c15df8e148af83f2
[2026-02-24T16:31:12.815+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:32:40.209+0800] {manager.py:537} INFO - DAG p_cdrd_all is missing and will be deactivated.
[2026-02-24T16:32:40.210+0800] {manager.py:537} INFO - DAG c_cdrd is missing and will be deactivated.
[2026-02-24T16:32:40.213+0800] {manager.py:549} INFO - Deactivated 2 DAGs which are no longer present in file.
[2026-02-24T16:32:40.217+0800] {manager.py:553} INFO - Deleted DAG c_cdrd in serialized_dag table
[2026-02-24T16:32:40.258+0800] {manager.py:553} INFO - Deleted DAG p_cdrd_all in serialized_dag table
[2026-02-24T16:36:16.110+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:40:42.779+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:40:39.544036+00:00 [scheduled]>
[2026-02-24T16:40:42.782+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:40:42.783+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:40:39.544036+00:00 [scheduled]>
[2026-02-24T16:40:42.785+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:40:39.544036+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:40:42.786+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:40:39.544036+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:40:42.787+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:40:39.544036+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:40:42.789+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:40:39.544036+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:40:45.121+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:40:47.194+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:40:39.544036+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:40:48.566+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:40:39.544036+00:00', try_number=1, map_index=-1)
[2026-02-24T16:40:48.575+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:40:39.544036+00:00, map_index=-1, run_start_date=2026-02-24 08:40:47.272437+00:00, run_end_date=2026-02-24 08:40:47.804209+00:00, run_duration=0.531772, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=294, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:40:42.784109+00:00, queued_by_job_id=208, pid=18913
[2026-02-24T16:40:51.989+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:40:39.544036+00:00: manual__2026-02-24T08:40:39.544036+00:00, state:running, queued_at: 2026-02-24 08:40:39.557299+00:00. externally triggered: True> successful
[2026-02-24T16:40:51.990+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:40:39.544036+00:00, run_id=manual__2026-02-24T08:40:39.544036+00:00, run_start_date=2026-02-24 08:40:42.756344+00:00, run_end_date=2026-02-24 08:40:51.990694+00:00, run_duration=9.23435, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:40:39.544036+00:00, data_interval_end=2026-02-24 08:40:39.544036+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:41:18.862+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:41:45.965+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:41:42.161413+00:00 [scheduled]>
[2026-02-24T16:41:45.966+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:41:45.967+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:41:42.161413+00:00 [scheduled]>
[2026-02-24T16:41:45.970+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:41:42.161413+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:41:45.971+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:41:42.161413+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:41:45.971+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:41:42.161413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:41:45.974+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:41:42.161413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:41:48.071+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:41:49.729+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:41:42.161413+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:41:51.133+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:41:42.161413+00:00', try_number=1, map_index=-1)
[2026-02-24T16:41:51.154+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:41:42.161413+00:00, map_index=-1, run_start_date=2026-02-24 08:41:49.802294+00:00, run_end_date=2026-02-24 08:41:50.336648+00:00, run_duration=0.534354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=295, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:41:45.968753+00:00, queued_by_job_id=208, pid=18947
[2026-02-24T16:41:53.953+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:41:42.161413+00:00: manual__2026-02-24T08:41:42.161413+00:00, state:running, queued_at: 2026-02-24 08:41:42.176173+00:00. externally triggered: True> successful
[2026-02-24T16:41:53.954+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:41:42.161413+00:00, run_id=manual__2026-02-24T08:41:42.161413+00:00, run_start_date=2026-02-24 08:41:45.944303+00:00, run_end_date=2026-02-24 08:41:53.954263+00:00, run_duration=8.00996, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:41:42.161413+00:00, data_interval_end=2026-02-24 08:41:42.161413+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:41:53.965+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:41:50.358657+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:41:50.360304+00:00 [scheduled]>
[2026-02-24T16:41:53.965+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T16:41:53.966+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T16:41:53.967+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:41:50.358657+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:41:50.360304+00:00 [scheduled]>
[2026-02-24T16:41:53.969+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:41:50.358657+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:41:50.360304+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:41:53.970+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:41:50.358657+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:41:53.971+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:41:50.358657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:41:53.972+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:41:50.360304+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:41:53.972+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:41:50.360304+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:41:53.975+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:41:50.358657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:41:56.192+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:41:57.629+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:41:50.358657+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:41:58.915+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:41:50.360304+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:42:01.138+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:42:02.630+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:41:50.360304+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:42:04.469+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:41:50.358657+00:00', try_number=1, map_index=-1)
[2026-02-24T16:42:04.471+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:41:50.360304+00:00', try_number=1, map_index=-1)
[2026-02-24T16:42:04.479+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:41:50.360304+00:00, map_index=-1, run_start_date=2026-02-24 08:42:02.697034+00:00, run_end_date=2026-02-24 08:42:03.732092+00:00, run_duration=1.035058, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=297, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:41:53.968532+00:00, queued_by_job_id=208, pid=18965
[2026-02-24T16:42:04.481+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:41:50.358657+00:00, map_index=-1, run_start_date=2026-02-24 08:41:57.692559+00:00, run_end_date=2026-02-24 08:41:58.185184+00:00, run_duration=0.492625, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=296, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:41:53.968532+00:00, queued_by_job_id=208, pid=18959
[2026-02-24T16:42:07.389+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:41:50.358657+00:00: dataset_triggered__2026-02-24T08:41:50.358657+00:00, state:running, queued_at: 2026-02-24 08:41:53.910019+00:00. externally triggered: False> successful
[2026-02-24T16:42:07.390+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:41:50.358657+00:00, run_id=dataset_triggered__2026-02-24T08:41:50.358657+00:00, run_start_date=2026-02-24 08:41:53.935015+00:00, run_end_date=2026-02-24 08:42:07.390030+00:00, run_duration=13.455015, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 08:41:42.161413+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T16:42:07.397+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:41:50.360304+00:00: dataset_triggered__2026-02-24T08:41:50.360304+00:00, state:running, queued_at: 2026-02-24 08:41:53.919004+00:00. externally triggered: False> successful
[2026-02-24T16:42:07.398+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:41:50.360304+00:00, run_id=dataset_triggered__2026-02-24T08:41:50.360304+00:00, run_start_date=2026-02-24 08:41:53.935127+00:00, run_end_date=2026-02-24 08:42:07.398423+00:00, run_duration=13.463296, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 08:41:42.161413+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T16:46:22.783+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:47:52.156+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:47:50.274813+00:00 [scheduled]>
[2026-02-24T16:47:52.157+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:47:52.158+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:47:50.274813+00:00 [scheduled]>
[2026-02-24T16:47:52.160+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:47:50.274813+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:47:52.161+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:47:50.274813+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:47:52.162+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:47:50.274813+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:47:52.164+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:47:50.274813+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:47:54.338+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:47:56.036+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:47:50.274813+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:47:57.385+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:47:50.274813+00:00', try_number=1, map_index=-1)
[2026-02-24T16:47:57.395+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:47:50.274813+00:00, map_index=-1, run_start_date=2026-02-24 08:47:56.107856+00:00, run_end_date=2026-02-24 08:47:56.640725+00:00, run_duration=0.532869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=298, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:47:52.159156+00:00, queued_by_job_id=208, pid=19205
[2026-02-24T16:48:00.063+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:47:50.274813+00:00: manual__2026-02-24T08:47:50.274813+00:00, state:running, queued_at: 2026-02-24 08:47:50.295858+00:00. externally triggered: True> successful
[2026-02-24T16:48:00.064+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:47:50.274813+00:00, run_id=manual__2026-02-24T08:47:50.274813+00:00, run_start_date=2026-02-24 08:47:52.136145+00:00, run_end_date=2026-02-24 08:48:00.064911+00:00, run_duration=7.928766, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:47:50.274813+00:00, data_interval_end=2026-02-24 08:47:50.274813+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:48:00.076+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:47:56.663455+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:47:56.664661+00:00 [scheduled]>
[2026-02-24T16:48:00.077+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T16:48:00.077+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T16:48:00.078+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:47:56.663455+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:47:56.664661+00:00 [scheduled]>
[2026-02-24T16:48:00.081+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:47:56.663455+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:47:56.664661+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:48:00.082+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:47:56.663455+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:48:00.083+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:47:56.663455+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:48:00.084+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:47:56.664661+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:48:00.085+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:47:56.664661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:48:00.087+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:47:56.663455+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:48:02.213+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:48:03.800+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:47:56.663455+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:48:05.047+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:47:56.664661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:48:07.180+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:48:08.622+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:47:56.664661+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:48:09.958+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:47:56.663455+00:00', try_number=1, map_index=-1)
[2026-02-24T16:48:09.960+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:47:56.664661+00:00', try_number=1, map_index=-1)
[2026-02-24T16:48:09.969+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:47:56.663455+00:00, map_index=-1, run_start_date=2026-02-24 08:48:03.872190+00:00, run_end_date=2026-02-24 08:48:04.332282+00:00, run_duration=0.460092, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=299, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:48:00.079958+00:00, queued_by_job_id=208, pid=19211
[2026-02-24T16:48:09.971+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:47:56.664661+00:00, map_index=-1, run_start_date=2026-02-24 08:48:08.708748+00:00, run_end_date=2026-02-24 08:48:09.241306+00:00, run_duration=0.532558, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=300, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:48:00.079958+00:00, queued_by_job_id=208, pid=19213
[2026-02-24T16:48:13.767+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:47:56.663455+00:00: dataset_triggered__2026-02-24T08:47:56.663455+00:00, state:running, queued_at: 2026-02-24 08:48:00.021915+00:00. externally triggered: False> failed
[2026-02-24T16:48:13.768+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:47:56.663455+00:00, run_id=dataset_triggered__2026-02-24T08:47:56.663455+00:00, run_start_date=2026-02-24 08:48:00.046424+00:00, run_end_date=2026-02-24 08:48:13.768884+00:00, run_duration=13.72246, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:47:50.274813+00:00, data_interval_end=2026-02-24 08:47:50.274813+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T16:48:13.774+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:47:56.664661+00:00: dataset_triggered__2026-02-24T08:47:56.664661+00:00, state:running, queued_at: 2026-02-24 08:48:00.033819+00:00. externally triggered: False> failed
[2026-02-24T16:48:13.775+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:47:56.664661+00:00, run_id=dataset_triggered__2026-02-24T08:47:56.664661+00:00, run_start_date=2026-02-24 08:48:00.046546+00:00, run_end_date=2026-02-24 08:48:13.775126+00:00, run_duration=13.72858, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:47:50.274813+00:00, data_interval_end=2026-02-24 08:47:50.274813+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T16:49:19.406+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:49:18.547830+00:00 [scheduled]>
[2026-02-24T16:49:19.407+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:49:19.408+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:49:18.547830+00:00 [scheduled]>
[2026-02-24T16:49:19.416+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:49:18.547830+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:49:19.418+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:49:18.547830+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:49:19.419+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:49:18.547830+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:49:19.422+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:49:18.547830+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:49:21.597+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:49:23.453+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:49:18.547830+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:49:24.808+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:49:18.547830+00:00', try_number=1, map_index=-1)
[2026-02-24T16:49:24.818+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:49:18.547830+00:00, map_index=-1, run_start_date=2026-02-24 08:49:23.533971+00:00, run_end_date=2026-02-24 08:49:24.060480+00:00, run_duration=0.526509, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=301, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:49:19.409731+00:00, queued_by_job_id=208, pid=19250
[2026-02-24T16:49:28.529+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:49:18.547830+00:00: manual__2026-02-24T08:49:18.547830+00:00, state:running, queued_at: 2026-02-24 08:49:18.560790+00:00. externally triggered: True> successful
[2026-02-24T16:49:28.530+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:49:18.547830+00:00, run_id=manual__2026-02-24T08:49:18.547830+00:00, run_start_date=2026-02-24 08:49:19.383942+00:00, run_end_date=2026-02-24 08:49:28.530468+00:00, run_duration=9.146526, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:49:18.547830+00:00, data_interval_end=2026-02-24 08:49:18.547830+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:49:28.541+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:49:24.079651+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:49:24.082042+00:00 [scheduled]>
[2026-02-24T16:49:28.542+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T16:49:28.542+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T16:49:28.543+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:49:24.079651+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:49:24.082042+00:00 [scheduled]>
[2026-02-24T16:49:28.546+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:49:24.079651+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:49:24.082042+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:49:28.547+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:49:24.079651+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:49:28.548+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:49:24.079651+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:49:28.549+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:49:24.082042+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:49:28.549+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:49:24.082042+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:49:28.552+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:49:24.079651+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:49:30.695+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:49:32.228+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:49:24.079651+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:49:33.971+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:49:24.082042+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:49:36.197+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:49:37.706+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:49:24.082042+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:49:39.010+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:49:24.079651+00:00', try_number=1, map_index=-1)
[2026-02-24T16:49:39.012+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:49:24.082042+00:00', try_number=1, map_index=-1)
[2026-02-24T16:49:39.021+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:49:24.079651+00:00, map_index=-1, run_start_date=2026-02-24 08:49:32.304094+00:00, run_end_date=2026-02-24 08:49:33.227839+00:00, run_duration=0.923745, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=302, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:49:28.544789+00:00, queued_by_job_id=208, pid=19253
[2026-02-24T16:49:39.023+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:49:24.082042+00:00, map_index=-1, run_start_date=2026-02-24 08:49:37.781835+00:00, run_end_date=2026-02-24 08:49:38.300910+00:00, run_duration=0.519075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=303, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:49:28.544789+00:00, queued_by_job_id=208, pid=19256
[2026-02-24T16:49:42.009+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:49:24.079651+00:00: dataset_triggered__2026-02-24T08:49:24.079651+00:00, state:running, queued_at: 2026-02-24 08:49:28.487021+00:00. externally triggered: False> successful
[2026-02-24T16:49:42.010+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:49:24.079651+00:00, run_id=dataset_triggered__2026-02-24T08:49:24.079651+00:00, run_start_date=2026-02-24 08:49:28.510736+00:00, run_end_date=2026-02-24 08:49:42.010443+00:00, run_duration=13.499707, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:49:18.547830+00:00, data_interval_end=2026-02-24 08:49:18.547830+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T16:49:42.015+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:49:24.082042+00:00: dataset_triggered__2026-02-24T08:49:24.082042+00:00, state:running, queued_at: 2026-02-24 08:49:28.496058+00:00. externally triggered: False> successful
[2026-02-24T16:49:42.016+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:49:24.082042+00:00, run_id=dataset_triggered__2026-02-24T08:49:24.082042+00:00, run_start_date=2026-02-24 08:49:28.510863+00:00, run_end_date=2026-02-24 08:49:42.016777+00:00, run_duration=13.505914, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:49:18.547830+00:00, data_interval_end=2026-02-24 08:49:18.547830+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T16:51:22.880+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:53:59.431+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:53:57.107668+00:00 [scheduled]>
[2026-02-24T16:53:59.431+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:53:59.432+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:53:57.107668+00:00 [scheduled]>
[2026-02-24T16:53:59.434+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:53:57.107668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:53:59.435+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:53:57.107668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:53:59.436+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:53:57.107668+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:53:59.438+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:53:57.107668+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:54:01.550+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:54:03.413+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:53:57.107668+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:54:04.790+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:53:57.107668+00:00', try_number=1, map_index=-1)
[2026-02-24T16:54:04.799+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:53:57.107668+00:00, map_index=-1, run_start_date=2026-02-24 08:54:03.533997+00:00, run_end_date=2026-02-24 08:54:04.061191+00:00, run_duration=0.527194, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=304, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:53:59.433623+00:00, queued_by_job_id=208, pid=19420
[2026-02-24T16:54:08.254+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:53:57.107668+00:00: manual__2026-02-24T08:53:57.107668+00:00, state:running, queued_at: 2026-02-24 08:53:57.121462+00:00. externally triggered: True> successful
[2026-02-24T16:54:08.256+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:53:57.107668+00:00, run_id=manual__2026-02-24T08:53:57.107668+00:00, run_start_date=2026-02-24 08:53:59.411139+00:00, run_end_date=2026-02-24 08:54:08.256164+00:00, run_duration=8.845025, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:53:57.107668+00:00, data_interval_end=2026-02-24 08:53:57.107668+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:54:08.267+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:54:04.079781+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:54:04.081771+00:00 [scheduled]>
[2026-02-24T16:54:08.268+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T16:54:08.268+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T16:54:08.269+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:54:04.079781+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:54:04.081771+00:00 [scheduled]>
[2026-02-24T16:54:08.273+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:54:04.079781+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:54:04.081771+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:54:08.274+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:54:04.079781+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:54:08.274+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:54:04.079781+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:54:08.275+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:54:04.081771+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:54:08.276+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:54:04.081771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:54:08.279+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:54:04.079781+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:54:10.470+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:54:11.932+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:54:04.079781+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:54:13.193+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:54:04.081771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:54:15.340+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:54:16.833+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:54:04.081771+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:54:18.534+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:54:04.079781+00:00', try_number=1, map_index=-1)
[2026-02-24T16:54:18.536+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:54:04.081771+00:00', try_number=1, map_index=-1)
[2026-02-24T16:54:18.545+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:54:04.081771+00:00, map_index=-1, run_start_date=2026-02-24 08:54:16.907975+00:00, run_end_date=2026-02-24 08:54:17.850975+00:00, run_duration=0.943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=306, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:54:08.270882+00:00, queued_by_job_id=208, pid=19426
[2026-02-24T16:54:18.547+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:54:04.079781+00:00, map_index=-1, run_start_date=2026-02-24 08:54:12.002562+00:00, run_end_date=2026-02-24 08:54:12.499482+00:00, run_duration=0.49692, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=305, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:54:08.270882+00:00, queued_by_job_id=208, pid=19423
[2026-02-24T16:54:22.188+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:54:04.079781+00:00: dataset_triggered__2026-02-24T08:54:04.079781+00:00, state:running, queued_at: 2026-02-24 08:54:08.212297+00:00. externally triggered: False> successful
[2026-02-24T16:54:22.189+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:54:04.079781+00:00, run_id=dataset_triggered__2026-02-24T08:54:04.079781+00:00, run_start_date=2026-02-24 08:54:08.237233+00:00, run_end_date=2026-02-24 08:54:22.188930+00:00, run_duration=13.951697, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:53:57.107668+00:00, data_interval_end=2026-02-24 08:53:57.107668+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T16:54:22.195+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:54:04.081771+00:00: dataset_triggered__2026-02-24T08:54:04.081771+00:00, state:running, queued_at: 2026-02-24 08:54:08.225116+00:00. externally triggered: False> successful
[2026-02-24T16:54:22.196+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:54:04.081771+00:00, run_id=dataset_triggered__2026-02-24T08:54:04.081771+00:00, run_start_date=2026-02-24 08:54:08.237350+00:00, run_end_date=2026-02-24 08:54:22.196512+00:00, run_duration=13.959162, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:53:57.107668+00:00, data_interval_end=2026-02-24 08:53:57.107668+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T16:56:01.186+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:55:59.503214+00:00 [scheduled]>
[2026-02-24T16:56:01.187+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:56:01.188+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:55:59.503214+00:00 [scheduled]>
[2026-02-24T16:56:01.191+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:55:59.503214+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:56:01.192+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:55:59.503214+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:56:01.193+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:55:59.503214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:56:01.195+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:55:59.503214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:56:03.563+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:56:05.405+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:55:59.503214+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:56:06.794+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:55:59.503214+00:00', try_number=1, map_index=-1)
[2026-02-24T16:56:06.803+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:55:59.503214+00:00, map_index=-1, run_start_date=2026-02-24 08:56:05.482425+00:00, run_end_date=2026-02-24 08:56:06.009711+00:00, run_duration=0.527286, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=307, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:56:01.189917+00:00, queued_by_job_id=208, pid=19486
[2026-02-24T16:56:09.392+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:55:59.503214+00:00: manual__2026-02-24T08:55:59.503214+00:00, state:running, queued_at: 2026-02-24 08:55:59.517244+00:00. externally triggered: True> successful
[2026-02-24T16:56:09.393+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:55:59.503214+00:00, run_id=manual__2026-02-24T08:55:59.503214+00:00, run_start_date=2026-02-24 08:56:01.162210+00:00, run_end_date=2026-02-24 08:56:09.393148+00:00, run_duration=8.230938, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:55:59.503214+00:00, data_interval_end=2026-02-24 08:55:59.503214+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:56:09.402+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:56:06.030062+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:56:06.031554+00:00 [scheduled]>
[2026-02-24T16:56:09.404+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T16:56:09.405+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T16:56:09.405+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:56:06.030062+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:56:06.031554+00:00 [scheduled]>
[2026-02-24T16:56:09.408+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:56:06.030062+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:56:06.031554+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:56:09.409+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:56:06.030062+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:56:09.410+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:56:06.030062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:56:09.411+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:56:06.031554+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:56:09.412+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:56:06.031554+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:56:09.415+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:56:06.030062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:56:11.498+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:56:12.986+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:56:06.030062+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:56:22.335+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:56:06.031554+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:56:24.855+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:56:26.324+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:56:06.031554+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:56:27.644+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:56:06.030062+00:00', try_number=1, map_index=-1)
[2026-02-24T16:56:27.645+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:56:06.031554+00:00', try_number=1, map_index=-1)
[2026-02-24T16:56:27.655+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:56:06.030062+00:00, map_index=-1, run_start_date=2026-02-24 08:56:13.061965+00:00, run_end_date=2026-02-24 08:56:21.623314+00:00, run_duration=8.561349, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=308, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:56:09.407104+00:00, queued_by_job_id=208, pid=19489
[2026-02-24T16:56:27.657+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:56:06.031554+00:00, map_index=-1, run_start_date=2026-02-24 08:56:26.400282+00:00, run_end_date=2026-02-24 08:56:26.903230+00:00, run_duration=0.502948, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=309, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:56:09.407104+00:00, queued_by_job_id=208, pid=19510
[2026-02-24T16:56:27.690+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T16:56:31.321+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:56:06.030062+00:00: dataset_triggered__2026-02-24T08:56:06.030062+00:00, state:running, queued_at: 2026-02-24 08:56:09.363092+00:00. externally triggered: False> successful
[2026-02-24T16:56:31.322+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:56:06.030062+00:00, run_id=dataset_triggered__2026-02-24T08:56:06.030062+00:00, run_start_date=2026-02-24 08:56:09.376224+00:00, run_end_date=2026-02-24 08:56:31.322355+00:00, run_duration=21.946131, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:55:59.503214+00:00, data_interval_end=2026-02-24 08:55:59.503214+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T16:56:31.328+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:56:06.031554+00:00: dataset_triggered__2026-02-24T08:56:06.031554+00:00, state:running, queued_at: 2026-02-24 08:56:09.353356+00:00. externally triggered: False> successful
[2026-02-24T16:56:31.329+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:56:06.031554+00:00, run_id=dataset_triggered__2026-02-24T08:56:06.031554+00:00, run_start_date=2026-02-24 08:56:09.376333+00:00, run_end_date=2026-02-24 08:56:31.329438+00:00, run_duration=21.953105, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:55:59.503214+00:00, data_interval_end=2026-02-24 08:55:59.503214+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T16:57:18.224+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:57:16.502452+00:00 [scheduled]>
[2026-02-24T16:57:18.225+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:57:18.226+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:57:16.502452+00:00 [scheduled]>
[2026-02-24T16:57:18.228+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:57:16.502452+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:57:18.229+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:57:16.502452+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:57:18.230+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:57:16.502452+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:57:18.232+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:57:16.502452+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:57:20.329+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:57:21.748+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:57:16.502452+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:57:23.051+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:57:16.502452+00:00', try_number=1, map_index=-1)
[2026-02-24T16:57:23.061+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:57:16.502452+00:00, map_index=-1, run_start_date=2026-02-24 08:57:21.820460+00:00, run_end_date=2026-02-24 08:57:22.329510+00:00, run_duration=0.50905, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=310, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:57:18.227523+00:00, queued_by_job_id=208, pid=19550
[2026-02-24T16:57:25.712+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:57:16.502452+00:00: manual__2026-02-24T08:57:16.502452+00:00, state:running, queued_at: 2026-02-24 08:57:16.514869+00:00. externally triggered: True> successful
[2026-02-24T16:57:25.713+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:57:16.502452+00:00, run_id=manual__2026-02-24T08:57:16.502452+00:00, run_start_date=2026-02-24 08:57:18.202760+00:00, run_end_date=2026-02-24 08:57:25.713352+00:00, run_duration=7.510592, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:57:16.502452+00:00, data_interval_end=2026-02-24 08:57:16.502452+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:57:25.724+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:57:22.348970+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:57:22.350419+00:00 [scheduled]>
[2026-02-24T16:57:25.725+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T16:57:25.725+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T16:57:25.726+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:57:22.348970+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:57:22.350419+00:00 [scheduled]>
[2026-02-24T16:57:25.728+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:57:22.348970+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:57:22.350419+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:57:25.730+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:57:22.348970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:57:25.730+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:57:22.348970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:57:25.731+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:57:22.350419+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:57:25.732+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:57:22.350419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:57:25.734+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:57:22.348970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:57:27.801+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:57:29.248+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:57:22.348970+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:57:30.453+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:57:22.350419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:57:32.559+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:57:33.958+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:57:22.350419+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:57:42.885+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:57:22.348970+00:00', try_number=1, map_index=-1)
[2026-02-24T16:57:42.889+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:57:22.350419+00:00', try_number=1, map_index=-1)
[2026-02-24T16:57:42.898+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:57:22.350419+00:00, map_index=-1, run_start_date=2026-02-24 08:57:34.029228+00:00, run_end_date=2026-02-24 08:57:42.199783+00:00, run_duration=8.170555, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=312, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:57:25.727464+00:00, queued_by_job_id=208, pid=19555
[2026-02-24T16:57:42.899+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:57:22.348970+00:00, map_index=-1, run_start_date=2026-02-24 08:57:29.320439+00:00, run_end_date=2026-02-24 08:57:29.777168+00:00, run_duration=0.456729, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=311, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:57:25.727464+00:00, queued_by_job_id=208, pid=19553
[2026-02-24T16:57:47.547+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:57:22.348970+00:00: dataset_triggered__2026-02-24T08:57:22.348970+00:00, state:running, queued_at: 2026-02-24 08:57:25.682340+00:00. externally triggered: False> successful
[2026-02-24T16:57:47.548+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:57:22.348970+00:00, run_id=dataset_triggered__2026-02-24T08:57:22.348970+00:00, run_start_date=2026-02-24 08:57:25.695758+00:00, run_end_date=2026-02-24 08:57:47.548444+00:00, run_duration=21.852686, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:57:16.502452+00:00, data_interval_end=2026-02-24 08:57:16.502452+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T16:57:47.555+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:57:22.350419+00:00: dataset_triggered__2026-02-24T08:57:22.350419+00:00, state:running, queued_at: 2026-02-24 08:57:25.673980+00:00. externally triggered: False> successful
[2026-02-24T16:57:47.556+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:57:22.350419+00:00, run_id=dataset_triggered__2026-02-24T08:57:22.350419+00:00, run_start_date=2026-02-24 08:57:25.695866+00:00, run_end_date=2026-02-24 08:57:47.556330+00:00, run_duration=21.860464, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:57:16.502452+00:00, data_interval_end=2026-02-24 08:57:16.502452+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T16:58:37.424+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:58:34.370641+00:00 [scheduled]>
[2026-02-24T16:58:37.425+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:58:37.426+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:58:34.370641+00:00 [scheduled]>
[2026-02-24T16:58:37.428+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:58:34.370641+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:58:37.429+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:58:34.370641+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:58:37.430+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:58:34.370641+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:58:37.432+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:58:34.370641+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:58:39.571+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:58:41.235+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:58:34.370641+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:58:42.537+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:58:34.370641+00:00', try_number=1, map_index=-1)
[2026-02-24T16:58:42.546+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:58:34.370641+00:00, map_index=-1, run_start_date=2026-02-24 08:58:41.309534+00:00, run_end_date=2026-02-24 08:58:41.821515+00:00, run_duration=0.511981, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=313, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:58:37.427428+00:00, queued_by_job_id=208, pid=19621
[2026-02-24T16:58:45.324+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:58:34.370641+00:00: manual__2026-02-24T08:58:34.370641+00:00, state:running, queued_at: 2026-02-24 08:58:34.382642+00:00. externally triggered: True> successful
[2026-02-24T16:58:45.325+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:58:34.370641+00:00, run_id=manual__2026-02-24T08:58:34.370641+00:00, run_start_date=2026-02-24 08:58:37.402358+00:00, run_end_date=2026-02-24 08:58:45.325299+00:00, run_duration=7.922941, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:58:34.370641+00:00, data_interval_end=2026-02-24 08:58:34.370641+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T16:58:45.338+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:58:41.840896+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:58:41.842498+00:00 [scheduled]>
[2026-02-24T16:58:45.340+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T16:58:45.341+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T16:58:45.341+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:58:41.840896+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:58:41.842498+00:00 [scheduled]>
[2026-02-24T16:58:45.344+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:58:41.840896+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:58:41.842498+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:58:45.345+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:58:41.840896+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:58:45.346+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:58:41.840896+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:58:45.347+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:58:41.842498+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:58:45.347+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:58:41.842498+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:58:45.351+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:58:41.840896+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:58:47.552+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:58:49.056+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:58:41.840896+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:58:57.837+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:58:41.842498+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:59:00.137+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T16:59:01.635+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:58:41.842498+00:00 [queued]> on host localhost-2.local
[2026-02-24T16:59:02.953+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:58:41.840896+00:00', try_number=1, map_index=-1)
[2026-02-24T16:59:02.955+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:58:41.842498+00:00', try_number=1, map_index=-1)
[2026-02-24T16:59:02.964+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:58:41.840896+00:00, map_index=-1, run_start_date=2026-02-24 08:58:49.127512+00:00, run_end_date=2026-02-24 08:58:57.123186+00:00, run_duration=7.995674, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=314, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:58:45.343057+00:00, queued_by_job_id=208, pid=19624
[2026-02-24T16:59:02.966+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:58:41.842498+00:00, map_index=-1, run_start_date=2026-02-24 08:59:01.712258+00:00, run_end_date=2026-02-24 08:59:02.224244+00:00, run_duration=0.511986, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=315, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:58:45.343057+00:00, queued_by_job_id=208, pid=19650
[2026-02-24T16:59:05.945+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:58:41.840896+00:00: dataset_triggered__2026-02-24T08:58:41.840896+00:00, state:running, queued_at: 2026-02-24 08:58:45.280530+00:00. externally triggered: False> successful
[2026-02-24T16:59:05.946+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:58:41.840896+00:00, run_id=dataset_triggered__2026-02-24T08:58:41.840896+00:00, run_start_date=2026-02-24 08:58:45.304550+00:00, run_end_date=2026-02-24 08:59:05.946266+00:00, run_duration=20.641716, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:58:34.370641+00:00, data_interval_end=2026-02-24 08:58:34.370641+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T16:59:05.951+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:58:41.842498+00:00: dataset_triggered__2026-02-24T08:58:41.842498+00:00, state:running, queued_at: 2026-02-24 08:58:45.289726+00:00. externally triggered: False> successful
[2026-02-24T16:59:05.952+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:58:41.842498+00:00, run_id=dataset_triggered__2026-02-24T08:58:41.842498+00:00, run_start_date=2026-02-24 08:58:45.304676+00:00, run_end_date=2026-02-24 08:59:05.952870+00:00, run_duration=20.648194, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:58:34.370641+00:00, data_interval_end=2026-02-24 08:58:34.370641+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T16:59:57.535+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:59:54.143585+00:00 [scheduled]>
[2026-02-24T16:59:57.536+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T16:59:57.537+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:59:54.143585+00:00 [scheduled]>
[2026-02-24T16:59:57.540+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:59:54.143585+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T16:59:57.541+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:59:54.143585+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T16:59:57.542+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:59:54.143585+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:59:57.544+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:59:54.143585+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T16:59:59.667+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:00:01.258+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:59:54.143585+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:00:02.594+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:59:54.143585+00:00', try_number=1, map_index=-1)
[2026-02-24T17:00:02.603+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:59:54.143585+00:00, map_index=-1, run_start_date=2026-02-24 09:00:01.332741+00:00, run_end_date=2026-02-24 09:00:01.846606+00:00, run_duration=0.513865, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=316, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:59:57.538757+00:00, queued_by_job_id=208, pid=19691
[2026-02-24T17:00:05.441+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:59:54.143585+00:00: manual__2026-02-24T08:59:54.143585+00:00, state:running, queued_at: 2026-02-24 08:59:54.156670+00:00. externally triggered: True> successful
[2026-02-24T17:00:05.442+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:59:54.143585+00:00, run_id=manual__2026-02-24T08:59:54.143585+00:00, run_start_date=2026-02-24 08:59:57.515229+00:00, run_end_date=2026-02-24 09:00:05.442193+00:00, run_duration=7.926964, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:59:54.143585+00:00, data_interval_end=2026-02-24 08:59:54.143585+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:00:05.453+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:00:01.867374+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:00:01.868783+00:00 [scheduled]>
[2026-02-24T17:00:05.454+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:00:05.455+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:00:05.456+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:00:01.867374+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:00:01.868783+00:00 [scheduled]>
[2026-02-24T17:00:05.459+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:00:01.867374+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:00:01.868783+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:00:05.460+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:00:01.867374+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:00:05.461+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:00:01.867374+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:00:05.462+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:00:01.868783+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:00:05.462+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:00:01.868783+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:00:05.466+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:00:01.867374+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:00:07.693+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:00:09.177+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:00:01.867374+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:00:17.936+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:00:01.868783+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:00:20.235+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:00:21.708+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:00:01.868783+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:00:28.821+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:00:01.867374+00:00', try_number=1, map_index=-1)
[2026-02-24T17:00:28.823+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:00:01.868783+00:00', try_number=1, map_index=-1)
[2026-02-24T17:00:28.833+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:00:01.867374+00:00, map_index=-1, run_start_date=2026-02-24 09:00:09.246809+00:00, run_end_date=2026-02-24 09:00:17.239403+00:00, run_duration=7.992594, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=317, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:00:05.457919+00:00, queued_by_job_id=208, pid=19701
[2026-02-24T17:00:28.834+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:00:01.868783+00:00, map_index=-1, run_start_date=2026-02-24 09:00:21.778912+00:00, run_end_date=2026-02-24 09:00:28.182573+00:00, run_duration=6.403661, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=318, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:00:05.457919+00:00, queued_by_job_id=208, pid=19724
[2026-02-24T17:00:31.896+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:00:01.867374+00:00: dataset_triggered__2026-02-24T09:00:01.867374+00:00, state:running, queued_at: 2026-02-24 09:00:05.409059+00:00. externally triggered: False> successful
[2026-02-24T17:00:31.898+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:00:01.867374+00:00, run_id=dataset_triggered__2026-02-24T09:00:01.867374+00:00, run_start_date=2026-02-24 09:00:05.421851+00:00, run_end_date=2026-02-24 09:00:31.898817+00:00, run_duration=26.476966, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:59:54.143585+00:00, data_interval_end=2026-02-24 08:59:54.143585+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:00:31.904+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:00:01.868783+00:00: dataset_triggered__2026-02-24T09:00:01.868783+00:00, state:running, queued_at: 2026-02-24 09:00:05.399271+00:00. externally triggered: False> successful
[2026-02-24T17:00:31.905+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:00:01.868783+00:00, run_id=dataset_triggered__2026-02-24T09:00:01.868783+00:00, run_start_date=2026-02-24 09:00:05.421955+00:00, run_end_date=2026-02-24 09:00:31.905134+00:00, run_duration=26.483179, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:59:54.143585+00:00, data_interval_end=2026-02-24 08:59:54.143585+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:01:30.945+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:06:09.077+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:06:06.826492+00:00 [scheduled]>
[2026-02-24T17:06:09.078+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T17:06:09.079+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:06:06.826492+00:00 [scheduled]>
[2026-02-24T17:06:09.082+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:06:06.826492+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:06:09.083+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:06:06.826492+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:06:09.084+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:06:06.826492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:06:09.086+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:06:06.826492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:06:11.240+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:06:13.482+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:06:06.826492+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:06:14.805+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:06:06.826492+00:00', try_number=1, map_index=-1)
[2026-02-24T17:06:14.815+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:06:06.826492+00:00, map_index=-1, run_start_date=2026-02-24 09:06:13.558159+00:00, run_end_date=2026-02-24 09:06:14.080437+00:00, run_duration=0.522278, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=319, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:06:09.080791+00:00, queued_by_job_id=208, pid=19989
[2026-02-24T17:06:17.435+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:06:06.826492+00:00: manual__2026-02-24T09:06:06.826492+00:00, state:running, queued_at: 2026-02-24 09:06:06.840482+00:00. externally triggered: True> successful
[2026-02-24T17:06:17.436+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:06:06.826492+00:00, run_id=manual__2026-02-24T09:06:06.826492+00:00, run_start_date=2026-02-24 09:06:09.055991+00:00, run_end_date=2026-02-24 09:06:17.436290+00:00, run_duration=8.380299, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:06:06.826492+00:00, data_interval_end=2026-02-24 09:06:06.826492+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:06:17.447+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:06:14.099955+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:06:14.101475+00:00 [scheduled]>
[2026-02-24T17:06:17.448+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:06:17.448+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:06:17.449+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:06:14.099955+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:06:14.101475+00:00 [scheduled]>
[2026-02-24T17:06:17.452+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:06:14.099955+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:06:14.101475+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:06:17.453+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:06:14.099955+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:06:17.454+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:06:14.099955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:06:17.455+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:06:14.101475+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:06:17.456+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:06:14.101475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:06:17.459+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:06:14.099955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:06:19.680+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:06:21.167+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:06:14.099955+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:06:28.922+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:06:14.101475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:06:31.313+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:06:32.860+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:06:14.101475+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:06:41.290+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:06:14.099955+00:00', try_number=1, map_index=-1)
[2026-02-24T17:06:41.291+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:06:14.101475+00:00', try_number=1, map_index=-1)
[2026-02-24T17:06:41.300+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:06:14.101475+00:00, map_index=-1, run_start_date=2026-02-24 09:06:32.933167+00:00, run_end_date=2026-02-24 09:06:40.578490+00:00, run_duration=7.645323, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=321, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:06:17.450975+00:00, queued_by_job_id=208, pid=20023
[2026-02-24T17:06:41.302+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:06:14.099955+00:00, map_index=-1, run_start_date=2026-02-24 09:06:21.236444+00:00, run_end_date=2026-02-24 09:06:28.238297+00:00, run_duration=7.001853, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=320, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:06:17.450975+00:00, queued_by_job_id=208, pid=19998
[2026-02-24T17:06:41.332+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:06:44.432+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:06:14.099955+00:00: dataset_triggered__2026-02-24T09:06:14.099955+00:00, state:running, queued_at: 2026-02-24 09:06:17.406757+00:00. externally triggered: False> successful
[2026-02-24T17:06:44.433+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:06:14.099955+00:00, run_id=dataset_triggered__2026-02-24T09:06:14.099955+00:00, run_start_date=2026-02-24 09:06:17.418221+00:00, run_end_date=2026-02-24 09:06:44.433034+00:00, run_duration=27.014813, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:06:06.826492+00:00, data_interval_end=2026-02-24 09:06:06.826492+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:06:44.437+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:06:14.101475+00:00: dataset_triggered__2026-02-24T09:06:14.101475+00:00, state:running, queued_at: 2026-02-24 09:06:17.391262+00:00. externally triggered: False> successful
[2026-02-24T17:06:44.439+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:06:14.101475+00:00, run_id=dataset_triggered__2026-02-24T09:06:14.101475+00:00, run_start_date=2026-02-24 09:06:17.418330+00:00, run_end_date=2026-02-24 09:06:44.439030+00:00, run_duration=27.0207, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:06:06.826492+00:00, data_interval_end=2026-02-24 09:06:06.826492+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:10:06.530+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:10:04.515914+00:00 [scheduled]>
[2026-02-24T17:10:06.531+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T17:10:06.531+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:10:04.515914+00:00 [scheduled]>
[2026-02-24T17:10:06.533+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:10:04.515914+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:10:06.534+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:10:04.515914+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:10:06.535+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:10:04.515914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:10:06.538+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:10:04.515914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:10:09.027+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:10:10.591+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:10:04.515914+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:10:11.909+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:10:04.515914+00:00', try_number=1, map_index=-1)
[2026-02-24T17:10:11.919+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:10:04.515914+00:00, map_index=-1, run_start_date=2026-02-24 09:10:10.666073+00:00, run_end_date=2026-02-24 09:10:11.195320+00:00, run_duration=0.529247, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=322, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:10:06.532728+00:00, queued_by_job_id=208, pid=20159
[2026-02-24T17:10:15.818+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:10:04.515914+00:00: manual__2026-02-24T09:10:04.515914+00:00, state:running, queued_at: 2026-02-24 09:10:04.532913+00:00. externally triggered: True> successful
[2026-02-24T17:10:15.819+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:10:04.515914+00:00, run_id=manual__2026-02-24T09:10:04.515914+00:00, run_start_date=2026-02-24 09:10:06.509626+00:00, run_end_date=2026-02-24 09:10:15.819205+00:00, run_duration=9.309579, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:10:04.515914+00:00, data_interval_end=2026-02-24 09:10:04.515914+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:10:15.829+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:10:11.215597+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:10:11.217924+00:00 [scheduled]>
[2026-02-24T17:10:15.830+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:10:15.830+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:10:15.831+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:10:11.215597+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:10:11.217924+00:00 [scheduled]>
[2026-02-24T17:10:15.835+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:10:11.215597+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:10:11.217924+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:10:15.836+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:10:11.215597+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:10:15.836+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:10:11.215597+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:10:15.837+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:10:11.217924+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:10:15.838+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:10:11.217924+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:10:15.840+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:10:11.215597+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:10:18.032+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:10:19.514+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:10:11.215597+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:10:26.241+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:10:11.217924+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:10:28.327+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:10:29.805+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:10:11.217924+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:10:37.076+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:10:11.215597+00:00', try_number=1, map_index=-1)
[2026-02-24T17:10:37.080+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:10:11.217924+00:00', try_number=1, map_index=-1)
[2026-02-24T17:10:37.091+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:10:11.217924+00:00, map_index=-1, run_start_date=2026-02-24 09:10:29.876201+00:00, run_end_date=2026-02-24 09:10:36.391462+00:00, run_duration=6.515261, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=324, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:10:15.833396+00:00, queued_by_job_id=208, pid=20178
[2026-02-24T17:10:37.092+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:10:11.215597+00:00, map_index=-1, run_start_date=2026-02-24 09:10:19.585191+00:00, run_end_date=2026-02-24 09:10:25.501828+00:00, run_duration=5.916637, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=323, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:10:15.833396+00:00, queued_by_job_id=208, pid=20164
[2026-02-24T17:10:40.214+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:10:11.215597+00:00: dataset_triggered__2026-02-24T09:10:11.215597+00:00, state:running, queued_at: 2026-02-24 09:10:15.744586+00:00. externally triggered: False> successful
[2026-02-24T17:10:40.215+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:10:11.215597+00:00, run_id=dataset_triggered__2026-02-24T09:10:11.215597+00:00, run_start_date=2026-02-24 09:10:15.789505+00:00, run_end_date=2026-02-24 09:10:40.215726+00:00, run_duration=24.426221, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:10:04.515914+00:00, data_interval_end=2026-02-24 09:10:04.515914+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:10:40.221+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:10:11.217924+00:00: dataset_triggered__2026-02-24T09:10:11.217924+00:00, state:running, queued_at: 2026-02-24 09:10:15.707784+00:00. externally triggered: False> successful
[2026-02-24T17:10:40.222+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:10:11.217924+00:00, run_id=dataset_triggered__2026-02-24T09:10:11.217924+00:00, run_start_date=2026-02-24 09:10:15.789807+00:00, run_end_date=2026-02-24 09:10:40.222513+00:00, run_duration=24.432706, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:10:04.515914+00:00, data_interval_end=2026-02-24 09:10:04.515914+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:11:44.245+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:16:45.212+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:17:10.878+0800] {manager.py:537} INFO - DAG p_cdrd_all is missing and will be deactivated.
[2026-02-24T17:17:10.879+0800] {manager.py:537} INFO - DAG c_cdrd_DAG2 is missing and will be deactivated.
[2026-02-24T17:17:10.879+0800] {manager.py:537} INFO - DAG c_cdrd_DAG1 is missing and will be deactivated.
[2026-02-24T17:17:10.882+0800] {manager.py:549} INFO - Deactivated 3 DAGs which are no longer present in file.
[2026-02-24T17:17:10.886+0800] {manager.py:553} INFO - Deleted DAG p_cdrd_all in serialized_dag table
[2026-02-24T17:17:10.890+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG1 in serialized_dag table
[2026-02-24T17:17:10.893+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG2 in serialized_dag table
[2026-02-24T17:21:45.358+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:26:45.835+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:31:48.221+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:32:50.177+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:32:45.789302+00:00 [scheduled]>
[2026-02-24T17:32:50.178+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T17:32:50.179+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:32:45.789302+00:00 [scheduled]>
[2026-02-24T17:32:50.182+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:32:45.789302+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:32:50.184+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:32:45.789302+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:32:50.185+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:32:45.789302+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:32:50.188+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:32:45.789302+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:32:52.388+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[['', '13756259846', 'zhujun@example.com', '676784', '360883']]
[2026-02-24T17:32:54.275+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:32:45.789302+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:32:55.563+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:32:45.789302+00:00', try_number=1, map_index=-1)
[2026-02-24T17:32:55.573+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:32:45.789302+00:00, map_index=-1, run_start_date=2026-02-24 09:32:54.481974+00:00, run_end_date=2026-02-24 09:32:54.763307+00:00, run_duration=0.281333, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=325, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:32:50.180814+00:00, queued_by_job_id=208, pid=20919
[2026-02-24T17:32:59.055+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:32:45.789302+00:00: manual__2026-02-24T09:32:45.789302+00:00, state:running, queued_at: 2026-02-24 09:32:45.813017+00:00. externally triggered: True> successful
[2026-02-24T17:32:59.057+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:32:45.789302+00:00, run_id=manual__2026-02-24T09:32:45.789302+00:00, run_start_date=2026-02-24 09:32:50.150710+00:00, run_end_date=2026-02-24 09:32:59.056955+00:00, run_duration=8.906245, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:32:45.789302+00:00, data_interval_end=2026-02-24 09:32:45.789302+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:32:59.069+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:32:54.785623+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:32:54.787315+00:00 [scheduled]>
[2026-02-24T17:32:59.071+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:32:59.072+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:32:59.073+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:32:54.785623+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:32:54.787315+00:00 [scheduled]>
[2026-02-24T17:32:59.076+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:32:54.785623+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:32:54.787315+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:32:59.077+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:32:54.785623+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:32:59.078+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:32:54.785623+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:32:59.079+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:32:54.787315+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:32:59.079+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:32:54.787315+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:32:59.082+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:32:54.785623+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:33:01.251+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[['', '18848576759', 'gsu@example.net', '549034', '254450']]
[2026-02-24T17:33:02.792+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:32:54.785623+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:33:09.581+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:32:54.787315+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:33:11.869+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[['', '18545597144', 'guiyingsun@example.com', '923174', '919792']]
[2026-02-24T17:33:13.446+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:32:54.787315+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:33:19.880+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:32:54.785623+00:00', try_number=1, map_index=-1)
[2026-02-24T17:33:19.882+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:32:54.787315+00:00', try_number=1, map_index=-1)
[2026-02-24T17:33:19.890+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:32:54.787315+00:00, map_index=-1, run_start_date=2026-02-24 09:33:13.648022+00:00, run_end_date=2026-02-24 09:33:19.248972+00:00, run_duration=5.60095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=327, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:32:59.074596+00:00, queued_by_job_id=208, pid=20939
[2026-02-24T17:33:19.892+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:32:54.785623+00:00, map_index=-1, run_start_date=2026-02-24 09:33:02.987853+00:00, run_end_date=2026-02-24 09:33:08.825974+00:00, run_duration=5.838121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=326, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:32:59.074596+00:00, queued_by_job_id=208, pid=20925
[2026-02-24T17:33:23.467+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:32:54.785623+00:00: dataset_triggered__2026-02-24T09:32:54.785623+00:00, state:running, queued_at: 2026-02-24 09:32:59.009451+00:00. externally triggered: False> successful
[2026-02-24T17:33:23.468+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:32:54.785623+00:00, run_id=dataset_triggered__2026-02-24T09:32:54.785623+00:00, run_start_date=2026-02-24 09:32:59.038492+00:00, run_end_date=2026-02-24 09:33:23.468494+00:00, run_duration=24.430002, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:32:45.789302+00:00, data_interval_end=2026-02-24 09:32:45.789302+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:33:23.474+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:32:54.787315+00:00: dataset_triggered__2026-02-24T09:32:54.787315+00:00, state:running, queued_at: 2026-02-24 09:32:59.024507+00:00. externally triggered: False> successful
[2026-02-24T17:33:23.475+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:32:54.787315+00:00, run_id=dataset_triggered__2026-02-24T09:32:54.787315+00:00, run_start_date=2026-02-24 09:32:59.038602+00:00, run_end_date=2026-02-24 09:33:23.475741+00:00, run_duration=24.437139, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:32:45.789302+00:00, data_interval_end=2026-02-24 09:32:45.789302+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:36:48.679+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:40:28.479+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:40:23.906460+00:00 [scheduled]>
[2026-02-24T17:40:28.480+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T17:40:28.481+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:40:23.906460+00:00 [scheduled]>
[2026-02-24T17:40:28.484+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:40:23.906460+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:40:28.485+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:40:23.906460+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:40:28.485+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:40:23.906460+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:40:28.487+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:40:23.906460+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:40:30.657+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:40:32.427+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:40:23.906460+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:40:33.685+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:40:23.906460+00:00', try_number=1, map_index=-1)
[2026-02-24T17:40:33.694+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:40:23.906460+00:00, map_index=-1, run_start_date=2026-02-24 09:40:32.499692+00:00, run_end_date=2026-02-24 09:40:32.986524+00:00, run_duration=0.486832, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=328, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:40:28.482642+00:00, queued_by_job_id=208, pid=21235
[2026-02-24T17:40:37.133+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:40:23.906460+00:00: manual__2026-02-24T09:40:23.906460+00:00, state:running, queued_at: 2026-02-24 09:40:23.920456+00:00. externally triggered: True> successful
[2026-02-24T17:40:37.134+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:40:23.906460+00:00, run_id=manual__2026-02-24T09:40:23.906460+00:00, run_start_date=2026-02-24 09:40:28.459967+00:00, run_end_date=2026-02-24 09:40:37.134817+00:00, run_duration=8.67485, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:40:23.906460+00:00, data_interval_end=2026-02-24 09:40:23.906460+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:40:37.146+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:40:33.006091+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:40:33.007771+00:00 [scheduled]>
[2026-02-24T17:40:37.147+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:40:37.147+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:40:37.148+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:40:33.006091+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:40:33.007771+00:00 [scheduled]>
[2026-02-24T17:40:37.151+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:40:33.006091+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:40:33.007771+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:40:37.152+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:40:33.006091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:40:37.153+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:40:33.006091+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:40:37.154+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:40:33.007771+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:40:37.155+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:40:33.007771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:40:37.158+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:40:33.006091+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:40:39.588+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:40:41.101+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:40:33.006091+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:40:42.301+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:40:33.007771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:40:44.748+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:40:46.172+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:40:33.007771+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:40:47.361+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:40:33.006091+00:00', try_number=1, map_index=-1)
[2026-02-24T17:40:47.365+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:40:33.007771+00:00', try_number=1, map_index=-1)
[2026-02-24T17:40:47.374+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:40:33.006091+00:00, map_index=-1, run_start_date=2026-02-24 09:40:41.171742+00:00, run_end_date=2026-02-24 09:40:41.620448+00:00, run_duration=0.448706, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=329, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:40:37.150450+00:00, queued_by_job_id=208, pid=21239
[2026-02-24T17:40:47.376+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:40:33.007771+00:00, map_index=-1, run_start_date=2026-02-24 09:40:46.247559+00:00, run_end_date=2026-02-24 09:40:46.669053+00:00, run_duration=0.421494, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=330, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:40:37.150450+00:00, queued_by_job_id=208, pid=21241
[2026-02-24T17:40:51.331+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:40:33.006091+00:00: dataset_triggered__2026-02-24T09:40:33.006091+00:00, state:running, queued_at: 2026-02-24 09:40:37.102501+00:00. externally triggered: False> failed
[2026-02-24T17:40:51.332+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:40:33.006091+00:00, run_id=dataset_triggered__2026-02-24T09:40:33.006091+00:00, run_start_date=2026-02-24 09:40:37.115687+00:00, run_end_date=2026-02-24 09:40:51.332678+00:00, run_duration=14.216991, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:40:23.906460+00:00, data_interval_end=2026-02-24 09:40:23.906460+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:40:51.337+0800] {dagrun.py:823} ERROR - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:40:33.007771+00:00: dataset_triggered__2026-02-24T09:40:33.007771+00:00, state:running, queued_at: 2026-02-24 09:40:37.088644+00:00. externally triggered: False> failed
[2026-02-24T17:40:51.338+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:40:33.007771+00:00, run_id=dataset_triggered__2026-02-24T09:40:33.007771+00:00, run_start_date=2026-02-24 09:40:37.115793+00:00, run_end_date=2026-02-24 09:40:51.338723+00:00, run_duration=14.22293, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:40:23.906460+00:00, data_interval_end=2026-02-24 09:40:23.906460+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:41:40.201+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:41:38.989132+00:00 [scheduled]>
[2026-02-24T17:41:40.202+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T17:41:40.204+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:41:38.989132+00:00 [scheduled]>
[2026-02-24T17:41:40.207+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:41:38.989132+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:41:40.208+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:41:38.989132+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:41:40.209+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:41:38.989132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:41:40.211+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:41:38.989132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:41:42.605+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:41:44.378+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:41:38.989132+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:41:45.694+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:41:38.989132+00:00', try_number=1, map_index=-1)
[2026-02-24T17:41:45.704+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:41:38.989132+00:00, map_index=-1, run_start_date=2026-02-24 09:41:44.453339+00:00, run_end_date=2026-02-24 09:41:44.971489+00:00, run_duration=0.51815, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=331, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:41:40.206193+00:00, queued_by_job_id=208, pid=21286
[2026-02-24T17:41:49.307+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:41:38.989132+00:00: manual__2026-02-24T09:41:38.989132+00:00, state:running, queued_at: 2026-02-24 09:41:39.002529+00:00. externally triggered: True> successful
[2026-02-24T17:41:49.308+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:41:38.989132+00:00, run_id=manual__2026-02-24T09:41:38.989132+00:00, run_start_date=2026-02-24 09:41:40.176348+00:00, run_end_date=2026-02-24 09:41:49.308656+00:00, run_duration=9.132308, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:41:38.989132+00:00, data_interval_end=2026-02-24 09:41:38.989132+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:41:49.319+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:41:44.989189+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:41:44.991139+00:00 [scheduled]>
[2026-02-24T17:41:49.320+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:41:49.321+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:41:49.322+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:41:44.989189+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:41:44.991139+00:00 [scheduled]>
[2026-02-24T17:41:49.325+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:41:44.989189+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:41:44.991139+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:41:49.326+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:41:44.989189+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:41:49.326+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:41:44.989189+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:41:49.327+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:41:44.991139+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:41:49.328+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:41:44.991139+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:41:49.331+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:41:44.989189+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:41:51.490+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:41:52.993+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:41:44.989189+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:42:01.969+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:41:44.991139+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:42:04.229+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:42:05.885+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:41:44.991139+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:42:11.909+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:41:44.989189+00:00', try_number=1, map_index=-1)
[2026-02-24T17:42:11.911+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:41:44.991139+00:00', try_number=1, map_index=-1)
[2026-02-24T17:42:11.920+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:41:44.989189+00:00, map_index=-1, run_start_date=2026-02-24 09:41:53.068684+00:00, run_end_date=2026-02-24 09:42:01.280337+00:00, run_duration=8.211653, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=332, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:41:49.323682+00:00, queued_by_job_id=208, pid=21291
[2026-02-24T17:42:11.921+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:41:44.991139+00:00, map_index=-1, run_start_date=2026-02-24 09:42:05.960737+00:00, run_end_date=2026-02-24 09:42:11.197528+00:00, run_duration=5.236791, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=333, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:41:49.323682+00:00, queued_by_job_id=208, pid=21318
[2026-02-24T17:42:11.946+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:42:15.652+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:41:44.989189+00:00: dataset_triggered__2026-02-24T09:41:44.989189+00:00, state:running, queued_at: 2026-02-24 09:41:49.265757+00:00. externally triggered: False> successful
[2026-02-24T17:42:15.654+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:41:44.989189+00:00, run_id=dataset_triggered__2026-02-24T09:41:44.989189+00:00, run_start_date=2026-02-24 09:41:49.289341+00:00, run_end_date=2026-02-24 09:42:15.653849+00:00, run_duration=26.364508, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:41:38.989132+00:00, data_interval_end=2026-02-24 09:41:38.989132+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:42:15.660+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:41:44.991139+00:00: dataset_triggered__2026-02-24T09:41:44.991139+00:00, state:running, queued_at: 2026-02-24 09:41:49.276187+00:00. externally triggered: False> successful
[2026-02-24T17:42:15.661+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:41:44.991139+00:00, run_id=dataset_triggered__2026-02-24T09:41:44.991139+00:00, run_start_date=2026-02-24 09:41:49.289464+00:00, run_end_date=2026-02-24 09:42:15.660995+00:00, run_duration=26.371531, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:41:38.989132+00:00, data_interval_end=2026-02-24 09:41:38.989132+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:46:11.675+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:46:09.019140+00:00 [scheduled]>
[2026-02-24T17:46:11.676+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T17:46:11.676+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:46:09.019140+00:00 [scheduled]>
[2026-02-24T17:46:11.679+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:46:09.019140+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:46:11.681+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:46:09.019140+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:46:11.682+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:46:09.019140+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:46:11.684+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:46:09.019140+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:46:14.247+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:46:16.860+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:46:09.019140+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:46:18.235+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:46:09.019140+00:00', try_number=1, map_index=-1)
[2026-02-24T17:46:18.245+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:46:09.019140+00:00, map_index=-1, run_start_date=2026-02-24 09:46:16.939158+00:00, run_end_date=2026-02-24 09:46:17.489333+00:00, run_duration=0.550175, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=334, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:46:11.678142+00:00, queued_by_job_id=208, pid=21446
[2026-02-24T17:46:23.111+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:46:09.019140+00:00: manual__2026-02-24T09:46:09.019140+00:00, state:running, queued_at: 2026-02-24 09:46:09.034560+00:00. externally triggered: True> successful
[2026-02-24T17:46:23.114+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:46:09.019140+00:00, run_id=manual__2026-02-24T09:46:09.019140+00:00, run_start_date=2026-02-24 09:46:11.654362+00:00, run_end_date=2026-02-24 09:46:23.114260+00:00, run_duration=11.459898, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:46:09.019140+00:00, data_interval_end=2026-02-24 09:46:09.019140+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:46:23.133+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:46:17.525887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:46:17.528214+00:00 [scheduled]>
[2026-02-24T17:46:23.134+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:46:23.134+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:46:23.135+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:46:17.525887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:46:17.528214+00:00 [scheduled]>
[2026-02-24T17:46:23.141+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:46:17.525887+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:46:17.528214+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:46:23.143+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:46:17.525887+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:46:23.144+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:46:17.525887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:46:23.145+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:46:17.528214+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:46:23.148+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:46:17.528214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:46:23.152+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:46:17.525887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:46:27.759+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:46:30.908+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:46:17.525887+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:46:38.200+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:46:17.528214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:46:41.158+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-24T17:46:43.013+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:46:17.528214+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:46:53.139+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:46:17.525887+00:00', try_number=1, map_index=-1)
[2026-02-24T17:46:53.141+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:46:17.528214+00:00', try_number=1, map_index=-1)
[2026-02-24T17:46:53.171+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:46:17.528214+00:00, map_index=-1, run_start_date=2026-02-24 09:46:43.102944+00:00, run_end_date=2026-02-24 09:46:52.408997+00:00, run_duration=9.306053, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=336, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:46:23.137957+00:00, queued_by_job_id=208, pid=21490
[2026-02-24T17:46:53.174+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:46:17.525887+00:00, map_index=-1, run_start_date=2026-02-24 09:46:30.987001+00:00, run_end_date=2026-02-24 09:46:37.453097+00:00, run_duration=6.466096, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=335, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:46:23.137957+00:00, queued_by_job_id=208, pid=21469
[2026-02-24T17:46:53.202+0800] {job.py:229} INFO - Heartbeat recovered after 34.94 seconds
[2026-02-24T17:46:56.524+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:46:17.525887+00:00: dataset_triggered__2026-02-24T09:46:17.525887+00:00, state:running, queued_at: 2026-02-24 09:46:23.022534+00:00. externally triggered: False> successful
[2026-02-24T17:46:56.526+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:46:17.525887+00:00, run_id=dataset_triggered__2026-02-24T09:46:17.525887+00:00, run_start_date=2026-02-24 09:46:23.048258+00:00, run_end_date=2026-02-24 09:46:56.525877+00:00, run_duration=33.477619, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:46:09.019140+00:00, data_interval_end=2026-02-24 09:46:09.019140+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:46:56.532+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:46:17.528214+00:00: dataset_triggered__2026-02-24T09:46:17.528214+00:00, state:running, queued_at: 2026-02-24 09:46:23.005727+00:00. externally triggered: False> successful
[2026-02-24T17:46:56.533+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:46:17.528214+00:00, run_id=dataset_triggered__2026-02-24T09:46:17.528214+00:00, run_start_date=2026-02-24 09:46:23.048460+00:00, run_end_date=2026-02-24 09:46:56.533790+00:00, run_duration=33.48533, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:46:09.019140+00:00, data_interval_end=2026-02-24 09:46:09.019140+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:47:15.662+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:51:16.897+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:51:12.512152+00:00 [scheduled]>
[2026-02-24T17:51:16.897+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-24T17:51:16.898+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:51:12.512152+00:00 [scheduled]>
[2026-02-24T17:51:16.901+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:51:12.512152+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:51:16.902+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:51:12.512152+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:51:16.903+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:51:12.512152+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:51:16.905+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:51:12.512152+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:51:20.290+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[['', '15667927258', 'guli@example.org', '188189', '251449']]
[2026-02-24T17:51:25.788+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:51:12.512152+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:51:29.257+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:51:12.512152+00:00', try_number=1, map_index=-1)
[2026-02-24T17:51:29.278+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:51:12.512152+00:00, map_index=-1, run_start_date=2026-02-24 09:51:26.111159+00:00, run_end_date=2026-02-24 09:51:27.009970+00:00, run_duration=0.898811, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=337, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:51:16.899929+00:00, queued_by_job_id=208, pid=21670
[2026-02-24T17:51:39.123+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:51:12.512152+00:00: manual__2026-02-24T09:51:12.512152+00:00, state:running, queued_at: 2026-02-24 09:51:12.527162+00:00. externally triggered: True> successful
[2026-02-24T17:51:39.126+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:51:12.512152+00:00, run_id=manual__2026-02-24T09:51:12.512152+00:00, run_start_date=2026-02-24 09:51:16.874566+00:00, run_end_date=2026-02-24 09:51:39.126151+00:00, run_duration=22.251585, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:51:12.512152+00:00, data_interval_end=2026-02-24 09:51:12.512152+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
[2026-02-24T17:51:39.176+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:51:27.074289+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:51:27.083642+00:00 [scheduled]>
[2026-02-24T17:51:39.178+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-24T17:51:39.182+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-24T17:51:39.188+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:51:27.074289+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:51:27.083642+00:00 [scheduled]>
[2026-02-24T17:51:39.200+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:51:27.074289+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:51:27.083642+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-24T17:51:39.204+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:51:27.074289+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:51:39.208+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:51:27.074289+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:51:39.217+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:51:27.083642+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-24T17:51:39.221+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:51:27.083642+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:51:39.227+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:51:27.074289+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:51:43.508+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[['', '15937840953', 'weina@example.com', '798099', '336009']]
[2026-02-24T17:51:48.385+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:51:27.074289+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:51:55.425+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:51:27.083642+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-24T17:51:58.768+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[['', '18982088593', 'qiang52@example.net', '236759', '419421']]
[2026-02-24T17:52:01.409+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:51:27.083642+00:00 [queued]> on host localhost-2.local
[2026-02-24T17:52:12.648+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:51:27.074289+00:00', try_number=1, map_index=-1)
[2026-02-24T17:52:12.651+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:51:27.083642+00:00', try_number=1, map_index=-1)
[2026-02-24T17:52:12.661+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:51:27.083642+00:00, map_index=-1, run_start_date=2026-02-24 09:52:01.852727+00:00, run_end_date=2026-02-24 09:52:11.931032+00:00, run_duration=10.078305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=339, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:51:39.194110+00:00, queued_by_job_id=208, pid=21701
[2026-02-24T17:52:12.662+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:51:27.074289+00:00, map_index=-1, run_start_date=2026-02-24 09:51:48.771647+00:00, run_end_date=2026-02-24 09:51:54.747660+00:00, run_duration=5.976013, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=338, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:51:39.194110+00:00, queued_by_job_id=208, pid=21682
[2026-02-24T17:52:12.681+0800] {job.py:229} INFO - Heartbeat recovered after 43.38 seconds
[2026-02-24T17:52:16.405+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:51:27.074289+00:00: dataset_triggered__2026-02-24T09:51:27.074289+00:00, state:running, queued_at: 2026-02-24 09:51:39.054733+00:00. externally triggered: False> successful
[2026-02-24T17:52:16.406+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:51:27.074289+00:00, run_id=dataset_triggered__2026-02-24T09:51:27.074289+00:00, run_start_date=2026-02-24 09:51:39.082752+00:00, run_end_date=2026-02-24 09:52:16.406388+00:00, run_duration=37.323636, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:51:12.512152+00:00, data_interval_end=2026-02-24 09:51:12.512152+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
[2026-02-24T17:52:16.411+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:51:27.083642+00:00: dataset_triggered__2026-02-24T09:51:27.083642+00:00, state:running, queued_at: 2026-02-24 09:51:39.012658+00:00. externally triggered: False> successful
[2026-02-24T17:52:16.412+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:51:27.083642+00:00, run_id=dataset_triggered__2026-02-24T09:51:27.083642+00:00, run_start_date=2026-02-24 09:51:39.082977+00:00, run_end_date=2026-02-24 09:52:16.412186+00:00, run_duration=37.329209, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:51:12.512152+00:00, data_interval_end=2026-02-24 09:51:12.512152+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
[2026-02-24T17:52:16.434+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T17:57:17.505+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:02:19.153+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:07:19.619+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:12:22.279+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:17:24.365+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:22:25.207+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:27:28.586+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:32:30.085+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-24T18:37:30.635+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
