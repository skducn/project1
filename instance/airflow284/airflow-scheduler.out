[2026-02-26T17:15:32.024+0800] {executor_loader.py:258} INFO - Loaded executor: SequentialExecutor
[2026-02-26T17:15:32.716+0800] {scheduler_job_runner.py:950} INFO - Starting the scheduler
[2026-02-26T17:15:32.718+0800] {scheduler_job_runner.py:957} INFO - Processing each file at most -1 times
[2026-02-26T17:15:32.726+0800] {manager.py:174} INFO - Launched DagFileProcessorManager with pid: 19721
[2026-02-26T17:15:32.734+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:15:34.756+0800] {settings.py:63} INFO - Configured default timezone Asia/Shanghai
[2026-02-26T17:15:34.807+0800] {manager.py:406} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2026-02-26T17:15:35.061+0800] {core.py:50} INFO - Starting log server on http://[::]:8793
[2026-02-26T17:15:53.912+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:15:49.701114+00:00 [scheduled]>
[2026-02-26T17:15:53.914+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-26T17:15:53.915+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:15:49.701114+00:00 [scheduled]>
[2026-02-26T17:15:53.918+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:15:49.701114+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:15:53.919+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:15:49.701114+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:15:53.920+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:15:49.701114+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:15:53.923+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:15:49.701114+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:15:56.036+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:15:58.024+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:15:49.701114+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:15:59.045+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:15:49.701114+00:00', try_number=1, map_index=-1)
[2026-02-26T17:15:59.060+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T09:15:49.701114+00:00, map_index=-1, run_start_date=2026-02-26 09:15:58.101655+00:00, run_end_date=2026-02-26 09:15:58.321599+00:00, run_duration=0.219944, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=426, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:15:53.916592+00:00, queued_by_job_id=425, pid=19749
[2026-02-26T17:16:02.452+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 09:15:49.701114+00:00: manual__2026-02-26T09:15:49.701114+00:00, state:running, queued_at: 2026-02-26 09:15:49.728261+00:00. externally triggered: True> successful
[2026-02-26T17:16:02.454+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 09:15:49.701114+00:00, run_id=manual__2026-02-26T09:15:49.701114+00:00, run_start_date=2026-02-26 09:15:53.741547+00:00, run_end_date=2026-02-26 09:16:02.454714+00:00, run_duration=8.713167, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:15:49.701114+00:00, data_interval_end=2026-02-26 09:15:49.701114+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
[2026-02-26T17:19:05.896+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:19:02.861621+00:00 [scheduled]>
[2026-02-26T17:19:05.897+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-26T17:19:05.899+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:19:02.861621+00:00 [scheduled]>
[2026-02-26T17:19:05.901+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:19:02.861621+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:19:05.902+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:19:02.861621+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:19:05.903+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:19:02.861621+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:19:05.906+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:19:02.861621+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:19:08.569+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:19:10.775+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:19:02.861621+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:19:11.774+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:19:02.861621+00:00', try_number=1, map_index=-1)
[2026-02-26T17:19:11.787+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T09:19:02.861621+00:00, map_index=-1, run_start_date=2026-02-26 09:19:10.848597+00:00, run_end_date=2026-02-26 09:19:11.068214+00:00, run_duration=0.219617, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=427, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:19:05.900332+00:00, queued_by_job_id=425, pid=19878
[2026-02-26T17:19:14.589+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 09:19:02.861621+00:00: manual__2026-02-26T09:19:02.861621+00:00, state:running, queued_at: 2026-02-26 09:19:02.876395+00:00. externally triggered: True> successful
[2026-02-26T17:19:14.590+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 09:19:02.861621+00:00, run_id=manual__2026-02-26T09:19:02.861621+00:00, run_start_date=2026-02-26 09:19:05.876084+00:00, run_end_date=2026-02-26 09:19:14.590502+00:00, run_duration=8.714418, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:19:02.861621+00:00, data_interval_end=2026-02-26 09:19:02.861621+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
[2026-02-26T17:20:33.776+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:23:21.555+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:23:19.712615+00:00 [scheduled]>
[2026-02-26T17:23:21.557+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
[2026-02-26T17:23:21.557+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:23:19.712615+00:00 [scheduled]>
[2026-02-26T17:23:21.560+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:23:19.712615+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:23:21.561+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:23:19.712615+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:23:21.562+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:23:19.712615+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:23:21.565+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:23:19.712615+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:23:23.830+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:23:26.317+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:23:19.712615+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:23:37.228+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:23:19.712615+00:00', try_number=1, map_index=-1)
[2026-02-26T17:23:37.255+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:23:19.712615+00:00, map_index=-1, run_start_date=2026-02-26 09:23:26.386628+00:00, run_end_date=2026-02-26 09:23:36.466096+00:00, run_duration=10.079468, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=428, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:23:21.559090+00:00, queued_by_job_id=425, pid=20063
[2026-02-26T17:23:40.627+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:23:19.712615+00:00: manual__2026-02-26T09:23:19.712615+00:00, state:running, queued_at: 2026-02-26 09:23:19.740643+00:00. externally triggered: True> successful
[2026-02-26T17:23:40.628+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:23:19.712615+00:00, run_id=manual__2026-02-26T09:23:19.712615+00:00, run_start_date=2026-02-26 09:23:21.534936+00:00, run_end_date=2026-02-26 09:23:40.628438+00:00, run_duration=19.093502, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:23:19.712615+00:00, data_interval_end=2026-02-26 09:23:19.712615+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
[2026-02-26T17:25:37.520+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:25:53.430+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:25:52.125609+00:00 [scheduled]>
[2026-02-26T17:25:53.431+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
[2026-02-26T17:25:53.432+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:25:52.125609+00:00 [scheduled]>
[2026-02-26T17:25:53.435+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:25:52.125609+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:25:53.437+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:25:52.125609+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:25:53.438+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:25:52.125609+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:25:53.440+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:25:52.125609+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:25:55.533+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:25:57.587+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:25:52.125609+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:26:13.118+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:25:52.125609+00:00', try_number=1, map_index=-1)
[2026-02-26T17:26:13.130+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:25:52.125609+00:00, map_index=-1, run_start_date=2026-02-26 09:25:57.723608+00:00, run_end_date=2026-02-26 09:26:12.391805+00:00, run_duration=14.668197, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=429, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:25:53.434696+00:00, queued_by_job_id=425, pid=20462
[2026-02-26T17:26:15.814+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:25:52.125609+00:00: manual__2026-02-26T09:25:52.125609+00:00, state:running, queued_at: 2026-02-26 09:25:52.140079+00:00. externally triggered: True> successful
[2026-02-26T17:26:15.815+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:25:52.125609+00:00, run_id=manual__2026-02-26T09:25:52.125609+00:00, run_start_date=2026-02-26 09:25:53.408264+00:00, run_end_date=2026-02-26 09:26:15.815120+00:00, run_duration=22.406856, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:25:52.125609+00:00, data_interval_end=2026-02-26 09:25:52.125609+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
[2026-02-26T17:29:01.414+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:28:58.825370+00:00 [scheduled]>
[2026-02-26T17:29:01.415+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
[2026-02-26T17:29:01.416+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:28:58.825370+00:00 [scheduled]>
[2026-02-26T17:29:01.418+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:28:58.825370+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:29:01.419+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:28:58.825370+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:29:01.420+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:28:58.825370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:29:01.423+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:28:58.825370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:29:03.477+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:29:05.580+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:28:58.825370+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:29:15.045+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:28:58.825370+00:00', try_number=1, map_index=-1)
[2026-02-26T17:29:15.055+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:28:58.825370+00:00, map_index=-1, run_start_date=2026-02-26 09:29:05.658175+00:00, run_end_date=2026-02-26 09:29:14.322106+00:00, run_duration=8.663931, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=430, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:29:01.417118+00:00, queued_by_job_id=425, pid=20605
[2026-02-26T17:29:17.849+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:28:58.825370+00:00: manual__2026-02-26T09:28:58.825370+00:00, state:running, queued_at: 2026-02-26 09:28:58.839186+00:00. externally triggered: True> successful
[2026-02-26T17:29:17.850+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:28:58.825370+00:00, run_id=manual__2026-02-26T09:28:58.825370+00:00, run_start_date=2026-02-26 09:29:01.395196+00:00, run_end_date=2026-02-26 09:29:17.849952+00:00, run_duration=16.454756, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:28:58.825370+00:00, data_interval_end=2026-02-26 09:28:58.825370+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
[2026-02-26T17:30:38.892+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:30:51.531+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:30:48.672992+00:00 [scheduled]>
[2026-02-26T17:30:51.532+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
[2026-02-26T17:30:51.533+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:30:48.672992+00:00 [scheduled]>
[2026-02-26T17:30:51.535+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:30:48.672992+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:30:51.536+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:30:48.672992+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:30:51.537+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:30:48.672992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:30:51.539+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:30:48.672992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:30:53.626+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:30:55.529+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:30:48.672992+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:31:04.638+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:30:48.672992+00:00', try_number=1, map_index=-1)
[2026-02-26T17:31:04.647+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:30:48.672992+00:00, map_index=-1, run_start_date=2026-02-26 09:30:55.601671+00:00, run_end_date=2026-02-26 09:31:03.939295+00:00, run_duration=8.337624, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=431, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:30:51.534240+00:00, queued_by_job_id=425, pid=20688
[2026-02-26T17:31:08.214+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:30:48.672992+00:00: manual__2026-02-26T09:30:48.672992+00:00, state:running, queued_at: 2026-02-26 09:30:48.686616+00:00. externally triggered: True> successful
[2026-02-26T17:31:08.215+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:30:48.672992+00:00, run_id=manual__2026-02-26T09:30:48.672992+00:00, run_start_date=2026-02-26 09:30:51.509922+00:00, run_end_date=2026-02-26 09:31:08.215109+00:00, run_duration=16.705187, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:30:48.672992+00:00, data_interval_end=2026-02-26 09:30:48.672992+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
[2026-02-26T17:33:09.582+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:33:06.057914+00:00 [scheduled]>
[2026-02-26T17:33:09.583+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
[2026-02-26T17:33:09.584+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:33:06.057914+00:00 [scheduled]>
[2026-02-26T17:33:09.587+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:33:06.057914+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:33:09.588+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:33:06.057914+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:33:09.589+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:33:06.057914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:33:09.591+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:33:06.057914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:33:11.959+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:33:14.191+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:33:06.057914+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:33:23.542+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:33:06.057914+00:00', try_number=1, map_index=-1)
[2026-02-26T17:33:23.552+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:33:06.057914+00:00, map_index=-1, run_start_date=2026-02-26 09:33:14.264776+00:00, run_end_date=2026-02-26 09:33:22.824913+00:00, run_duration=8.560137, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=432, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:33:09.585822+00:00, queued_by_job_id=425, pid=20803
[2026-02-26T17:33:26.778+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:33:06.057914+00:00: manual__2026-02-26T09:33:06.057914+00:00, state:running, queued_at: 2026-02-26 09:33:06.070241+00:00. externally triggered: True> successful
[2026-02-26T17:33:26.779+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:33:06.057914+00:00, run_id=manual__2026-02-26T09:33:06.057914+00:00, run_start_date=2026-02-26 09:33:09.557101+00:00, run_end_date=2026-02-26 09:33:26.779389+00:00, run_duration=17.222288, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:33:06.057914+00:00, data_interval_end=2026-02-26 09:33:06.057914+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
[2026-02-26T17:35:42.833+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:36:55.396+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:36:52.351602+00:00 [scheduled]>
[2026-02-26T17:36:55.397+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
[2026-02-26T17:36:55.398+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:36:52.351602+00:00 [scheduled]>
[2026-02-26T17:36:55.400+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:36:52.351602+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:36:55.401+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:36:52.351602+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:36:55.402+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:36:52.351602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:36:55.404+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:36:52.351602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:36:57.537+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T17:36:59.691+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:36:52.351602+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:37:14.627+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:36:52.351602+00:00', try_number=1, map_index=-1)
[2026-02-26T17:37:14.638+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:36:52.351602+00:00, map_index=-1, run_start_date=2026-02-26 09:36:59.767870+00:00, run_end_date=2026-02-26 09:37:13.936056+00:00, run_duration=14.168186, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=433, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:36:55.399337+00:00, queued_by_job_id=425, pid=21024
[2026-02-26T17:37:17.858+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:36:52.351602+00:00: manual__2026-02-26T09:36:52.351602+00:00, state:running, queued_at: 2026-02-26 09:36:52.363527+00:00. externally triggered: True> successful
[2026-02-26T17:37:17.860+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:36:52.351602+00:00, run_id=manual__2026-02-26T09:36:52.351602+00:00, run_start_date=2026-02-26 09:36:55.378814+00:00, run_end_date=2026-02-26 09:37:17.859894+00:00, run_duration=22.48108, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:36:52.351602+00:00, data_interval_end=2026-02-26 09:36:52.351602+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
[2026-02-26T17:40:44.320+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:45:46.546+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:50:50.130+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:55:34.539+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:55:30.426904+00:00 [scheduled]>
[2026-02-26T17:55:34.541+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
[2026-02-26T17:55:34.542+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:55:30.426904+00:00 [scheduled]>
[2026-02-26T17:55:34.545+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:55:30.426904+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:55:34.547+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:55:30.426904+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:55:34.547+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:55:30.426904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:55:34.550+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:55:30.426904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:55:36.682+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T17:55:39.113+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:55:30.426904+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:55:55.637+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:55:30.426904+00:00', try_number=1, map_index=-1)
[2026-02-26T17:55:55.648+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:55:30.426904+00:00, map_index=-1, run_start_date=2026-02-26 09:55:39.189077+00:00, run_end_date=2026-02-26 09:55:54.904749+00:00, run_duration=15.715672, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=434, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:55:34.543771+00:00, queued_by_job_id=425, pid=21878
[2026-02-26T17:55:55.679+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T17:55:59.739+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:55:30.426904+00:00: manual__2026-02-26T09:55:30.426904+00:00, state:running, queued_at: 2026-02-26 09:55:30.447279+00:00. externally triggered: True> successful
[2026-02-26T17:55:59.740+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:55:30.426904+00:00, run_id=manual__2026-02-26T09:55:30.426904+00:00, run_start_date=2026-02-26 09:55:34.513486+00:00, run_end_date=2026-02-26 09:55:59.740075+00:00, run_duration=25.226589, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:55:30.426904+00:00, data_interval_end=2026-02-26 09:55:30.426904+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
[2026-02-26T17:58:29.473+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_with_independent_runs.producer_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
[2026-02-26T17:58:29.474+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_with_independent_runs has 0/16 running and queued tasks
[2026-02-26T17:58:29.475+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_with_independent_runs.producer_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
[2026-02-26T17:58:29.478+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_with_independent_runs.producer_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:58:29.479+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='producer_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2026-02-26T17:58:29.480+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'producer_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:58:29.482+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'producer_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:58:31.760+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T17:58:34.680+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_with_independent_runs.producer_task manual__2026-02-26T09:58:26.764299+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:58:35.727+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='producer_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
[2026-02-26T17:58:35.737+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=producer_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:58:34.747751+00:00, run_end_date=2026-02-26 09:58:34.980187+00:00, run_duration=0.232436, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=435, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 09:58:29.476925+00:00, queued_by_job_id=425, pid=22075
[2026-02-26T17:58:38.492+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer1_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer2_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
[2026-02-26T17:58:38.493+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_with_independent_runs has 0/16 running and queued tasks
[2026-02-26T17:58:38.494+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_with_independent_runs has 1/16 running and queued tasks
[2026-02-26T17:58:38.495+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer1_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer2_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
[2026-02-26T17:58:38.497+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_with_independent_runs.consumer1_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_with_independent_runs.consumer2_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:58:38.499+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer1_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-26T17:58:38.500+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer1_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:58:38.500+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer2_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-26T17:58:38.501+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer2_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:58:38.504+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer1_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:58:40.662+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T17:58:42.921+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_with_independent_runs.consumer1_task manual__2026-02-26T09:58:26.764299+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:58:53.120+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer2_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:58:55.286+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T17:58:57.243+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_with_independent_runs.consumer2_task manual__2026-02-26T09:58:26.764299+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:59:03.601+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer1_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
[2026-02-26T17:59:03.603+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer2_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
[2026-02-26T17:59:03.613+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=consumer1_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:58:42.994832+00:00, run_end_date=2026-02-26 09:58:52.367581+00:00, run_duration=9.372749, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=436, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:58:38.496230+00:00, queued_by_job_id=425, pid=22082
[2026-02-26T17:59:03.615+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=consumer2_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:58:57.319721+00:00, run_end_date=2026-02-26 09:59:02.919434+00:00, run_duration=5.599713, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=437, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:58:38.496230+00:00, queued_by_job_id=425, pid=22117
[2026-02-26T17:59:07.907+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_with_independent_runs.cleanup_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
[2026-02-26T17:59:07.908+0800] {scheduler_job_runner.py:507} INFO - DAG integrated_cdrd_with_independent_runs has 0/16 running and queued tasks
[2026-02-26T17:59:07.909+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_with_independent_runs.cleanup_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
[2026-02-26T17:59:07.911+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_with_independent_runs.cleanup_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T17:59:07.912+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='cleanup_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T17:59:07.913+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'cleanup_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:59:07.915+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'cleanup_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T17:59:10.032+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T17:59:11.715+0800] {task_command.py:467} INFO - Running <TaskInstance: integrated_cdrd_with_independent_runs.cleanup_task manual__2026-02-26T09:58:26.764299+00:00 [queued]> on host localhost-2.local
[2026-02-26T17:59:12.824+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='cleanup_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
[2026-02-26T17:59:12.832+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=cleanup_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:59:11.781586+00:00, run_end_date=2026-02-26 09:59:12.105461+00:00, run_duration=0.323875, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=438, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:59:07.910367+00:00, queued_by_job_id=425, pid=22141
[2026-02-26T17:59:15.243+0800] {dagrun.py:854} INFO - Marking run <DagRun integrated_cdrd_with_independent_runs @ 2026-02-26 09:58:26.764299+00:00: manual__2026-02-26T09:58:26.764299+00:00, state:running, queued_at: 2026-02-26 09:58:26.800040+00:00. externally triggered: True> successful
[2026-02-26T17:59:15.244+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=integrated_cdrd_with_independent_runs, execution_date=2026-02-26 09:58:26.764299+00:00, run_id=manual__2026-02-26T09:58:26.764299+00:00, run_start_date=2026-02-26 09:58:29.444523+00:00, run_end_date=2026-02-26 09:59:15.244322+00:00, run_duration=45.799799, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:58:26.764299+00:00, data_interval_end=2026-02-26 09:58:26.764299+00:00, dag_hash=1e5bdc01ec591dca6a1f6624a26306df
[2026-02-26T18:00:56.129+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T18:02:33.025+0800] {manager.py:537} INFO - DAG p_cdrd_all is missing and will be deactivated.
[2026-02-26T18:02:33.027+0800] {manager.py:537} INFO - DAG c_cdrd_DAG2 is missing and will be deactivated.
[2026-02-26T18:02:33.027+0800] {manager.py:537} INFO - DAG c_cdrd_DAG1 is missing and will be deactivated.
[2026-02-26T18:02:33.027+0800] {manager.py:537} INFO - DAG integrated_cdrd_complete is missing and will be deactivated.
[2026-02-26T18:02:33.027+0800] {manager.py:537} INFO - DAG coordinator_cdrd_final is missing and will be deactivated.
[2026-02-26T18:02:33.028+0800] {manager.py:537} INFO - DAG integrated_cdrd_with_independent_runs is missing and will be deactivated.
[2026-02-26T18:02:33.032+0800] {manager.py:549} INFO - Deactivated 6 DAGs which are no longer present in file.
[2026-02-26T18:02:33.036+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG2 in serialized_dag table
[2026-02-26T18:02:33.038+0800] {manager.py:553} INFO - Deleted DAG c_cdrd_DAG1 in serialized_dag table
[2026-02-26T18:02:33.040+0800] {manager.py:553} INFO - Deleted DAG p_cdrd_all in serialized_dag table
[2026-02-26T18:02:33.042+0800] {manager.py:553} INFO - Deleted DAG integrated_cdrd_complete in serialized_dag table
[2026-02-26T18:02:33.044+0800] {manager.py:553} INFO - Deleted DAG integrated_cdrd_with_independent_runs in serialized_dag table
[2026-02-26T18:02:33.046+0800] {manager.py:553} INFO - Deleted DAG coordinator_cdrd_final in serialized_dag table
[2026-02-26T18:02:41.710+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.producer_task manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
[2026-02-26T18:02:41.711+0800] {scheduler_job_runner.py:507} INFO - DAG cdrd_test_workflow_with_independent_tasks has 0/16 running and queued tasks
[2026-02-26T18:02:41.712+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.producer_task manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
[2026-02-26T18:02:41.714+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_workflow_with_independent_tasks.producer_task manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:02:41.715+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='producer_task', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
[2026-02-26T18:02:41.716+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'producer_task', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:02:41.719+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'producer_task', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:02:44.061+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T18:02:45.632+0800] {task_command.py:467} INFO - Running <TaskInstance: cdrd_test_workflow_with_independent_tasks.producer_task manual__2026-02-26T10:02:37.803650+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:02:46.869+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='producer_task', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
[2026-02-26T18:02:46.882+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=producer_task, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:02:45.821678+00:00, run_end_date=2026-02-26 10:02:46.043749+00:00, run_duration=0.222071, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=439, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 10:02:41.713828+00:00, queued_by_job_id=425, pid=22275
[2026-02-26T18:02:51.462+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_user_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_role_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
[2026-02-26T18:02:51.463+0800] {scheduler_job_runner.py:507} INFO - DAG cdrd_test_workflow_with_independent_tasks has 0/16 running and queued tasks
[2026-02-26T18:02:51.464+0800] {scheduler_job_runner.py:507} INFO - DAG cdrd_test_workflow_with_independent_tasks has 1/16 running and queued tasks
[2026-02-26T18:02:51.465+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_user_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_role_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
[2026-02-26T18:02:51.467+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_user_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>, <TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_role_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:02:51.468+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_user_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-26T18:02:51.469+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_user_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:02:51.470+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_role_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
[2026-02-26T18:02:51.471+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_role_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:02:51.473+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_user_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:02:53.651+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T18:02:55.147+0800] {task_command.py:467} INFO - Running <TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_user_management manual__2026-02-26T10:02:37.803650+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:03:03.643+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_role_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:03:05.814+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T18:03:07.334+0800] {task_command.py:467} INFO - Running <TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_role_management manual__2026-02-26T10:02:37.803650+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:03:14.915+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_user_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
[2026-02-26T18:03:14.917+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_role_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
[2026-02-26T18:03:14.925+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=consumer_role_management, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:03:07.534513+00:00, run_end_date=2026-02-26 10:03:14.076970+00:00, run_duration=6.542457, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=441, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 10:02:51.466396+00:00, queued_by_job_id=425, pid=22314
[2026-02-26T18:03:14.927+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=consumer_user_management, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:02:55.328205+00:00, run_end_date=2026-02-26 10:03:02.908759+00:00, run_duration=7.580554, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=440, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 10:02:51.466396+00:00, queued_by_job_id=425, pid=22278
[2026-02-26T18:03:18.251+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.final_cleanup manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
[2026-02-26T18:03:18.253+0800] {scheduler_job_runner.py:507} INFO - DAG cdrd_test_workflow_with_independent_tasks has 0/16 running and queued tasks
[2026-02-26T18:03:18.253+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.final_cleanup manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
[2026-02-26T18:03:18.256+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_workflow_with_independent_tasks.final_cleanup manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:03:18.257+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='final_cleanup', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:03:18.258+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'final_cleanup', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:03:18.261+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'final_cleanup', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:03:20.761+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
[2026-02-26T18:03:23.158+0800] {task_command.py:467} INFO - Running <TaskInstance: cdrd_test_workflow_with_independent_tasks.final_cleanup manual__2026-02-26T10:02:37.803650+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:03:24.914+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='final_cleanup', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
[2026-02-26T18:03:24.924+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=final_cleanup, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:03:23.580842+00:00, run_end_date=2026-02-26 10:03:24.171679+00:00, run_duration=0.590837, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=442, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:03:18.255347+00:00, queued_by_job_id=425, pid=22348
[2026-02-26T18:03:28.335+0800] {dagrun.py:854} INFO - Marking run <DagRun cdrd_test_workflow_with_independent_tasks @ 2026-02-26 10:02:37.803650+00:00: manual__2026-02-26T10:02:37.803650+00:00, state:running, queued_at: 2026-02-26 10:02:37.831036+00:00. externally triggered: True> successful
[2026-02-26T18:03:28.336+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=cdrd_test_workflow_with_independent_tasks, execution_date=2026-02-26 10:02:37.803650+00:00, run_id=manual__2026-02-26T10:02:37.803650+00:00, run_start_date=2026-02-26 10:02:41.685169+00:00, run_end_date=2026-02-26 10:03:28.336284+00:00, run_duration=46.651115, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:02:37.803650+00:00, data_interval_end=2026-02-26 10:02:37.803650+00:00, dag_hash=1bb173a514cce065a7a973b3d6c02328
[2026-02-26T18:05:59.527+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T18:07:43.284+0800] {manager.py:537} INFO - DAG cdrd_test_workflow_with_independent_tasks is missing and will be deactivated.
[2026-02-26T18:07:43.285+0800] {manager.py:537} INFO - DAG cdrd_test_workflow_integrated is missing and will be deactivated.
[2026-02-26T18:07:43.287+0800] {manager.py:549} INFO - Deactivated 2 DAGs which are no longer present in file.
[2026-02-26T18:07:43.291+0800] {manager.py:553} INFO - Deleted DAG cdrd_test_workflow_with_independent_tasks in serialized_dag table
[2026-02-26T18:07:43.294+0800] {manager.py:553} INFO - Deleted DAG cdrd_test_workflow_integrated in serialized_dag table
[2026-02-26T18:10:54.030+0800] {manager.py:537} INFO - DAG integrated_cdrd_complete is missing and will be deactivated.
[2026-02-26T18:10:54.031+0800] {manager.py:537} INFO - DAG integrated_cdrd_with_independent_runs is missing and will be deactivated.
[2026-02-26T18:10:54.035+0800] {manager.py:549} INFO - Deactivated 2 DAGs which are no longer present in file.
[2026-02-26T18:10:54.037+0800] {manager.py:553} INFO - Deleted DAG integrated_cdrd_complete in serialized_dag table
[2026-02-26T18:10:54.041+0800] {manager.py:553} INFO - Deleted DAG integrated_cdrd_with_independent_runs in serialized_dag table
[2026-02-26T18:11:01.105+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
[2026-02-26T18:11:38.087+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:11:35.192872+00:00 [scheduled]>
[2026-02-26T18:11:38.088+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-26T18:11:38.089+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:11:35.192872+00:00 [scheduled]>
[2026-02-26T18:11:38.091+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:11:35.192872+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:11:38.092+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:11:35.192872+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:11:38.093+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:11:35.192872+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:11:38.095+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:11:35.192872+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:11:40.236+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:11:42.370+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:11:35.192872+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:11:43.385+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:11:35.192872+00:00', try_number=1, map_index=-1)
[2026-02-26T18:11:43.395+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T10:11:35.192872+00:00, map_index=-1, run_start_date=2026-02-26 10:11:42.449152+00:00, run_end_date=2026-02-26 10:11:42.667490+00:00, run_duration=0.218338, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=443, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:11:38.090361+00:00, queued_by_job_id=425, pid=22671
[2026-02-26T18:11:46.100+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 10:11:35.192872+00:00: manual__2026-02-26T10:11:35.192872+00:00, state:running, queued_at: 2026-02-26 10:11:35.206413+00:00. externally triggered: True> successful
[2026-02-26T18:11:46.101+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 10:11:35.192872+00:00, run_id=manual__2026-02-26T10:11:35.192872+00:00, run_start_date=2026-02-26 10:11:38.064783+00:00, run_end_date=2026-02-26 10:11:46.101176+00:00, run_duration=8.036393, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:11:35.192872+00:00, data_interval_end=2026-02-26 10:11:35.192872+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
[2026-02-26T18:11:46.112+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:11:42.687993+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:11:42.689631+00:00 [scheduled]>
[2026-02-26T18:11:46.112+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-26T18:11:46.113+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-26T18:11:46.114+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:11:42.687993+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:11:42.689631+00:00 [scheduled]>
[2026-02-26T18:11:46.118+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:11:42.687993+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:11:42.689631+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:11:46.119+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:11:42.687993+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:11:46.119+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:11:42.687993+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:11:46.120+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:11:42.689631+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:11:46.121+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:11:42.689631+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:11:46.123+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:11:42.687993+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:11:48.279+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:11:50.046+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:11:42.687993+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:11:59.723+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:11:42.689631+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:12:02.225+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:12:03.921+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:11:42.689631+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:12:10.300+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:11:42.687993+00:00', try_number=1, map_index=-1)
[2026-02-26T18:12:10.302+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:11:42.689631+00:00', try_number=1, map_index=-1)
[2026-02-26T18:12:10.315+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T10:11:42.687993+00:00, map_index=-1, run_start_date=2026-02-26 10:11:50.111229+00:00, run_end_date=2026-02-26 10:11:58.961118+00:00, run_duration=8.849889, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=444, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:11:46.115954+00:00, queued_by_job_id=425, pid=22674
[2026-02-26T18:12:10.316+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T10:11:42.689631+00:00, map_index=-1, run_start_date=2026-02-26 10:12:03.986567+00:00, run_end_date=2026-02-26 10:12:09.559449+00:00, run_duration=5.572882, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=445, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:11:46.115954+00:00, queued_by_job_id=425, pid=22707
[2026-02-26T18:12:13.355+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 10:11:42.687993+00:00: dataset_triggered__2026-02-26T10:11:42.687993+00:00, state:running, queued_at: 2026-02-26 10:11:46.061430+00:00. externally triggered: False> successful
[2026-02-26T18:12:13.357+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 10:11:42.687993+00:00, run_id=dataset_triggered__2026-02-26T10:11:42.687993+00:00, run_start_date=2026-02-26 10:11:46.081481+00:00, run_end_date=2026-02-26 10:12:13.356796+00:00, run_duration=27.275315, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:27:07.816788+00:00, data_interval_end=2026-02-26 10:11:35.192872+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
[2026-02-26T18:12:13.362+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 10:11:42.689631+00:00: dataset_triggered__2026-02-26T10:11:42.689631+00:00, state:running, queued_at: 2026-02-26 10:11:46.043180+00:00. externally triggered: False> successful
[2026-02-26T18:12:13.363+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 10:11:42.689631+00:00, run_id=dataset_triggered__2026-02-26T10:11:42.689631+00:00, run_start_date=2026-02-26 10:11:46.081582+00:00, run_end_date=2026-02-26 10:12:13.363559+00:00, run_duration=27.281977, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:27:07.816788+00:00, data_interval_end=2026-02-26 10:11:35.192872+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
[2026-02-26T18:13:47.203+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:13:46.477363+00:00 [scheduled]>
[2026-02-26T18:13:47.204+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-26T18:13:47.205+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:13:46.477363+00:00 [scheduled]>
[2026-02-26T18:13:47.207+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:13:46.477363+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:13:47.208+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:13:46.477363+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:13:47.209+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:13:46.477363+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:13:47.212+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:13:46.477363+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:13:49.425+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:13:51.212+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:13:46.477363+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:13:52.254+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:13:46.477363+00:00', try_number=1, map_index=-1)
[2026-02-26T18:13:52.263+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T10:13:46.477363+00:00, map_index=-1, run_start_date=2026-02-26 10:13:51.285716+00:00, run_end_date=2026-02-26 10:13:51.494609+00:00, run_duration=0.208893, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=446, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:13:47.206495+00:00, queued_by_job_id=425, pid=22788
[2026-02-26T18:13:55.035+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 10:13:46.477363+00:00: manual__2026-02-26T10:13:46.477363+00:00, state:running, queued_at: 2026-02-26 10:13:46.491611+00:00. externally triggered: True> successful
[2026-02-26T18:13:55.036+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 10:13:46.477363+00:00, run_id=manual__2026-02-26T10:13:46.477363+00:00, run_start_date=2026-02-26 10:13:47.182933+00:00, run_end_date=2026-02-26 10:13:55.036148+00:00, run_duration=7.853215, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:13:46.477363+00:00, data_interval_end=2026-02-26 10:13:46.477363+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
[2026-02-26T18:13:55.046+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:13:51.514442+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:13:51.515976+00:00 [scheduled]>
[2026-02-26T18:13:55.047+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-26T18:13:55.048+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-26T18:13:55.049+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:13:51.514442+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:13:51.515976+00:00 [scheduled]>
[2026-02-26T18:13:55.052+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:13:51.514442+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:13:51.515976+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:13:55.053+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:13:51.514442+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:13:55.054+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:13:51.514442+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:13:55.054+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:13:51.515976+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:13:55.055+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:13:51.515976+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:13:55.058+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:13:51.514442+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:13:57.155+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:13:58.814+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:13:51.514442+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:14:06.960+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:13:51.515976+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:14:09.136+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:14:10.912+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:13:51.515976+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:14:17.371+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:13:51.514442+00:00', try_number=1, map_index=-1)
[2026-02-26T18:14:17.374+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:13:51.515976+00:00', try_number=1, map_index=-1)
[2026-02-26T18:14:17.382+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T10:13:51.514442+00:00, map_index=-1, run_start_date=2026-02-26 10:13:58.903337+00:00, run_end_date=2026-02-26 10:14:06.181138+00:00, run_duration=7.277801, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=447, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:13:55.050809+00:00, queued_by_job_id=425, pid=22791
[2026-02-26T18:14:17.384+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T10:13:51.515976+00:00, map_index=-1, run_start_date=2026-02-26 10:14:10.982615+00:00, run_end_date=2026-02-26 10:14:16.638278+00:00, run_duration=5.655663, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=448, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:13:55.050809+00:00, queued_by_job_id=425, pid=22823
[2026-02-26T18:14:20.984+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 10:13:51.514442+00:00: dataset_triggered__2026-02-26T10:13:51.514442+00:00, state:running, queued_at: 2026-02-26 10:13:54.992674+00:00. externally triggered: False> successful
[2026-02-26T18:14:20.985+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 10:13:51.514442+00:00, run_id=dataset_triggered__2026-02-26T10:13:51.514442+00:00, run_start_date=2026-02-26 10:13:55.017108+00:00, run_end_date=2026-02-26 10:14:20.985241+00:00, run_duration=25.968133, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:13:46.477363+00:00, data_interval_end=2026-02-26 10:13:46.477363+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
[2026-02-26T18:14:20.990+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 10:13:51.515976+00:00: dataset_triggered__2026-02-26T10:13:51.515976+00:00, state:running, queued_at: 2026-02-26 10:13:55.001387+00:00. externally triggered: False> successful
[2026-02-26T18:14:20.991+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 10:13:51.515976+00:00, run_id=dataset_triggered__2026-02-26T10:13:51.515976+00:00, run_start_date=2026-02-26 10:13:55.017241+00:00, run_end_date=2026-02-26 10:14:20.991236+00:00, run_duration=25.973995, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:13:46.477363+00:00, data_interval_end=2026-02-26 10:13:46.477363+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
[2026-02-26T18:15:01.152+0800] {scheduler_job_runner.py:435} INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:14:58.421790+00:00 [scheduled]>
[2026-02-26T18:15:01.153+0800] {scheduler_job_runner.py:507} INFO - DAG p_cdrd_all has 0/16 running and queued tasks
[2026-02-26T18:15:01.153+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:14:58.421790+00:00 [scheduled]>
[2026-02-26T18:15:01.156+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:14:58.421790+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:15:01.157+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:14:58.421790+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:15:01.158+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:14:58.421790+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:15:01.160+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:14:58.421790+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:15:03.224+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:15:04.858+0800] {task_command.py:467} INFO - Running <TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:14:58.421790+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:15:05.888+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:14:58.421790+00:00', try_number=1, map_index=-1)
[2026-02-26T18:15:05.898+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T10:14:58.421790+00:00, map_index=-1, run_start_date=2026-02-26 10:15:04.963941+00:00, run_end_date=2026-02-26 10:15:05.177699+00:00, run_duration=0.213758, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=449, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:15:01.155020+00:00, queued_by_job_id=425, pid=22876
[2026-02-26T18:15:08.465+0800] {dagrun.py:854} INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 10:14:58.421790+00:00: manual__2026-02-26T10:14:58.421790+00:00, state:running, queued_at: 2026-02-26 10:14:58.434417+00:00. externally triggered: True> successful
[2026-02-26T18:15:08.466+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 10:14:58.421790+00:00, run_id=manual__2026-02-26T10:14:58.421790+00:00, run_start_date=2026-02-26 10:15:01.132725+00:00, run_end_date=2026-02-26 10:15:08.466053+00:00, run_duration=7.333328, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:14:58.421790+00:00, data_interval_end=2026-02-26 10:14:58.421790+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
[2026-02-26T18:15:08.476+0800] {scheduler_job_runner.py:435} INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:15:05.197117+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:15:05.199047+00:00 [scheduled]>
[2026-02-26T18:15:08.477+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
[2026-02-26T18:15:08.478+0800] {scheduler_job_runner.py:507} INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
[2026-02-26T18:15:08.479+0800] {scheduler_job_runner.py:646} INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:15:05.197117+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:15:05.199047+00:00 [scheduled]>
[2026-02-26T18:15:08.482+0800] {scheduler_job_runner.py:748} INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:15:05.197117+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:15:05.199047+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2026-02-26T18:15:08.483+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:15:05.197117+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:15:08.484+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:15:05.197117+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:15:08.484+0800] {scheduler_job_runner.py:692} INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:15:05.199047+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2026-02-26T18:15:08.485+0800] {base_executor.py:169} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:15:05.199047+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:15:08.488+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:15:05.197117+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:15:10.565+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:15:12.315+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:15:05.197117+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:15:18.715+0800] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:15:05.199047+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
[2026-02-26T18:15:20.920+0800] {dagbag.py:588} INFO - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD/cdrd_1p1n2t.py
Current directory: /Users/linghuchong/Downloads/51/Python/project/instance/airflow284/dags/tag_CDRD
Project root: /Users/linghuchong/Downloads/51/Python/project
Added /Users/linghuchong/Downloads/51/Python/project to sys.path
PO module path: /Users/linghuchong/Downloads/51/Python/project/PO
PO module exists: True
[2026-02-26T18:15:22.607+0800] {task_command.py:467} INFO - Running <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:15:05.199047+00:00 [queued]> on host localhost-2.local
[2026-02-26T18:15:30.453+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:15:05.197117+00:00', try_number=1, map_index=-1)
[2026-02-26T18:15:30.457+0800] {scheduler_job_runner.py:776} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:15:05.199047+00:00', try_number=1, map_index=-1)
[2026-02-26T18:15:30.466+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T10:15:05.199047+00:00, map_index=-1, run_start_date=2026-02-26 10:15:22.675918+00:00, run_end_date=2026-02-26 10:15:29.724573+00:00, run_duration=7.048655, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=451, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:15:08.480731+00:00, queued_by_job_id=425, pid=22918
[2026-02-26T18:15:30.468+0800] {scheduler_job_runner.py:813} INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T10:15:05.197117+00:00, map_index=-1, run_start_date=2026-02-26 10:15:12.386991+00:00, run_end_date=2026-02-26 10:15:17.997438+00:00, run_duration=5.610447, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=450, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:15:08.480731+00:00, queued_by_job_id=425, pid=22879
[2026-02-26T18:15:34.562+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 10:15:05.197117+00:00: dataset_triggered__2026-02-26T10:15:05.197117+00:00, state:running, queued_at: 2026-02-26 10:15:08.426699+00:00. externally triggered: False> successful
[2026-02-26T18:15:34.563+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 10:15:05.197117+00:00, run_id=dataset_triggered__2026-02-26T10:15:05.197117+00:00, run_start_date=2026-02-26 10:15:08.447841+00:00, run_end_date=2026-02-26 10:15:34.563610+00:00, run_duration=26.115769, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:14:58.421790+00:00, data_interval_end=2026-02-26 10:14:58.421790+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
[2026-02-26T18:15:34.570+0800] {dagrun.py:854} INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 10:15:05.199047+00:00: dataset_triggered__2026-02-26T10:15:05.199047+00:00, state:running, queued_at: 2026-02-26 10:15:08.435296+00:00. externally triggered: False> successful
[2026-02-26T18:15:34.571+0800] {dagrun.py:905} INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 10:15:05.199047+00:00, run_id=dataset_triggered__2026-02-26T10:15:05.199047+00:00, run_start_date=2026-02-26 10:15:08.447961+00:00, run_end_date=2026-02-26 10:15:34.571336+00:00, run_duration=26.123375, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:14:58.421790+00:00, data_interval_end=2026-02-26 10:14:58.421790+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
[2026-02-26T18:16:01.321+0800] {scheduler_job_runner.py:1949} INFO - Adopting or resetting orphaned tasks for active dag runs
