2026-02-12 21:17:30,021 INFO - Task context logging is enabled
2026-02-12 21:17:30,023 INFO - Loaded executor: SequentialExecutor
2026-02-12 21:17:30,086 INFO - Starting the scheduler
2026-02-12 21:17:30,087 INFO - Processing each file at most -1 times
2026-02-12 21:17:30,093 INFO - Launched DagFileProcessorManager with pid: 26882
2026-02-12 21:17:30,098 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-12 21:17:30,164 INFO - DAG dw_order_sync is at (or above) max_active_runs (1 of 1), not creating any more runs
2026-02-12 21:17:30,223 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:17:30,224 INFO - DAG dw_order_sync has 0/1 running and queued tasks
2026-02-12 21:17:30,224 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:17:30,227 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-12 21:17:30,228 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2026-02-12 21:17:30,228 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:17:30,230 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:17:32,962 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-12 21:17:32,984 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=scheduled__2026-02-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-12 13:17:32.325739+00:00, run_end_date=2026-02-12 13:17:32.514673+00:00, run_duration=0.188934, state=success, executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-12 13:17:30.225672+00:00, queued_by_job_id=6, pid=26888
2026-02-12 21:17:33,036 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:17:33,037 INFO - DAG dw_order_sync has 0/1 running and queued tasks
2026-02-12 21:17:33,038 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:17:33,040 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-12 21:17:33,042 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-12 21:17:33,044 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:17:33,046 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:17:35,973 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-12 21:17:35,983 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=scheduled__2026-02-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-12 13:17:35.106136+00:00, run_end_date=2026-02-12 13:17:35.558556+00:00, run_duration=0.45242, state=success, executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-12 13:17:33.039501+00:00, queued_by_job_id=6, pid=26895
2026-02-12 21:17:36,042 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:17:36,043 INFO - DAG dw_order_sync has 0/1 running and queued tasks
2026-02-12 21:17:36,044 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:17:36,047 WARNING - cannot record scheduled_duration for task run_automation_test2 because previous state change time has not been saved
2026-02-12 21:17:36,048 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-12 21:17:36,049 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:17:36,050 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:17:38,987 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-12 21:17:38,996 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=scheduled__2026-02-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-12 13:17:38.197138+00:00, run_end_date=2026-02-12 13:17:38.575304+00:00, run_duration=0.378166, state=success, executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-12 13:17:36.045714+00:00, queued_by_job_id=6, pid=26903
2026-02-12 21:17:39,027 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 00:00:00+00:00: scheduled__2026-02-11T00:00:00+00:00, state:running, queued_at: 2026-02-12 13:17:30.153407+00:00. externally triggered: False> successful
2026-02-12 21:17:39,028 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 00:00:00+00:00, run_id=scheduled__2026-02-11T00:00:00+00:00, run_start_date=2026-02-12 13:17:30.177921+00:00, run_end_date=2026-02-12 13:17:39.028781+00:00, run_duration=8.85086, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-11 00:00:00+00:00, data_interval_end=2026-02-12 00:00:00+00:00, dag_hash=e351ac217fac2a089c8384eaffc0bd32
2026-02-12 21:17:39,035 INFO - Setting next_dagrun for dw_order_sync to 2026-02-12 00:00:00+00:00, run_after=2026-02-13 00:00:00+00:00
2026-02-12 21:19:25,070 INFO - Exiting gracefully upon receiving signal 15
2026-02-12 21:19:25,539 INFO - Sending 15 to group 26882. PIDs of all processes in the group: []
2026-02-12 21:19:25,540 INFO - Sending the signal 15 to group 26882
2026-02-12 21:19:25,540 INFO - Sending the signal 15 to process 26882 as process group is missing.
2026-02-12 21:19:25,552 INFO - Sending 15 to group 26882. PIDs of all processes in the group: []
2026-02-12 21:19:25,553 INFO - Sending the signal 15 to group 26882
2026-02-12 21:19:25,554 INFO - Sending the signal 15 to process 26882 as process group is missing.
2026-02-12 21:19:25,554 INFO - Exited execute loop
2026-02-12 21:19:45,682 INFO - Task context logging is enabled
2026-02-12 21:19:45,685 INFO - Loaded executor: SequentialExecutor
2026-02-12 21:19:45,750 INFO - Starting the scheduler
2026-02-12 21:19:45,751 INFO - Processing each file at most -1 times
2026-02-12 21:19:45,758 INFO - Launched DagFileProcessorManager with pid: 27056
2026-02-12 21:19:45,762 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-12 21:20:25,927 INFO - DAG dw_order_sync is at (or above) max_active_runs (1 of 1), not creating any more runs
2026-02-12 21:20:25,996 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:20:25,997 INFO - DAG dw_order_sync has 0/1 running and queued tasks
2026-02-12 21:20:25,998 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:20:26,000 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-12 21:20:26,002 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2026-02-12 21:20:26,003 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:20:26,006 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:20:29,161 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-12 21:20:29,174 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=scheduled__2026-02-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-12 13:20:28.520622+00:00, run_end_date=2026-02-12 13:20:28.719856+00:00, run_duration=0.199234, state=success, executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-12 13:20:25.998848+00:00, queued_by_job_id=7, pid=27116
2026-02-12 21:20:29,226 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:20:29,227 INFO - DAG dw_order_sync has 0/1 running and queued tasks
2026-02-12 21:20:29,228 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:20:29,230 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-12 21:20:29,231 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-12 21:20:29,232 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:20:29,233 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:20:32,070 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-12 21:20:32,081 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=scheduled__2026-02-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-12 13:20:31.254210+00:00, run_end_date=2026-02-12 13:20:31.654600+00:00, run_duration=0.40039, state=success, executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-12 13:20:29.229252+00:00, queued_by_job_id=7, pid=27122
2026-02-12 21:20:32,126 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:20:32,127 INFO - DAG dw_order_sync has 0/1 running and queued tasks
2026-02-12 21:20:32,127 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-11T00:00:00+00:00 [scheduled]>
2026-02-12 21:20:32,130 WARNING - cannot record scheduled_duration for task run_automation_test2 because previous state change time has not been saved
2026-02-12 21:20:32,131 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-12 21:20:32,132 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:20:32,134 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-12 21:20:35,166 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-12 21:20:35,176 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=scheduled__2026-02-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-12 13:20:34.352695+00:00, run_end_date=2026-02-12 13:20:34.740636+00:00, run_duration=0.387941, state=success, executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-12 13:20:32.128735+00:00, queued_by_job_id=7, pid=27133
2026-02-12 21:20:35,216 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 00:00:00+00:00: scheduled__2026-02-11T00:00:00+00:00, state:running, queued_at: 2026-02-12 13:20:25.916977+00:00. externally triggered: False> successful
2026-02-12 21:20:35,218 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 00:00:00+00:00, run_id=scheduled__2026-02-11T00:00:00+00:00, run_start_date=2026-02-12 13:20:25.939835+00:00, run_end_date=2026-02-12 13:20:35.217933+00:00, run_duration=9.278098, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-11 00:00:00+00:00, data_interval_end=2026-02-12 00:00:00+00:00, dag_hash=e351ac217fac2a089c8384eaffc0bd32
2026-02-12 21:20:35,226 INFO - Setting next_dagrun for dw_order_sync to 2026-02-12 00:00:00+00:00, run_after=2026-02-13 00:00:00+00:00
2026-02-12 21:23:44,559 INFO - Exiting gracefully upon receiving signal 15
2026-02-12 21:23:45,001 INFO - Sending 15 to group 27056. PIDs of all processes in the group: []
2026-02-12 21:23:45,002 INFO - Sending the signal 15 to group 27056
2026-02-12 21:23:45,003 INFO - Sending the signal 15 to process 27056 as process group is missing.
2026-02-12 21:23:45,015 INFO - Sending 15 to group 27056. PIDs of all processes in the group: []
2026-02-12 21:23:45,016 INFO - Sending the signal 15 to group 27056
2026-02-12 21:23:45,016 INFO - Sending the signal 15 to process 27056 as process group is missing.
2026-02-12 21:23:45,017 INFO - Exited execute loop
2026-02-12 21:26:49,569 INFO - Task context logging is enabled
2026-02-12 21:26:49,572 INFO - Loaded executor: SequentialExecutor
2026-02-12 21:26:49,662 INFO - Starting the scheduler
2026-02-12 21:26:49,663 INFO - Processing each file at most -1 times
2026-02-12 21:26:49,673 INFO - Launched DagFileProcessorManager with pid: 27464
2026-02-12 21:26:49,678 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-12 21:27:37,587 INFO - Exiting gracefully upon receiving signal 15
2026-02-12 21:27:38,015 INFO - Sending 15 to group 27464. PIDs of all processes in the group: []
2026-02-12 21:27:38,016 INFO - Sending the signal 15 to group 27464
2026-02-12 21:27:38,017 INFO - Sending the signal 15 to process 27464 as process group is missing.
2026-02-12 21:27:38,028 INFO - Sending 15 to group 27464. PIDs of all processes in the group: []
2026-02-12 21:27:38,029 INFO - Sending the signal 15 to group 27464
2026-02-12 21:27:38,029 INFO - Sending the signal 15 to process 27464 as process group is missing.
2026-02-12 21:27:38,030 INFO - Exited execute loop
2026-02-12 21:27:41,429 INFO - Task context logging is enabled
2026-02-12 21:27:41,431 INFO - Loaded executor: SequentialExecutor
2026-02-12 21:27:41,511 INFO - Starting the scheduler
2026-02-12 21:27:41,513 INFO - Processing each file at most -1 times
2026-02-12 21:27:41,523 INFO - Launched DagFileProcessorManager with pid: 27544
2026-02-12 21:27:41,531 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-12 21:28:33,359 INFO - Exiting gracefully upon receiving signal 15
2026-02-12 21:28:33,811 INFO - Sending 15 to group 27544. PIDs of all processes in the group: []
2026-02-12 21:28:33,812 INFO - Sending the signal 15 to group 27544
2026-02-12 21:28:33,813 INFO - Sending the signal 15 to process 27544 as process group is missing.
2026-02-12 21:28:33,823 INFO - Sending 15 to group 27544. PIDs of all processes in the group: []
2026-02-12 21:28:33,824 INFO - Sending the signal 15 to group 27544
2026-02-12 21:28:33,824 INFO - Sending the signal 15 to process 27544 as process group is missing.
2026-02-12 21:28:33,825 INFO - Exited execute loop
2026-02-12 23:46:06,769 INFO - Loaded executor: SequentialExecutor
2026-02-12 23:52:57,159 INFO - Loaded executor: SequentialExecutor
2026-02-12 23:56:05,946 INFO - Loaded executor: SequentialExecutor
2026-02-13 00:06:42,462 INFO - Loaded executor: SequentialExecutor
2026-02-13 00:16:01,354 INFO - Loaded executor: SequentialExecutor
2026-02-13 00:35:48,895 INFO - Loaded executor: SequentialExecutor
2026-02-13 00:35:49,435 INFO - Starting the scheduler
2026-02-13 00:35:49,436 INFO - Processing each file at most -1 times
2026-02-13 00:35:49,442 INFO - Launched DagFileProcessorManager with pid: 3597
2026-02-13 00:35:49,447 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 00:42:12,985 INFO - Heartbeat recovered after 169.74 seconds
2026-02-13 00:43:05,883 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 00:43:06,886 INFO - Sending Signals.SIGTERM to group 3597. PIDs of all processes in the group: [3597]
2026-02-13 00:43:06,887 INFO - Sending the signal Signals.SIGTERM to group 3597
2026-02-13 00:43:06,903 INFO - Process psutil.Process(pid=3597, status='terminated', exitcode=<Negsignal.SIGTERM: -15>, started='00:35:49') (3597) terminated with exit code Negsignal.SIGTERM
2026-02-13 00:43:06,905 INFO - Sending Signals.SIGTERM to group 3597. PIDs of all processes in the group: []
2026-02-13 00:43:06,906 INFO - Sending the signal Signals.SIGTERM to group 3597
2026-02-13 00:43:06,907 INFO - Sending the signal Signals.SIGTERM to process 3597 as process group is missing.
2026-02-13 00:43:06,908 INFO - Exited execute loop
2026-02-13 08:12:37,398 INFO - Loaded executor: SequentialExecutor
2026-02-13 08:12:38,859 INFO - Starting the scheduler
2026-02-13 08:12:38,861 INFO - Processing each file at most -1 times
2026-02-13 08:12:38,877 INFO - Launched DagFileProcessorManager with pid: 1168
2026-02-13 08:12:38,885 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:12:49,995 INFO - Setting next_dagrun for dw_order_sync to 2026-02-13 00:00:00+00:00, run_after=2026-02-14 00:00:00+00:00
2026-02-13 08:12:50,338 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-12T00:00:00+00:00 [scheduled]>
2026-02-13 08:12:50,339 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:12:50,340 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-12T00:00:00+00:00 [scheduled]>
2026-02-13 08:12:50,344 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-12T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:12:50,346 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-13 08:12:50,348 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:12:50,350 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:12:55,572 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-12T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-13 08:12:55,592 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=scheduled__2026-02-12T00:00:00+00:00, map_index=-1, run_start_date=2026-02-13 00:12:54.275855+00:00, run_end_date=2026-02-13 00:12:54.689110+00:00, run_duration=0.413255, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=8, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 00:12:50.342111+00:00, queued_by_job_id=7, pid=1198
2026-02-13 08:12:55,683 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-12T00:00:00+00:00 [scheduled]>
2026-02-13 08:12:55,684 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:12:55,685 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-12T00:00:00+00:00 [scheduled]>
2026-02-13 08:12:55,688 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-12T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:12:55,689 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 08:12:55,690 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:12:55,693 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:13:27,391 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-12T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-13 08:13:27,401 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=scheduled__2026-02-12T00:00:00+00:00, map_index=-1, run_start_date=2026-02-13 00:12:59.657432+00:00, run_end_date=2026-02-13 00:13:26.757785+00:00, run_duration=27.100353, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 00:12:55.686573+00:00, queued_by_job_id=7, pid=1212
2026-02-13 08:13:27,423 INFO - Heartbeat recovered after 31.81 seconds
2026-02-13 08:13:30,110 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-12T00:00:00+00:00 [scheduled]>
2026-02-13 08:13:30,111 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:13:30,112 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-12T00:00:00+00:00 [scheduled]>
2026-02-13 08:13:30,114 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-12T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:13:30,115 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-12T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:13:30,116 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:13:30,118 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:13:39,662 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-12T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-13 08:13:39,673 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=scheduled__2026-02-12T00:00:00+00:00, map_index=-1, run_start_date=2026-02-13 00:13:32.857265+00:00, run_end_date=2026-02-13 00:13:39.140010+00:00, run_duration=6.282745, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:13:30.113324+00:00, queued_by_job_id=7, pid=1281
2026-02-13 08:13:39,735 INFO - Marking run <DagRun dw_order_sync @ 2026-02-12 00:00:00+00:00: scheduled__2026-02-12T00:00:00+00:00, state:running, queued_at: 2026-02-13 00:12:49.964054+00:00. externally triggered: False> successful
2026-02-13 08:13:39,737 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-12 00:00:00+00:00, run_id=scheduled__2026-02-12T00:00:00+00:00, run_start_date=2026-02-13 00:12:50.025095+00:00, run_end_date=2026-02-13 00:13:39.737284+00:00, run_duration=49.712189, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-12 00:00:00+00:00, data_interval_end=2026-02-13 00:00:00+00:00, dag_hash=340b2787125831c612b39fbc22c30471
2026-02-13 08:13:39,742 INFO - Setting next_dagrun for dw_order_sync to 2026-02-13 00:00:00+00:00, run_after=2026-02-14 00:00:00+00:00
2026-02-13 08:17:38,958 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:18:26,045 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>
2026-02-13 08:18:26,046 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:18:26,047 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>
2026-02-13 08:18:26,049 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:18:26,050 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:18:24.219436+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-13 08:18:26,050 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:18:24.219436+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:18:26,053 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:18:24.219436+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:18:29,844 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:18:24.219436+00:00', try_number=1, map_index=-1)
2026-02-13 08:18:29,854 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T00:18:24.219436+00:00, map_index=-1, run_start_date=2026-02-13 00:18:28.969094+00:00, run_end_date=2026-02-13 00:18:29.318396+00:00, run_duration=0.349302, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=11, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 00:18:26.048266+00:00, queued_by_job_id=7, pid=1606
2026-02-13 08:18:29,904 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>
2026-02-13 08:18:29,905 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:18:29,906 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>
2026-02-13 08:18:29,908 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:18:29,909 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:18:24.219436+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 08:18:29,910 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:18:24.219436+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:18:29,912 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:18:24.219436+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:18:44,568 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:18:24.219436+00:00', try_number=1, map_index=-1)
2026-02-13 08:18:44,578 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-13T00:18:24.219436+00:00, map_index=-1, run_start_date=2026-02-13 00:18:32.487156+00:00, run_end_date=2026-02-13 00:18:44.040088+00:00, run_duration=11.552932, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=12, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 00:18:29.907098+00:00, queued_by_job_id=7, pid=1609
2026-02-13 08:18:44,647 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>
2026-02-13 08:18:44,648 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:18:44,648 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>
2026-02-13 08:18:44,650 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:18:24.219436+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:18:44,651 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:18:24.219436+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:18:44,652 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:18:24.219436+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:18:44,654 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:18:24.219436+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:18:55,247 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:18:24.219436+00:00', try_number=1, map_index=-1)
2026-02-13 08:18:55,256 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-13T00:18:24.219436+00:00, map_index=-1, run_start_date=2026-02-13 00:18:47.083853+00:00, run_end_date=2026-02-13 00:18:54.735331+00:00, run_duration=7.651478, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=13, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:18:44.649721+00:00, queued_by_job_id=7, pid=1634
2026-02-13 08:18:57,472 INFO - Marking run <DagRun dw_order_sync @ 2026-02-13 00:18:24.219436+00:00: manual__2026-02-13T00:18:24.219436+00:00, state:running, queued_at: 2026-02-13 00:18:24.242798+00:00. externally triggered: True> successful
2026-02-13 08:18:57,473 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-13 00:18:24.219436+00:00, run_id=manual__2026-02-13T00:18:24.219436+00:00, run_start_date=2026-02-13 00:18:26.017239+00:00, run_end_date=2026-02-13 00:18:57.473471+00:00, run_duration=31.456232, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-12 00:00:00+00:00, data_interval_end=2026-02-13 00:00:00+00:00, dag_hash=340b2787125831c612b39fbc22c30471
2026-02-13 08:19:43,818 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>
2026-02-13 08:19:43,819 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:19:43,820 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>
2026-02-13 08:19:43,822 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:19:43,824 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:19:42.112301+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-13 08:19:43,824 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:19:42.112301+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:19:43,827 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:19:42.112301+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:19:47,263 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:19:42.112301+00:00', try_number=1, map_index=-1)
2026-02-13 08:19:47,272 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T00:19:42.112301+00:00, map_index=-1, run_start_date=2026-02-13 00:19:46.421204+00:00, run_end_date=2026-02-13 00:19:46.743513+00:00, run_duration=0.322309, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=14, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 00:19:43.821755+00:00, queued_by_job_id=7, pid=1697
2026-02-13 08:19:47,347 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>
2026-02-13 08:19:47,348 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:19:47,349 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>
2026-02-13 08:19:47,351 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:19:47,352 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:19:42.112301+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 08:19:47,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:19:42.112301+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:19:47,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:19:42.112301+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:19:56,969 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:19:42.112301+00:00', try_number=1, map_index=-1)
2026-02-13 08:19:56,978 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-13T00:19:42.112301+00:00, map_index=-1, run_start_date=2026-02-13 00:19:49.742640+00:00, run_end_date=2026-02-13 00:19:56.428057+00:00, run_duration=6.685417, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=15, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 00:19:47.350025+00:00, queued_by_job_id=7, pid=1700
2026-02-13 08:19:57,044 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>
2026-02-13 08:19:57,045 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:19:57,045 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>
2026-02-13 08:19:57,047 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:19:42.112301+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:19:57,048 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:19:42.112301+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:19:57,049 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:19:42.112301+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:19:57,052 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:19:42.112301+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:20:07,717 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:19:42.112301+00:00', try_number=1, map_index=-1)
2026-02-13 08:20:07,727 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-13T00:19:42.112301+00:00, map_index=-1, run_start_date=2026-02-13 00:19:59.681703+00:00, run_end_date=2026-02-13 00:20:07.265611+00:00, run_duration=7.583908, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=16, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:19:57.046632+00:00, queued_by_job_id=7, pid=1719
2026-02-13 08:20:10,034 INFO - Marking run <DagRun dw_order_sync @ 2026-02-13 00:19:42.112301+00:00: manual__2026-02-13T00:19:42.112301+00:00, state:running, queued_at: 2026-02-13 00:19:42.125379+00:00. externally triggered: True> successful
2026-02-13 08:20:10,036 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-13 00:19:42.112301+00:00, run_id=manual__2026-02-13T00:19:42.112301+00:00, run_start_date=2026-02-13 00:19:43.798104+00:00, run_end_date=2026-02-13 00:20:10.035933+00:00, run_duration=26.237829, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-12 00:00:00+00:00, data_interval_end=2026-02-13 00:00:00+00:00, dag_hash=340b2787125831c612b39fbc22c30471
2026-02-13 08:20:58,292 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>
2026-02-13 08:20:58,293 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:20:58,294 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>
2026-02-13 08:20:58,297 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:20:58,298 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:20:57.274669+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-13 08:20:58,299 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:20:57.274669+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:20:58,302 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:20:57.274669+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:21:02,514 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:20:57.274669+00:00', try_number=1, map_index=-1)
2026-02-13 08:21:02,524 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T00:20:57.274669+00:00, map_index=-1, run_start_date=2026-02-13 00:21:01.677546+00:00, run_end_date=2026-02-13 00:21:02.028194+00:00, run_duration=0.350648, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=17, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 00:20:58.296391+00:00, queued_by_job_id=7, pid=1772
2026-02-13 08:21:02,580 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>
2026-02-13 08:21:02,581 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:21:02,582 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>
2026-02-13 08:21:02,585 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:21:02,586 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:20:57.274669+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 08:21:02,586 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:20:57.274669+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:21:02,589 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:20:57.274669+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:21:13,444 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:20:57.274669+00:00', try_number=1, map_index=-1)
2026-02-13 08:21:13,457 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-13T00:20:57.274669+00:00, map_index=-1, run_start_date=2026-02-13 00:21:05.502972+00:00, run_end_date=2026-02-13 00:21:12.895029+00:00, run_duration=7.392057, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=18, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 00:21:02.583646+00:00, queued_by_job_id=7, pid=1775
2026-02-13 08:21:15,924 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>
2026-02-13 08:21:15,925 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:21:15,926 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>
2026-02-13 08:21:15,928 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:20:57.274669+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:21:15,929 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:20:57.274669+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:21:15,930 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:20:57.274669+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:21:15,932 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:20:57.274669+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:21:25,166 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:20:57.274669+00:00', try_number=1, map_index=-1)
2026-02-13 08:21:25,176 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-13T00:20:57.274669+00:00, map_index=-1, run_start_date=2026-02-13 00:21:18.637785+00:00, run_end_date=2026-02-13 00:21:24.632121+00:00, run_duration=5.994336, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=19, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:21:15.927188+00:00, queued_by_job_id=7, pid=1796
2026-02-13 08:21:25,224 INFO - Marking run <DagRun dw_order_sync @ 2026-02-13 00:20:57.274669+00:00: manual__2026-02-13T00:20:57.274669+00:00, state:running, queued_at: 2026-02-13 00:20:57.314532+00:00. externally triggered: True> successful
2026-02-13 08:21:25,225 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-13 00:20:57.274669+00:00, run_id=manual__2026-02-13T00:20:57.274669+00:00, run_start_date=2026-02-13 00:20:58.266283+00:00, run_end_date=2026-02-13 00:21:25.225572+00:00, run_duration=26.959289, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-12 00:00:00+00:00, data_interval_end=2026-02-13 00:00:00+00:00, dag_hash=340b2787125831c612b39fbc22c30471
2026-02-13 08:22:39,004 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:23:29,386 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 08:23:29,939 INFO - Sending Signals.SIGTERM to group 1168. PIDs of all processes in the group: []
2026-02-13 08:23:29,940 INFO - Sending the signal Signals.SIGTERM to group 1168
2026-02-13 08:23:29,940 INFO - Sending the signal Signals.SIGTERM to process 1168 as process group is missing.
2026-02-13 08:23:29,950 INFO - Sending Signals.SIGTERM to group 1168. PIDs of all processes in the group: []
2026-02-13 08:23:29,950 INFO - Sending the signal Signals.SIGTERM to group 1168
2026-02-13 08:23:29,951 INFO - Sending the signal Signals.SIGTERM to process 1168 as process group is missing.
2026-02-13 08:23:29,952 INFO - Exited execute loop
2026-02-13 08:23:42,233 INFO - Loaded executor: SequentialExecutor
2026-02-13 08:23:42,734 INFO - Starting the scheduler
2026-02-13 08:23:42,735 INFO - Processing each file at most -1 times
2026-02-13 08:23:42,741 INFO - Launched DagFileProcessorManager with pid: 2011
2026-02-13 08:23:42,746 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:23:55,543 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>
2026-02-13 08:23:55,544 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:23:55,545 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>
2026-02-13 08:23:55,547 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:23:55,549 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:23:54.584326+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-13 08:23:55,550 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:23:54.584326+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:23:55,552 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:23:54.584326+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:23:59,521 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:23:54.584326+00:00', try_number=1, map_index=-1)
2026-02-13 08:23:59,535 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T00:23:54.584326+00:00, map_index=-1, run_start_date=2026-02-13 00:23:58.552150+00:00, run_end_date=2026-02-13 00:23:58.918671+00:00, run_duration=0.366521, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=21, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 00:23:55.546246+00:00, queued_by_job_id=20, pid=2017
2026-02-13 08:23:59,601 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>
2026-02-13 08:23:59,602 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:23:59,603 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>
2026-02-13 08:23:59,605 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:23:59,606 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:23:54.584326+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 08:23:59,606 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:23:54.584326+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:23:59,609 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:23:54.584326+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:24:11,649 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:23:54.584326+00:00', try_number=1, map_index=-1)
2026-02-13 08:24:11,662 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-13T00:23:54.584326+00:00, map_index=-1, run_start_date=2026-02-13 00:24:03.078048+00:00, run_end_date=2026-02-13 00:24:11.084049+00:00, run_duration=8.006001, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=22, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 00:23:59.604060+00:00, queued_by_job_id=20, pid=2023
2026-02-13 08:24:11,723 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>
2026-02-13 08:24:11,724 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:24:11,725 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>
2026-02-13 08:24:11,727 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:23:54.584326+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:24:11,729 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:23:54.584326+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:24:11,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:23:54.584326+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:24:11,732 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:23:54.584326+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:24:21,197 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:23:54.584326+00:00', try_number=1, map_index=-1)
2026-02-13 08:24:21,208 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-13T00:23:54.584326+00:00, map_index=-1, run_start_date=2026-02-13 00:24:14.431573+00:00, run_end_date=2026-02-13 00:24:20.682794+00:00, run_duration=6.251221, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=23, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:24:11.726498+00:00, queued_by_job_id=20, pid=2068
2026-02-13 08:24:23,703 INFO - Marking run <DagRun dw_order_sync @ 2026-02-13 00:23:54.584326+00:00: manual__2026-02-13T00:23:54.584326+00:00, state:running, queued_at: 2026-02-13 00:23:54.610819+00:00. externally triggered: True> successful
2026-02-13 08:24:23,705 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-13 00:23:54.584326+00:00, run_id=manual__2026-02-13T00:23:54.584326+00:00, run_start_date=2026-02-13 00:23:55.367677+00:00, run_end_date=2026-02-13 00:24:23.705760+00:00, run_duration=28.338083, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-11 16:00:00+00:00, data_interval_end=2026-02-12 16:00:00+00:00, dag_hash=e441836cdc8ba3fd622c724e955ce635
2026-02-13 08:28:42,805 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:28:48,974 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 08:28:49,456 INFO - Sending Signals.SIGTERM to group 2011. PIDs of all processes in the group: []
2026-02-13 08:28:49,457 INFO - Sending the signal Signals.SIGTERM to group 2011
2026-02-13 08:28:49,458 INFO - Sending the signal Signals.SIGTERM to process 2011 as process group is missing.
2026-02-13 08:28:49,467 INFO - Sending Signals.SIGTERM to group 2011. PIDs of all processes in the group: []
2026-02-13 08:28:49,468 INFO - Sending the signal Signals.SIGTERM to group 2011
2026-02-13 08:28:49,469 INFO - Sending the signal Signals.SIGTERM to process 2011 as process group is missing.
2026-02-13 08:28:49,469 INFO - Exited execute loop
2026-02-13 08:29:02,714 INFO - Loaded executor: SequentialExecutor
2026-02-13 08:29:03,229 INFO - Starting the scheduler
2026-02-13 08:29:03,230 INFO - Processing each file at most -1 times
2026-02-13 08:29:03,236 INFO - Launched DagFileProcessorManager with pid: 2365
2026-02-13 08:29:03,243 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:29:14,715 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>
2026-02-13 08:29:14,717 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:29:14,717 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>
2026-02-13 08:29:14,721 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:29:14,721 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:29:13.278904+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-13 08:29:14,722 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:29:13.278904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:29:14,724 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:29:13.278904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:29:18,672 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:29:13.278904+00:00', try_number=1, map_index=-1)
2026-02-13 08:29:18,687 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T00:29:13.278904+00:00, map_index=-1, run_start_date=2026-02-13 00:29:17.569141+00:00, run_end_date=2026-02-13 00:29:17.961250+00:00, run_duration=0.392109, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=25, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 00:29:14.719303+00:00, queued_by_job_id=24, pid=2374
2026-02-13 08:29:18,761 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>
2026-02-13 08:29:18,762 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:29:18,763 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>
2026-02-13 08:29:18,765 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:29:18,767 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:29:13.278904+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 08:29:18,767 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:29:13.278904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:29:18,770 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:29:13.278904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:29:30,124 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:29:13.278904+00:00', try_number=1, map_index=-1)
2026-02-13 08:29:30,136 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-13T00:29:13.278904+00:00, map_index=-1, run_start_date=2026-02-13 00:29:21.731928+00:00, run_end_date=2026-02-13 00:29:29.534630+00:00, run_duration=7.802702, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=26, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 00:29:18.764704+00:00, queued_by_job_id=24, pid=2377
2026-02-13 08:29:30,195 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>
2026-02-13 08:29:30,196 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:29:30,197 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>
2026-02-13 08:29:30,199 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-13T00:29:13.278904+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:29:30,200 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:29:13.278904+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:29:30,201 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:29:13.278904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:29:30,203 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-13T00:29:13.278904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:29:40,780 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-13T00:29:13.278904+00:00', try_number=1, map_index=-1)
2026-02-13 08:29:40,790 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-13T00:29:13.278904+00:00, map_index=-1, run_start_date=2026-02-13 00:29:32.988371+00:00, run_end_date=2026-02-13 00:29:40.200077+00:00, run_duration=7.211706, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=27, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:29:30.198138+00:00, queued_by_job_id=24, pid=2397
2026-02-13 08:29:43,372 INFO - Marking run <DagRun dw_order_sync @ 2026-02-13 00:29:13.278904+00:00: manual__2026-02-13T00:29:13.278904+00:00, state:running, queued_at: 2026-02-13 00:29:13.310493+00:00. externally triggered: True> successful
2026-02-13 08:29:43,374 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-13 00:29:13.278904+00:00, run_id=manual__2026-02-13T00:29:13.278904+00:00, run_start_date=2026-02-13 00:29:14.523500+00:00, run_end_date=2026-02-13 00:29:43.374511+00:00, run_duration=28.851011, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-11 16:00:00+00:00, data_interval_end=2026-02-12 16:00:00+00:00, dag_hash=e441836cdc8ba3fd622c724e955ce635
2026-02-13 08:30:35,235 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 08:30:35,782 INFO - Sending Signals.SIGTERM to group 2365. PIDs of all processes in the group: []
2026-02-13 08:30:35,782 INFO - Sending the signal Signals.SIGTERM to group 2365
2026-02-13 08:30:35,783 INFO - Sending the signal Signals.SIGTERM to process 2365 as process group is missing.
2026-02-13 08:30:35,793 INFO - Sending Signals.SIGTERM to group 2365. PIDs of all processes in the group: []
2026-02-13 08:30:35,794 INFO - Sending the signal Signals.SIGTERM to group 2365
2026-02-13 08:30:35,795 INFO - Sending the signal Signals.SIGTERM to process 2365 as process group is missing.
2026-02-13 08:30:35,796 INFO - Exited execute loop
2026-02-13 08:30:42,025 INFO - Loaded executor: SequentialExecutor
2026-02-13 08:30:42,545 INFO - Starting the scheduler
2026-02-13 08:30:42,546 INFO - Processing each file at most -1 times
2026-02-13 08:30:42,554 INFO - Launched DagFileProcessorManager with pid: 2436
2026-02-13 08:30:42,558 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:31:09,872 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:31:08.416794+00:00 [scheduled]>
2026-02-13 08:31:09,872 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:31:09,873 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:31:08.416794+00:00 [scheduled]>
2026-02-13 08:31:09,876 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-13T00:31:08.416794+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:31:09,878 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:31:08.416794+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-13 08:31:09,878 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:31:08.416794+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:31:09,881 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-13T00:31:08.416794+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:31:13,564 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T00:31:08.416794+00:00', try_number=1, map_index=-1)
2026-02-13 08:31:13,577 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T00:31:08.416794+00:00, map_index=-1, run_start_date=2026-02-13 00:31:12.615491+00:00, run_end_date=2026-02-13 00:31:12.976229+00:00, run_duration=0.360738, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=29, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 00:31:09.874916+00:00, queued_by_job_id=28, pid=2457
2026-02-13 08:31:13,648 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:31:08.416794+00:00 [scheduled]>
2026-02-13 08:31:13,650 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-13 08:31:13,651 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:31:08.416794+00:00 [scheduled]>
2026-02-13 08:31:13,653 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-13T00:31:08.416794+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:31:13,654 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:31:08.416794+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 08:31:13,655 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:31:08.416794+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:31:13,657 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-13T00:31:08.416794+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-13 08:31:25,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-13T00:31:08.416794+00:00', try_number=1, map_index=-1)
2026-02-13 08:35:42,613 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:40:42,882 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:40:55,627 INFO - Setting next_dagrun for test_connection_mysql to None, run_after=None
2026-02-13 08:40:55,661 INFO - 1 tasks up for execution:
	<TaskInstance: test_connection_mysql.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 08:40:55,662 INFO - DAG test_connection_mysql has 0/16 running and queued tasks
2026-02-13 08:40:55,663 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connection_mysql.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 08:40:55,665 INFO - Trying to enqueue tasks: [<TaskInstance: test_connection_mysql.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:40:55,666 INFO - Sending TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:40:55,666 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:40:55,670 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:41:00,273 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=1, map_index=-1)
2026-02-13 08:41:00,288 INFO - TaskInstance Finished: dag_id=test_connection_mysql, task_id=query_mysql, run_id=scheduled__2026-02-11T16:00:00+00:00, map_index=-1, run_start_date=2026-02-13 00:40:59.167541+00:00, run_end_date=2026-02-13 00:40:59.564241+00:00, run_duration=0.3967, state=up_for_retry, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:40:55.664053+00:00, queued_by_job_id=28, pid=2814
2026-02-13 08:42:00,559 INFO - 1 tasks up for execution:
	<TaskInstance: test_connection_mysql.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 08:42:00,560 INFO - DAG test_connection_mysql has 0/16 running and queued tasks
2026-02-13 08:42:00,560 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connection_mysql.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 08:42:00,563 INFO - Trying to enqueue tasks: [<TaskInstance: test_connection_mysql.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:42:00,564 INFO - Sending TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:42:00,565 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:42:00,568 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:42:05,091 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=2, map_index=-1)
2026-02-13 08:42:05,108 INFO - TaskInstance Finished: dag_id=test_connection_mysql, task_id=query_mysql, run_id=scheduled__2026-02-11T16:00:00+00:00, map_index=-1, run_start_date=2026-02-13 00:42:03.948778+00:00, run_end_date=2026-02-13 00:42:04.349330+00:00, run_duration=0.400552, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:42:00.561931+00:00, queued_by_job_id=28, pid=2859
2026-02-13 08:42:05,175 ERROR - Marking run <DagRun test_connection_mysql @ 2026-02-11 16:00:00+00:00: scheduled__2026-02-11T16:00:00+00:00, state:running, queued_at: 2026-02-13 00:40:55.618665+00:00. externally triggered: False> failed
2026-02-13 08:42:05,178 INFO - DagRun Finished: dag_id=test_connection_mysql, execution_date=2026-02-11 16:00:00+00:00, run_id=scheduled__2026-02-11T16:00:00+00:00, run_start_date=2026-02-13 00:40:55.639877+00:00, run_end_date=2026-02-13 00:42:05.178026+00:00, run_duration=69.538149, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-11 16:00:00+00:00, data_interval_end=2026-02-11 16:00:00+00:00, dag_hash=8182ea0d671bb8e51dd0fa1c60bbda16
2026-02-13 08:42:05,183 INFO - Setting next_dagrun for test_connection_mysql to None, run_after=None
2026-02-13 08:44:46,863 INFO - 1 tasks up for execution:
	<TaskInstance: test_connection_mysql.query_mysql manual__2026-02-13T00:44:42.784171+00:00 [scheduled]>
2026-02-13 08:44:46,865 INFO - DAG test_connection_mysql has 0/16 running and queued tasks
2026-02-13 08:44:46,866 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connection_mysql.query_mysql manual__2026-02-13T00:44:42.784171+00:00 [scheduled]>
2026-02-13 08:44:46,868 INFO - Trying to enqueue tasks: [<TaskInstance: test_connection_mysql.query_mysql manual__2026-02-13T00:44:42.784171+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:44:46,869 INFO - Sending TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='manual__2026-02-13T00:44:42.784171+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:44:46,870 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'manual__2026-02-13T00:44:42.784171+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:44:46,872 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'manual__2026-02-13T00:44:42.784171+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:44:51,430 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='manual__2026-02-13T00:44:42.784171+00:00', try_number=1, map_index=-1)
2026-02-13 08:44:51,439 INFO - TaskInstance Finished: dag_id=test_connection_mysql, task_id=query_mysql, run_id=manual__2026-02-13T00:44:42.784171+00:00, map_index=-1, run_start_date=2026-02-13 00:44:50.072758+00:00, run_end_date=2026-02-13 00:44:50.861206+00:00, run_duration=0.788448, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:44:46.867278+00:00, queued_by_job_id=28, pid=3074
2026-02-13 08:44:51,517 INFO - Marking run <DagRun test_connection_mysql @ 2026-02-13 00:44:42.784171+00:00: manual__2026-02-13T00:44:42.784171+00:00, state:running, queued_at: 2026-02-13 00:44:42.803526+00:00. externally triggered: True> successful
2026-02-13 08:44:51,517 INFO - DagRun Finished: dag_id=test_connection_mysql, execution_date=2026-02-13 00:44:42.784171+00:00, run_id=manual__2026-02-13T00:44:42.784171+00:00, run_start_date=2026-02-13 00:44:46.843289+00:00, run_end_date=2026-02-13 00:44:51.517879+00:00, run_duration=4.67459, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 00:44:42.784171+00:00, data_interval_end=2026-02-13 00:44:42.784171+00:00, dag_hash=8182ea0d671bb8e51dd0fa1c60bbda16
2026-02-13 08:45:42,918 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:50:42,965 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 08:53:58,786 INFO - 1 tasks up for execution:
	<TaskInstance: test_connection_mysql.query_mysql manual__2026-02-13T00:53:57.396587+00:00 [scheduled]>
2026-02-13 08:53:58,788 INFO - DAG test_connection_mysql has 0/16 running and queued tasks
2026-02-13 08:53:58,788 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_connection_mysql.query_mysql manual__2026-02-13T00:53:57.396587+00:00 [scheduled]>
2026-02-13 08:53:58,791 INFO - Trying to enqueue tasks: [<TaskInstance: test_connection_mysql.query_mysql manual__2026-02-13T00:53:57.396587+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 08:53:58,792 INFO - Sending TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='manual__2026-02-13T00:53:57.396587+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 08:53:58,792 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'manual__2026-02-13T00:53:57.396587+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:53:58,795 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_connection_mysql', 'query_mysql', 'manual__2026-02-13T00:53:57.396587+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 08:54:03,075 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_connection_mysql', task_id='query_mysql', run_id='manual__2026-02-13T00:53:57.396587+00:00', try_number=1, map_index=-1)
2026-02-13 08:54:03,084 INFO - TaskInstance Finished: dag_id=test_connection_mysql, task_id=query_mysql, run_id=manual__2026-02-13T00:53:57.396587+00:00, map_index=-1, run_start_date=2026-02-13 00:54:02.066217+00:00, run_end_date=2026-02-13 00:54:02.476936+00:00, run_duration=0.410719, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 00:53:58.790025+00:00, queued_by_job_id=28, pid=3438
2026-02-13 08:54:03,133 INFO - Marking run <DagRun test_connection_mysql @ 2026-02-13 00:53:57.396587+00:00: manual__2026-02-13T00:53:57.396587+00:00, state:running, queued_at: 2026-02-13 00:53:57.404714+00:00. externally triggered: True> successful
2026-02-13 08:54:03,134 INFO - DagRun Finished: dag_id=test_connection_mysql, execution_date=2026-02-13 00:53:57.396587+00:00, run_id=manual__2026-02-13T00:53:57.396587+00:00, run_start_date=2026-02-13 00:53:58.761358+00:00, run_end_date=2026-02-13 00:54:03.134804+00:00, run_duration=4.373446, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 00:53:57.396587+00:00, data_interval_end=2026-02-13 00:53:57.396587+00:00, dag_hash=8182ea0d671bb8e51dd0fa1c60bbda16
2026-02-13 08:55:43,011 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:00:43,041 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:05:43,084 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:10:43,123 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:11:02,748 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 09:11:03,362 INFO - Sending Signals.SIGTERM to group 2436. PIDs of all processes in the group: []
2026-02-13 09:11:03,364 INFO - Sending the signal Signals.SIGTERM to group 2436
2026-02-13 09:11:03,365 INFO - Sending the signal Signals.SIGTERM to process 2436 as process group is missing.
2026-02-13 09:11:03,378 INFO - Sending Signals.SIGTERM to group 2436. PIDs of all processes in the group: []
2026-02-13 09:11:03,379 INFO - Sending the signal Signals.SIGTERM to group 2436
2026-02-13 09:11:03,379 INFO - Sending the signal Signals.SIGTERM to process 2436 as process group is missing.
2026-02-13 09:11:03,380 INFO - Exited execute loop
2026-02-13 09:11:12,391 INFO - Loaded executor: SequentialExecutor
2026-02-13 09:11:12,965 INFO - Starting the scheduler
2026-02-13 09:11:12,966 INFO - Processing each file at most -1 times
2026-02-13 09:11:12,972 INFO - Launched DagFileProcessorManager with pid: 3753
2026-02-13 09:11:12,977 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:12:05,446 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 09:12:06,128 INFO - Sending Signals.SIGTERM to group 3753. PIDs of all processes in the group: []
2026-02-13 09:12:06,129 INFO - Sending the signal Signals.SIGTERM to group 3753
2026-02-13 09:12:06,129 INFO - Sending the signal Signals.SIGTERM to process 3753 as process group is missing.
2026-02-13 09:12:06,140 INFO - Sending Signals.SIGTERM to group 3753. PIDs of all processes in the group: []
2026-02-13 09:12:06,140 INFO - Sending the signal Signals.SIGTERM to group 3753
2026-02-13 09:12:06,141 INFO - Sending the signal Signals.SIGTERM to process 3753 as process group is missing.
2026-02-13 09:12:06,142 INFO - Exited execute loop
2026-02-13 09:12:14,160 INFO - Loaded executor: SequentialExecutor
2026-02-13 09:12:14,587 INFO - Starting the scheduler
2026-02-13 09:12:14,589 INFO - Processing each file at most -1 times
2026-02-13 09:12:14,594 INFO - Launched DagFileProcessorManager with pid: 3821
2026-02-13 09:12:14,601 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:12:39,295 INFO - Setting next_dagrun for test_crm to None, run_after=None
2026-02-13 09:12:39,349 INFO - 1 tasks up for execution:
	<TaskInstance: test_crm.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 09:12:39,350 INFO - DAG test_crm has 0/16 running and queued tasks
2026-02-13 09:12:39,350 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_crm.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 09:12:39,353 INFO - Trying to enqueue tasks: [<TaskInstance: test_crm.query_mysql scheduled__2026-02-11T16:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 09:12:39,354 INFO - Sending TaskInstanceKey(dag_id='test_crm', task_id='query_mysql', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 09:12:39,355 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_crm', 'query_mysql', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:39,359 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_crm', 'query_mysql', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:44,256 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_crm', task_id='query_mysql', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=1, map_index=-1)
2026-02-13 09:12:44,273 INFO - TaskInstance Finished: dag_id=test_crm, task_id=query_mysql, run_id=scheduled__2026-02-11T16:00:00+00:00, map_index=-1, run_start_date=2026-02-13 01:12:43.115596+00:00, run_end_date=2026-02-13 01:12:43.579810+00:00, run_duration=0.464214, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 01:12:39.351859+00:00, queued_by_job_id=36, pid=3846
2026-02-13 09:12:44,334 INFO - 1 tasks up for execution:
	<TaskInstance: test_crm.process_result scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 09:12:44,335 INFO - DAG test_crm has 0/16 running and queued tasks
2026-02-13 09:12:44,336 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_crm.process_result scheduled__2026-02-11T16:00:00+00:00 [scheduled]>
2026-02-13 09:12:44,339 INFO - Trying to enqueue tasks: [<TaskInstance: test_crm.process_result scheduled__2026-02-11T16:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 09:12:44,340 INFO - Sending TaskInstanceKey(dag_id='test_crm', task_id='process_result', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 09:12:44,341 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_crm', 'process_result', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:44,344 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_crm', 'process_result', 'scheduled__2026-02-11T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:48,635 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_crm', task_id='process_result', run_id='scheduled__2026-02-11T16:00:00+00:00', try_number=1, map_index=-1)
2026-02-13 09:12:48,648 INFO - TaskInstance Finished: dag_id=test_crm, task_id=process_result, run_id=scheduled__2026-02-11T16:00:00+00:00, map_index=-1, run_start_date=2026-02-13 01:12:47.510069+00:00, run_end_date=2026-02-13 01:12:47.907668+00:00, run_duration=0.397599, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 01:12:44.337745+00:00, queued_by_job_id=36, pid=3848
2026-02-13 09:12:48,713 INFO - Marking run <DagRun test_crm @ 2026-02-11 16:00:00+00:00: scheduled__2026-02-11T16:00:00+00:00, state:running, queued_at: 2026-02-13 01:12:39.284770+00:00. externally triggered: False> successful
2026-02-13 09:12:48,717 INFO - DagRun Finished: dag_id=test_crm, execution_date=2026-02-11 16:00:00+00:00, run_id=scheduled__2026-02-11T16:00:00+00:00, run_start_date=2026-02-13 01:12:39.306973+00:00, run_end_date=2026-02-13 01:12:48.717091+00:00, run_duration=9.410118, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-11 16:00:00+00:00, data_interval_end=2026-02-11 16:00:00+00:00, dag_hash=ea7b094825b9087a0f7bf9077bdf754f
2026-02-13 09:12:48,722 INFO - Setting next_dagrun for test_crm to None, run_after=None
2026-02-13 09:12:48,732 INFO - 1 tasks up for execution:
	<TaskInstance: test_crm.query_mysql manual__2026-02-13T01:12:44.736895+00:00 [scheduled]>
2026-02-13 09:12:48,732 INFO - DAG test_crm has 0/16 running and queued tasks
2026-02-13 09:12:48,733 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_crm.query_mysql manual__2026-02-13T01:12:44.736895+00:00 [scheduled]>
2026-02-13 09:12:48,736 INFO - Trying to enqueue tasks: [<TaskInstance: test_crm.query_mysql manual__2026-02-13T01:12:44.736895+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 09:12:48,738 INFO - Sending TaskInstanceKey(dag_id='test_crm', task_id='query_mysql', run_id='manual__2026-02-13T01:12:44.736895+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-13 09:12:48,738 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_crm', 'query_mysql', 'manual__2026-02-13T01:12:44.736895+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:48,741 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_crm', 'query_mysql', 'manual__2026-02-13T01:12:44.736895+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:52,576 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_crm', task_id='query_mysql', run_id='manual__2026-02-13T01:12:44.736895+00:00', try_number=1, map_index=-1)
2026-02-13 09:12:52,588 INFO - TaskInstance Finished: dag_id=test_crm, task_id=query_mysql, run_id=manual__2026-02-13T01:12:44.736895+00:00, map_index=-1, run_start_date=2026-02-13 01:12:51.507038+00:00, run_end_date=2026-02-13 01:12:51.930818+00:00, run_duration=0.42378, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 01:12:48.735440+00:00, queued_by_job_id=36, pid=3850
2026-02-13 09:12:55,277 INFO - 1 tasks up for execution:
	<TaskInstance: test_crm.process_result manual__2026-02-13T01:12:44.736895+00:00 [scheduled]>
2026-02-13 09:12:55,278 INFO - DAG test_crm has 0/16 running and queued tasks
2026-02-13 09:12:55,279 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_crm.process_result manual__2026-02-13T01:12:44.736895+00:00 [scheduled]>
2026-02-13 09:12:55,281 INFO - Trying to enqueue tasks: [<TaskInstance: test_crm.process_result manual__2026-02-13T01:12:44.736895+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 09:12:55,283 INFO - Sending TaskInstanceKey(dag_id='test_crm', task_id='process_result', run_id='manual__2026-02-13T01:12:44.736895+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 09:12:55,284 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_crm', 'process_result', 'manual__2026-02-13T01:12:44.736895+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:55,286 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_crm', 'process_result', 'manual__2026-02-13T01:12:44.736895+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_crm/test_crm.py']
2026-02-13 09:12:59,178 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_crm', task_id='process_result', run_id='manual__2026-02-13T01:12:44.736895+00:00', try_number=1, map_index=-1)
2026-02-13 09:12:59,189 INFO - TaskInstance Finished: dag_id=test_crm, task_id=process_result, run_id=manual__2026-02-13T01:12:44.736895+00:00, map_index=-1, run_start_date=2026-02-13 01:12:58.054459+00:00, run_end_date=2026-02-13 01:12:58.474659+00:00, run_duration=0.4202, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=40, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 01:12:55.280355+00:00, queued_by_job_id=36, pid=3853
2026-02-13 09:13:02,163 INFO - Marking run <DagRun test_crm @ 2026-02-13 01:12:44.736895+00:00: manual__2026-02-13T01:12:44.736895+00:00, state:running, queued_at: 2026-02-13 01:12:44.758653+00:00. externally triggered: True> successful
2026-02-13 09:13:02,164 INFO - DagRun Finished: dag_id=test_crm, execution_date=2026-02-13 01:12:44.736895+00:00, run_id=manual__2026-02-13T01:12:44.736895+00:00, run_start_date=2026-02-13 01:12:48.694657+00:00, run_end_date=2026-02-13 01:13:02.164612+00:00, run_duration=13.469955, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 01:12:44.736895+00:00, data_interval_end=2026-02-13 01:12:44.736895+00:00, dag_hash=ea7b094825b9087a0f7bf9077bdf754f
2026-02-13 09:17:14,651 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:22:15,420 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:27:15,461 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:32:15,501 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:37:15,709 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:42:16,203 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:47:17,492 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:52:17,526 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 09:57:17,571 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:02:17,615 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:07:17,663 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:12:17,673 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:17:20,012 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:22:20,050 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:27:20,091 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:32:20,132 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:37:20,172 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:42:21,754 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 10:56:19,329 INFO - Heartbeat recovered after 721.45 seconds
2026-02-13 10:58:12,630 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 10:58:13,433 INFO - Sending Signals.SIGTERM to group 3821. PIDs of all processes in the group: []
2026-02-13 10:58:13,435 INFO - Sending the signal Signals.SIGTERM to group 3821
2026-02-13 10:58:13,436 INFO - Sending the signal Signals.SIGTERM to process 3821 as process group is missing.
2026-02-13 10:58:13,453 INFO - Sending Signals.SIGTERM to group 3821. PIDs of all processes in the group: []
2026-02-13 10:58:13,454 INFO - Sending the signal Signals.SIGTERM to group 3821
2026-02-13 10:58:13,454 INFO - Sending the signal Signals.SIGTERM to process 3821 as process group is missing.
2026-02-13 10:58:13,455 INFO - Exited execute loop
2026-02-13 10:58:20,272 INFO - Loaded executor: SequentialExecutor
2026-02-13 10:58:20,874 INFO - Starting the scheduler
2026-02-13 10:58:20,877 INFO - Processing each file at most -1 times
2026-02-13 10:58:20,887 INFO - Launched DagFileProcessorManager with pid: 6580
2026-02-13 10:58:20,897 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:00:57,496 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:00:56.955760+00:00 [scheduled]>
2026-02-13 11:00:57,497 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 11:00:57,497 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:00:56.955760+00:00 [scheduled]>
2026-02-13 11:00:57,501 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:00:56.955760+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:00:57,502 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:00:56.955760+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:00:57,503 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:00:56.955760+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:00:57,506 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:00:56.955760+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:01:01,698 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:00:56.955760+00:00', try_number=1, map_index=-1)
2026-02-13 11:01:01,712 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T03:00:56.955760+00:00, map_index=-1, run_start_date=2026-02-13 03:01:00.771346+00:00, run_end_date=2026-02-13 03:01:01.167277+00:00, run_duration=0.395931, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=42, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:00:57.499727+00:00, queued_by_job_id=41, pid=6637
2026-02-13 11:01:01,759 ERROR - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 03:00:56.955760+00:00: manual__2026-02-13T03:00:56.955760+00:00, state:running, queued_at: 2026-02-13 03:00:56.975748+00:00. externally triggered: True> failed
2026-02-13 11:01:01,761 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 03:00:56.955760+00:00, run_id=manual__2026-02-13T03:00:56.955760+00:00, run_start_date=2026-02-13 03:00:57.463039+00:00, run_end_date=2026-02-13 03:01:01.761192+00:00, run_duration=4.298153, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 03:00:56.955760+00:00, data_interval_end=2026-02-13 03:00:56.955760+00:00, dag_hash=292d5ad65135765608fc09000942b435
2026-02-13 11:03:01,854 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:03:00.730591+00:00 [scheduled]>
2026-02-13 11:03:01,855 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 11:03:01,856 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:03:00.730591+00:00 [scheduled]>
2026-02-13 11:03:01,859 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:03:00.730591+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:03:01,860 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:03:00.730591+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:03:01,861 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:03:00.730591+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:03:01,863 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:03:00.730591+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:03:06,370 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:03:00.730591+00:00', try_number=1, map_index=-1)
2026-02-13 11:03:06,381 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T03:03:00.730591+00:00, map_index=-1, run_start_date=2026-02-13 03:03:05.280088+00:00, run_end_date=2026-02-13 03:03:05.732314+00:00, run_duration=0.452226, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=43, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:03:01.857929+00:00, queued_by_job_id=41, pid=6697
2026-02-13 11:03:09,188 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 03:03:00.730591+00:00: manual__2026-02-13T03:03:00.730591+00:00, state:running, queued_at: 2026-02-13 03:03:00.744300+00:00. externally triggered: True> successful
2026-02-13 11:03:09,189 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 03:03:00.730591+00:00, run_id=manual__2026-02-13T03:03:00.730591+00:00, run_start_date=2026-02-13 03:03:01.834575+00:00, run_end_date=2026-02-13 03:03:09.189026+00:00, run_duration=7.354451, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 03:03:00.730591+00:00, data_interval_end=2026-02-13 03:03:00.730591+00:00, dag_hash=292d5ad65135765608fc09000942b435
2026-02-13 11:03:09,252 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:03:05.749067+00:00 [scheduled]>
2026-02-13 11:03:09,263 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 11:03:09,264 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:03:05.749067+00:00 [scheduled]>
2026-02-13 11:03:09,267 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:03:05.749067+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:03:09,269 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:03:05.749067+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:03:09,269 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:03:05.749067+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:03:09,288 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:03:05.749067+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:03:13,851 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:03:05.749067+00:00', try_number=1, map_index=-1)
2026-02-13 11:03:13,865 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T03:03:05.749067+00:00, map_index=-1, run_start_date=2026-02-13 03:03:12.595873+00:00, run_end_date=2026-02-13 03:03:12.993313+00:00, run_duration=0.39744, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=44, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:03:09.266267+00:00, queued_by_job_id=41, pid=6700
2026-02-13 11:03:16,803 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 03:03:05.749067+00:00: dataset_triggered__2026-02-13T03:03:05.749067+00:00, state:running, queued_at: 2026-02-13 03:03:09.151978+00:00. externally triggered: False> successful
2026-02-13 11:03:16,805 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 03:03:05.749067+00:00, run_id=dataset_triggered__2026-02-13T03:03:05.749067+00:00, run_start_date=2026-02-13 03:03:09.172019+00:00, run_end_date=2026-02-13 03:03:16.805082+00:00, run_duration=7.633063, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:03:00.730591+00:00, data_interval_end=2026-02-13 03:03:00.730591+00:00, dag_hash=336021f9586175064690381be57e6c20
2026-02-13 11:03:20,949 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:08:22,300 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:13:23,601 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:15:30,076 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:15:28.766581+00:00 [scheduled]>
2026-02-13 11:15:30,077 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 11:15:30,078 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:15:28.766581+00:00 [scheduled]>
2026-02-13 11:15:30,082 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:15:28.766581+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:15:30,086 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:15:28.766581+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:15:30,087 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:15:28.766581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:15:30,090 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:15:28.766581+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:15:34,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:15:28.766581+00:00', try_number=1, map_index=-1)
2026-02-13 11:15:34,780 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T03:15:28.766581+00:00, map_index=-1, run_start_date=2026-02-13 03:15:33.736246+00:00, run_end_date=2026-02-13 03:15:34.213945+00:00, run_duration=0.477699, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=45, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:15:30.079798+00:00, queued_by_job_id=41, pid=6940
2026-02-13 11:15:37,777 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 03:15:28.766581+00:00: manual__2026-02-13T03:15:28.766581+00:00, state:running, queued_at: 2026-02-13 03:15:28.788425+00:00. externally triggered: True> successful
2026-02-13 11:15:37,778 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 03:15:28.766581+00:00, run_id=manual__2026-02-13T03:15:28.766581+00:00, run_start_date=2026-02-13 03:15:30.048480+00:00, run_end_date=2026-02-13 03:15:37.778437+00:00, run_duration=7.729957, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 03:15:28.766581+00:00, data_interval_end=2026-02-13 03:15:28.766581+00:00, dag_hash=292d5ad65135765608fc09000942b435
2026-02-13 11:15:37,788 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:15:34.232141+00:00 [scheduled]>
2026-02-13 11:15:37,789 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 11:15:37,789 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:15:34.232141+00:00 [scheduled]>
2026-02-13 11:15:37,792 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:15:34.232141+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:15:37,793 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:15:34.232141+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:15:37,793 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:15:34.232141+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:15:37,796 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:15:34.232141+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:15:41,571 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:15:34.232141+00:00', try_number=1, map_index=-1)
2026-02-13 11:15:41,579 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T03:15:34.232141+00:00, map_index=-1, run_start_date=2026-02-13 03:15:40.639840+00:00, run_end_date=2026-02-13 03:15:40.968642+00:00, run_duration=0.328802, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=46, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:15:37.790849+00:00, queued_by_job_id=41, pid=6950
2026-02-13 11:15:44,402 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 03:15:34.232141+00:00: dataset_triggered__2026-02-13T03:15:34.232141+00:00, state:running, queued_at: 2026-02-13 03:15:37.748990+00:00. externally triggered: False> successful
2026-02-13 11:15:44,403 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 03:15:34.232141+00:00, run_id=dataset_triggered__2026-02-13T03:15:34.232141+00:00, run_start_date=2026-02-13 03:15:37.762831+00:00, run_end_date=2026-02-13 03:15:44.403607+00:00, run_duration=6.640776, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:15:28.766581+00:00, data_interval_end=2026-02-13 03:15:28.766581+00:00, dag_hash=336021f9586175064690381be57e6c20
2026-02-13 11:18:23,607 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:20:51,068 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:20:50.500982+00:00 [scheduled]>
2026-02-13 11:20:51,070 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 11:20:51,070 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:20:50.500982+00:00 [scheduled]>
2026-02-13 11:20:51,073 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:20:50.500982+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:20:51,076 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:20:50.500982+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:20:51,077 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:20:50.500982+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:20:51,079 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:20:50.500982+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:20:55,321 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:20:50.500982+00:00', try_number=1, map_index=-1)
2026-02-13 11:20:55,333 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T03:20:50.500982+00:00, map_index=-1, run_start_date=2026-02-13 03:20:54.354533+00:00, run_end_date=2026-02-13 03:20:54.789942+00:00, run_duration=0.435409, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=47, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:20:51.072024+00:00, queued_by_job_id=41, pid=7038
2026-02-13 11:20:55,403 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 03:20:50.500982+00:00: manual__2026-02-13T03:20:50.500982+00:00, state:running, queued_at: 2026-02-13 03:20:50.514067+00:00. externally triggered: True> successful
2026-02-13 11:20:55,404 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 03:20:50.500982+00:00, run_id=manual__2026-02-13T03:20:50.500982+00:00, run_start_date=2026-02-13 03:20:51.039154+00:00, run_end_date=2026-02-13 03:20:55.404373+00:00, run_duration=4.365219, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 03:20:50.500982+00:00, data_interval_end=2026-02-13 03:20:50.500982+00:00, dag_hash=292d5ad65135765608fc09000942b435
2026-02-13 11:20:55,414 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:20:54.810387+00:00 [scheduled]>
2026-02-13 11:20:55,415 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 11:20:55,416 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:20:54.810387+00:00 [scheduled]>
2026-02-13 11:20:55,418 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:20:54.810387+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:20:55,419 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:20:54.810387+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:20:55,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:20:54.810387+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:20:55,422 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:20:54.810387+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:20:58,946 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:20:54.810387+00:00', try_number=1, map_index=-1)
2026-02-13 11:20:58,954 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T03:20:54.810387+00:00, map_index=-1, run_start_date=2026-02-13 03:20:58.179565+00:00, run_end_date=2026-02-13 03:20:58.478434+00:00, run_duration=0.298869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=48, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:20:55.417432+00:00, queued_by_job_id=41, pid=7041
2026-02-13 11:20:58,998 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 03:20:54.810387+00:00: dataset_triggered__2026-02-13T03:20:54.810387+00:00, state:running, queued_at: 2026-02-13 03:20:55.377690+00:00. externally triggered: False> successful
2026-02-13 11:20:58,999 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 03:20:54.810387+00:00, run_id=dataset_triggered__2026-02-13T03:20:54.810387+00:00, run_start_date=2026-02-13 03:20:55.389670+00:00, run_end_date=2026-02-13 03:20:58.999297+00:00, run_duration=3.609627, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:20:50.500982+00:00, data_interval_end=2026-02-13 03:20:50.500982+00:00, dag_hash=336021f9586175064690381be57e6c20
2026-02-13 11:23:26,021 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:28:26,768 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:33:29,567 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:36:01,032 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:35:59.119446+00:00 [scheduled]>
2026-02-13 11:36:01,033 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 11:36:01,033 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:35:59.119446+00:00 [scheduled]>
2026-02-13 11:36:01,036 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:35:59.119446+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:36:01,038 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:35:59.119446+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:36:01,038 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:35:59.119446+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:36:01,041 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:35:59.119446+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:36:05,394 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:35:59.119446+00:00', try_number=1, map_index=-1)
2026-02-13 11:36:05,403 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T03:35:59.119446+00:00, map_index=-1, run_start_date=2026-02-13 03:36:04.315076+00:00, run_end_date=2026-02-13 03:36:04.807601+00:00, run_duration=0.492525, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=49, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:36:01.035143+00:00, queued_by_job_id=41, pid=7372
2026-02-13 11:36:05,485 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 03:35:59.119446+00:00: manual__2026-02-13T03:35:59.119446+00:00, state:running, queued_at: 2026-02-13 03:35:59.143100+00:00. externally triggered: True> successful
2026-02-13 11:36:05,486 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 03:35:59.119446+00:00, run_id=manual__2026-02-13T03:35:59.119446+00:00, run_start_date=2026-02-13 03:36:01.007029+00:00, run_end_date=2026-02-13 03:36:05.486652+00:00, run_duration=4.479623, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 03:35:59.119446+00:00, data_interval_end=2026-02-13 03:35:59.119446+00:00, dag_hash=292d5ad65135765608fc09000942b435
2026-02-13 11:36:05,495 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:36:04.836355+00:00 [scheduled]>
2026-02-13 11:36:05,496 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 11:36:05,497 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:36:04.836355+00:00 [scheduled]>
2026-02-13 11:36:05,500 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:36:04.836355+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:36:05,501 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:36:04.836355+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:36:05,503 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:36:04.836355+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:36:05,505 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:36:04.836355+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:36:09,727 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:36:04.836355+00:00', try_number=1, map_index=-1)
2026-02-13 11:36:09,739 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T03:36:04.836355+00:00, map_index=-1, run_start_date=2026-02-13 03:36:08.780611+00:00, run_end_date=2026-02-13 03:36:09.134619+00:00, run_duration=0.354008, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=50, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:36:05.498785+00:00, queued_by_job_id=41, pid=7374
2026-02-13 11:36:12,405 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 03:36:04.836355+00:00: dataset_triggered__2026-02-13T03:36:04.836355+00:00, state:running, queued_at: 2026-02-13 03:36:05.455807+00:00. externally triggered: False> successful
2026-02-13 11:36:12,406 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 03:36:04.836355+00:00, run_id=dataset_triggered__2026-02-13T03:36:04.836355+00:00, run_start_date=2026-02-13 03:36:05.471261+00:00, run_end_date=2026-02-13 03:36:12.406530+00:00, run_duration=6.935269, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:35:59.119446+00:00, data_interval_end=2026-02-13 03:35:59.119446+00:00, dag_hash=336021f9586175064690381be57e6c20
2026-02-13 11:38:31,668 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:43:34,324 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:46:30,369 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:46:26.998824+00:00 [scheduled]>
2026-02-13 11:46:30,370 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 11:46:30,371 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:46:26.998824+00:00 [scheduled]>
2026-02-13 11:46:30,373 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:46:26.998824+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:46:30,375 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:46:26.998824+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:46:30,375 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:46:26.998824+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:46:30,378 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:46:26.998824+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:46:34,819 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:46:26.998824+00:00', try_number=1, map_index=-1)
2026-02-13 11:46:34,830 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T03:46:26.998824+00:00, map_index=-1, run_start_date=2026-02-13 03:46:33.729665+00:00, run_end_date=2026-02-13 03:46:34.216917+00:00, run_duration=0.487252, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=51, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:46:30.372500+00:00, queued_by_job_id=41, pid=7653
2026-02-13 11:46:34,916 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 03:46:26.998824+00:00: manual__2026-02-13T03:46:26.998824+00:00, state:running, queued_at: 2026-02-13 03:46:27.011741+00:00. externally triggered: True> successful
2026-02-13 11:46:34,917 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 03:46:26.998824+00:00, run_id=manual__2026-02-13T03:46:26.998824+00:00, run_start_date=2026-02-13 03:46:30.350067+00:00, run_end_date=2026-02-13 03:46:34.917490+00:00, run_duration=4.567423, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 03:46:26.998824+00:00, data_interval_end=2026-02-13 03:46:26.998824+00:00, dag_hash=3f1d48a4dcef25843133576f388d134e
2026-02-13 11:46:35,986 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:46:34.235716+00:00 [scheduled]>
2026-02-13 11:46:35,987 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 11:46:35,988 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:46:34.235716+00:00 [scheduled]>
2026-02-13 11:46:35,990 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:46:34.235716+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:46:35,991 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:46:34.235716+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:46:35,992 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:46:34.235716+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:46:35,995 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:46:34.235716+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:46:39,588 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:46:34.235716+00:00', try_number=1, map_index=-1)
2026-02-13 11:46:39,598 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T03:46:34.235716+00:00, map_index=-1, run_start_date=2026-02-13 03:46:38.748184+00:00, run_end_date=2026-02-13 03:46:39.042286+00:00, run_duration=0.294102, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=52, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:46:35.989011+00:00, queued_by_job_id=41, pid=7658
2026-02-13 11:46:39,637 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 03:46:34.235716+00:00: dataset_triggered__2026-02-13T03:46:34.235716+00:00, state:running, queued_at: 2026-02-13 03:46:34.891969+00:00. externally triggered: False> successful
2026-02-13 11:46:39,638 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 03:46:34.235716+00:00, run_id=dataset_triggered__2026-02-13T03:46:34.235716+00:00, run_start_date=2026-02-13 03:46:35.955545+00:00, run_end_date=2026-02-13 03:46:39.638248+00:00, run_duration=3.682703, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:46:26.998824+00:00, data_interval_end=2026-02-13 03:46:26.998824+00:00, dag_hash=4f5cee350ba129ab524aa1ccabba746a
2026-02-13 11:48:34,351 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:53:34,384 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 11:58:14,988 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:58:13.633239+00:00 [scheduled]>
2026-02-13 11:58:14,990 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 11:58:14,990 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:58:13.633239+00:00 [scheduled]>
2026-02-13 11:58:14,993 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T03:58:13.633239+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:58:14,995 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:58:13.633239+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:58:14,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:58:13.633239+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:58:14,998 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T03:58:13.633239+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:58:19,405 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T03:58:13.633239+00:00', try_number=1, map_index=-1)
2026-02-13 11:58:19,413 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T03:58:13.633239+00:00, map_index=-1, run_start_date=2026-02-13 03:58:18.240372+00:00, run_end_date=2026-02-13 03:58:18.829312+00:00, run_duration=0.58894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=53, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:58:14.992155+00:00, queued_by_job_id=41, pid=7917
2026-02-13 11:58:19,491 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 03:58:13.633239+00:00: manual__2026-02-13T03:58:13.633239+00:00, state:running, queued_at: 2026-02-13 03:58:13.650127+00:00. externally triggered: True> successful
2026-02-13 11:58:19,492 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 03:58:13.633239+00:00, run_id=manual__2026-02-13T03:58:13.633239+00:00, run_start_date=2026-02-13 03:58:14.959849+00:00, run_end_date=2026-02-13 03:58:19.492612+00:00, run_duration=4.532763, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 03:58:13.633239+00:00, data_interval_end=2026-02-13 03:58:13.633239+00:00, dag_hash=3f1d48a4dcef25843133576f388d134e
2026-02-13 11:58:19,502 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:58:18.846380+00:00 [scheduled]>
2026-02-13 11:58:19,503 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 11:58:19,504 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:58:18.846380+00:00 [scheduled]>
2026-02-13 11:58:19,506 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T03:58:18.846380+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 11:58:19,507 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:58:18.846380+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 11:58:19,508 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:58:18.846380+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:58:19,510 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T03:58:18.846380+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 11:58:23,280 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T03:58:18.846380+00:00', try_number=1, map_index=-1)
2026-02-13 11:58:23,290 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T03:58:18.846380+00:00, map_index=-1, run_start_date=2026-02-13 03:58:22.470670+00:00, run_end_date=2026-02-13 03:58:22.760214+00:00, run_duration=0.289544, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=54, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 03:58:19.505294+00:00, queued_by_job_id=41, pid=7928
2026-02-13 11:58:25,935 ERROR - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 03:58:18.846380+00:00: dataset_triggered__2026-02-13T03:58:18.846380+00:00, state:running, queued_at: 2026-02-13 03:58:19.464908+00:00. externally triggered: False> failed
2026-02-13 11:58:25,937 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 03:58:18.846380+00:00, run_id=dataset_triggered__2026-02-13T03:58:18.846380+00:00, run_start_date=2026-02-13 03:58:19.478973+00:00, run_end_date=2026-02-13 03:58:25.937314+00:00, run_duration=6.458341, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:58:13.633239+00:00, data_interval_end=2026-02-13 03:58:13.633239+00:00, dag_hash=14c7fa46f6353af733f2f3432dad8780
2026-02-13 11:58:36,153 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 12:00:37,867 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T04:00:36.991126+00:00 [scheduled]>
2026-02-13 12:00:37,869 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 12:00:37,870 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T04:00:36.991126+00:00 [scheduled]>
2026-02-13 12:00:37,873 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T04:00:36.991126+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 12:00:37,874 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T04:00:36.991126+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 12:00:37,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T04:00:36.991126+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 12:00:37,877 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T04:00:36.991126+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 12:00:42,458 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T04:00:36.991126+00:00', try_number=1, map_index=-1)
2026-02-13 12:00:42,467 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T04:00:36.991126+00:00, map_index=-1, run_start_date=2026-02-13 04:00:41.386106+00:00, run_end_date=2026-02-13 04:00:41.894495+00:00, run_duration=0.508389, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=55, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 04:00:37.871705+00:00, queued_by_job_id=41, pid=7993
2026-02-13 12:00:44,981 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 04:00:36.991126+00:00: manual__2026-02-13T04:00:36.991126+00:00, state:running, queued_at: 2026-02-13 04:00:37.010364+00:00. externally triggered: True> successful
2026-02-13 12:00:44,982 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 04:00:36.991126+00:00, run_id=manual__2026-02-13T04:00:36.991126+00:00, run_start_date=2026-02-13 04:00:37.845866+00:00, run_end_date=2026-02-13 04:00:44.982304+00:00, run_duration=7.136438, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 04:00:36.991126+00:00, data_interval_end=2026-02-13 04:00:36.991126+00:00, dag_hash=3f1d48a4dcef25843133576f388d134e
2026-02-13 12:00:44,992 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T04:00:41.913811+00:00 [scheduled]>
2026-02-13 12:00:44,993 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 12:00:44,994 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T04:00:41.913811+00:00 [scheduled]>
2026-02-13 12:00:44,997 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T04:00:41.913811+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 12:00:44,998 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T04:00:41.913811+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 12:00:44,999 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T04:00:41.913811+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 12:00:45,002 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T04:00:41.913811+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 12:00:48,637 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T04:00:41.913811+00:00', try_number=1, map_index=-1)
2026-02-13 12:00:48,646 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T04:00:41.913811+00:00, map_index=-1, run_start_date=2026-02-13 04:00:47.820152+00:00, run_end_date=2026-02-13 04:00:48.130048+00:00, run_duration=0.309896, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=56, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 04:00:44.995486+00:00, queued_by_job_id=41, pid=7996
2026-02-13 12:00:51,386 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 04:00:41.913811+00:00: dataset_triggered__2026-02-13T04:00:41.913811+00:00, state:running, queued_at: 2026-02-13 04:00:44.951380+00:00. externally triggered: False> successful
2026-02-13 12:00:51,388 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 04:00:41.913811+00:00, run_id=dataset_triggered__2026-02-13T04:00:41.913811+00:00, run_start_date=2026-02-13 04:00:44.966340+00:00, run_end_date=2026-02-13 04:00:51.387965+00:00, run_duration=6.421625, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 04:00:36.991126+00:00, data_interval_end=2026-02-13 04:00:36.991126+00:00, dag_hash=14c7fa46f6353af733f2f3432dad8780
2026-02-13 12:03:36,505 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 12:04:19,944 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 12:04:20,828 INFO - Sending Signals.SIGTERM to group 6580. PIDs of all processes in the group: []
2026-02-13 12:04:20,829 INFO - Sending the signal Signals.SIGTERM to group 6580
2026-02-13 12:04:20,830 INFO - Sending the signal Signals.SIGTERM to process 6580 as process group is missing.
2026-02-13 12:04:20,841 INFO - Sending Signals.SIGTERM to group 6580. PIDs of all processes in the group: []
2026-02-13 12:04:20,842 INFO - Sending the signal Signals.SIGTERM to group 6580
2026-02-13 12:04:20,842 INFO - Sending the signal Signals.SIGTERM to process 6580 as process group is missing.
2026-02-13 12:04:20,843 INFO - Exited execute loop
2026-02-13 19:42:32,372 INFO - Loaded executor: SequentialExecutor
2026-02-13 19:42:33,149 INFO - Starting the scheduler
2026-02-13 19:42:33,150 INFO - Processing each file at most -1 times
2026-02-13 19:42:33,154 INFO - Launched DagFileProcessorManager with pid: 1145
2026-02-13 19:42:33,163 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 19:47:33,229 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 19:50:54,997 INFO - Exiting gracefully upon receiving signal 15
2026-02-13 19:50:55,522 INFO - Sending Signals.SIGTERM to group 1145. PIDs of all processes in the group: []
2026-02-13 19:50:55,523 INFO - Sending the signal Signals.SIGTERM to group 1145
2026-02-13 19:50:55,524 INFO - Sending the signal Signals.SIGTERM to process 1145 as process group is missing.
2026-02-13 19:50:55,532 INFO - Sending Signals.SIGTERM to group 1145. PIDs of all processes in the group: []
2026-02-13 19:50:55,532 INFO - Sending the signal Signals.SIGTERM to group 1145
2026-02-13 19:50:55,533 INFO - Sending the signal Signals.SIGTERM to process 1145 as process group is missing.
2026-02-13 19:50:55,534 INFO - Exited execute loop
2026-02-13 19:50:57,816 INFO - Loaded executor: SequentialExecutor
2026-02-13 19:50:58,423 INFO - Starting the scheduler
2026-02-13 19:50:58,424 INFO - Processing each file at most -1 times
2026-02-13 19:50:58,430 INFO - Launched DagFileProcessorManager with pid: 1967
2026-02-13 19:50:58,434 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 19:55:58,497 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:00:58,534 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:05:43,697 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:05:42.321399+00:00 [scheduled]>
2026-02-13 20:05:43,698 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 20:05:43,699 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:05:42.321399+00:00 [scheduled]>
2026-02-13 20:05:43,702 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:05:42.321399+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:05:43,703 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:05:42.321399+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:05:43,704 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:05:42.321399+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:05:43,706 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:05:42.321399+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:05:47,540 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:05:42.321399+00:00', try_number=1, map_index=-1)
2026-02-13 20:05:47,554 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T12:05:42.321399+00:00, map_index=-1, run_start_date=2026-02-13 12:05:46.682805+00:00, run_end_date=2026-02-13 12:05:46.990071+00:00, run_duration=0.307266, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=59, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:05:43.701172+00:00, queued_by_job_id=58, pid=3698
2026-02-13 20:05:50,213 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 12:05:42.321399+00:00: manual__2026-02-13T12:05:42.321399+00:00, state:running, queued_at: 2026-02-13 12:05:42.344376+00:00. externally triggered: True> successful
2026-02-13 20:05:50,215 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 12:05:42.321399+00:00, run_id=manual__2026-02-13T12:05:42.321399+00:00, run_start_date=2026-02-13 12:05:43.663188+00:00, run_end_date=2026-02-13 12:05:50.215457+00:00, run_duration=6.552269, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 12:05:42.321399+00:00, data_interval_end=2026-02-13 12:05:42.321399+00:00, dag_hash=3f1d48a4dcef25843133576f388d134e
2026-02-13 20:05:50,227 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:05:47.008811+00:00 [scheduled]>
2026-02-13 20:05:50,228 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 20:05:50,228 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:05:47.008811+00:00 [scheduled]>
2026-02-13 20:05:50,231 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:05:47.008811+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:05:50,231 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:05:47.008811+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:05:50,232 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:05:47.008811+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:05:50,235 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:05:47.008811+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:05:53,881 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:05:47.008811+00:00', try_number=1, map_index=-1)
2026-02-13 20:05:53,890 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T12:05:47.008811+00:00, map_index=-1, run_start_date=2026-02-13 12:05:53.046067+00:00, run_end_date=2026-02-13 12:05:53.334332+00:00, run_duration=0.288265, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=60, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:05:50.229712+00:00, queued_by_job_id=58, pid=3703
2026-02-13 20:05:56,508 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 12:05:47.008811+00:00: dataset_triggered__2026-02-13T12:05:47.008811+00:00, state:running, queued_at: 2026-02-13 12:05:50.177063+00:00. externally triggered: False> successful
2026-02-13 20:05:56,510 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 12:05:47.008811+00:00, run_id=dataset_triggered__2026-02-13T12:05:47.008811+00:00, run_start_date=2026-02-13 12:05:50.200171+00:00, run_end_date=2026-02-13 12:05:56.510050+00:00, run_duration=6.309879, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 12:05:42.321399+00:00, data_interval_end=2026-02-13 12:05:42.321399+00:00, dag_hash=14c7fa46f6353af733f2f3432dad8780
2026-02-13 20:05:58,580 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:09:33,541 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:09:29.883245+00:00 [scheduled]>
2026-02-13 20:09:33,542 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 20:09:33,543 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:09:29.883245+00:00 [scheduled]>
2026-02-13 20:09:33,545 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:09:29.883245+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:09:33,547 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:09:29.883245+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:09:33,547 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:09:29.883245+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:09:33,550 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:09:29.883245+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:09:37,223 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:09:29.883245+00:00', try_number=1, map_index=-1)
2026-02-13 20:09:37,235 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T12:09:29.883245+00:00, map_index=-1, run_start_date=2026-02-13 12:09:36.390309+00:00, run_end_date=2026-02-13 12:09:36.700380+00:00, run_duration=0.310071, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=61, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:09:33.544335+00:00, queued_by_job_id=58, pid=4043
2026-02-13 20:09:40,006 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 12:09:29.883245+00:00: manual__2026-02-13T12:09:29.883245+00:00, state:running, queued_at: 2026-02-13 12:09:29.901006+00:00. externally triggered: True> successful
2026-02-13 20:09:40,007 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 12:09:29.883245+00:00, run_id=manual__2026-02-13T12:09:29.883245+00:00, run_start_date=2026-02-13 12:09:33.517270+00:00, run_end_date=2026-02-13 12:09:40.007568+00:00, run_duration=6.490298, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 12:09:29.883245+00:00, data_interval_end=2026-02-13 12:09:29.883245+00:00, dag_hash=3f1d48a4dcef25843133576f388d134e
2026-02-13 20:09:40,017 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:09:36.719651+00:00 [scheduled]>
2026-02-13 20:09:40,018 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 20:09:40,019 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:09:36.719651+00:00 [scheduled]>
2026-02-13 20:09:40,021 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:09:36.719651+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:09:40,022 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:09:36.719651+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:09:40,023 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:09:36.719651+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:09:40,025 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:09:36.719651+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:09:43,612 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:09:36.719651+00:00', try_number=1, map_index=-1)
2026-02-13 20:09:43,623 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T12:09:36.719651+00:00, map_index=-1, run_start_date=2026-02-13 12:09:42.727518+00:00, run_end_date=2026-02-13 12:09:43.057478+00:00, run_duration=0.32996, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=62, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:09:40.020429+00:00, queued_by_job_id=58, pid=4046
2026-02-13 20:09:43,675 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 12:09:36.719651+00:00: dataset_triggered__2026-02-13T12:09:36.719651+00:00, state:running, queued_at: 2026-02-13 12:09:39.972173+00:00. externally triggered: False> successful
2026-02-13 20:09:43,676 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 12:09:36.719651+00:00, run_id=dataset_triggered__2026-02-13T12:09:36.719651+00:00, run_start_date=2026-02-13 12:09:39.990831+00:00, run_end_date=2026-02-13 12:09:43.676394+00:00, run_duration=3.685563, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 12:09:29.883245+00:00, data_interval_end=2026-02-13 12:09:29.883245+00:00, dag_hash=14c7fa46f6353af733f2f3432dad8780
2026-02-13 20:10:58,656 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:13:51,739 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:13:50.192029+00:00 [scheduled]>
2026-02-13 20:13:51,741 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 20:13:51,742 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:13:50.192029+00:00 [scheduled]>
2026-02-13 20:13:51,745 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:13:50.192029+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:13:51,746 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:13:50.192029+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:13:51,747 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:13:50.192029+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:13:51,751 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:13:50.192029+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:13:55,931 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:13:50.192029+00:00', try_number=1, map_index=-1)
2026-02-13 20:13:55,940 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T12:13:50.192029+00:00, map_index=-1, run_start_date=2026-02-13 12:13:55.058956+00:00, run_end_date=2026-02-13 12:13:55.377104+00:00, run_duration=0.318148, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=63, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:13:51.743848+00:00, queued_by_job_id=58, pid=4129
2026-02-13 20:13:58,602 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 12:13:50.192029+00:00: manual__2026-02-13T12:13:50.192029+00:00, state:running, queued_at: 2026-02-13 12:13:50.210479+00:00. externally triggered: True> successful
2026-02-13 20:13:58,603 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 12:13:50.192029+00:00, run_id=manual__2026-02-13T12:13:50.192029+00:00, run_start_date=2026-02-13 12:13:51.717860+00:00, run_end_date=2026-02-13 12:13:58.603159+00:00, run_duration=6.885299, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 12:13:50.192029+00:00, data_interval_end=2026-02-13 12:13:50.192029+00:00, dag_hash=3f1d48a4dcef25843133576f388d134e
2026-02-13 20:13:58,614 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:13:55.394014+00:00 [scheduled]>
	<TaskInstance: consumer_dw_order_stat.stat_order_data dataset_triggered__2026-02-13T12:13:55.395586+00:00 [scheduled]>
2026-02-13 20:13:58,615 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 20:13:58,615 INFO - DAG consumer_dw_order_stat has 0/16 running and queued tasks
2026-02-13 20:13:58,616 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:13:55.394014+00:00 [scheduled]>
	<TaskInstance: consumer_dw_order_stat.stat_order_data dataset_triggered__2026-02-13T12:13:55.395586+00:00 [scheduled]>
2026-02-13 20:13:58,620 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:13:55.394014+00:00 [scheduled]>, <TaskInstance: consumer_dw_order_stat.stat_order_data dataset_triggered__2026-02-13T12:13:55.395586+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:13:58,621 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:13:55.394014+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:13:58,622 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:13:55.394014+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:13:58,623 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_stat', task_id='stat_order_data', run_id='dataset_triggered__2026-02-13T12:13:55.395586+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:13:58,624 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_stat', 'stat_order_data', 'dataset_triggered__2026-02-13T12:13:55.395586+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:13:58,626 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:13:55.394014+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:14:02,003 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_stat', 'stat_order_data', 'dataset_triggered__2026-02-13T12:13:55.395586+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:14:05,778 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:13:55.394014+00:00', try_number=1, map_index=-1)
2026-02-13 20:14:05,781 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_stat', task_id='stat_order_data', run_id='dataset_triggered__2026-02-13T12:13:55.395586+00:00', try_number=1, map_index=-1)
2026-02-13 20:14:05,792 INFO - TaskInstance Finished: dag_id=consumer_dw_order_stat, task_id=stat_order_data, run_id=dataset_triggered__2026-02-13T12:13:55.395586+00:00, map_index=-1, run_start_date=2026-02-13 12:14:04.714562+00:00, run_end_date=2026-02-13 12:14:05.087446+00:00, run_duration=0.372884, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=65, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:13:58.618017+00:00, queued_by_job_id=58, pid=4137
2026-02-13 20:14:05,794 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T12:13:55.394014+00:00, map_index=-1, run_start_date=2026-02-13 12:14:01.165983+00:00, run_end_date=2026-02-13 12:14:01.461394+00:00, run_duration=0.295411, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=64, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:13:58.618017+00:00, queued_by_job_id=58, pid=4135
2026-02-13 20:14:08,181 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 12:13:55.394014+00:00: dataset_triggered__2026-02-13T12:13:55.394014+00:00, state:running, queued_at: 2026-02-13 12:13:58.566381+00:00. externally triggered: False> successful
2026-02-13 20:14:08,182 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 12:13:55.394014+00:00, run_id=dataset_triggered__2026-02-13T12:13:55.394014+00:00, run_start_date=2026-02-13 12:13:58.580294+00:00, run_end_date=2026-02-13 12:14:08.182001+00:00, run_duration=9.601707, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 12:13:50.192029+00:00, data_interval_end=2026-02-13 12:13:50.192029+00:00, dag_hash=812fdc4eaaef0b4b0ecbeb4a4a10f6ba
2026-02-13 20:14:08,186 INFO - Marking run <DagRun consumer_dw_order_stat @ 2026-02-13 12:13:55.395586+00:00: dataset_triggered__2026-02-13T12:13:55.395586+00:00, state:running, queued_at: 2026-02-13 12:13:58.543810+00:00. externally triggered: False> successful
2026-02-13 20:14:08,187 INFO - DagRun Finished: dag_id=consumer_dw_order_stat, execution_date=2026-02-13 12:13:55.395586+00:00, run_id=dataset_triggered__2026-02-13T12:13:55.395586+00:00, run_start_date=2026-02-13 12:13:58.580476+00:00, run_end_date=2026-02-13 12:14:08.187176+00:00, run_duration=9.6067, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:03:00.730591+00:00, data_interval_end=2026-02-13 12:13:50.192029+00:00, dag_hash=c48b04123af906598e7caee12eaa4367
2026-02-13 20:15:58,690 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:20:58,733 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:21:51,040 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:21:48.664790+00:00 [scheduled]>
2026-02-13 20:21:51,041 INFO - DAG producer_dw_order_sync has 0/16 running and queued tasks
2026-02-13 20:21:51,042 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:21:48.664790+00:00 [scheduled]>
2026-02-13 20:21:51,044 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dw_order_sync.sync_order_data manual__2026-02-13T12:21:48.664790+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:21:51,046 INFO - Sending TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:21:48.664790+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:21:51,046 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:21:48.664790+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:21:51,049 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dw_order_sync', 'sync_order_data', 'manual__2026-02-13T12:21:48.664790+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:21:54,887 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-13T12:21:48.664790+00:00', try_number=1, map_index=-1)
2026-02-13 20:21:54,896 INFO - TaskInstance Finished: dag_id=producer_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-13T12:21:48.664790+00:00, map_index=-1, run_start_date=2026-02-13 12:21:53.977335+00:00, run_end_date=2026-02-13 12:21:54.269269+00:00, run_duration=0.291934, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=66, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:21:51.043245+00:00, queued_by_job_id=58, pid=4284
2026-02-13 20:21:54,978 INFO - Marking run <DagRun producer_dw_order_sync @ 2026-02-13 12:21:48.664790+00:00: manual__2026-02-13T12:21:48.664790+00:00, state:running, queued_at: 2026-02-13 12:21:48.677286+00:00. externally triggered: True> successful
2026-02-13 20:21:54,979 INFO - DagRun Finished: dag_id=producer_dw_order_sync, execution_date=2026-02-13 12:21:48.664790+00:00, run_id=manual__2026-02-13T12:21:48.664790+00:00, run_start_date=2026-02-13 12:21:51.020627+00:00, run_end_date=2026-02-13 12:21:54.979822+00:00, run_duration=3.959195, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 12:21:48.664790+00:00, data_interval_end=2026-02-13 12:21:48.664790+00:00, dag_hash=3f1d48a4dcef25843133576f388d134e
2026-02-13 20:21:56,044 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:21:54.286709+00:00 [scheduled]>
	<TaskInstance: consumer_dw_order_stat.stat_order_data dataset_triggered__2026-02-13T12:21:54.288058+00:00 [scheduled]>
2026-02-13 20:21:56,045 INFO - DAG consumer_dw_order_clean has 0/16 running and queued tasks
2026-02-13 20:21:56,046 INFO - DAG consumer_dw_order_stat has 0/16 running and queued tasks
2026-02-13 20:21:56,046 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:21:54.286709+00:00 [scheduled]>
	<TaskInstance: consumer_dw_order_stat.stat_order_data dataset_triggered__2026-02-13T12:21:54.288058+00:00 [scheduled]>
2026-02-13 20:21:56,049 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dw_order_clean.clean_order_data dataset_triggered__2026-02-13T12:21:54.286709+00:00 [scheduled]>, <TaskInstance: consumer_dw_order_stat.stat_order_data dataset_triggered__2026-02-13T12:21:54.288058+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 20:21:56,051 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:21:54.286709+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:21:56,051 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:21:54.286709+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:21:56,052 INFO - Sending TaskInstanceKey(dag_id='consumer_dw_order_stat', task_id='stat_order_data', run_id='dataset_triggered__2026-02-13T12:21:54.288058+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 20:21:56,053 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dw_order_stat', 'stat_order_data', 'dataset_triggered__2026-02-13T12:21:54.288058+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:21:56,056 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T12:21:54.286709+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:21:59,594 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dw_order_stat', 'stat_order_data', 'dataset_triggered__2026-02-13T12:21:54.288058+00:00', '--local', '--subdir', 'DAGS_FOLDER/dataset_demo.py']
2026-02-13 20:22:03,258 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T12:21:54.286709+00:00', try_number=1, map_index=-1)
2026-02-13 20:22:03,261 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dw_order_stat', task_id='stat_order_data', run_id='dataset_triggered__2026-02-13T12:21:54.288058+00:00', try_number=1, map_index=-1)
2026-02-13 20:22:03,270 INFO - TaskInstance Finished: dag_id=consumer_dw_order_stat, task_id=stat_order_data, run_id=dataset_triggered__2026-02-13T12:21:54.288058+00:00, map_index=-1, run_start_date=2026-02-13 12:22:02.385933+00:00, run_end_date=2026-02-13 12:22:02.704072+00:00, run_duration=0.318139, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=68, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:21:56.047787+00:00, queued_by_job_id=58, pid=4291
2026-02-13 20:22:03,271 INFO - TaskInstance Finished: dag_id=consumer_dw_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T12:21:54.286709+00:00, map_index=-1, run_start_date=2026-02-13 12:21:58.731908+00:00, run_end_date=2026-02-13 12:21:59.040815+00:00, run_duration=0.308907, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=67, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 12:21:56.047787+00:00, queued_by_job_id=58, pid=4286
2026-02-13 20:22:03,319 INFO - Marking run <DagRun consumer_dw_order_clean @ 2026-02-13 12:21:54.286709+00:00: dataset_triggered__2026-02-13T12:21:54.286709+00:00, state:running, queued_at: 2026-02-13 12:21:54.960377+00:00. externally triggered: False> successful
2026-02-13 20:22:03,320 INFO - DagRun Finished: dag_id=consumer_dw_order_clean, execution_date=2026-02-13 12:21:54.286709+00:00, run_id=dataset_triggered__2026-02-13T12:21:54.286709+00:00, run_start_date=2026-02-13 12:21:56.016376+00:00, run_end_date=2026-02-13 12:22:03.320464+00:00, run_duration=7.304088, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 12:21:48.664790+00:00, data_interval_end=2026-02-13 12:21:48.664790+00:00, dag_hash=812fdc4eaaef0b4b0ecbeb4a4a10f6ba
2026-02-13 20:22:03,326 INFO - Marking run <DagRun consumer_dw_order_stat @ 2026-02-13 12:21:54.288058+00:00: dataset_triggered__2026-02-13T12:21:54.288058+00:00, state:running, queued_at: 2026-02-13 12:21:54.951524+00:00. externally triggered: False> successful
2026-02-13 20:22:03,326 INFO - DagRun Finished: dag_id=consumer_dw_order_stat, execution_date=2026-02-13 12:21:54.288058+00:00, run_id=dataset_triggered__2026-02-13T12:21:54.288058+00:00, run_start_date=2026-02-13 12:21:56.016534+00:00, run_end_date=2026-02-13 12:22:03.326873+00:00, run_duration=7.310339, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 12:21:48.664790+00:00, data_interval_end=2026-02-13 12:21:48.664790+00:00, dag_hash=c48b04123af906598e7caee12eaa4367
2026-02-13 20:25:58,762 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:30:59,716 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:35:47,170 INFO - Heartbeat recovered after 52.16 seconds
2026-02-13 20:36:43,312 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 20:46:08,120 INFO - Heartbeat recovered after 566.01 seconds
2026-02-13 20:56:12,320 INFO - Heartbeat recovered after 564.29 seconds
2026-02-13 21:03:46,056 INFO - Heartbeat recovered after 412.95 seconds
2026-02-13 21:07:02,437 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:12:02,479 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:17:02,520 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:19:19,678 INFO - 1 tasks up for execution:
	<TaskInstance: producer_variable_sync.sync_order_data manual__2026-02-13T13:19:17.469369+00:00 [scheduled]>
2026-02-13 21:19:19,679 INFO - DAG producer_variable_sync has 0/16 running and queued tasks
2026-02-13 21:19:19,680 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_variable_sync.sync_order_data manual__2026-02-13T13:19:17.469369+00:00 [scheduled]>
2026-02-13 21:19:19,683 INFO - Trying to enqueue tasks: [<TaskInstance: producer_variable_sync.sync_order_data manual__2026-02-13T13:19:17.469369+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:19:19,684 INFO - Sending TaskInstanceKey(dag_id='producer_variable_sync', task_id='sync_order_data', run_id='manual__2026-02-13T13:19:17.469369+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:19:19,685 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'sync_order_data', 'manual__2026-02-13T13:19:17.469369+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:19:19,687 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'sync_order_data', 'manual__2026-02-13T13:19:17.469369+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:19:23,528 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_variable_sync', task_id='sync_order_data', run_id='manual__2026-02-13T13:19:17.469369+00:00', try_number=1, map_index=-1)
2026-02-13 21:19:23,537 INFO - TaskInstance Finished: dag_id=producer_variable_sync, task_id=sync_order_data, run_id=manual__2026-02-13T13:19:17.469369+00:00, map_index=-1, run_start_date=2026-02-13 13:19:22.495248+00:00, run_end_date=2026-02-13 13:19:22.877515+00:00, run_duration=0.382267, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=69, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:19:19.681950+00:00, queued_by_job_id=58, pid=5226
2026-02-13 21:19:25,891 INFO - Marking run <DagRun producer_variable_sync @ 2026-02-13 13:19:17.469369+00:00: manual__2026-02-13T13:19:17.469369+00:00, state:running, queued_at: 2026-02-13 13:19:17.493292+00:00. externally triggered: True> successful
2026-02-13 21:19:25,892 INFO - DagRun Finished: dag_id=producer_variable_sync, execution_date=2026-02-13 13:19:17.469369+00:00, run_id=manual__2026-02-13T13:19:17.469369+00:00, run_start_date=2026-02-13 13:19:19.656584+00:00, run_end_date=2026-02-13 13:19:25.892123+00:00, run_duration=6.235539, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:19:17.469369+00:00, data_interval_end=2026-02-13 13:19:17.469369+00:00, dag_hash=2a5b3cdcb15949c1bf7f46b81e786a9a
2026-02-13 21:19:25,902 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_variable.clean_order_data dataset_triggered__2026-02-13T13:19:22.894249+00:00 [scheduled]>
2026-02-13 21:19:25,903 INFO - DAG consumer_variable has 0/16 running and queued tasks
2026-02-13 21:19:25,903 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_variable.clean_order_data dataset_triggered__2026-02-13T13:19:22.894249+00:00 [scheduled]>
2026-02-13 21:19:25,905 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_variable.clean_order_data dataset_triggered__2026-02-13T13:19:22.894249+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:19:25,906 INFO - Sending TaskInstanceKey(dag_id='consumer_variable', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T13:19:22.894249+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:19:25,907 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_variable', 'clean_order_data', 'dataset_triggered__2026-02-13T13:19:22.894249+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:19:25,910 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_variable', 'clean_order_data', 'dataset_triggered__2026-02-13T13:19:22.894249+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:19:29,339 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_variable', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T13:19:22.894249+00:00', try_number=1, map_index=-1)
2026-02-13 21:19:29,346 INFO - TaskInstance Finished: dag_id=consumer_variable, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T13:19:22.894249+00:00, map_index=-1, run_start_date=2026-02-13 13:19:28.423596+00:00, run_end_date=2026-02-13 13:19:28.783442+00:00, run_duration=0.359846, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=70, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:19:25.904698+00:00, queued_by_job_id=58, pid=5229
2026-02-13 21:19:31,724 INFO - Marking run <DagRun consumer_variable @ 2026-02-13 13:19:22.894249+00:00: dataset_triggered__2026-02-13T13:19:22.894249+00:00, state:running, queued_at: 2026-02-13 13:19:25.861534+00:00. externally triggered: False> successful
2026-02-13 21:19:31,725 INFO - DagRun Finished: dag_id=consumer_variable, execution_date=2026-02-13 13:19:22.894249+00:00, run_id=dataset_triggered__2026-02-13T13:19:22.894249+00:00, run_start_date=2026-02-13 13:19:25.879140+00:00, run_end_date=2026-02-13 13:19:31.725056+00:00, run_duration=5.845916, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 03:03:00.730591+00:00, data_interval_end=2026-02-13 13:19:17.469369+00:00, dag_hash=dc521a83a3ec097ba48717ae4aff0641
2026-02-13 21:22:04,558 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:27:05,895 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:28:31,067 INFO - 1 tasks up for execution:
	<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-13T13:28:30.405028+00:00 [scheduled]>
2026-02-13 21:28:31,068 INFO - DAG producer_variable_sync has 0/16 running and queued tasks
2026-02-13 21:28:31,070 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-13T13:28:30.405028+00:00 [scheduled]>
2026-02-13 21:28:31,072 INFO - Trying to enqueue tasks: [<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-13T13:28:30.405028+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:28:31,073 INFO - Sending TaskInstanceKey(dag_id='producer_variable_sync', task_id='producer_variable_save_data', run_id='manual__2026-02-13T13:28:30.405028+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:28:31,074 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'producer_variable_save_data', 'manual__2026-02-13T13:28:30.405028+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:28:31,076 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'producer_variable_save_data', 'manual__2026-02-13T13:28:30.405028+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:28:35,156 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_variable_sync', task_id='producer_variable_save_data', run_id='manual__2026-02-13T13:28:30.405028+00:00', try_number=1, map_index=-1)
2026-02-13 21:28:35,166 INFO - TaskInstance Finished: dag_id=producer_variable_sync, task_id=producer_variable_save_data, run_id=manual__2026-02-13T13:28:30.405028+00:00, map_index=-1, run_start_date=2026-02-13 13:28:34.258092+00:00, run_end_date=2026-02-13 13:28:34.611299+00:00, run_duration=0.353207, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=71, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:28:31.071275+00:00, queued_by_job_id=58, pid=5475
2026-02-13 21:28:37,689 INFO - Marking run <DagRun producer_variable_sync @ 2026-02-13 13:28:30.405028+00:00: manual__2026-02-13T13:28:30.405028+00:00, state:running, queued_at: 2026-02-13 13:28:30.415552+00:00. externally triggered: True> successful
2026-02-13 21:28:37,690 INFO - DagRun Finished: dag_id=producer_variable_sync, execution_date=2026-02-13 13:28:30.405028+00:00, run_id=manual__2026-02-13T13:28:30.405028+00:00, run_start_date=2026-02-13 13:28:31.048918+00:00, run_end_date=2026-02-13 13:28:37.690420+00:00, run_duration=6.641502, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:28:30.405028+00:00, data_interval_end=2026-02-13 13:28:30.405028+00:00, dag_hash=47cb4504eff6f0d33ccb9eb1ea3c16ae
2026-02-13 21:28:37,700 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-13T13:28:34.631014+00:00 [scheduled]>
2026-02-13 21:28:37,701 INFO - DAG consumer_variable has 0/16 running and queued tasks
2026-02-13 21:28:37,702 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-13T13:28:34.631014+00:00 [scheduled]>
2026-02-13 21:28:37,704 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-13T13:28:34.631014+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:28:37,705 INFO - Sending TaskInstanceKey(dag_id='consumer_variable', task_id='consumer_variable_read_data', run_id='dataset_triggered__2026-02-13T13:28:34.631014+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:28:37,706 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_variable', 'consumer_variable_read_data', 'dataset_triggered__2026-02-13T13:28:34.631014+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:28:37,708 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_variable', 'consumer_variable_read_data', 'dataset_triggered__2026-02-13T13:28:34.631014+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:28:41,345 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_variable', task_id='consumer_variable_read_data', run_id='dataset_triggered__2026-02-13T13:28:34.631014+00:00', try_number=1, map_index=-1)
2026-02-13 21:28:41,354 INFO - TaskInstance Finished: dag_id=consumer_variable, task_id=consumer_variable_read_data, run_id=dataset_triggered__2026-02-13T13:28:34.631014+00:00, map_index=-1, run_start_date=2026-02-13 13:28:40.356836+00:00, run_end_date=2026-02-13 13:28:40.752507+00:00, run_duration=0.395671, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=72, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:28:37.702957+00:00, queued_by_job_id=58, pid=5478
2026-02-13 21:28:43,942 INFO - Marking run <DagRun consumer_variable @ 2026-02-13 13:28:34.631014+00:00: dataset_triggered__2026-02-13T13:28:34.631014+00:00, state:running, queued_at: 2026-02-13 13:28:37.659479+00:00. externally triggered: False> successful
2026-02-13 21:28:43,943 INFO - DagRun Finished: dag_id=consumer_variable, execution_date=2026-02-13 13:28:34.631014+00:00, run_id=dataset_triggered__2026-02-13T13:28:34.631014+00:00, run_start_date=2026-02-13 13:28:37.675820+00:00, run_end_date=2026-02-13 13:28:43.943383+00:00, run_duration=6.267563, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 13:28:30.405028+00:00, data_interval_end=2026-02-13 13:28:30.405028+00:00, dag_hash=ea6f50333c860200cf7319bc15b25ef1
2026-02-13 21:31:43,552 INFO - 1 tasks up for execution:
	<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-13T13:31:41.629277+00:00 [scheduled]>
2026-02-13 21:31:43,553 INFO - DAG producer_variable_sync has 0/16 running and queued tasks
2026-02-13 21:31:43,553 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-13T13:31:41.629277+00:00 [scheduled]>
2026-02-13 21:31:43,556 INFO - Trying to enqueue tasks: [<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-13T13:31:41.629277+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:31:43,557 INFO - Sending TaskInstanceKey(dag_id='producer_variable_sync', task_id='producer_variable_save_data', run_id='manual__2026-02-13T13:31:41.629277+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:31:43,558 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'producer_variable_save_data', 'manual__2026-02-13T13:31:41.629277+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:31:43,560 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'producer_variable_save_data', 'manual__2026-02-13T13:31:41.629277+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:31:47,575 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_variable_sync', task_id='producer_variable_save_data', run_id='manual__2026-02-13T13:31:41.629277+00:00', try_number=1, map_index=-1)
2026-02-13 21:31:47,585 INFO - TaskInstance Finished: dag_id=producer_variable_sync, task_id=producer_variable_save_data, run_id=manual__2026-02-13T13:31:41.629277+00:00, map_index=-1, run_start_date=2026-02-13 13:31:46.632761+00:00, run_end_date=2026-02-13 13:31:47.023060+00:00, run_duration=0.390299, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=73, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:31:43.554757+00:00, queued_by_job_id=58, pid=5562
2026-02-13 21:31:47,689 INFO - Marking run <DagRun producer_variable_sync @ 2026-02-13 13:31:41.629277+00:00: manual__2026-02-13T13:31:41.629277+00:00, state:running, queued_at: 2026-02-13 13:31:41.647968+00:00. externally triggered: True> successful
2026-02-13 21:31:47,690 INFO - DagRun Finished: dag_id=producer_variable_sync, execution_date=2026-02-13 13:31:41.629277+00:00, run_id=manual__2026-02-13T13:31:41.629277+00:00, run_start_date=2026-02-13 13:31:43.532261+00:00, run_end_date=2026-02-13 13:31:47.690795+00:00, run_duration=4.158534, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:31:41.629277+00:00, data_interval_end=2026-02-13 13:31:41.629277+00:00, dag_hash=47cb4504eff6f0d33ccb9eb1ea3c16ae
2026-02-13 21:31:48,750 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-13T13:31:47.043088+00:00 [scheduled]>
2026-02-13 21:31:48,751 INFO - DAG consumer_variable has 0/16 running and queued tasks
2026-02-13 21:31:48,752 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-13T13:31:47.043088+00:00 [scheduled]>
2026-02-13 21:31:48,755 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-13T13:31:47.043088+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:31:48,756 INFO - Sending TaskInstanceKey(dag_id='consumer_variable', task_id='consumer_variable_read_data', run_id='dataset_triggered__2026-02-13T13:31:47.043088+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:31:48,757 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_variable', 'consumer_variable_read_data', 'dataset_triggered__2026-02-13T13:31:47.043088+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:31:48,759 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_variable', 'consumer_variable_read_data', 'dataset_triggered__2026-02-13T13:31:47.043088+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-13 21:31:52,346 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_variable', task_id='consumer_variable_read_data', run_id='dataset_triggered__2026-02-13T13:31:47.043088+00:00', try_number=1, map_index=-1)
2026-02-13 21:31:52,356 INFO - TaskInstance Finished: dag_id=consumer_variable, task_id=consumer_variable_read_data, run_id=dataset_triggered__2026-02-13T13:31:47.043088+00:00, map_index=-1, run_start_date=2026-02-13 13:31:51.450539+00:00, run_end_date=2026-02-13 13:31:51.793322+00:00, run_duration=0.342783, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=74, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:31:48.753858+00:00, queued_by_job_id=58, pid=5565
2026-02-13 21:31:52,397 INFO - Marking run <DagRun consumer_variable @ 2026-02-13 13:31:47.043088+00:00: dataset_triggered__2026-02-13T13:31:47.043088+00:00, state:running, queued_at: 2026-02-13 13:31:47.668267+00:00. externally triggered: False> successful
2026-02-13 21:31:52,398 INFO - DagRun Finished: dag_id=consumer_variable, execution_date=2026-02-13 13:31:47.043088+00:00, run_id=dataset_triggered__2026-02-13T13:31:47.043088+00:00, run_start_date=2026-02-13 13:31:48.728389+00:00, run_end_date=2026-02-13 13:31:52.398312+00:00, run_duration=3.669923, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 13:31:41.629277+00:00, data_interval_end=2026-02-13 13:31:41.629277+00:00, dag_hash=ea6f50333c860200cf7319bc15b25ef1
2026-02-13 21:32:05,939 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:37:07,679 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:39:02,998 INFO - 1 tasks up for execution:
	<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:38:59.836012+00:00 [scheduled]>
2026-02-13 21:39:02,999 INFO - DAG producer_object_sync has 0/16 running and queued tasks
2026-02-13 21:39:03,000 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:38:59.836012+00:00 [scheduled]>
2026-02-13 21:39:03,002 INFO - Trying to enqueue tasks: [<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:38:59.836012+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:39:03,003 INFO - Sending TaskInstanceKey(dag_id='producer_object_sync', task_id='producer_object_save_data', run_id='manual__2026-02-13T13:38:59.836012+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:39:03,005 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_object_sync', 'producer_object_save_data', 'manual__2026-02-13T13:38:59.836012+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:39:03,007 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_object_sync', 'producer_object_save_data', 'manual__2026-02-13T13:38:59.836012+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:39:06,811 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_object_sync', task_id='producer_object_save_data', run_id='manual__2026-02-13T13:38:59.836012+00:00', try_number=1, map_index=-1)
2026-02-13 21:39:06,821 INFO - TaskInstance Finished: dag_id=producer_object_sync, task_id=producer_object_save_data, run_id=manual__2026-02-13T13:38:59.836012+00:00, map_index=-1, run_start_date=2026-02-13 13:39:05.940543+00:00, run_end_date=2026-02-13 13:39:06.286740+00:00, run_duration=0.346197, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=75, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:39:03.001168+00:00, queued_by_job_id=58, pid=5812
2026-02-13 21:39:09,593 ERROR - Marking run <DagRun producer_object_sync @ 2026-02-13 13:38:59.836012+00:00: manual__2026-02-13T13:38:59.836012+00:00, state:running, queued_at: 2026-02-13 13:38:59.851509+00:00. externally triggered: True> failed
2026-02-13 21:39:09,594 INFO - DagRun Finished: dag_id=producer_object_sync, execution_date=2026-02-13 13:38:59.836012+00:00, run_id=manual__2026-02-13T13:38:59.836012+00:00, run_start_date=2026-02-13 13:39:02.978128+00:00, run_end_date=2026-02-13 13:39:09.594334+00:00, run_duration=6.616206, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:38:59.836012+00:00, data_interval_end=2026-02-13 13:38:59.836012+00:00, dag_hash=7d555625b44488c0b76434bc238566ca
2026-02-13 21:42:07,722 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:42:54,108 INFO - 1 tasks up for execution:
	<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:42:53.973560+00:00 [scheduled]>
2026-02-13 21:42:54,110 INFO - DAG producer_object_sync has 0/16 running and queued tasks
2026-02-13 21:42:54,111 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:42:53.973560+00:00 [scheduled]>
2026-02-13 21:42:54,115 INFO - Trying to enqueue tasks: [<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:42:53.973560+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:42:54,116 INFO - Sending TaskInstanceKey(dag_id='producer_object_sync', task_id='producer_object_save_data', run_id='manual__2026-02-13T13:42:53.973560+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:42:54,117 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_object_sync', 'producer_object_save_data', 'manual__2026-02-13T13:42:53.973560+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:42:54,120 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_object_sync', 'producer_object_save_data', 'manual__2026-02-13T13:42:53.973560+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:42:58,061 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_object_sync', task_id='producer_object_save_data', run_id='manual__2026-02-13T13:42:53.973560+00:00', try_number=1, map_index=-1)
2026-02-13 21:42:58,072 INFO - TaskInstance Finished: dag_id=producer_object_sync, task_id=producer_object_save_data, run_id=manual__2026-02-13T13:42:53.973560+00:00, map_index=-1, run_start_date=2026-02-13 13:42:57.153377+00:00, run_end_date=2026-02-13 13:42:57.481345+00:00, run_duration=0.327968, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=76, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:42:54.113360+00:00, queued_by_job_id=58, pid=5890
2026-02-13 21:42:58,121 ERROR - Marking run <DagRun producer_object_sync @ 2026-02-13 13:42:53.973560+00:00: manual__2026-02-13T13:42:53.973560+00:00, state:running, queued_at: 2026-02-13 13:42:53.990856+00:00. externally triggered: True> failed
2026-02-13 21:42:58,122 INFO - DagRun Finished: dag_id=producer_object_sync, execution_date=2026-02-13 13:42:53.973560+00:00, run_id=manual__2026-02-13T13:42:53.973560+00:00, run_start_date=2026-02-13 13:42:54.085628+00:00, run_end_date=2026-02-13 13:42:58.122290+00:00, run_duration=4.036662, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:42:53.973560+00:00, data_interval_end=2026-02-13 13:42:53.973560+00:00, dag_hash=7d555625b44488c0b76434bc238566ca
2026-02-13 21:43:38,119 INFO - 1 tasks up for execution:
	<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:43:37.197651+00:00 [scheduled]>
2026-02-13 21:43:38,119 INFO - DAG producer_object_sync has 0/16 running and queued tasks
2026-02-13 21:43:38,120 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:43:37.197651+00:00 [scheduled]>
2026-02-13 21:43:38,122 INFO - Trying to enqueue tasks: [<TaskInstance: producer_object_sync.producer_object_save_data manual__2026-02-13T13:43:37.197651+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:43:38,123 INFO - Sending TaskInstanceKey(dag_id='producer_object_sync', task_id='producer_object_save_data', run_id='manual__2026-02-13T13:43:37.197651+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:43:38,124 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_object_sync', 'producer_object_save_data', 'manual__2026-02-13T13:43:37.197651+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:43:38,127 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_object_sync', 'producer_object_save_data', 'manual__2026-02-13T13:43:37.197651+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:43:41,738 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_object_sync', task_id='producer_object_save_data', run_id='manual__2026-02-13T13:43:37.197651+00:00', try_number=1, map_index=-1)
2026-02-13 21:43:41,753 INFO - TaskInstance Finished: dag_id=producer_object_sync, task_id=producer_object_save_data, run_id=manual__2026-02-13T13:43:37.197651+00:00, map_index=-1, run_start_date=2026-02-13 13:43:40.845454+00:00, run_end_date=2026-02-13 13:43:41.203293+00:00, run_duration=0.357839, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=77, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:43:38.121725+00:00, queued_by_job_id=58, pid=5930
2026-02-13 21:43:41,819 INFO - Marking run <DagRun producer_object_sync @ 2026-02-13 13:43:37.197651+00:00: manual__2026-02-13T13:43:37.197651+00:00, state:running, queued_at: 2026-02-13 13:43:37.209001+00:00. externally triggered: True> successful
2026-02-13 21:43:41,820 INFO - DagRun Finished: dag_id=producer_object_sync, execution_date=2026-02-13 13:43:37.197651+00:00, run_id=manual__2026-02-13T13:43:37.197651+00:00, run_start_date=2026-02-13 13:43:38.088254+00:00, run_end_date=2026-02-13 13:43:41.820298+00:00, run_duration=3.732044, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:43:37.197651+00:00, data_interval_end=2026-02-13 13:43:37.197651+00:00, dag_hash=7d555625b44488c0b76434bc238566ca
2026-02-13 21:43:45,429 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_object.consumer_object_read_data dataset_triggered__2026-02-13T13:43:41.221425+00:00 [scheduled]>
2026-02-13 21:43:45,430 INFO - DAG consumer_object has 0/16 running and queued tasks
2026-02-13 21:43:45,431 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_object.consumer_object_read_data dataset_triggered__2026-02-13T13:43:41.221425+00:00 [scheduled]>
2026-02-13 21:43:45,433 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_object.consumer_object_read_data dataset_triggered__2026-02-13T13:43:41.221425+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:43:45,434 INFO - Sending TaskInstanceKey(dag_id='consumer_object', task_id='consumer_object_read_data', run_id='dataset_triggered__2026-02-13T13:43:41.221425+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:43:45,434 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_object', 'consumer_object_read_data', 'dataset_triggered__2026-02-13T13:43:41.221425+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:43:45,437 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_object', 'consumer_object_read_data', 'dataset_triggered__2026-02-13T13:43:41.221425+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_object.py']
2026-02-13 21:43:48,831 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_object', task_id='consumer_object_read_data', run_id='dataset_triggered__2026-02-13T13:43:41.221425+00:00', try_number=1, map_index=-1)
2026-02-13 21:43:48,841 INFO - TaskInstance Finished: dag_id=consumer_object, task_id=consumer_object_read_data, run_id=dataset_triggered__2026-02-13T13:43:41.221425+00:00, map_index=-1, run_start_date=2026-02-13 13:43:47.997174+00:00, run_end_date=2026-02-13 13:43:48.343217+00:00, run_duration=0.346043, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=78, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:43:45.431998+00:00, queued_by_job_id=58, pid=5934
2026-02-13 21:43:51,539 INFO - Marking run <DagRun consumer_object @ 2026-02-13 13:43:41.221425+00:00: dataset_triggered__2026-02-13T13:43:41.221425+00:00, state:running, queued_at: 2026-02-13 13:43:41.800292+00:00. externally triggered: False> successful
2026-02-13 21:43:51,540 INFO - DagRun Finished: dag_id=consumer_object, execution_date=2026-02-13 13:43:41.221425+00:00, run_id=dataset_triggered__2026-02-13T13:43:41.221425+00:00, run_start_date=2026-02-13 13:43:45.407571+00:00, run_end_date=2026-02-13 13:43:51.540699+00:00, run_duration=6.133128, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 13:43:37.197651+00:00, data_interval_end=2026-02-13 13:43:37.197651+00:00, dag_hash=9b4f52719dbf1e041ad0cea210d36db5
2026-02-13 21:47:07,760 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:51:55,988 INFO - Heartbeat recovered after 31.24 seconds
2026-02-13 21:52:07,535 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:52:06.718290+00:00 [scheduled]>
2026-02-13 21:52:07,535 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 21:52:07,536 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:52:06.718290+00:00 [scheduled]>
2026-02-13 21:52:07,538 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:52:06.718290+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:52:07,539 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T13:52:06.718290+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:52:07,540 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T13:52:06.718290+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:52:07,542 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T13:52:06.718290+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:52:11,323 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T13:52:06.718290+00:00', try_number=1, map_index=-1)
2026-02-13 21:52:11,333 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T13:52:06.718290+00:00, map_index=-1, run_start_date=2026-02-13 13:52:10.400351+00:00, run_end_date=2026-02-13 13:52:10.729860+00:00, run_duration=0.329509, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=79, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:52:07.537647+00:00, queued_by_job_id=58, pid=6332
2026-02-13 21:52:11,362 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:52:14,130 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:14,142 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 13:52:06.718290+00:00: manual__2026-02-13T13:52:06.718290+00:00, state:running, queued_at: 2026-02-13 13:52:06.732084+00:00. externally triggered: True> successful
2026-02-13 21:52:14,143 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 13:52:06.718290+00:00, run_id=manual__2026-02-13T13:52:06.718290+00:00, run_start_date=2026-02-13 13:52:07.514774+00:00, run_end_date=2026-02-13 13:52:14.143258+00:00, run_duration=6.628484, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:52:06.718290+00:00, data_interval_end=2026-02-13 13:52:06.718290+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 21:52:17,893 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:21,713 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:22,763 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:22,946 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:23,993 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:25,034 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:28,558 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:29,614 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:33,248 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:36,508 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:40,325 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:41,368 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:41,564 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:42,627 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:43,293 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:43,610 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:47,287 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:50,962 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:54,576 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:55,650 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:52:56,691 ERROR - DAG 'consumer_dagRun' not found in serialized_dag table
2026-02-13 21:54:49,428 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:52:10.746398+00:00 [scheduled]>
2026-02-13 21:54:49,429 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 21:54:49,429 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:52:10.746398+00:00 [scheduled]>
2026-02-13 21:54:49,432 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:52:10.746398+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:54:49,433 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T13:52:10.746398+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:54:49,434 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T13:52:10.746398+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:54:49,436 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T13:52:10.746398+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:54:53,066 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T13:52:10.746398+00:00', try_number=1, map_index=-1)
2026-02-13 21:54:53,076 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T13:52:10.746398+00:00, map_index=-1, run_start_date=2026-02-13 13:54:52.208560+00:00, run_end_date=2026-02-13 13:54:52.544442+00:00, run_duration=0.335882, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=80, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:54:49.430891+00:00, queued_by_job_id=58, pid=6449
2026-02-13 21:54:56,219 ERROR - Marking run <DagRun consumer_dagRun @ 2026-02-13 13:52:10.746398+00:00: dataset_triggered__2026-02-13T13:52:10.746398+00:00, state:running, queued_at: 2026-02-13 13:54:49.394621+00:00. externally triggered: False> failed
2026-02-13 21:54:56,220 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 13:52:10.746398+00:00, run_id=dataset_triggered__2026-02-13T13:52:10.746398+00:00, run_start_date=2026-02-13 13:54:49.408553+00:00, run_end_date=2026-02-13 13:54:56.220773+00:00, run_duration=6.81222, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 13:52:06.718290+00:00, data_interval_end=2026-02-13 13:52:06.718290+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 21:55:14,007 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:55:12.814268+00:00 [scheduled]>
2026-02-13 21:55:14,009 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 21:55:14,009 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:55:12.814268+00:00 [scheduled]>
2026-02-13 21:55:14,013 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:55:12.814268+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:55:14,014 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T13:55:12.814268+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:55:14,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T13:55:12.814268+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:55:14,017 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T13:55:12.814268+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:55:17,669 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T13:55:12.814268+00:00', try_number=1, map_index=-1)
2026-02-13 21:55:17,678 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T13:55:12.814268+00:00, map_index=-1, run_start_date=2026-02-13 13:55:16.717090+00:00, run_end_date=2026-02-13 13:55:17.073853+00:00, run_duration=0.356763, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=81, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:55:14.011004+00:00, queued_by_job_id=58, pid=6502
2026-02-13 21:55:20,368 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 13:55:12.814268+00:00: manual__2026-02-13T13:55:12.814268+00:00, state:running, queued_at: 2026-02-13 13:55:12.825993+00:00. externally triggered: True> successful
2026-02-13 21:55:20,369 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 13:55:12.814268+00:00, run_id=manual__2026-02-13T13:55:12.814268+00:00, run_start_date=2026-02-13 13:55:13.982701+00:00, run_end_date=2026-02-13 13:55:20.368974+00:00, run_duration=6.386273, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:55:12.814268+00:00, data_interval_end=2026-02-13 13:55:12.814268+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 21:55:20,379 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:55:17.093128+00:00 [scheduled]>
2026-02-13 21:55:20,380 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 21:55:20,381 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:55:17.093128+00:00 [scheduled]>
2026-02-13 21:55:20,384 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:55:17.093128+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:55:20,385 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T13:55:17.093128+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:55:20,385 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T13:55:17.093128+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:55:20,388 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T13:55:17.093128+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:55:24,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T13:55:17.093128+00:00', try_number=1, map_index=-1)
2026-02-13 21:55:24,325 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T13:55:17.093128+00:00, map_index=-1, run_start_date=2026-02-13 13:55:23.391484+00:00, run_end_date=2026-02-13 13:55:23.734496+00:00, run_duration=0.343012, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=82, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:55:20.382361+00:00, queued_by_job_id=58, pid=6513
2026-02-13 21:55:27,141 ERROR - Marking run <DagRun consumer_dagRun @ 2026-02-13 13:55:17.093128+00:00: dataset_triggered__2026-02-13T13:55:17.093128+00:00, state:running, queued_at: 2026-02-13 13:55:20.336102+00:00. externally triggered: False> failed
2026-02-13 21:55:27,142 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 13:55:17.093128+00:00, run_id=dataset_triggered__2026-02-13T13:55:17.093128+00:00, run_start_date=2026-02-13 13:55:20.353740+00:00, run_end_date=2026-02-13 13:55:27.142224+00:00, run_duration=6.788484, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 13:55:12.814268+00:00, data_interval_end=2026-02-13 13:55:12.814268+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 21:57:11,554 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 21:57:49,410 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:57:46.936479+00:00 [scheduled]>
2026-02-13 21:57:49,411 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 21:57:49,411 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:57:46.936479+00:00 [scheduled]>
2026-02-13 21:57:49,414 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T13:57:46.936479+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:57:49,415 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T13:57:46.936479+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:57:49,415 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T13:57:46.936479+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:57:49,418 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T13:57:46.936479+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:57:53,060 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T13:57:46.936479+00:00', try_number=1, map_index=-1)
2026-02-13 21:57:53,069 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T13:57:46.936479+00:00, map_index=-1, run_start_date=2026-02-13 13:57:52.121692+00:00, run_end_date=2026-02-13 13:57:52.477999+00:00, run_duration=0.356307, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=83, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:57:49.412761+00:00, queued_by_job_id=58, pid=6600
2026-02-13 21:57:55,764 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 13:57:46.936479+00:00: manual__2026-02-13T13:57:46.936479+00:00, state:running, queued_at: 2026-02-13 13:57:46.947402+00:00. externally triggered: True> successful
2026-02-13 21:57:55,765 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 13:57:46.936479+00:00, run_id=manual__2026-02-13T13:57:46.936479+00:00, run_start_date=2026-02-13 13:57:49.390250+00:00, run_end_date=2026-02-13 13:57:55.765280+00:00, run_duration=6.37503, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 13:57:46.936479+00:00, data_interval_end=2026-02-13 13:57:46.936479+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 21:57:55,775 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:57:52.497306+00:00 [scheduled]>
2026-02-13 21:57:55,776 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 21:57:55,776 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:57:52.497306+00:00 [scheduled]>
2026-02-13 21:57:55,779 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T13:57:52.497306+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 21:57:55,780 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T13:57:52.497306+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 21:57:55,780 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T13:57:52.497306+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:57:55,783 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T13:57:52.497306+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 21:57:59,135 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T13:57:52.497306+00:00', try_number=1, map_index=-1)
2026-02-13 21:57:59,145 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T13:57:52.497306+00:00, map_index=-1, run_start_date=2026-02-13 13:57:58.299452+00:00, run_end_date=2026-02-13 13:57:58.648892+00:00, run_duration=0.34944, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=84, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 13:57:55.777895+00:00, queued_by_job_id=58, pid=6605
2026-02-13 21:58:01,737 INFO - Marking run <DagRun consumer_dagRun @ 2026-02-13 13:57:52.497306+00:00: dataset_triggered__2026-02-13T13:57:52.497306+00:00, state:running, queued_at: 2026-02-13 13:57:55.735901+00:00. externally triggered: False> successful
2026-02-13 21:58:01,739 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 13:57:52.497306+00:00, run_id=dataset_triggered__2026-02-13T13:57:52.497306+00:00, run_start_date=2026-02-13 13:57:55.751523+00:00, run_end_date=2026-02-13 13:58:01.738990+00:00, run_duration=5.987467, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 13:57:46.936479+00:00, data_interval_end=2026-02-13 13:57:46.936479+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 22:02:12,674 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 22:06:36,977 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:06:35.989891+00:00 [scheduled]>
2026-02-13 22:06:36,978 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 22:06:36,979 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:06:35.989891+00:00 [scheduled]>
2026-02-13 22:06:36,982 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:06:35.989891+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:06:36,983 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:06:35.989891+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:06:36,984 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:06:35.989891+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:06:36,987 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:06:35.989891+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:06:40,628 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:06:35.989891+00:00', try_number=1, map_index=-1)
2026-02-13 22:06:40,637 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T14:06:35.989891+00:00, map_index=-1, run_start_date=2026-02-13 14:06:39.723961+00:00, run_end_date=2026-02-13 14:06:40.072376+00:00, run_duration=0.348415, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=85, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:06:36.980892+00:00, queued_by_job_id=58, pid=6815
2026-02-13 22:06:40,707 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 14:06:35.989891+00:00: manual__2026-02-13T14:06:35.989891+00:00, state:running, queued_at: 2026-02-13 14:06:36.008553+00:00. externally triggered: True> successful
2026-02-13 22:06:40,708 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 14:06:35.989891+00:00, run_id=manual__2026-02-13T14:06:35.989891+00:00, run_start_date=2026-02-13 14:06:36.954082+00:00, run_end_date=2026-02-13 14:06:40.708210+00:00, run_duration=3.754128, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 14:06:35.989891+00:00, data_interval_end=2026-02-13 14:06:35.989891+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 22:06:41,764 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:06:40.090635+00:00 [scheduled]>
2026-02-13 22:06:41,765 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 22:06:41,766 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:06:40.090635+00:00 [scheduled]>
2026-02-13 22:06:41,768 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:06:40.090635+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:06:41,769 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:06:40.090635+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:06:41,770 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:06:40.090635+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:06:41,772 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:06:40.090635+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:06:45,440 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:06:40.090635+00:00', try_number=1, map_index=-1)
2026-02-13 22:06:45,449 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T14:06:40.090635+00:00, map_index=-1, run_start_date=2026-02-13 14:06:44.502527+00:00, run_end_date=2026-02-13 14:06:44.869335+00:00, run_duration=0.366808, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=86, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:06:41.767241+00:00, queued_by_job_id=58, pid=6818
2026-02-13 22:06:47,915 INFO - Marking run <DagRun consumer_dagRun @ 2026-02-13 14:06:40.090635+00:00: dataset_triggered__2026-02-13T14:06:40.090635+00:00, state:running, queued_at: 2026-02-13 14:06:40.689164+00:00. externally triggered: False> successful
2026-02-13 22:06:47,916 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 14:06:40.090635+00:00, run_id=dataset_triggered__2026-02-13T14:06:40.090635+00:00, run_start_date=2026-02-13 14:06:41.744462+00:00, run_end_date=2026-02-13 14:06:47.916201+00:00, run_duration=6.171739, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 14:06:35.989891+00:00, data_interval_end=2026-02-13 14:06:35.989891+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 22:07:12,550 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 22:10:21,604 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:10:18.122537+00:00 [scheduled]>
2026-02-13 22:10:21,605 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 22:10:21,605 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:10:18.122537+00:00 [scheduled]>
2026-02-13 22:10:21,608 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:10:18.122537+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:10:21,609 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:10:18.122537+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:10:21,609 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:10:18.122537+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:10:21,612 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:10:18.122537+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:10:25,302 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:10:18.122537+00:00', try_number=1, map_index=-1)
2026-02-13 22:10:25,313 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T14:10:18.122537+00:00, map_index=-1, run_start_date=2026-02-13 14:10:24.346755+00:00, run_end_date=2026-02-13 14:10:24.735967+00:00, run_duration=0.389212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=87, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:10:21.607014+00:00, queued_by_job_id=58, pid=6947
2026-02-13 22:10:27,802 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 14:10:18.122537+00:00: manual__2026-02-13T14:10:18.122537+00:00, state:running, queued_at: 2026-02-13 14:10:18.133454+00:00. externally triggered: True> successful
2026-02-13 22:10:27,803 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 14:10:18.122537+00:00, run_id=manual__2026-02-13T14:10:18.122537+00:00, run_start_date=2026-02-13 14:10:21.584849+00:00, run_end_date=2026-02-13 14:10:27.803156+00:00, run_duration=6.218307, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 14:10:18.122537+00:00, data_interval_end=2026-02-13 14:10:18.122537+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 22:10:27,812 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:10:24.755287+00:00 [scheduled]>
2026-02-13 22:10:27,812 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 22:10:27,813 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:10:24.755287+00:00 [scheduled]>
2026-02-13 22:10:27,815 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:10:24.755287+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:10:27,816 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:10:24.755287+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:10:27,817 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:10:24.755287+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:10:27,819 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:10:24.755287+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:10:31,354 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:10:24.755287+00:00', try_number=1, map_index=-1)
2026-02-13 22:10:31,365 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T14:10:24.755287+00:00, map_index=-1, run_start_date=2026-02-13 14:10:30.335444+00:00, run_end_date=2026-02-13 14:10:30.752163+00:00, run_duration=0.416719, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=88, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:10:27.814468+00:00, queued_by_job_id=58, pid=6950
2026-02-13 22:10:33,872 INFO - Marking run <DagRun consumer_dagRun @ 2026-02-13 14:10:24.755287+00:00: dataset_triggered__2026-02-13T14:10:24.755287+00:00, state:running, queued_at: 2026-02-13 14:10:27.773909+00:00. externally triggered: False> successful
2026-02-13 22:10:33,873 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 14:10:24.755287+00:00, run_id=dataset_triggered__2026-02-13T14:10:24.755287+00:00, run_start_date=2026-02-13 14:10:27.789025+00:00, run_end_date=2026-02-13 14:10:33.873466+00:00, run_duration=6.084441, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 14:10:18.122537+00:00, data_interval_end=2026-02-13 14:10:18.122537+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 22:12:13,179 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 22:13:59,439 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:13:57.660372+00:00 [scheduled]>
2026-02-13 22:13:59,440 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 22:13:59,441 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:13:57.660372+00:00 [scheduled]>
2026-02-13 22:13:59,443 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:13:57.660372+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:13:59,444 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:13:57.660372+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:13:59,445 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:13:57.660372+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:13:59,447 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:13:57.660372+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:14:02,992 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:13:57.660372+00:00', try_number=1, map_index=-1)
2026-02-13 22:14:03,002 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T14:13:57.660372+00:00, map_index=-1, run_start_date=2026-02-13 14:14:02.134441+00:00, run_end_date=2026-02-13 14:14:02.467478+00:00, run_duration=0.333037, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=89, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:13:59.442521+00:00, queued_by_job_id=58, pid=7044
2026-02-13 22:14:05,542 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 14:13:57.660372+00:00: manual__2026-02-13T14:13:57.660372+00:00, state:running, queued_at: 2026-02-13 14:13:57.671428+00:00. externally triggered: True> successful
2026-02-13 22:14:05,543 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 14:13:57.660372+00:00, run_id=manual__2026-02-13T14:13:57.660372+00:00, run_start_date=2026-02-13 14:13:59.418194+00:00, run_end_date=2026-02-13 14:14:05.543694+00:00, run_duration=6.1255, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 14:13:57.660372+00:00, data_interval_end=2026-02-13 14:13:57.660372+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 22:14:05,554 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:14:02.484868+00:00 [scheduled]>
2026-02-13 22:14:05,555 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 22:14:05,555 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:14:02.484868+00:00 [scheduled]>
2026-02-13 22:14:05,558 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:14:02.484868+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:14:05,559 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:14:02.484868+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:14:05,560 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:14:02.484868+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:14:05,562 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:14:02.484868+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:14:09,256 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:14:02.484868+00:00', try_number=1, map_index=-1)
2026-02-13 22:14:09,266 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T14:14:02.484868+00:00, map_index=-1, run_start_date=2026-02-13 14:14:08.328089+00:00, run_end_date=2026-02-13 14:14:08.672120+00:00, run_duration=0.344031, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=90, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:14:05.557023+00:00, queued_by_job_id=58, pid=7047
2026-02-13 22:14:11,726 ERROR - Marking run <DagRun consumer_dagRun @ 2026-02-13 14:14:02.484868+00:00: dataset_triggered__2026-02-13T14:14:02.484868+00:00, state:running, queued_at: 2026-02-13 14:14:05.513229+00:00. externally triggered: False> failed
2026-02-13 22:14:11,727 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 14:14:02.484868+00:00, run_id=dataset_triggered__2026-02-13T14:14:02.484868+00:00, run_start_date=2026-02-13 14:14:05.528608+00:00, run_end_date=2026-02-13 14:14:11.727269+00:00, run_duration=6.198661, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 14:13:57.660372+00:00, data_interval_end=2026-02-13 14:13:57.660372+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 22:16:13,521 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:16:12.947371+00:00 [scheduled]>
2026-02-13 22:16:13,523 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 22:16:13,524 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:16:12.947371+00:00 [scheduled]>
2026-02-13 22:16:13,530 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:16:12.947371+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:16:13,532 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:16:12.947371+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:16:13,535 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:16:12.947371+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:16:13,538 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:16:12.947371+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:16:17,388 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:16:12.947371+00:00', try_number=1, map_index=-1)
2026-02-13 22:16:17,397 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T14:16:12.947371+00:00, map_index=-1, run_start_date=2026-02-13 14:16:16.438898+00:00, run_end_date=2026-02-13 14:16:16.785992+00:00, run_duration=0.347094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=91, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:16:13.528314+00:00, queued_by_job_id=58, pid=7109
2026-02-13 22:16:19,827 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 14:16:12.947371+00:00: manual__2026-02-13T14:16:12.947371+00:00, state:running, queued_at: 2026-02-13 14:16:12.958807+00:00. externally triggered: True> successful
2026-02-13 22:16:19,828 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 14:16:12.947371+00:00, run_id=manual__2026-02-13T14:16:12.947371+00:00, run_start_date=2026-02-13 14:16:13.494028+00:00, run_end_date=2026-02-13 14:16:19.828416+00:00, run_duration=6.334388, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 14:16:12.947371+00:00, data_interval_end=2026-02-13 14:16:12.947371+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 22:16:19,839 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:16:16.802861+00:00 [scheduled]>
2026-02-13 22:16:19,840 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 22:16:19,841 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:16:16.802861+00:00 [scheduled]>
2026-02-13 22:16:19,843 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:16:16.802861+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:16:19,845 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:16:16.802861+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:16:19,845 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:16:16.802861+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:16:19,859 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:16:16.802861+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:16:23,430 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:16:16.802861+00:00', try_number=1, map_index=-1)
2026-02-13 22:16:23,440 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T14:16:16.802861+00:00, map_index=-1, run_start_date=2026-02-13 14:16:22.517118+00:00, run_end_date=2026-02-13 14:16:22.859699+00:00, run_duration=0.342581, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=92, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:16:19.842621+00:00, queued_by_job_id=58, pid=7112
2026-02-13 22:16:25,793 ERROR - Marking run <DagRun consumer_dagRun @ 2026-02-13 14:16:16.802861+00:00: dataset_triggered__2026-02-13T14:16:16.802861+00:00, state:running, queued_at: 2026-02-13 14:16:19.797692+00:00. externally triggered: False> failed
2026-02-13 22:16:25,794 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 14:16:16.802861+00:00, run_id=dataset_triggered__2026-02-13T14:16:16.802861+00:00, run_start_date=2026-02-13 14:16:19.813628+00:00, run_end_date=2026-02-13 14:16:25.794565+00:00, run_duration=5.980937, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 14:16:12.947371+00:00, data_interval_end=2026-02-13 14:16:12.947371+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 22:17:15,957 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 22:18:36,852 INFO - 1 tasks up for execution:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:18:33.086772+00:00 [scheduled]>
2026-02-13 22:18:36,853 INFO - DAG producer_dagRun_sync has 0/16 running and queued tasks
2026-02-13 22:18:36,854 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:18:33.086772+00:00 [scheduled]>
2026-02-13 22:18:36,856 INFO - Trying to enqueue tasks: [<TaskInstance: producer_dagRun_sync.producer_dagRun_read_data manual__2026-02-13T14:18:33.086772+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:18:36,857 INFO - Sending TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:18:33.086772+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:18:36,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:18:33.086772+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:18:36,860 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_dagRun_sync', 'producer_dagRun_read_data', 'manual__2026-02-13T14:18:33.086772+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:18:40,386 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_dagRun_sync', task_id='producer_dagRun_read_data', run_id='manual__2026-02-13T14:18:33.086772+00:00', try_number=1, map_index=-1)
2026-02-13 22:18:40,396 INFO - TaskInstance Finished: dag_id=producer_dagRun_sync, task_id=producer_dagRun_read_data, run_id=manual__2026-02-13T14:18:33.086772+00:00, map_index=-1, run_start_date=2026-02-13 14:18:39.380049+00:00, run_end_date=2026-02-13 14:18:39.772192+00:00, run_duration=0.392143, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=93, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:18:36.855081+00:00, queued_by_job_id=58, pid=7167
2026-02-13 22:18:42,913 INFO - Marking run <DagRun producer_dagRun_sync @ 2026-02-13 14:18:33.086772+00:00: manual__2026-02-13T14:18:33.086772+00:00, state:running, queued_at: 2026-02-13 14:18:33.097380+00:00. externally triggered: True> successful
2026-02-13 22:18:42,915 INFO - DagRun Finished: dag_id=producer_dagRun_sync, execution_date=2026-02-13 14:18:33.086772+00:00, run_id=manual__2026-02-13T14:18:33.086772+00:00, run_start_date=2026-02-13 14:18:36.832831+00:00, run_end_date=2026-02-13 14:18:42.914955+00:00, run_duration=6.082124, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 14:18:33.086772+00:00, data_interval_end=2026-02-13 14:18:33.086772+00:00, dag_hash=25f10c75cc4c07b582101befabedd510
2026-02-13 22:18:42,923 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:18:39.791063+00:00 [scheduled]>
2026-02-13 22:18:42,924 INFO - DAG consumer_dagRun has 0/16 running and queued tasks
2026-02-13 22:18:42,925 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:18:39.791063+00:00 [scheduled]>
2026-02-13 22:18:42,927 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_dagRun.consumer_dagRun_read_data dataset_triggered__2026-02-13T14:18:39.791063+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-13 22:18:42,928 INFO - Sending TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:18:39.791063+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-13 22:18:42,929 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:18:39.791063+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:18:42,931 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_dagRun', 'consumer_dagRun_read_data', 'dataset_triggered__2026-02-13T14:18:39.791063+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_dagRun.py']
2026-02-13 22:18:46,451 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_dagRun', task_id='consumer_dagRun_read_data', run_id='dataset_triggered__2026-02-13T14:18:39.791063+00:00', try_number=1, map_index=-1)
2026-02-13 22:18:46,462 INFO - TaskInstance Finished: dag_id=consumer_dagRun, task_id=consumer_dagRun_read_data, run_id=dataset_triggered__2026-02-13T14:18:39.791063+00:00, map_index=-1, run_start_date=2026-02-13 14:18:45.469212+00:00, run_end_date=2026-02-13 14:18:45.856053+00:00, run_duration=0.386841, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 14:18:42.926427+00:00, queued_by_job_id=58, pid=7170
2026-02-13 22:18:48,993 INFO - Marking run <DagRun consumer_dagRun @ 2026-02-13 14:18:39.791063+00:00: dataset_triggered__2026-02-13T14:18:39.791063+00:00, state:running, queued_at: 2026-02-13 14:18:42.889311+00:00. externally triggered: False> successful
2026-02-13 22:18:48,994 INFO - DagRun Finished: dag_id=consumer_dagRun, execution_date=2026-02-13 14:18:39.791063+00:00, run_id=dataset_triggered__2026-02-13T14:18:39.791063+00:00, run_start_date=2026-02-13 14:18:42.901593+00:00, run_end_date=2026-02-13 14:18:48.994842+00:00, run_duration=6.093249, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 14:18:33.086772+00:00, data_interval_end=2026-02-13 14:18:33.086772+00:00, dag_hash=02234ad8a70e7998ae33f6010c2f1915
2026-02-13 22:22:17,944 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 22:27:19,824 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 22:40:51,979 INFO - Heartbeat recovered after 571.90 seconds
2026-02-13 22:50:59,301 INFO - Heartbeat recovered after 563.76 seconds
2026-02-13 22:50:59,308 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 23:01:06,531 INFO - Heartbeat recovered after 563.61 seconds
2026-02-13 23:11:12,154 INFO - Heartbeat recovered after 563.49 seconds
2026-02-13 23:21:20,678 INFO - Heartbeat recovered after 562.76 seconds
2026-02-13 23:31:30,594 INFO - Heartbeat recovered after 561.78 seconds
2026-02-13 23:41:33,667 INFO - Heartbeat recovered after 563.32 seconds
2026-02-13 23:51:41,698 INFO - Heartbeat recovered after 563.13 seconds
2026-02-13 23:51:44,900 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-13 23:56:53,714 INFO - Heartbeat recovered after 254.35 seconds
2026-02-14 00:00:01,286 INFO - Setting next_dagrun for dw_order_sync to 2026-02-13 16:00:00+00:00, run_after=2026-02-14 16:00:00+00:00
2026-02-14 00:00:01,317 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-12T16:00:00+00:00 [scheduled]>
2026-02-14 00:00:01,318 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-14 00:00:01,319 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-12T16:00:00+00:00 [scheduled]>
2026-02-14 00:00:01,321 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.sync_order_data scheduled__2026-02-12T16:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:00:01,322 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-12T16:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-14 00:00:01,323 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-12T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-14 00:00:01,325 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'scheduled__2026-02-12T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-14 00:00:04,849 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='scheduled__2026-02-12T16:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 00:00:04,858 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=scheduled__2026-02-12T16:00:00+00:00, map_index=-1, run_start_date=2026-02-13 16:00:03.979413+00:00, run_end_date=2026-02-13 16:00:04.328890+00:00, run_duration=0.349477, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-13 16:00:01.320394+00:00, queued_by_job_id=58, pid=7943
2026-02-14 00:00:04,930 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-12T16:00:00+00:00 [scheduled]>
2026-02-14 00:00:04,931 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-14 00:00:04,932 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-12T16:00:00+00:00 [scheduled]>
2026-02-14 00:00:04,934 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test scheduled__2026-02-12T16:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:00:04,935 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-12T16:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-14 00:00:04,935 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-12T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-14 00:00:04,938 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'scheduled__2026-02-12T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-14 00:00:18,552 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='scheduled__2026-02-12T16:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 00:00:18,562 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=scheduled__2026-02-12T16:00:00+00:00, map_index=-1, run_start_date=2026-02-13 16:00:07.576342+00:00, run_end_date=2026-02-13 16:00:17.993253+00:00, run_duration=10.416911, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=96, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-13 16:00:04.933235+00:00, queued_by_job_id=58, pid=7947
2026-02-14 00:00:20,968 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-12T16:00:00+00:00 [scheduled]>
2026-02-14 00:00:20,969 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-14 00:00:20,969 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-12T16:00:00+00:00 [scheduled]>
2026-02-14 00:00:20,972 INFO - Trying to enqueue tasks: [<TaskInstance: dw_order_sync.run_automation_test2 scheduled__2026-02-12T16:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:00:20,973 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-12T16:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 00:00:20,974 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-12T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-14 00:00:20,976 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'scheduled__2026-02-12T16:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-14 00:00:30,194 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='scheduled__2026-02-12T16:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 00:00:30,204 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=scheduled__2026-02-12T16:00:00+00:00, map_index=-1, run_start_date=2026-02-13 16:00:23.620092+00:00, run_end_date=2026-02-13 16:00:29.702270+00:00, run_duration=6.082178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=97, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 16:00:20.970755+00:00, queued_by_job_id=58, pid=7978
2026-02-14 00:00:33,560 INFO - Marking run <DagRun dw_order_sync @ 2026-02-12 16:00:00+00:00: scheduled__2026-02-12T16:00:00+00:00, state:running, queued_at: 2026-02-13 16:00:01.279749+00:00. externally triggered: False> successful
2026-02-14 00:00:33,563 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-12 16:00:00+00:00, run_id=scheduled__2026-02-12T16:00:00+00:00, run_start_date=2026-02-13 16:00:01.295060+00:00, run_end_date=2026-02-13 16:00:33.563140+00:00, run_duration=32.26808, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-12 16:00:00+00:00, data_interval_end=2026-02-13 16:00:00+00:00, dag_hash=e441836cdc8ba3fd622c724e955ce635
2026-02-14 00:00:33,572 INFO - Setting next_dagrun for dw_order_sync to 2026-02-13 16:00:00+00:00, run_after=2026-02-14 16:00:00+00:00
2026-02-14 00:00:58,043 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 00:02:55,975 INFO - Orphaning unreferenced dataset 'dataset://xcom/'
2026-02-14 00:05:08,446 INFO - Exiting gracefully upon receiving signal 15
2026-02-14 00:05:09,313 INFO - Sending Signals.SIGTERM to group 1967. PIDs of all processes in the group: []
2026-02-14 00:05:09,315 INFO - Sending the signal Signals.SIGTERM to group 1967
2026-02-14 00:05:09,316 INFO - Sending the signal Signals.SIGTERM to process 1967 as process group is missing.
2026-02-14 00:05:09,328 INFO - Sending Signals.SIGTERM to group 1967. PIDs of all processes in the group: []
2026-02-14 00:05:09,328 INFO - Sending the signal Signals.SIGTERM to group 1967
2026-02-14 00:05:09,329 INFO - Sending the signal Signals.SIGTERM to process 1967 as process group is missing.
2026-02-14 00:05:09,330 INFO - Exited execute loop
2026-02-14 00:05:11,444 INFO - Loaded executor: SequentialExecutor
2026-02-14 00:05:11,974 INFO - Starting the scheduler
2026-02-14 00:05:11,975 INFO - Processing each file at most -1 times
2026-02-14 00:05:11,981 INFO - Launched DagFileProcessorManager with pid: 8376
2026-02-14 00:05:11,986 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 00:05:58,194 INFO - 1 tasks up for execution:
	<TaskInstance: producer_xcom_sync.producer_xcom_save_data manual__2026-02-13T16:05:55.895216+00:00 [scheduled]>
2026-02-14 00:05:58,195 INFO - DAG producer_xcom_sync has 0/16 running and queued tasks
2026-02-14 00:05:58,196 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_xcom_sync.producer_xcom_save_data manual__2026-02-13T16:05:55.895216+00:00 [scheduled]>
2026-02-14 00:05:58,200 INFO - Trying to enqueue tasks: [<TaskInstance: producer_xcom_sync.producer_xcom_save_data manual__2026-02-13T16:05:55.895216+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:05:58,200 INFO - Sending TaskInstanceKey(dag_id='producer_xcom_sync', task_id='producer_xcom_save_data', run_id='manual__2026-02-13T16:05:55.895216+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 00:05:58,201 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_xcom_sync', 'producer_xcom_save_data', 'manual__2026-02-13T16:05:55.895216+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_xcom.py']
2026-02-14 00:05:58,204 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_xcom_sync', 'producer_xcom_save_data', 'manual__2026-02-13T16:05:55.895216+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_xcom.py']
2026-02-14 00:06:01,825 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_xcom_sync', task_id='producer_xcom_save_data', run_id='manual__2026-02-13T16:05:55.895216+00:00', try_number=1, map_index=-1)
2026-02-14 00:06:01,839 INFO - TaskInstance Finished: dag_id=producer_xcom_sync, task_id=producer_xcom_save_data, run_id=manual__2026-02-13T16:05:55.895216+00:00, map_index=-1, run_start_date=2026-02-13 16:06:00.749982+00:00, run_end_date=2026-02-13 16:06:01.099449+00:00, run_duration=0.349467, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=99, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 16:05:58.197995+00:00, queued_by_job_id=98, pid=8426
2026-02-14 00:06:04,561 INFO - Marking run <DagRun producer_xcom_sync @ 2026-02-13 16:05:55.895216+00:00: manual__2026-02-13T16:05:55.895216+00:00, state:running, queued_at: 2026-02-13 16:05:55.916304+00:00. externally triggered: True> successful
2026-02-14 00:06:04,562 INFO - DagRun Finished: dag_id=producer_xcom_sync, execution_date=2026-02-13 16:05:55.895216+00:00, run_id=manual__2026-02-13T16:05:55.895216+00:00, run_start_date=2026-02-13 16:05:58.158330+00:00, run_end_date=2026-02-13 16:06:04.562528+00:00, run_duration=6.404198, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 16:05:55.895216+00:00, data_interval_end=2026-02-13 16:05:55.895216+00:00, dag_hash=122444dd0c644311f38ec0d9e938cb3b
2026-02-14 00:06:04,572 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_xcom2.consumer_xcom_read_data2 dataset_triggered__2026-02-13T16:06:01.114736+00:00 [scheduled]>
	<TaskInstance: consumer_xcom1.consumer_xcom_read_data1 dataset_triggered__2026-02-13T16:06:01.116213+00:00 [scheduled]>
2026-02-14 00:06:04,573 INFO - DAG consumer_xcom2 has 0/16 running and queued tasks
2026-02-14 00:06:04,574 INFO - DAG consumer_xcom1 has 0/16 running and queued tasks
2026-02-14 00:06:04,575 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_xcom2.consumer_xcom_read_data2 dataset_triggered__2026-02-13T16:06:01.114736+00:00 [scheduled]>
	<TaskInstance: consumer_xcom1.consumer_xcom_read_data1 dataset_triggered__2026-02-13T16:06:01.116213+00:00 [scheduled]>
2026-02-14 00:06:04,578 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_xcom2.consumer_xcom_read_data2 dataset_triggered__2026-02-13T16:06:01.114736+00:00 [scheduled]>, <TaskInstance: consumer_xcom1.consumer_xcom_read_data1 dataset_triggered__2026-02-13T16:06:01.116213+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:06:04,579 INFO - Sending TaskInstanceKey(dag_id='consumer_xcom2', task_id='consumer_xcom_read_data2', run_id='dataset_triggered__2026-02-13T16:06:01.114736+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 00:06:04,579 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_xcom2', 'consumer_xcom_read_data2', 'dataset_triggered__2026-02-13T16:06:01.114736+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_xcom.py']
2026-02-14 00:06:04,580 INFO - Sending TaskInstanceKey(dag_id='consumer_xcom1', task_id='consumer_xcom_read_data1', run_id='dataset_triggered__2026-02-13T16:06:01.116213+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 00:06:04,581 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_xcom1', 'consumer_xcom_read_data1', 'dataset_triggered__2026-02-13T16:06:01.116213+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_xcom.py']
2026-02-14 00:06:04,583 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_xcom2', 'consumer_xcom_read_data2', 'dataset_triggered__2026-02-13T16:06:01.114736+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_xcom.py']
2026-02-14 00:06:08,150 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_xcom1', 'consumer_xcom_read_data1', 'dataset_triggered__2026-02-13T16:06:01.116213+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_xcom.py']
2026-02-14 00:06:11,952 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_xcom2', task_id='consumer_xcom_read_data2', run_id='dataset_triggered__2026-02-13T16:06:01.114736+00:00', try_number=1, map_index=-1)
2026-02-14 00:06:11,955 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_xcom1', task_id='consumer_xcom_read_data1', run_id='dataset_triggered__2026-02-13T16:06:01.116213+00:00', try_number=1, map_index=-1)
2026-02-14 00:06:11,966 INFO - TaskInstance Finished: dag_id=consumer_xcom2, task_id=consumer_xcom_read_data2, run_id=dataset_triggered__2026-02-13T16:06:01.114736+00:00, map_index=-1, run_start_date=2026-02-13 16:06:07.095447+00:00, run_end_date=2026-02-13 16:06:07.457738+00:00, run_duration=0.362291, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=100, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 16:06:04.576236+00:00, queued_by_job_id=98, pid=8429
2026-02-14 00:06:11,968 INFO - TaskInstance Finished: dag_id=consumer_xcom1, task_id=consumer_xcom_read_data1, run_id=dataset_triggered__2026-02-13T16:06:01.116213+00:00, map_index=-1, run_start_date=2026-02-13 16:06:10.881821+00:00, run_end_date=2026-02-13 16:06:11.256517+00:00, run_duration=0.374696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=101, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 16:06:04.576236+00:00, queued_by_job_id=98, pid=8431
2026-02-14 00:06:14,399 INFO - Marking run <DagRun consumer_xcom2 @ 2026-02-13 16:06:01.114736+00:00: dataset_triggered__2026-02-13T16:06:01.114736+00:00, state:running, queued_at: 2026-02-13 16:06:04.530766+00:00. externally triggered: False> successful
2026-02-14 00:06:14,400 INFO - DagRun Finished: dag_id=consumer_xcom2, execution_date=2026-02-13 16:06:01.114736+00:00, run_id=dataset_triggered__2026-02-13T16:06:01.114736+00:00, run_start_date=2026-02-13 16:06:04.545102+00:00, run_end_date=2026-02-13 16:06:14.400651+00:00, run_duration=9.855549, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 16:05:55.895216+00:00, data_interval_end=2026-02-13 16:05:55.895216+00:00, dag_hash=18e83b8aaf201b23343a6d45144041ed
2026-02-14 00:06:14,405 INFO - Marking run <DagRun consumer_xcom1 @ 2026-02-13 16:06:01.116213+00:00: dataset_triggered__2026-02-13T16:06:01.116213+00:00, state:running, queued_at: 2026-02-13 16:06:04.518235+00:00. externally triggered: False> successful
2026-02-14 00:06:14,406 INFO - DagRun Finished: dag_id=consumer_xcom1, execution_date=2026-02-13 16:06:01.116213+00:00, run_id=dataset_triggered__2026-02-13T16:06:01.116213+00:00, run_start_date=2026-02-13 16:06:04.545210+00:00, run_end_date=2026-02-13 16:06:14.406239+00:00, run_duration=9.861029, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 16:05:55.895216+00:00, data_interval_end=2026-02-13 16:05:55.895216+00:00, dag_hash=5e2a1ff8e090009575648e79d38671d9
2026-02-14 00:10:13,490 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 00:15:13,529 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 00:20:13,567 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 00:25:15,945 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 00:25:19,569 INFO - 1 tasks up for execution:
	<TaskInstance: producer_DIPOA_dw_order_raw_sync.sync_raw_order_data manual__2026-02-13T16:25:15.518091+00:00 [scheduled]>
2026-02-14 00:25:19,570 INFO - DAG producer_DIPOA_dw_order_raw_sync has 0/16 running and queued tasks
2026-02-14 00:25:19,570 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_DIPOA_dw_order_raw_sync.sync_raw_order_data manual__2026-02-13T16:25:15.518091+00:00 [scheduled]>
2026-02-14 00:25:19,573 INFO - Trying to enqueue tasks: [<TaskInstance: producer_DIPOA_dw_order_raw_sync.sync_raw_order_data manual__2026-02-13T16:25:15.518091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:25:19,574 INFO - Sending TaskInstanceKey(dag_id='producer_DIPOA_dw_order_raw_sync', task_id='sync_raw_order_data', run_id='manual__2026-02-13T16:25:15.518091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 00:25:19,574 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_DIPOA_dw_order_raw_sync', 'sync_raw_order_data', 'manual__2026-02-13T16:25:15.518091+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_DIPOA.py']
2026-02-14 00:25:19,577 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_DIPOA_dw_order_raw_sync', 'sync_raw_order_data', 'manual__2026-02-13T16:25:15.518091+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_DIPOA.py']
2026-02-14 00:25:23,379 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_DIPOA_dw_order_raw_sync', task_id='sync_raw_order_data', run_id='manual__2026-02-13T16:25:15.518091+00:00', try_number=1, map_index=-1)
2026-02-14 00:25:23,390 INFO - TaskInstance Finished: dag_id=producer_DIPOA_dw_order_raw_sync, task_id=sync_raw_order_data, run_id=manual__2026-02-13T16:25:15.518091+00:00, map_index=-1, run_start_date=2026-02-13 16:25:22.386615+00:00, run_end_date=2026-02-13 16:25:22.769273+00:00, run_duration=0.382658, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=102, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 16:25:19.571822+00:00, queued_by_job_id=98, pid=8989
2026-02-14 00:25:25,975 INFO - Marking run <DagRun producer_DIPOA_dw_order_raw_sync @ 2026-02-13 16:25:15.518091+00:00: manual__2026-02-13T16:25:15.518091+00:00, state:running, queued_at: 2026-02-13 16:25:15.533854+00:00. externally triggered: True> successful
2026-02-14 00:25:25,977 INFO - DagRun Finished: dag_id=producer_DIPOA_dw_order_raw_sync, execution_date=2026-02-13 16:25:15.518091+00:00, run_id=manual__2026-02-13T16:25:15.518091+00:00, run_start_date=2026-02-13 16:25:19.549371+00:00, run_end_date=2026-02-13 16:25:25.976934+00:00, run_duration=6.427563, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-13 16:25:15.518091+00:00, data_interval_end=2026-02-13 16:25:15.518091+00:00, dag_hash=24391711b5e16fd626025bfde1dadd75
2026-02-14 00:25:25,986 INFO - 1 tasks up for execution:
	<TaskInstance: consumer1_order_clean.clean_order_data dataset_triggered__2026-02-13T16:25:22.789030+00:00 [scheduled]>
2026-02-14 00:25:25,987 INFO - DAG consumer1_order_clean has 0/16 running and queued tasks
2026-02-14 00:25:25,987 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer1_order_clean.clean_order_data dataset_triggered__2026-02-13T16:25:22.789030+00:00 [scheduled]>
2026-02-14 00:25:25,990 INFO - Trying to enqueue tasks: [<TaskInstance: consumer1_order_clean.clean_order_data dataset_triggered__2026-02-13T16:25:22.789030+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:25:25,991 INFO - Sending TaskInstanceKey(dag_id='consumer1_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T16:25:22.789030+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 00:25:25,992 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer1_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T16:25:22.789030+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_DIPOA.py']
2026-02-14 00:25:25,994 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer1_order_clean', 'clean_order_data', 'dataset_triggered__2026-02-13T16:25:22.789030+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_DIPOA.py']
2026-02-14 00:25:29,627 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer1_order_clean', task_id='clean_order_data', run_id='dataset_triggered__2026-02-13T16:25:22.789030+00:00', try_number=1, map_index=-1)
2026-02-14 00:25:29,638 INFO - TaskInstance Finished: dag_id=consumer1_order_clean, task_id=clean_order_data, run_id=dataset_triggered__2026-02-13T16:25:22.789030+00:00, map_index=-1, run_start_date=2026-02-13 16:25:28.594463+00:00, run_end_date=2026-02-13 16:25:28.990966+00:00, run_duration=0.396503, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=103, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 16:25:25.988916+00:00, queued_by_job_id=98, pid=8992
2026-02-14 00:25:32,110 INFO - Marking run <DagRun consumer1_order_clean @ 2026-02-13 16:25:22.789030+00:00: dataset_triggered__2026-02-13T16:25:22.789030+00:00, state:running, queued_at: 2026-02-13 16:25:25.946870+00:00. externally triggered: False> successful
2026-02-14 00:25:32,111 INFO - DagRun Finished: dag_id=consumer1_order_clean, execution_date=2026-02-13 16:25:22.789030+00:00, run_id=dataset_triggered__2026-02-13T16:25:22.789030+00:00, run_start_date=2026-02-13 16:25:25.963573+00:00, run_end_date=2026-02-13 16:25:32.111196+00:00, run_duration=6.147623, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 16:25:15.518091+00:00, data_interval_end=2026-02-13 16:25:15.518091+00:00, dag_hash=3829db3dbf828c470c9a060bc9bfe7f1
2026-02-14 00:25:32,120 INFO - 1 tasks up for execution:
	<TaskInstance: consumer2_order_stat.stat_order_data dataset_triggered__2026-02-13T16:25:29.009309+00:00 [scheduled]>
2026-02-14 00:25:32,121 INFO - DAG consumer2_order_stat has 0/16 running and queued tasks
2026-02-14 00:25:32,122 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer2_order_stat.stat_order_data dataset_triggered__2026-02-13T16:25:29.009309+00:00 [scheduled]>
2026-02-14 00:25:32,124 INFO - Trying to enqueue tasks: [<TaskInstance: consumer2_order_stat.stat_order_data dataset_triggered__2026-02-13T16:25:29.009309+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 00:25:32,126 INFO - Sending TaskInstanceKey(dag_id='consumer2_order_stat', task_id='stat_order_data', run_id='dataset_triggered__2026-02-13T16:25:29.009309+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 00:25:32,126 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer2_order_stat', 'stat_order_data', 'dataset_triggered__2026-02-13T16:25:29.009309+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_DIPOA.py']
2026-02-14 00:25:32,129 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer2_order_stat', 'stat_order_data', 'dataset_triggered__2026-02-13T16:25:29.009309+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_DIPOA.py']
2026-02-14 00:25:35,745 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer2_order_stat', task_id='stat_order_data', run_id='dataset_triggered__2026-02-13T16:25:29.009309+00:00', try_number=1, map_index=-1)
2026-02-14 00:25:35,757 INFO - TaskInstance Finished: dag_id=consumer2_order_stat, task_id=stat_order_data, run_id=dataset_triggered__2026-02-13T16:25:29.009309+00:00, map_index=-1, run_start_date=2026-02-13 16:25:34.752886+00:00, run_end_date=2026-02-13 16:25:35.142861+00:00, run_duration=0.389975, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=104, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-13 16:25:32.123201+00:00, queued_by_job_id=98, pid=8995
2026-02-14 00:25:38,337 INFO - Marking run <DagRun consumer2_order_stat @ 2026-02-13 16:25:29.009309+00:00: dataset_triggered__2026-02-13T16:25:29.009309+00:00, state:running, queued_at: 2026-02-13 16:25:32.084110+00:00. externally triggered: False> successful
2026-02-14 00:25:38,338 INFO - DagRun Finished: dag_id=consumer2_order_stat, execution_date=2026-02-13 16:25:29.009309+00:00, run_id=dataset_triggered__2026-02-13T16:25:29.009309+00:00, run_start_date=2026-02-13 16:25:32.096788+00:00, run_end_date=2026-02-13 16:25:38.338114+00:00, run_duration=6.241326, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-13 16:25:15.518091+00:00, data_interval_end=2026-02-13 16:25:15.518091+00:00, dag_hash=366c5b167887ebcb721d4da129564e00
2026-02-14 00:30:18,234 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 00:34:04,027 INFO - Exiting gracefully upon receiving signal 15
2026-02-14 00:34:05,035 INFO - Sending Signals.SIGTERM to group 8376. PIDs of all processes in the group: [8376]
2026-02-14 00:34:05,038 INFO - Sending the signal Signals.SIGTERM to group 8376
2026-02-14 00:34:05,099 INFO - Process psutil.Process(pid=8376, status='terminated', exitcode=<Negsignal.SIGTERM: -15>, started='00:05:11') (8376) terminated with exit code Negsignal.SIGTERM
2026-02-14 00:34:05,105 INFO - Sending Signals.SIGTERM to group 8376. PIDs of all processes in the group: []
2026-02-14 00:34:05,107 INFO - Sending the signal Signals.SIGTERM to group 8376
2026-02-14 00:34:05,108 INFO - Sending the signal Signals.SIGTERM to process 8376 as process group is missing.
2026-02-14 00:34:05,109 INFO - Exited execute loop
2026-02-14 11:07:57,862 INFO - Loaded executor: SequentialExecutor
2026-02-14 11:07:58,408 INFO - Starting the scheduler
2026-02-14 11:07:58,409 INFO - Processing each file at most -1 times
2026-02-14 11:07:58,416 INFO - Launched DagFileProcessorManager with pid: 1047
2026-02-14 11:07:58,420 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:13:00,155 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:18:00,182 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:23:00,301 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:28:00,470 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:32:47,572 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-14T03:32:46.003371+00:00 [scheduled]>
2026-02-14 11:32:47,573 INFO - DAG producer_1_N_sync has 0/16 running and queued tasks
2026-02-14 11:32:47,574 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-14T03:32:46.003371+00:00 [scheduled]>
2026-02-14 11:32:47,577 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-14T03:32:46.003371+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:32:47,577 INFO - Sending TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-14T03:32:46.003371+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:32:47,578 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-14T03:32:46.003371+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-14 11:32:47,581 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-14T03:32:46.003371+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-14 11:32:51,778 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-14T03:32:46.003371+00:00', try_number=1, map_index=-1)
2026-02-14 11:32:51,791 INFO - TaskInstance Finished: dag_id=producer_1_N_sync, task_id=producer_1_N_save_data, run_id=manual__2026-02-14T03:32:46.003371+00:00, map_index=-1, run_start_date=2026-02-14 03:32:50.698525+00:00, run_end_date=2026-02-14 03:32:51.091467+00:00, run_duration=0.392942, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:32:47.575365+00:00, queued_by_job_id=105, pid=2428
2026-02-14 11:32:54,743 INFO - Marking run <DagRun producer_1_N_sync @ 2026-02-14 03:32:46.003371+00:00: manual__2026-02-14T03:32:46.003371+00:00, state:running, queued_at: 2026-02-14 03:32:46.030701+00:00. externally triggered: True> successful
2026-02-14 11:32:54,745 INFO - DagRun Finished: dag_id=producer_1_N_sync, execution_date=2026-02-14 03:32:46.003371+00:00, run_id=manual__2026-02-14T03:32:46.003371+00:00, run_start_date=2026-02-14 03:32:47.531979+00:00, run_end_date=2026-02-14 03:32:54.745296+00:00, run_duration=7.213317, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 03:32:46.003371+00:00, data_interval_end=2026-02-14 03:32:46.003371+00:00, dag_hash=9c94ea8be6439fe2a4c875752cf2dfbb
2026-02-14 11:32:54,756 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-14T03:32:51.110002+00:00 [scheduled]>
	<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-14T03:32:51.112812+00:00 [scheduled]>
2026-02-14 11:32:54,757 INFO - DAG consumer_1_N_stat_order_data has 0/16 running and queued tasks
2026-02-14 11:32:54,757 INFO - DAG consumer_1_N_clean_order_data has 0/16 running and queued tasks
2026-02-14 11:32:54,758 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-14T03:32:51.110002+00:00 [scheduled]>
	<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-14T03:32:51.112812+00:00 [scheduled]>
2026-02-14 11:32:54,762 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-14T03:32:51.110002+00:00 [scheduled]>, <TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-14T03:32:51.112812+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:32:54,763 INFO - Sending TaskInstanceKey(dag_id='consumer_1_N_stat_order_data', task_id='consumer_1_N_read_stat_order_data', run_id='dataset_triggered__2026-02-14T03:32:51.110002+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:32:54,763 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1_N_stat_order_data', 'consumer_1_N_read_stat_order_data', 'dataset_triggered__2026-02-14T03:32:51.110002+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-14 11:32:54,764 INFO - Sending TaskInstanceKey(dag_id='consumer_1_N_clean_order_data', task_id='consumer_1_N_read_clean_order_data', run_id='dataset_triggered__2026-02-14T03:32:51.112812+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:32:54,765 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_data', 'consumer_1_N_read_clean_order_data', 'dataset_triggered__2026-02-14T03:32:51.112812+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-14 11:32:54,767 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1_N_stat_order_data', 'consumer_1_N_read_stat_order_data', 'dataset_triggered__2026-02-14T03:32:51.110002+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-14 11:32:58,392 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_data', 'consumer_1_N_read_clean_order_data', 'dataset_triggered__2026-02-14T03:32:51.112812+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-14 11:33:02,475 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1_N_stat_order_data', task_id='consumer_1_N_read_stat_order_data', run_id='dataset_triggered__2026-02-14T03:32:51.110002+00:00', try_number=1, map_index=-1)
2026-02-14 11:33:02,477 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1_N_clean_order_data', task_id='consumer_1_N_read_clean_order_data', run_id='dataset_triggered__2026-02-14T03:32:51.112812+00:00', try_number=1, map_index=-1)
2026-02-14 11:33:02,491 INFO - TaskInstance Finished: dag_id=consumer_1_N_stat_order_data, task_id=consumer_1_N_read_stat_order_data, run_id=dataset_triggered__2026-02-14T03:32:51.110002+00:00, map_index=-1, run_start_date=2026-02-14 03:32:57.388387+00:00, run_end_date=2026-02-14 03:32:57.754514+00:00, run_duration=0.366127, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=107, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:32:54.760069+00:00, queued_by_job_id=105, pid=2432
2026-02-14 11:33:02,492 INFO - TaskInstance Finished: dag_id=consumer_1_N_clean_order_data, task_id=consumer_1_N_read_clean_order_data, run_id=dataset_triggered__2026-02-14T03:32:51.112812+00:00, map_index=-1, run_start_date=2026-02-14 03:33:01.472039+00:00, run_end_date=2026-02-14 03:33:01.863441+00:00, run_duration=0.391402, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=108, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:32:54.760069+00:00, queued_by_job_id=105, pid=2437
2026-02-14 11:33:02,523 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:33:05,158 INFO - Marking run <DagRun consumer_1_N_stat_order_data @ 2026-02-14 03:32:51.110002+00:00: dataset_triggered__2026-02-14T03:32:51.110002+00:00, state:running, queued_at: 2026-02-14 03:32:54.715732+00:00. externally triggered: False> successful
2026-02-14 11:33:05,159 INFO - DagRun Finished: dag_id=consumer_1_N_stat_order_data, execution_date=2026-02-14 03:32:51.110002+00:00, run_id=dataset_triggered__2026-02-14T03:32:51.110002+00:00, run_start_date=2026-02-14 03:32:54.727529+00:00, run_end_date=2026-02-14 03:33:05.158995+00:00, run_duration=10.431466, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-14 03:32:46.003371+00:00, data_interval_end=2026-02-14 03:32:46.003371+00:00, dag_hash=94f55b14533c43cd663b6f903564f319
2026-02-14 11:33:05,164 INFO - Marking run <DagRun consumer_1_N_clean_order_data @ 2026-02-14 03:32:51.112812+00:00: dataset_triggered__2026-02-14T03:32:51.112812+00:00, state:running, queued_at: 2026-02-14 03:32:54.699044+00:00. externally triggered: False> successful
2026-02-14 11:33:05,165 INFO - DagRun Finished: dag_id=consumer_1_N_clean_order_data, execution_date=2026-02-14 03:32:51.112812+00:00, run_id=dataset_triggered__2026-02-14T03:32:51.112812+00:00, run_start_date=2026-02-14 03:32:54.727628+00:00, run_end_date=2026-02-14 03:33:05.165330+00:00, run_duration=10.437702, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-14 03:32:46.003371+00:00, data_interval_end=2026-02-14 03:32:46.003371+00:00, dag_hash=c61c84e3308591cb31098ffc7795ade0
2026-02-14 11:36:03,831 INFO - 1 tasks up for execution:
	<TaskInstance: producer_N_1_dw_order_sync.sync_order_data manual__2026-02-14T03:36:00.776536+00:00 [scheduled]>
2026-02-14 11:36:03,832 INFO - DAG producer_N_1_dw_order_sync has 0/16 running and queued tasks
2026-02-14 11:36:03,832 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_N_1_dw_order_sync.sync_order_data manual__2026-02-14T03:36:00.776536+00:00 [scheduled]>
2026-02-14 11:36:03,835 INFO - Trying to enqueue tasks: [<TaskInstance: producer_N_1_dw_order_sync.sync_order_data manual__2026-02-14T03:36:00.776536+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:36:03,836 INFO - Sending TaskInstanceKey(dag_id='producer_N_1_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-14T03:36:00.776536+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:36:03,836 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_N_1_dw_order_sync', 'sync_order_data', 'manual__2026-02-14T03:36:00.776536+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:36:03,839 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_N_1_dw_order_sync', 'sync_order_data', 'manual__2026-02-14T03:36:00.776536+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:36:07,738 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_N_1_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-14T03:36:00.776536+00:00', try_number=1, map_index=-1)
2026-02-14 11:36:07,752 INFO - TaskInstance Finished: dag_id=producer_N_1_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-14T03:36:00.776536+00:00, map_index=-1, run_start_date=2026-02-14 03:36:06.815869+00:00, run_end_date=2026-02-14 03:36:07.204195+00:00, run_duration=0.388326, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=109, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:36:03.833916+00:00, queued_by_job_id=105, pid=2607
2026-02-14 11:36:10,397 INFO - Marking run <DagRun producer_N_1_dw_order_sync @ 2026-02-14 03:36:00.776536+00:00: manual__2026-02-14T03:36:00.776536+00:00, state:running, queued_at: 2026-02-14 03:36:00.799507+00:00. externally triggered: True> successful
2026-02-14 11:36:10,398 INFO - DagRun Finished: dag_id=producer_N_1_dw_order_sync, execution_date=2026-02-14 03:36:00.776536+00:00, run_id=manual__2026-02-14T03:36:00.776536+00:00, run_start_date=2026-02-14 03:36:03.811605+00:00, run_end_date=2026-02-14 03:36:10.398453+00:00, run_duration=6.586848, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 03:36:00.776536+00:00, data_interval_end=2026-02-14 03:36:00.776536+00:00, dag_hash=c52fa1a388ba1be81c6c42bf2d418436
2026-02-14 11:36:24,211 INFO - 1 tasks up for execution:
	<TaskInstance: producer_N_1_dw_user_sync.sync_user_data manual__2026-02-14T03:36:20.021965+00:00 [scheduled]>
2026-02-14 11:36:24,213 INFO - DAG producer_N_1_dw_user_sync has 0/16 running and queued tasks
2026-02-14 11:36:24,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_N_1_dw_user_sync.sync_user_data manual__2026-02-14T03:36:20.021965+00:00 [scheduled]>
2026-02-14 11:36:24,216 INFO - Trying to enqueue tasks: [<TaskInstance: producer_N_1_dw_user_sync.sync_user_data manual__2026-02-14T03:36:20.021965+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:36:24,217 INFO - Sending TaskInstanceKey(dag_id='producer_N_1_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-14T03:36:20.021965+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:36:24,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_N_1_dw_user_sync', 'sync_user_data', 'manual__2026-02-14T03:36:20.021965+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:36:24,220 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_N_1_dw_user_sync', 'sync_user_data', 'manual__2026-02-14T03:36:20.021965+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:36:28,110 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_N_1_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-14T03:36:20.021965+00:00', try_number=1, map_index=-1)
2026-02-14 11:36:28,123 INFO - TaskInstance Finished: dag_id=producer_N_1_dw_user_sync, task_id=sync_user_data, run_id=manual__2026-02-14T03:36:20.021965+00:00, map_index=-1, run_start_date=2026-02-14 03:36:27.111353+00:00, run_end_date=2026-02-14 03:36:27.495680+00:00, run_duration=0.384327, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:36:24.214954+00:00, queued_by_job_id=105, pid=2616
2026-02-14 11:36:30,604 INFO - Marking run <DagRun producer_N_1_dw_user_sync @ 2026-02-14 03:36:20.021965+00:00: manual__2026-02-14T03:36:20.021965+00:00, state:running, queued_at: 2026-02-14 03:36:20.035784+00:00. externally triggered: True> successful
2026-02-14 11:36:30,605 INFO - DagRun Finished: dag_id=producer_N_1_dw_user_sync, execution_date=2026-02-14 03:36:20.021965+00:00, run_id=manual__2026-02-14T03:36:20.021965+00:00, run_start_date=2026-02-14 03:36:24.193164+00:00, run_end_date=2026-02-14 03:36:30.605369+00:00, run_duration=6.412205, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 03:36:20.021965+00:00, data_interval_end=2026-02-14 03:36:20.021965+00:00, dag_hash=f21aec43673b2c968a2fc26e9e7f5cea
2026-02-14 11:36:30,614 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_N_1_order_user_analysis.analyze_order_user dataset_triggered__2026-02-14T03:36:27.516973+00:00 [scheduled]>
2026-02-14 11:36:30,615 INFO - DAG consumer_N_1_order_user_analysis has 0/16 running and queued tasks
2026-02-14 11:36:30,615 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_N_1_order_user_analysis.analyze_order_user dataset_triggered__2026-02-14T03:36:27.516973+00:00 [scheduled]>
2026-02-14 11:36:30,618 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_N_1_order_user_analysis.analyze_order_user dataset_triggered__2026-02-14T03:36:27.516973+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:36:30,619 INFO - Sending TaskInstanceKey(dag_id='consumer_N_1_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-14T03:36:27.516973+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:36:30,619 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_N_1_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-14T03:36:27.516973+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:36:30,622 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_N_1_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-14T03:36:27.516973+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:36:34,161 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_N_1_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-14T03:36:27.516973+00:00', try_number=1, map_index=-1)
2026-02-14 11:36:34,171 INFO - TaskInstance Finished: dag_id=consumer_N_1_order_user_analysis, task_id=analyze_order_user, run_id=dataset_triggered__2026-02-14T03:36:27.516973+00:00, map_index=-1, run_start_date=2026-02-14 03:36:33.250171+00:00, run_end_date=2026-02-14 03:36:33.631813+00:00, run_duration=0.381642, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:36:30.616775+00:00, queued_by_job_id=105, pid=2620
2026-02-14 11:36:36,612 ERROR - Marking run <DagRun consumer_N_1_order_user_analysis @ 2026-02-14 03:36:27.516973+00:00: dataset_triggered__2026-02-14T03:36:27.516973+00:00, state:running, queued_at: 2026-02-14 03:36:30.577081+00:00. externally triggered: False> failed
2026-02-14 11:36:36,613 INFO - DagRun Finished: dag_id=consumer_N_1_order_user_analysis, execution_date=2026-02-14 03:36:27.516973+00:00, run_id=dataset_triggered__2026-02-14T03:36:27.516973+00:00, run_start_date=2026-02-14 03:36:30.591444+00:00, run_end_date=2026-02-14 03:36:36.613428+00:00, run_duration=6.021984, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-14 03:36:00.776536+00:00, data_interval_end=2026-02-14 03:36:20.021965+00:00, dag_hash=6baf9b26ce8f026143cfbb65a8bc4568
2026-02-14 11:38:03,284 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:38:57,771 INFO - 1 tasks up for execution:
	<TaskInstance: producer_N_1_dw_order_sync.sync_order_data manual__2026-02-14T03:38:53.631710+00:00 [scheduled]>
2026-02-14 11:38:57,772 INFO - DAG producer_N_1_dw_order_sync has 0/16 running and queued tasks
2026-02-14 11:38:57,773 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_N_1_dw_order_sync.sync_order_data manual__2026-02-14T03:38:53.631710+00:00 [scheduled]>
2026-02-14 11:38:57,777 INFO - Trying to enqueue tasks: [<TaskInstance: producer_N_1_dw_order_sync.sync_order_data manual__2026-02-14T03:38:53.631710+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:38:57,778 INFO - Sending TaskInstanceKey(dag_id='producer_N_1_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-14T03:38:53.631710+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:38:57,779 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_N_1_dw_order_sync', 'sync_order_data', 'manual__2026-02-14T03:38:53.631710+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:38:57,782 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_N_1_dw_order_sync', 'sync_order_data', 'manual__2026-02-14T03:38:53.631710+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:39:02,244 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_N_1_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-14T03:38:53.631710+00:00', try_number=1, map_index=-1)
2026-02-14 11:39:02,255 INFO - TaskInstance Finished: dag_id=producer_N_1_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-14T03:38:53.631710+00:00, map_index=-1, run_start_date=2026-02-14 03:39:01.278348+00:00, run_end_date=2026-02-14 03:39:01.646406+00:00, run_duration=0.368058, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:38:57.775611+00:00, queued_by_job_id=105, pid=2724
2026-02-14 11:39:04,761 INFO - Marking run <DagRun producer_N_1_dw_order_sync @ 2026-02-14 03:38:53.631710+00:00: manual__2026-02-14T03:38:53.631710+00:00, state:running, queued_at: 2026-02-14 03:38:53.643631+00:00. externally triggered: True> successful
2026-02-14 11:39:04,762 INFO - DagRun Finished: dag_id=producer_N_1_dw_order_sync, execution_date=2026-02-14 03:38:53.631710+00:00, run_id=manual__2026-02-14T03:38:53.631710+00:00, run_start_date=2026-02-14 03:38:57.749214+00:00, run_end_date=2026-02-14 03:39:04.762095+00:00, run_duration=7.012881, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 03:38:53.631710+00:00, data_interval_end=2026-02-14 03:38:53.631710+00:00, dag_hash=c52fa1a388ba1be81c6c42bf2d418436
2026-02-14 11:39:04,771 INFO - 1 tasks up for execution:
	<TaskInstance: producer_N_1_dw_user_sync.sync_user_data manual__2026-02-14T03:38:57.131057+00:00 [scheduled]>
2026-02-14 11:39:04,772 INFO - DAG producer_N_1_dw_user_sync has 0/16 running and queued tasks
2026-02-14 11:39:04,773 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_N_1_dw_user_sync.sync_user_data manual__2026-02-14T03:38:57.131057+00:00 [scheduled]>
2026-02-14 11:39:04,775 INFO - Trying to enqueue tasks: [<TaskInstance: producer_N_1_dw_user_sync.sync_user_data manual__2026-02-14T03:38:57.131057+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:39:04,777 INFO - Sending TaskInstanceKey(dag_id='producer_N_1_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-14T03:38:57.131057+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:39:04,778 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_N_1_dw_user_sync', 'sync_user_data', 'manual__2026-02-14T03:38:57.131057+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:39:04,780 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_N_1_dw_user_sync', 'sync_user_data', 'manual__2026-02-14T03:38:57.131057+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:39:08,354 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_N_1_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-14T03:38:57.131057+00:00', try_number=1, map_index=-1)
2026-02-14 11:39:08,364 INFO - TaskInstance Finished: dag_id=producer_N_1_dw_user_sync, task_id=sync_user_data, run_id=manual__2026-02-14T03:38:57.131057+00:00, map_index=-1, run_start_date=2026-02-14 03:39:07.398305+00:00, run_end_date=2026-02-14 03:39:07.752752+00:00, run_duration=0.354447, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:39:04.774486+00:00, queued_by_job_id=105, pid=2732
2026-02-14 11:39:10,872 INFO - Marking run <DagRun producer_N_1_dw_user_sync @ 2026-02-14 03:38:57.131057+00:00: manual__2026-02-14T03:38:57.131057+00:00, state:running, queued_at: 2026-02-14 03:38:57.144678+00:00. externally triggered: True> successful
2026-02-14 11:39:10,873 INFO - DagRun Finished: dag_id=producer_N_1_dw_user_sync, execution_date=2026-02-14 03:38:57.131057+00:00, run_id=manual__2026-02-14T03:38:57.131057+00:00, run_start_date=2026-02-14 03:39:04.743265+00:00, run_end_date=2026-02-14 03:39:10.873656+00:00, run_duration=6.130391, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 03:38:57.131057+00:00, data_interval_end=2026-02-14 03:38:57.131057+00:00, dag_hash=f21aec43673b2c968a2fc26e9e7f5cea
2026-02-14 11:39:10,884 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_N_1_order_user_analysis.analyze_order_user dataset_triggered__2026-02-14T03:39:07.770729+00:00 [scheduled]>
2026-02-14 11:39:10,885 INFO - DAG consumer_N_1_order_user_analysis has 0/16 running and queued tasks
2026-02-14 11:39:10,886 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_N_1_order_user_analysis.analyze_order_user dataset_triggered__2026-02-14T03:39:07.770729+00:00 [scheduled]>
2026-02-14 11:39:10,888 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_N_1_order_user_analysis.analyze_order_user dataset_triggered__2026-02-14T03:39:07.770729+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 11:39:10,890 INFO - Sending TaskInstanceKey(dag_id='consumer_N_1_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-14T03:39:07.770729+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-14 11:39:10,890 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_N_1_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-14T03:39:07.770729+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:39:10,894 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_N_1_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-14T03:39:07.770729+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /N_producer_1_consumer.py']
2026-02-14 11:39:14,462 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_N_1_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-14T03:39:07.770729+00:00', try_number=1, map_index=-1)
2026-02-14 11:39:14,473 INFO - TaskInstance Finished: dag_id=consumer_N_1_order_user_analysis, task_id=analyze_order_user, run_id=dataset_triggered__2026-02-14T03:39:07.770729+00:00, map_index=-1, run_start_date=2026-02-14 03:39:13.505551+00:00, run_end_date=2026-02-14 03:39:13.874952+00:00, run_duration=0.369401, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-14 03:39:10.887510+00:00, queued_by_job_id=105, pid=2736
2026-02-14 11:39:17,035 INFO - Marking run <DagRun consumer_N_1_order_user_analysis @ 2026-02-14 03:39:07.770729+00:00: dataset_triggered__2026-02-14T03:39:07.770729+00:00, state:running, queued_at: 2026-02-14 03:39:10.836944+00:00. externally triggered: False> successful
2026-02-14 11:39:17,036 INFO - DagRun Finished: dag_id=consumer_N_1_order_user_analysis, execution_date=2026-02-14 03:39:07.770729+00:00, run_id=dataset_triggered__2026-02-14T03:39:07.770729+00:00, run_start_date=2026-02-14 03:39:10.858349+00:00, run_end_date=2026-02-14 03:39:17.036580+00:00, run_duration=6.178231, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-14 03:38:53.631710+00:00, data_interval_end=2026-02-14 03:38:57.131057+00:00, dag_hash=6baf9b26ce8f026143cfbb65a8bc4568
2026-02-14 11:43:05,661 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:49:34,163 INFO - Heartbeat recovered after 255.48 seconds
2026-02-14 11:52:16,522 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 11:57:19,028 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:02:19,963 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:07:21,610 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:12:21,762 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:17:21,998 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:22:22,287 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:27:24,316 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:32:26,676 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:44:02,216 INFO - Heartbeat recovered after 568.58 seconds
2026-02-14 12:48:32,153 INFO - Heartbeat recovered after 234.68 seconds
2026-02-14 12:50:41,958 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 12:55:43,868 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 13:01:11,138 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 13:06:15,550 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 13:09:12,928 INFO - Setting next_dagrun for branch_task_data_quality to 2026-02-14 05:00:00+00:00, run_after=2026-02-14 06:00:00+00:00
2026-02-14 13:09:16,251 INFO - 1 tasks up for execution:
	<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T04:00:00+00:00 [scheduled]>
2026-02-14 13:09:16,253 INFO - DAG branch_task_data_quality has 0/16 running and queued tasks
2026-02-14 13:09:16,254 INFO - Setting the following tasks to queued state:
	<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T04:00:00+00:00 [scheduled]>
2026-02-14 13:09:16,257 INFO - Trying to enqueue tasks: [<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T04:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 13:09:16,258 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='scheduled__2026-02-14T04:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-14 13:09:16,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'scheduled__2026-02-14T04:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:16,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'scheduled__2026-02-14T04:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:20,291 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='scheduled__2026-02-14T04:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 13:09:20,301 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=branch_check_quality, run_id=scheduled__2026-02-14T04:00:00+00:00, map_index=-1, run_start_date=2026-02-14 05:09:19.313693+00:00, run_end_date=2026-02-14 05:09:19.708239+00:00, run_duration=0.394546, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=115, pool=default_pool, queue=default, priority_weight=5, operator=BranchPythonOperator, queued_dttm=2026-02-14 05:09:16.255557+00:00, queued_by_job_id=105, pid=5146
2026-02-14 13:09:23,142 INFO - 1 tasks up for execution:
	<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T04:00:00+00:00 [scheduled]>
2026-02-14 13:09:23,143 INFO - DAG branch_task_data_quality has 0/16 running and queued tasks
2026-02-14 13:09:23,143 INFO - Setting the following tasks to queued state:
	<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T04:00:00+00:00 [scheduled]>
2026-02-14 13:09:23,146 INFO - Trying to enqueue tasks: [<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T04:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 13:09:23,147 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='scheduled__2026-02-14T04:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-14 13:09:23,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'scheduled__2026-02-14T04:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:23,150 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'scheduled__2026-02-14T04:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:26,861 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='scheduled__2026-02-14T04:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 13:09:26,871 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=task_process_normal, run_id=scheduled__2026-02-14T04:00:00+00:00, map_index=-1, run_start_date=2026-02-14 05:09:25.932846+00:00, run_end_date=2026-02-14 05:09:26.284209+00:00, run_duration=0.351363, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=116, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-14 05:09:23.144899+00:00, queued_by_job_id=105, pid=5149
2026-02-14 13:09:29,730 INFO - 1 tasks up for execution:
	<TaskInstance: branch_task_data_quality.branch_check_quality manual__2026-02-14T05:09:16.552321+00:00 [scheduled]>
2026-02-14 13:09:29,731 INFO - DAG branch_task_data_quality has 0/16 running and queued tasks
2026-02-14 13:09:29,731 INFO - Setting the following tasks to queued state:
	<TaskInstance: branch_task_data_quality.branch_check_quality manual__2026-02-14T05:09:16.552321+00:00 [scheduled]>
2026-02-14 13:09:29,734 INFO - Trying to enqueue tasks: [<TaskInstance: branch_task_data_quality.branch_check_quality manual__2026-02-14T05:09:16.552321+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 13:09:29,735 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='manual__2026-02-14T05:09:16.552321+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-14 13:09:29,736 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'manual__2026-02-14T05:09:16.552321+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:29,738 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'manual__2026-02-14T05:09:16.552321+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:33,343 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='manual__2026-02-14T05:09:16.552321+00:00', try_number=1, map_index=-1)
2026-02-14 13:09:33,353 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=branch_check_quality, run_id=manual__2026-02-14T05:09:16.552321+00:00, map_index=-1, run_start_date=2026-02-14 05:09:32.398471+00:00, run_end_date=2026-02-14 05:09:32.757500+00:00, run_duration=0.359029, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=117, pool=default_pool, queue=default, priority_weight=5, operator=BranchPythonOperator, queued_dttm=2026-02-14 05:09:29.732802+00:00, queued_by_job_id=105, pid=5152
2026-02-14 13:09:36,117 INFO - Marking run <DagRun branch_task_data_quality @ 2026-02-14 04:00:00+00:00: scheduled__2026-02-14T04:00:00+00:00, state:running, queued_at: 2026-02-14 05:09:12.917691+00:00. externally triggered: False> successful
2026-02-14 13:09:36,119 INFO - DagRun Finished: dag_id=branch_task_data_quality, execution_date=2026-02-14 04:00:00+00:00, run_id=scheduled__2026-02-14T04:00:00+00:00, run_start_date=2026-02-14 05:09:12.942178+00:00, run_end_date=2026-02-14 05:09:36.119027+00:00, run_duration=23.176849, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-14 04:00:00+00:00, data_interval_end=2026-02-14 05:00:00+00:00, dag_hash=7306175be177de820215d4c99a20fe56
2026-02-14 13:09:36,126 INFO - Setting next_dagrun for branch_task_data_quality to 2026-02-14 05:00:00+00:00, run_after=2026-02-14 06:00:00+00:00
2026-02-14 13:09:36,139 INFO - 1 tasks up for execution:
	<TaskInstance: branch_task_data_quality.task_process_normal manual__2026-02-14T05:09:16.552321+00:00 [scheduled]>
2026-02-14 13:09:36,140 INFO - DAG branch_task_data_quality has 0/16 running and queued tasks
2026-02-14 13:09:36,140 INFO - Setting the following tasks to queued state:
	<TaskInstance: branch_task_data_quality.task_process_normal manual__2026-02-14T05:09:16.552321+00:00 [scheduled]>
2026-02-14 13:09:36,143 INFO - Trying to enqueue tasks: [<TaskInstance: branch_task_data_quality.task_process_normal manual__2026-02-14T05:09:16.552321+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 13:09:36,145 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='manual__2026-02-14T05:09:16.552321+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-14 13:09:36,145 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'manual__2026-02-14T05:09:16.552321+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:36,148 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'manual__2026-02-14T05:09:16.552321+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 13:09:39,699 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='manual__2026-02-14T05:09:16.552321+00:00', try_number=1, map_index=-1)
2026-02-14 13:09:39,710 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=task_process_normal, run_id=manual__2026-02-14T05:09:16.552321+00:00, map_index=-1, run_start_date=2026-02-14 05:09:38.799845+00:00, run_end_date=2026-02-14 05:09:39.154774+00:00, run_duration=0.354929, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=118, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-14 05:09:36.141855+00:00, queued_by_job_id=105, pid=5155
2026-02-14 13:09:46,088 INFO - Marking run <DagRun branch_task_data_quality @ 2026-02-14 05:09:16.552321+00:00: manual__2026-02-14T05:09:16.552321+00:00, state:running, queued_at: 2026-02-14 05:09:16.580469+00:00. externally triggered: True> successful
2026-02-14 13:09:46,089 INFO - DagRun Finished: dag_id=branch_task_data_quality, execution_date=2026-02-14 05:09:16.552321+00:00, run_id=manual__2026-02-14T05:09:16.552321+00:00, run_start_date=2026-02-14 05:09:23.107910+00:00, run_end_date=2026-02-14 05:09:46.089112+00:00, run_duration=22.981202, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 04:00:00+00:00, data_interval_end=2026-02-14 05:00:00+00:00, dag_hash=7306175be177de820215d4c99a20fe56
2026-02-14 13:11:18,109 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 13:16:19,692 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 13:18:39,036 INFO - Exiting gracefully upon receiving signal 15
2026-02-14 13:18:39,767 INFO - Sending Signals.SIGTERM to group 1047. PIDs of all processes in the group: []
2026-02-14 13:18:39,768 INFO - Sending the signal Signals.SIGTERM to group 1047
2026-02-14 13:18:39,769 INFO - Sending the signal Signals.SIGTERM to process 1047 as process group is missing.
2026-02-14 13:18:39,777 INFO - Sending Signals.SIGTERM to group 1047. PIDs of all processes in the group: []
2026-02-14 13:18:39,778 INFO - Sending the signal Signals.SIGTERM to group 1047
2026-02-14 13:18:39,778 INFO - Sending the signal Signals.SIGTERM to process 1047 as process group is missing.
2026-02-14 13:18:39,779 INFO - Exited execute loop
2026-02-14 19:33:33,041 INFO - Loaded executor: SequentialExecutor
2026-02-14 19:33:33,953 INFO - Starting the scheduler
2026-02-14 19:33:33,954 INFO - Processing each file at most -1 times
2026-02-14 19:33:33,964 INFO - Launched DagFileProcessorManager with pid: 2807
2026-02-14 19:33:33,973 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 19:33:44,002 INFO - Setting next_dagrun for branch_task_data_quality to 2026-02-14 10:00:00+00:00, run_after=2026-02-14 11:00:00+00:00
2026-02-14 19:33:49,857 INFO - Setting next_dagrun for branch_task_data_quality to 2026-02-14 11:00:00+00:00, run_after=2026-02-14 12:00:00+00:00
2026-02-14 19:33:49,915 INFO - 1 tasks up for execution:
	<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T05:00:00+00:00 [scheduled]>
2026-02-14 19:33:49,916 INFO - DAG branch_task_data_quality has 0/16 running and queued tasks
2026-02-14 19:33:49,917 INFO - Setting the following tasks to queued state:
	<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T05:00:00+00:00 [scheduled]>
2026-02-14 19:33:49,921 INFO - Trying to enqueue tasks: [<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T05:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 19:33:49,923 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='scheduled__2026-02-14T05:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-14 19:33:49,924 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'scheduled__2026-02-14T05:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:33:49,928 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'scheduled__2026-02-14T05:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:33:55,043 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='scheduled__2026-02-14T05:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 19:33:55,062 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=branch_check_quality, run_id=scheduled__2026-02-14T05:00:00+00:00, map_index=-1, run_start_date=2026-02-14 11:33:53.945767+00:00, run_end_date=2026-02-14 11:33:54.401521+00:00, run_duration=0.455754, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=120, pool=default_pool, queue=default, priority_weight=5, operator=BranchPythonOperator, queued_dttm=2026-02-14 11:33:49.919014+00:00, queued_by_job_id=119, pid=2840
2026-02-14 19:33:58,760 INFO - 2 tasks up for execution:
	<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T10:00:00+00:00 [scheduled]>
	<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T05:00:00+00:00 [scheduled]>
2026-02-14 19:33:58,761 INFO - DAG branch_task_data_quality has 0/16 running and queued tasks
2026-02-14 19:33:58,762 INFO - DAG branch_task_data_quality has 1/16 running and queued tasks
2026-02-14 19:33:58,763 INFO - Setting the following tasks to queued state:
	<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T10:00:00+00:00 [scheduled]>
	<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T05:00:00+00:00 [scheduled]>
2026-02-14 19:33:58,768 INFO - Trying to enqueue tasks: [<TaskInstance: branch_task_data_quality.branch_check_quality scheduled__2026-02-14T10:00:00+00:00 [scheduled]>, <TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T05:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 19:33:58,770 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='scheduled__2026-02-14T10:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-14 19:33:58,771 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'scheduled__2026-02-14T10:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:33:58,772 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='scheduled__2026-02-14T05:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-14 19:33:58,773 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'scheduled__2026-02-14T05:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:33:58,776 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'branch_check_quality', 'scheduled__2026-02-14T10:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:34:06,061 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'scheduled__2026-02-14T05:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:34:12,078 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='branch_check_quality', run_id='scheduled__2026-02-14T10:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 19:34:12,088 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='scheduled__2026-02-14T05:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 19:34:12,110 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=branch_check_quality, run_id=scheduled__2026-02-14T10:00:00+00:00, map_index=-1, run_start_date=2026-02-14 11:34:04.555732+00:00, run_end_date=2026-02-14 11:34:05.050239+00:00, run_duration=0.494507, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=121, pool=default_pool, queue=default, priority_weight=5, operator=BranchPythonOperator, queued_dttm=2026-02-14 11:33:58.765801+00:00, queued_by_job_id=119, pid=2857
2026-02-14 19:34:12,142 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=task_process_normal, run_id=scheduled__2026-02-14T05:00:00+00:00, map_index=-1, run_start_date=2026-02-14 11:34:10.670552+00:00, run_end_date=2026-02-14 11:34:11.270539+00:00, run_duration=0.599987, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=122, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-14 11:33:58.765801+00:00, queued_by_job_id=119, pid=2863
2026-02-14 19:34:16,955 INFO - 1 tasks up for execution:
	<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T10:00:00+00:00 [scheduled]>
2026-02-14 19:34:16,957 INFO - DAG branch_task_data_quality has 0/16 running and queued tasks
2026-02-14 19:34:16,958 INFO - Setting the following tasks to queued state:
	<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T10:00:00+00:00 [scheduled]>
2026-02-14 19:34:16,962 INFO - Trying to enqueue tasks: [<TaskInstance: branch_task_data_quality.task_process_normal scheduled__2026-02-14T10:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-14 19:34:16,964 INFO - Sending TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='scheduled__2026-02-14T10:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-14 19:34:16,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'scheduled__2026-02-14T10:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:34:16,969 INFO - Executing command: ['airflow', 'tasks', 'run', 'branch_task_data_quality', 'task_process_normal', 'scheduled__2026-02-14T10:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER//branchDAG.py']
2026-02-14 19:34:22,100 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='branch_task_data_quality', task_id='task_process_normal', run_id='scheduled__2026-02-14T10:00:00+00:00', try_number=1, map_index=-1)
2026-02-14 19:34:22,115 INFO - TaskInstance Finished: dag_id=branch_task_data_quality, task_id=task_process_normal, run_id=scheduled__2026-02-14T10:00:00+00:00, map_index=-1, run_start_date=2026-02-14 11:34:20.997576+00:00, run_end_date=2026-02-14 11:34:21.457591+00:00, run_duration=0.460015, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=123, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-14 11:34:16.960513+00:00, queued_by_job_id=119, pid=2881
2026-02-14 19:34:26,607 INFO - Marking run <DagRun branch_task_data_quality @ 2026-02-14 05:00:00+00:00: scheduled__2026-02-14T05:00:00+00:00, state:running, queued_at: 2026-02-14 11:33:43.966748+00:00. externally triggered: False> successful
2026-02-14 19:34:26,610 INFO - DagRun Finished: dag_id=branch_task_data_quality, execution_date=2026-02-14 05:00:00+00:00, run_id=scheduled__2026-02-14T05:00:00+00:00, run_start_date=2026-02-14 11:33:44.023914+00:00, run_end_date=2026-02-14 11:34:26.610385+00:00, run_duration=42.586471, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-14 05:00:00+00:00, data_interval_end=2026-02-14 06:00:00+00:00, dag_hash=7306175be177de820215d4c99a20fe56
2026-02-14 19:34:26,618 INFO - Setting next_dagrun for branch_task_data_quality to 2026-02-14 10:00:00+00:00, run_after=2026-02-14 11:00:00+00:00
2026-02-14 19:34:30,098 INFO - Setting next_dagrun for branch_task_data_quality to 2026-02-14 11:00:00+00:00, run_after=2026-02-14 12:00:00+00:00
2026-02-14 19:34:30,117 INFO - Marking run <DagRun branch_task_data_quality @ 2026-02-14 10:00:00+00:00: scheduled__2026-02-14T10:00:00+00:00, state:running, queued_at: 2026-02-14 11:33:49.846385+00:00. externally triggered: False> successful
2026-02-14 19:34:30,119 INFO - DagRun Finished: dag_id=branch_task_data_quality, execution_date=2026-02-14 10:00:00+00:00, run_id=scheduled__2026-02-14T10:00:00+00:00, run_start_date=2026-02-14 11:33:49.867999+00:00, run_end_date=2026-02-14 11:34:30.119234+00:00, run_duration=40.251235, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-14 10:00:00+00:00, data_interval_end=2026-02-14 11:00:00+00:00, dag_hash=7306175be177de820215d4c99a20fe56
2026-02-14 19:34:30,128 INFO - Setting next_dagrun for branch_task_data_quality to 2026-02-14 11:00:00+00:00, run_after=2026-02-14 12:00:00+00:00
2026-02-14 19:38:35,448 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 19:43:36,543 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 19:48:39,176 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 19:53:39,282 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 19:56:49,114 INFO - Marking run <DagRun producer_mysql_order_data @ 2026-02-14 11:56:46.825462+00:00: manual__2026-02-14T11:56:46.825462+00:00, state:running, queued_at: 2026-02-14 11:56:46.844695+00:00. externally triggered: True> successful
2026-02-14 19:56:49,116 INFO - DagRun Finished: dag_id=producer_mysql_order_data, execution_date=2026-02-14 11:56:46.825462+00:00, run_id=manual__2026-02-14T11:56:46.825462+00:00, run_start_date=2026-02-14 11:56:49.104174+00:00, run_end_date=2026-02-14 11:56:49.116144+00:00, run_duration=0.01197, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 11:56:46.825462+00:00, data_interval_end=2026-02-14 11:56:46.825462+00:00, dag_hash=2a678ab063ca21354030065030dcffdc
2026-02-14 19:58:39,309 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:03:41,016 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:08:14,152 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-14 12:08:12.052459+00:00: manual__2026-02-14T12:08:12.052459+00:00, state:running, queued_at: 2026-02-14 12:08:12.068867+00:00. externally triggered: True> successful
2026-02-14 20:08:14,154 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-14 12:08:12.052459+00:00, run_id=manual__2026-02-14T12:08:12.052459+00:00, run_start_date=2026-02-14 12:08:14.145698+00:00, run_end_date=2026-02-14 12:08:14.154553+00:00, run_duration=0.008855, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 12:08:12.052459+00:00, data_interval_end=2026-02-14 12:08:12.052459+00:00, dag_hash=964d20dddc21507f57e8633fe2e1e46a
2026-02-14 20:08:41,976 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:12:18,130 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-14 12:12:16.345549+00:00: manual__2026-02-14T12:12:16.345549+00:00, state:running, queued_at: 2026-02-14 12:12:16.358900+00:00. externally triggered: True> successful
2026-02-14 20:12:18,131 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-14 12:12:16.345549+00:00, run_id=manual__2026-02-14T12:12:16.345549+00:00, run_start_date=2026-02-14 12:12:18.123075+00:00, run_end_date=2026-02-14 12:12:18.131554+00:00, run_duration=0.008479, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 12:12:16.345549+00:00, data_interval_end=2026-02-14 12:12:16.345549+00:00, dag_hash=964d20dddc21507f57e8633fe2e1e46a
2026-02-14 20:13:44,525 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:16:53,110 INFO - Exiting gracefully upon receiving signal 15
2026-02-14 20:16:54,127 INFO - Sending Signals.SIGTERM to group 2807. PIDs of all processes in the group: [2807]
2026-02-14 20:16:54,128 INFO - Sending the signal Signals.SIGTERM to group 2807
2026-02-14 20:16:54,158 INFO - Process psutil.Process(pid=2807, status='terminated', exitcode=<Negsignal.SIGTERM: -15>, started='19:33:33') (2807) terminated with exit code Negsignal.SIGTERM
2026-02-14 20:16:54,179 INFO - Sending Signals.SIGTERM to group 2807. PIDs of all processes in the group: []
2026-02-14 20:16:54,181 INFO - Sending the signal Signals.SIGTERM to group 2807
2026-02-14 20:16:54,182 INFO - Sending the signal Signals.SIGTERM to process 2807 as process group is missing.
2026-02-14 20:16:54,183 INFO - Exited execute loop
2026-02-14 20:21:05,982 INFO - Loaded executor: SequentialExecutor
2026-02-14 20:21:06,566 INFO - Starting the scheduler
2026-02-14 20:21:06,567 INFO - Processing each file at most -1 times
2026-02-14 20:21:06,572 INFO - Launched DagFileProcessorManager with pid: 4958
2026-02-14 20:21:06,579 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:21:27,573 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-14 12:21:26.210043+00:00: manual__2026-02-14T12:21:26.210043+00:00, state:running, queued_at: 2026-02-14 12:21:26.235594+00:00. externally triggered: True> successful
2026-02-14 20:21:27,575 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-14 12:21:26.210043+00:00, run_id=manual__2026-02-14T12:21:26.210043+00:00, run_start_date=2026-02-14 12:21:27.403715+00:00, run_end_date=2026-02-14 12:21:27.575589+00:00, run_duration=0.171874, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 12:21:26.210043+00:00, data_interval_end=2026-02-14 12:21:26.210043+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-14 20:26:09,004 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:30:49,645 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-14 12:30:47.770071+00:00: manual__2026-02-14T12:30:47.770071+00:00, state:running, queued_at: 2026-02-14 12:30:47.792143+00:00. externally triggered: True> successful
2026-02-14 20:30:49,647 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-14 12:30:47.770071+00:00, run_id=manual__2026-02-14T12:30:47.770071+00:00, run_start_date=2026-02-14 12:30:49.636523+00:00, run_end_date=2026-02-14 12:30:49.647114+00:00, run_duration=0.010591, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 12:30:47.770071+00:00, data_interval_end=2026-02-14 12:30:47.770071+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-14 20:31:11,321 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:33:12,293 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-14 12:33:09.114451+00:00: manual__2026-02-14T12:33:09.114451+00:00, state:running, queued_at: 2026-02-14 12:33:09.133033+00:00. externally triggered: True> successful
2026-02-14 20:33:12,294 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-14 12:33:09.114451+00:00, run_id=manual__2026-02-14T12:33:09.114451+00:00, run_start_date=2026-02-14 12:33:12.284247+00:00, run_end_date=2026-02-14 12:33:12.294469+00:00, run_duration=0.010222, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-14 12:33:09.114451+00:00, data_interval_end=2026-02-14 12:33:09.114451+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-14 20:36:13,886 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:41:15,065 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:46:17,383 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:51:17,416 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 20:56:19,702 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:01:22,108 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:06:24,844 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:11:25,419 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:16:27,907 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:21:30,267 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:26:31,688 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:31:34,107 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:36:35,892 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:41:38,300 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:46:41,081 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:51:44,142 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 21:56:46,974 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:01:49,871 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:06:51,365 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:11:52,802 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:16:54,667 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:21:57,036 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:25:24,841 INFO - Heartbeat recovered after 124.13 seconds
2026-02-14 22:28:54,772 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:33:57,543 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:39:00,381 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:44:01,496 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:49:04,247 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:54:05,654 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 22:59:08,430 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 23:04:10,309 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 23:09:12,801 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 23:14:13,708 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 23:19:15,223 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 23:24:15,888 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 23:29:18,115 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-14 23:29:25,388 INFO - Exiting gracefully upon receiving signal 15
2026-02-14 23:29:26,282 INFO - Sending Signals.SIGTERM to group 4958. PIDs of all processes in the group: []
2026-02-14 23:29:26,284 INFO - Sending the signal Signals.SIGTERM to group 4958
2026-02-14 23:29:26,285 INFO - Sending the signal Signals.SIGTERM to process 4958 as process group is missing.
2026-02-14 23:29:26,294 INFO - Sending Signals.SIGTERM to group 4958. PIDs of all processes in the group: []
2026-02-14 23:29:26,294 INFO - Sending the signal Signals.SIGTERM to group 4958
2026-02-14 23:29:26,295 INFO - Sending the signal Signals.SIGTERM to process 4958 as process group is missing.
2026-02-14 23:29:26,296 INFO - Exited execute loop
2026-02-15 15:57:53,910 INFO - Loaded executor: SequentialExecutor
2026-02-15 15:57:54,960 INFO - Starting the scheduler
2026-02-15 15:57:54,962 INFO - Processing each file at most -1 times
2026-02-15 15:57:54,973 INFO - Launched DagFileProcessorManager with pid: 1011
2026-02-15 15:57:54,983 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:02:56,734 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:11:25,198 INFO - Heartbeat recovered after 390.08 seconds
2026-02-15 16:14:20,523 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:19:23,164 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:20:34,310 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:20:31.221949+00:00 [scheduled]>
2026-02-15 16:20:34,310 INFO - DAG producer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:20:34,311 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:20:31.221949+00:00 [scheduled]>
2026-02-15 16:20:34,314 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:20:31.221949+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:20:34,315 INFO - Sending TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:20:31.221949+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:20:34,316 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:20:31.221949+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:20:34,318 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:20:31.221949+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:20:37,990 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:20:31.221949+00:00', try_number=1, map_index=-1)
2026-02-15 16:20:38,005 INFO - TaskInstance Finished: dag_id=producer_order_mysql, task_id=sync_order_data, run_id=manual__2026-02-15T08:20:31.221949+00:00, map_index=-1, run_start_date=2026-02-15 08:20:36.957461+00:00, run_end_date=2026-02-15 08:20:37.318201+00:00, run_duration=0.36074, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:20:34.313061+00:00, queued_by_job_id=125, pid=2348
2026-02-15 16:20:40,656 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-15 08:20:31.221949+00:00: manual__2026-02-15T08:20:31.221949+00:00, state:running, queued_at: 2026-02-15 08:20:31.249112+00:00. externally triggered: True> successful
2026-02-15 16:20:40,658 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-15 08:20:31.221949+00:00, run_id=manual__2026-02-15T08:20:31.221949+00:00, run_start_date=2026-02-15 08:20:34.270820+00:00, run_end_date=2026-02-15 08:20:40.658445+00:00, run_duration=6.387625, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 08:20:31.221949+00:00, data_interval_end=2026-02-15 08:20:31.221949+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-15 16:20:40,667 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:20:37.334108+00:00 [scheduled]>
2026-02-15 16:20:40,668 INFO - DAG consumer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:20:40,669 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:20:37.334108+00:00 [scheduled]>
2026-02-15 16:20:40,671 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:20:37.334108+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:20:40,672 INFO - Sending TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:20:37.334108+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:20:40,673 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:20:37.334108+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:20:40,675 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:20:37.334108+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:20:44,081 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:20:37.334108+00:00', try_number=1, map_index=-1)
2026-02-15 16:20:44,091 INFO - TaskInstance Finished: dag_id=consumer_order_mysql, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T08:20:37.334108+00:00, map_index=-1, run_start_date=2026-02-15 08:20:43.189450+00:00, run_end_date=2026-02-15 08:20:43.529989+00:00, run_duration=0.340539, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:20:40.670651+00:00, queued_by_job_id=125, pid=2351
2026-02-15 16:20:46,710 ERROR - Marking run <DagRun consumer_order_mysql @ 2026-02-15 08:20:37.334108+00:00: dataset_triggered__2026-02-15T08:20:37.334108+00:00, state:running, queued_at: 2026-02-15 08:20:40.623731+00:00. externally triggered: False> failed
2026-02-15 16:20:46,711 INFO - DagRun Finished: dag_id=consumer_order_mysql, execution_date=2026-02-15 08:20:37.334108+00:00, run_id=dataset_triggered__2026-02-15T08:20:37.334108+00:00, run_start_date=2026-02-15 08:20:40.644735+00:00, run_end_date=2026-02-15 08:20:46.711057+00:00, run_duration=6.066322, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 08:20:31.221949+00:00, data_interval_end=2026-02-15 08:20:31.221949+00:00, dag_hash=12e15934c89c6e697010b52e04f32b30
2026-02-15 16:23:06,551 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:23:03.595532+00:00 [scheduled]>
2026-02-15 16:23:06,552 INFO - DAG producer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:23:06,553 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:23:03.595532+00:00 [scheduled]>
2026-02-15 16:23:06,555 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:23:03.595532+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:23:06,556 INFO - Sending TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:23:03.595532+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:23:06,557 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:23:03.595532+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:23:06,559 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:23:03.595532+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:23:10,251 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:23:03.595532+00:00', try_number=1, map_index=-1)
2026-02-15 16:23:10,263 INFO - TaskInstance Finished: dag_id=producer_order_mysql, task_id=sync_order_data, run_id=manual__2026-02-15T08:23:03.595532+00:00, map_index=-1, run_start_date=2026-02-15 08:23:09.275814+00:00, run_end_date=2026-02-15 08:23:09.660724+00:00, run_duration=0.38491, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:23:06.554078+00:00, queued_by_job_id=125, pid=2490
2026-02-15 16:23:12,887 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-15 08:23:03.595532+00:00: manual__2026-02-15T08:23:03.595532+00:00, state:running, queued_at: 2026-02-15 08:23:03.615355+00:00. externally triggered: True> successful
2026-02-15 16:23:12,888 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-15 08:23:03.595532+00:00, run_id=manual__2026-02-15T08:23:03.595532+00:00, run_start_date=2026-02-15 08:23:06.531922+00:00, run_end_date=2026-02-15 08:23:12.888437+00:00, run_duration=6.356515, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 08:23:03.595532+00:00, data_interval_end=2026-02-15 08:23:03.595532+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-15 16:23:12,897 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:23:09.677763+00:00 [scheduled]>
2026-02-15 16:23:12,898 INFO - DAG consumer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:23:12,899 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:23:09.677763+00:00 [scheduled]>
2026-02-15 16:23:12,901 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:23:09.677763+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:23:12,902 INFO - Sending TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:23:09.677763+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:23:12,903 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:23:09.677763+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:23:12,905 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:23:09.677763+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:23:16,562 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:23:09.677763+00:00', try_number=1, map_index=-1)
2026-02-15 16:23:16,572 INFO - TaskInstance Finished: dag_id=consumer_order_mysql, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T08:23:09.677763+00:00, map_index=-1, run_start_date=2026-02-15 08:23:15.449617+00:00, run_end_date=2026-02-15 08:23:15.887352+00:00, run_duration=0.437735, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:23:12.900177+00:00, queued_by_job_id=125, pid=2493
2026-02-15 16:23:19,131 INFO - Marking run <DagRun consumer_order_mysql @ 2026-02-15 08:23:09.677763+00:00: dataset_triggered__2026-02-15T08:23:09.677763+00:00, state:running, queued_at: 2026-02-15 08:23:12.861334+00:00. externally triggered: False> successful
2026-02-15 16:23:19,132 INFO - DagRun Finished: dag_id=consumer_order_mysql, execution_date=2026-02-15 08:23:09.677763+00:00, run_id=dataset_triggered__2026-02-15T08:23:09.677763+00:00, run_start_date=2026-02-15 08:23:12.875117+00:00, run_end_date=2026-02-15 08:23:19.131958+00:00, run_duration=6.256841, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 08:23:03.595532+00:00, data_interval_end=2026-02-15 08:23:03.595532+00:00, dag_hash=12e15934c89c6e697010b52e04f32b30
2026-02-15 16:24:24,206 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:29:25,763 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:34:26,931 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:39:28,907 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:43:39,969 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:43:37.783738+00:00 [scheduled]>
2026-02-15 16:43:39,970 INFO - DAG producer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:43:39,971 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:43:37.783738+00:00 [scheduled]>
2026-02-15 16:43:39,973 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:43:37.783738+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:43:39,974 INFO - Sending TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:43:37.783738+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:43:39,975 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:43:37.783738+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:43:39,977 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:43:37.783738+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:43:43,700 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:43:37.783738+00:00', try_number=1, map_index=-1)
2026-02-15 16:43:43,709 INFO - TaskInstance Finished: dag_id=producer_order_mysql, task_id=sync_order_data, run_id=manual__2026-02-15T08:43:37.783738+00:00, map_index=-1, run_start_date=2026-02-15 08:43:42.748972+00:00, run_end_date=2026-02-15 08:43:43.123360+00:00, run_duration=0.374388, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:43:39.972153+00:00, queued_by_job_id=125, pid=3390
2026-02-15 16:43:46,296 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-15 08:43:37.783738+00:00: manual__2026-02-15T08:43:37.783738+00:00, state:running, queued_at: 2026-02-15 08:43:37.802419+00:00. externally triggered: True> successful
2026-02-15 16:43:46,297 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-15 08:43:37.783738+00:00, run_id=manual__2026-02-15T08:43:37.783738+00:00, run_start_date=2026-02-15 08:43:39.948365+00:00, run_end_date=2026-02-15 08:43:46.297152+00:00, run_duration=6.348787, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 08:43:37.783738+00:00, data_interval_end=2026-02-15 08:43:37.783738+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-15 16:43:46,307 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:43:43.140152+00:00 [scheduled]>
2026-02-15 16:43:46,308 INFO - DAG consumer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:43:46,308 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:43:43.140152+00:00 [scheduled]>
2026-02-15 16:43:46,311 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:43:43.140152+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:43:46,312 INFO - Sending TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:43:43.140152+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:43:46,312 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:43:43.140152+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:43:46,315 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:43:43.140152+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:43:49,814 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:43:43.140152+00:00', try_number=1, map_index=-1)
2026-02-15 16:43:49,822 INFO - TaskInstance Finished: dag_id=consumer_order_mysql, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T08:43:43.140152+00:00, map_index=-1, run_start_date=2026-02-15 08:43:48.872686+00:00, run_end_date=2026-02-15 08:43:49.311331+00:00, run_duration=0.438645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:43:46.309880+00:00, queued_by_job_id=125, pid=3393
2026-02-15 16:43:52,492 INFO - Marking run <DagRun consumer_order_mysql @ 2026-02-15 08:43:43.140152+00:00: dataset_triggered__2026-02-15T08:43:43.140152+00:00, state:running, queued_at: 2026-02-15 08:43:46.269290+00:00. externally triggered: False> successful
2026-02-15 16:43:52,493 INFO - DagRun Finished: dag_id=consumer_order_mysql, execution_date=2026-02-15 08:43:43.140152+00:00, run_id=dataset_triggered__2026-02-15T08:43:43.140152+00:00, run_start_date=2026-02-15 08:43:46.282966+00:00, run_end_date=2026-02-15 08:43:52.493241+00:00, run_duration=6.210275, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 08:43:37.783738+00:00, data_interval_end=2026-02-15 08:43:37.783738+00:00, dag_hash=12e15934c89c6e697010b52e04f32b30
2026-02-15 16:44:31,221 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:47:10,700 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:47:09.878272+00:00 [scheduled]>
2026-02-15 16:47:10,702 INFO - DAG producer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:47:10,703 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:47:09.878272+00:00 [scheduled]>
2026-02-15 16:47:10,705 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:47:09.878272+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:47:10,706 INFO - Sending TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:47:09.878272+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:47:10,707 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:47:09.878272+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:47:10,709 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:47:09.878272+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:47:14,866 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:47:09.878272+00:00', try_number=1, map_index=-1)
2026-02-15 16:47:14,875 INFO - TaskInstance Finished: dag_id=producer_order_mysql, task_id=sync_order_data, run_id=manual__2026-02-15T08:47:09.878272+00:00, map_index=-1, run_start_date=2026-02-15 08:47:13.887974+00:00, run_end_date=2026-02-15 08:47:14.261265+00:00, run_duration=0.373291, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=132, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:47:10.704327+00:00, queued_by_job_id=125, pid=3535
2026-02-15 16:47:17,361 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-15 08:47:09.878272+00:00: manual__2026-02-15T08:47:09.878272+00:00, state:running, queued_at: 2026-02-15 08:47:09.890049+00:00. externally triggered: True> successful
2026-02-15 16:47:17,363 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-15 08:47:09.878272+00:00, run_id=manual__2026-02-15T08:47:09.878272+00:00, run_start_date=2026-02-15 08:47:10.671755+00:00, run_end_date=2026-02-15 08:47:17.363024+00:00, run_duration=6.691269, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 08:47:09.878272+00:00, data_interval_end=2026-02-15 08:47:09.878272+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-15 16:47:17,374 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:47:14.278092+00:00 [scheduled]>
2026-02-15 16:47:17,375 INFO - DAG consumer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:47:17,375 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:47:14.278092+00:00 [scheduled]>
2026-02-15 16:47:17,378 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:47:14.278092+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:47:17,379 INFO - Sending TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:47:14.278092+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:47:17,380 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:47:14.278092+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:47:17,383 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:47:14.278092+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:47:21,203 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:47:14.278092+00:00', try_number=1, map_index=-1)
2026-02-15 16:47:21,212 INFO - TaskInstance Finished: dag_id=consumer_order_mysql, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T08:47:14.278092+00:00, map_index=-1, run_start_date=2026-02-15 08:47:20.124929+00:00, run_end_date=2026-02-15 08:47:20.608615+00:00, run_duration=0.483686, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=133, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:47:17.377017+00:00, queued_by_job_id=125, pid=3538
2026-02-15 16:47:23,839 INFO - Marking run <DagRun consumer_order_mysql @ 2026-02-15 08:47:14.278092+00:00: dataset_triggered__2026-02-15T08:47:14.278092+00:00, state:running, queued_at: 2026-02-15 08:47:17.332903+00:00. externally triggered: False> successful
2026-02-15 16:47:23,840 INFO - DagRun Finished: dag_id=consumer_order_mysql, execution_date=2026-02-15 08:47:14.278092+00:00, run_id=dataset_triggered__2026-02-15T08:47:14.278092+00:00, run_start_date=2026-02-15 08:47:17.348345+00:00, run_end_date=2026-02-15 08:47:23.840515+00:00, run_duration=6.49217, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 08:47:09.878272+00:00, data_interval_end=2026-02-15 08:47:09.878272+00:00, dag_hash=12e15934c89c6e697010b52e04f32b30
2026-02-15 16:49:33,736 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:52:01,430 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:51:59.598541+00:00 [scheduled]>
2026-02-15 16:52:01,431 INFO - DAG producer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:52:01,432 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:51:59.598541+00:00 [scheduled]>
2026-02-15 16:52:01,434 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:51:59.598541+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:52:01,436 INFO - Sending TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:51:59.598541+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:52:01,436 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:51:59.598541+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:52:01,439 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:51:59.598541+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:52:05,410 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:51:59.598541+00:00', try_number=1, map_index=-1)
2026-02-15 16:52:05,419 INFO - TaskInstance Finished: dag_id=producer_order_mysql, task_id=sync_order_data, run_id=manual__2026-02-15T08:51:59.598541+00:00, map_index=-1, run_start_date=2026-02-15 08:52:04.391133+00:00, run_end_date=2026-02-15 08:52:04.822273+00:00, run_duration=0.43114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=134, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:52:01.432882+00:00, queued_by_job_id=125, pid=3749
2026-02-15 16:52:08,020 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-15 08:51:59.598541+00:00: manual__2026-02-15T08:51:59.598541+00:00, state:running, queued_at: 2026-02-15 08:51:59.609747+00:00. externally triggered: True> successful
2026-02-15 16:52:08,021 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-15 08:51:59.598541+00:00, run_id=manual__2026-02-15T08:51:59.598541+00:00, run_start_date=2026-02-15 08:52:01.410145+00:00, run_end_date=2026-02-15 08:52:08.021039+00:00, run_duration=6.610894, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 08:51:59.598541+00:00, data_interval_end=2026-02-15 08:51:59.598541+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-15 16:52:08,030 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:52:04.840837+00:00 [scheduled]>
2026-02-15 16:52:08,031 INFO - DAG consumer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:52:08,031 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:52:04.840837+00:00 [scheduled]>
2026-02-15 16:52:08,033 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:52:04.840837+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:52:08,035 INFO - Sending TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:52:04.840837+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:52:08,035 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:52:04.840837+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:52:08,038 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:52:04.840837+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:52:11,726 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:52:04.840837+00:00', try_number=1, map_index=-1)
2026-02-15 16:52:11,735 INFO - TaskInstance Finished: dag_id=consumer_order_mysql, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T08:52:04.840837+00:00, map_index=-1, run_start_date=2026-02-15 08:52:10.658116+00:00, run_end_date=2026-02-15 08:52:11.145601+00:00, run_duration=0.487485, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=135, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:52:08.032712+00:00, queued_by_job_id=125, pid=3752
2026-02-15 16:52:14,362 INFO - Marking run <DagRun consumer_order_mysql @ 2026-02-15 08:52:04.840837+00:00: dataset_triggered__2026-02-15T08:52:04.840837+00:00, state:running, queued_at: 2026-02-15 08:52:07.989842+00:00. externally triggered: False> successful
2026-02-15 16:52:14,363 INFO - DagRun Finished: dag_id=consumer_order_mysql, execution_date=2026-02-15 08:52:04.840837+00:00, run_id=dataset_triggered__2026-02-15T08:52:04.840837+00:00, run_start_date=2026-02-15 08:52:08.006323+00:00, run_end_date=2026-02-15 08:52:14.363724+00:00, run_duration=6.357401, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 08:51:59.598541+00:00, data_interval_end=2026-02-15 08:51:59.598541+00:00, dag_hash=12e15934c89c6e697010b52e04f32b30
2026-02-15 16:53:05,118 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:53:01.949106+00:00 [scheduled]>
2026-02-15 16:53:05,119 INFO - DAG producer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:53:05,120 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:53:01.949106+00:00 [scheduled]>
2026-02-15 16:53:05,122 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_mysql.sync_order_data manual__2026-02-15T08:53:01.949106+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:53:05,124 INFO - Sending TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:53:01.949106+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:53:05,124 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:53:01.949106+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:53:05,127 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_mysql', 'sync_order_data', 'manual__2026-02-15T08:53:01.949106+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:53:08,819 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_mysql', task_id='sync_order_data', run_id='manual__2026-02-15T08:53:01.949106+00:00', try_number=1, map_index=-1)
2026-02-15 16:53:08,829 INFO - TaskInstance Finished: dag_id=producer_order_mysql, task_id=sync_order_data, run_id=manual__2026-02-15T08:53:01.949106+00:00, map_index=-1, run_start_date=2026-02-15 08:53:07.797065+00:00, run_end_date=2026-02-15 08:53:08.206592+00:00, run_duration=0.409527, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=136, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:53:05.121622+00:00, queued_by_job_id=125, pid=3781
2026-02-15 16:53:11,710 INFO - Marking run <DagRun producer_order_mysql @ 2026-02-15 08:53:01.949106+00:00: manual__2026-02-15T08:53:01.949106+00:00, state:running, queued_at: 2026-02-15 08:53:01.968186+00:00. externally triggered: True> successful
2026-02-15 16:53:11,711 INFO - DagRun Finished: dag_id=producer_order_mysql, execution_date=2026-02-15 08:53:01.949106+00:00, run_id=manual__2026-02-15T08:53:01.949106+00:00, run_start_date=2026-02-15 08:53:05.094052+00:00, run_end_date=2026-02-15 08:53:11.711074+00:00, run_duration=6.617022, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 08:53:01.949106+00:00, data_interval_end=2026-02-15 08:53:01.949106+00:00, dag_hash=8adaa434cd10062f2620192444602f8e
2026-02-15 16:53:11,720 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:53:08.224546+00:00 [scheduled]>
2026-02-15 16:53:11,721 INFO - DAG consumer_order_mysql has 0/16 running and queued tasks
2026-02-15 16:53:11,722 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:53:08.224546+00:00 [scheduled]>
2026-02-15 16:53:11,724 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_mysql.clean_order_data dataset_triggered__2026-02-15T08:53:08.224546+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 16:53:11,725 INFO - Sending TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:53:08.224546+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 16:53:11,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:53:08.224546+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:53:11,728 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_mysql', 'clean_order_data', 'dataset_triggered__2026-02-15T08:53:08.224546+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db2.py']
2026-02-15 16:53:15,456 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_mysql', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T08:53:08.224546+00:00', try_number=1, map_index=-1)
2026-02-15 16:53:15,465 INFO - TaskInstance Finished: dag_id=consumer_order_mysql, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T08:53:08.224546+00:00, map_index=-1, run_start_date=2026-02-15 08:53:14.379673+00:00, run_end_date=2026-02-15 08:53:14.885960+00:00, run_duration=0.506287, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=137, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 08:53:11.723081+00:00, queued_by_job_id=125, pid=3785
2026-02-15 16:53:18,304 INFO - Marking run <DagRun consumer_order_mysql @ 2026-02-15 08:53:08.224546+00:00: dataset_triggered__2026-02-15T08:53:08.224546+00:00, state:running, queued_at: 2026-02-15 08:53:11.684187+00:00. externally triggered: False> successful
2026-02-15 16:53:18,305 INFO - DagRun Finished: dag_id=consumer_order_mysql, execution_date=2026-02-15 08:53:08.224546+00:00, run_id=dataset_triggered__2026-02-15T08:53:08.224546+00:00, run_start_date=2026-02-15 08:53:11.697224+00:00, run_end_date=2026-02-15 08:53:18.305273+00:00, run_duration=6.608049, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 08:53:01.949106+00:00, data_interval_end=2026-02-15 08:53:01.949106+00:00, dag_hash=12e15934c89c6e697010b52e04f32b30
2026-02-15 16:54:36,744 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 16:59:39,240 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:04:40,588 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:08:08,599 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:08:07.117190+00:00 [scheduled]>
2026-02-15 17:08:08,600 INFO - DAG producer_order_sqlserver has 0/16 running and queued tasks
2026-02-15 17:08:08,601 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:08:07.117190+00:00 [scheduled]>
2026-02-15 17:08:08,604 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:08:07.117190+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 17:08:08,605 INFO - Sending TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:08:07.117190+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 17:08:08,606 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:08:07.117190+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:08:08,608 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:08:07.117190+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:08:13,562 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:08:07.117190+00:00', try_number=1, map_index=-1)
2026-02-15 17:08:13,571 INFO - TaskInstance Finished: dag_id=producer_order_sqlserver, task_id=sync_order_data, run_id=manual__2026-02-15T09:08:07.117190+00:00, map_index=-1, run_start_date=2026-02-15 09:08:12.481857+00:00, run_end_date=2026-02-15 09:08:12.852376+00:00, run_duration=0.370519, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=138, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 09:08:08.602841+00:00, queued_by_job_id=125, pid=4423
2026-02-15 17:08:16,219 INFO - Marking run <DagRun producer_order_sqlserver @ 2026-02-15 09:08:07.117190+00:00: manual__2026-02-15T09:08:07.117190+00:00, state:running, queued_at: 2026-02-15 09:08:07.129819+00:00. externally triggered: True> successful
2026-02-15 17:08:16,220 INFO - DagRun Finished: dag_id=producer_order_sqlserver, execution_date=2026-02-15 09:08:07.117190+00:00, run_id=manual__2026-02-15T09:08:07.117190+00:00, run_start_date=2026-02-15 09:08:08.576755+00:00, run_end_date=2026-02-15 09:08:16.220235+00:00, run_duration=7.64348, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 09:08:07.117190+00:00, data_interval_end=2026-02-15 09:08:07.117190+00:00, dag_hash=c534735c11f1f608816c92d09c67d709
2026-02-15 17:08:16,229 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_sqlserver.clean_order_data dataset_triggered__2026-02-15T09:08:12.868772+00:00 [scheduled]>
2026-02-15 17:08:16,230 INFO - DAG consumer_order_sqlserver has 0/16 running and queued tasks
2026-02-15 17:08:16,231 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_sqlserver.clean_order_data dataset_triggered__2026-02-15T09:08:12.868772+00:00 [scheduled]>
2026-02-15 17:08:16,233 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_sqlserver.clean_order_data dataset_triggered__2026-02-15T09:08:12.868772+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 17:08:16,234 INFO - Sending TaskInstanceKey(dag_id='consumer_order_sqlserver', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T09:08:12.868772+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 17:08:16,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_sqlserver', 'clean_order_data', 'dataset_triggered__2026-02-15T09:08:12.868772+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:08:16,238 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_sqlserver', 'clean_order_data', 'dataset_triggered__2026-02-15T09:08:12.868772+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:08:19,838 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_sqlserver', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T09:08:12.868772+00:00', try_number=1, map_index=-1)
2026-02-15 17:08:19,846 INFO - TaskInstance Finished: dag_id=consumer_order_sqlserver, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T09:08:12.868772+00:00, map_index=-1, run_start_date=2026-02-15 09:08:18.847774+00:00, run_end_date=2026-02-15 09:08:19.210150+00:00, run_duration=0.362376, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=139, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 09:08:16.232545+00:00, queued_by_job_id=125, pid=4426
2026-02-15 17:08:22,549 ERROR - Marking run <DagRun consumer_order_sqlserver @ 2026-02-15 09:08:12.868772+00:00: dataset_triggered__2026-02-15T09:08:12.868772+00:00, state:running, queued_at: 2026-02-15 09:08:16.192012+00:00. externally triggered: False> failed
2026-02-15 17:08:22,550 INFO - DagRun Finished: dag_id=consumer_order_sqlserver, execution_date=2026-02-15 09:08:12.868772+00:00, run_id=dataset_triggered__2026-02-15T09:08:12.868772+00:00, run_start_date=2026-02-15 09:08:16.206206+00:00, run_end_date=2026-02-15 09:08:22.550239+00:00, run_duration=6.344033, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 09:08:07.117190+00:00, data_interval_end=2026-02-15 09:08:07.117190+00:00, dag_hash=4bfcc7af7a5b312e79e6f8e335db1b32
2026-02-15 17:09:43,425 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:11:08,964 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:11:05.621117+00:00 [scheduled]>
2026-02-15 17:11:08,965 INFO - DAG producer_order_sqlserver has 0/16 running and queued tasks
2026-02-15 17:11:08,966 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:11:05.621117+00:00 [scheduled]>
2026-02-15 17:11:08,968 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:11:05.621117+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 17:11:08,970 INFO - Sending TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:11:05.621117+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 17:11:08,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:11:05.621117+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:11:08,973 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:11:05.621117+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:11:13,029 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:11:05.621117+00:00', try_number=1, map_index=-1)
2026-02-15 17:11:13,038 INFO - TaskInstance Finished: dag_id=producer_order_sqlserver, task_id=sync_order_data, run_id=manual__2026-02-15T09:11:05.621117+00:00, map_index=-1, run_start_date=2026-02-15 09:11:12.018323+00:00, run_end_date=2026-02-15 09:11:12.396732+00:00, run_duration=0.378409, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=140, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 09:11:08.967435+00:00, queued_by_job_id=125, pid=4535
2026-02-15 17:11:15,669 ERROR - Marking run <DagRun producer_order_sqlserver @ 2026-02-15 09:11:05.621117+00:00: manual__2026-02-15T09:11:05.621117+00:00, state:running, queued_at: 2026-02-15 09:11:05.633027+00:00. externally triggered: True> failed
2026-02-15 17:11:15,670 INFO - DagRun Finished: dag_id=producer_order_sqlserver, execution_date=2026-02-15 09:11:05.621117+00:00, run_id=manual__2026-02-15T09:11:05.621117+00:00, run_start_date=2026-02-15 09:11:08.942850+00:00, run_end_date=2026-02-15 09:11:15.670612+00:00, run_duration=6.727762, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 09:11:05.621117+00:00, data_interval_end=2026-02-15 09:11:05.621117+00:00, dag_hash=c534735c11f1f608816c92d09c67d709
2026-02-15 17:14:45,184 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:15:46,526 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:15:43.478244+00:00 [scheduled]>
2026-02-15 17:15:46,527 INFO - DAG producer_order_sqlserver has 0/16 running and queued tasks
2026-02-15 17:15:46,528 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:15:43.478244+00:00 [scheduled]>
2026-02-15 17:15:46,530 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:15:43.478244+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 17:15:46,531 INFO - Sending TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:15:43.478244+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 17:15:46,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:15:43.478244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:15:46,534 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:15:43.478244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:15:50,677 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:15:43.478244+00:00', try_number=1, map_index=-1)
2026-02-15 17:15:50,686 INFO - TaskInstance Finished: dag_id=producer_order_sqlserver, task_id=sync_order_data, run_id=manual__2026-02-15T09:15:43.478244+00:00, map_index=-1, run_start_date=2026-02-15 09:15:49.614062+00:00, run_end_date=2026-02-15 09:15:49.993795+00:00, run_duration=0.379733, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=141, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 09:15:46.529585+00:00, queued_by_job_id=125, pid=4704
2026-02-15 17:15:53,248 ERROR - Marking run <DagRun producer_order_sqlserver @ 2026-02-15 09:15:43.478244+00:00: manual__2026-02-15T09:15:43.478244+00:00, state:running, queued_at: 2026-02-15 09:15:43.489512+00:00. externally triggered: True> failed
2026-02-15 17:15:53,250 INFO - DagRun Finished: dag_id=producer_order_sqlserver, execution_date=2026-02-15 09:15:43.478244+00:00, run_id=manual__2026-02-15T09:15:43.478244+00:00, run_start_date=2026-02-15 09:15:46.507541+00:00, run_end_date=2026-02-15 09:15:53.249903+00:00, run_duration=6.742362, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 09:15:43.478244+00:00, data_interval_end=2026-02-15 09:15:43.478244+00:00, dag_hash=c534735c11f1f608816c92d09c67d709
2026-02-15 17:18:04,013 INFO - 1 tasks up for execution:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:18:02.962311+00:00 [scheduled]>
2026-02-15 17:18:04,027 INFO - DAG producer_order_sqlserver has 0/16 running and queued tasks
2026-02-15 17:18:04,028 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:18:02.962311+00:00 [scheduled]>
2026-02-15 17:18:04,034 INFO - Trying to enqueue tasks: [<TaskInstance: producer_order_sqlserver.sync_order_data manual__2026-02-15T09:18:02.962311+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 17:18:04,035 INFO - Sending TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:18:02.962311+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 17:18:04,036 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:18:02.962311+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:18:04,052 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_order_sqlserver', 'sync_order_data', 'manual__2026-02-15T09:18:02.962311+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:18:08,384 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_order_sqlserver', task_id='sync_order_data', run_id='manual__2026-02-15T09:18:02.962311+00:00', try_number=1, map_index=-1)
2026-02-15 17:18:08,392 INFO - TaskInstance Finished: dag_id=producer_order_sqlserver, task_id=sync_order_data, run_id=manual__2026-02-15T09:18:02.962311+00:00, map_index=-1, run_start_date=2026-02-15 09:18:07.187874+00:00, run_end_date=2026-02-15 09:18:07.829922+00:00, run_duration=0.642048, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=142, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 09:18:04.031523+00:00, queued_by_job_id=125, pid=4788
2026-02-15 17:18:10,980 INFO - Marking run <DagRun producer_order_sqlserver @ 2026-02-15 09:18:02.962311+00:00: manual__2026-02-15T09:18:02.962311+00:00, state:running, queued_at: 2026-02-15 09:18:02.970703+00:00. externally triggered: True> successful
2026-02-15 17:18:10,981 INFO - DagRun Finished: dag_id=producer_order_sqlserver, execution_date=2026-02-15 09:18:02.962311+00:00, run_id=manual__2026-02-15T09:18:02.962311+00:00, run_start_date=2026-02-15 09:18:03.961549+00:00, run_end_date=2026-02-15 09:18:10.981245+00:00, run_duration=7.019696, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-15 09:18:02.962311+00:00, data_interval_end=2026-02-15 09:18:02.962311+00:00, dag_hash=c534735c11f1f608816c92d09c67d709
2026-02-15 17:18:10,991 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_order_sqlserver.clean_order_data dataset_triggered__2026-02-15T09:18:07.845834+00:00 [scheduled]>
2026-02-15 17:18:10,992 INFO - DAG consumer_order_sqlserver has 0/16 running and queued tasks
2026-02-15 17:18:10,992 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_order_sqlserver.clean_order_data dataset_triggered__2026-02-15T09:18:07.845834+00:00 [scheduled]>
2026-02-15 17:18:10,995 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_order_sqlserver.clean_order_data dataset_triggered__2026-02-15T09:18:07.845834+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-15 17:18:10,996 INFO - Sending TaskInstanceKey(dag_id='consumer_order_sqlserver', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T09:18:07.845834+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-15 17:18:10,997 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_order_sqlserver', 'clean_order_data', 'dataset_triggered__2026-02-15T09:18:07.845834+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:18:10,999 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_order_sqlserver', 'clean_order_data', 'dataset_triggered__2026-02-15T09:18:07.845834+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_db_sqlserver.py']
2026-02-15 17:18:14,934 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_order_sqlserver', task_id='clean_order_data', run_id='dataset_triggered__2026-02-15T09:18:07.845834+00:00', try_number=1, map_index=-1)
2026-02-15 17:18:14,942 INFO - TaskInstance Finished: dag_id=consumer_order_sqlserver, task_id=clean_order_data, run_id=dataset_triggered__2026-02-15T09:18:07.845834+00:00, map_index=-1, run_start_date=2026-02-15 09:18:13.644053+00:00, run_end_date=2026-02-15 09:18:14.445610+00:00, run_duration=0.801557, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=143, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-15 09:18:10.993879+00:00, queued_by_job_id=125, pid=4791
2026-02-15 17:18:17,733 INFO - Marking run <DagRun consumer_order_sqlserver @ 2026-02-15 09:18:07.845834+00:00: dataset_triggered__2026-02-15T09:18:07.845834+00:00, state:running, queued_at: 2026-02-15 09:18:10.951674+00:00. externally triggered: False> successful
2026-02-15 17:18:17,734 INFO - DagRun Finished: dag_id=consumer_order_sqlserver, execution_date=2026-02-15 09:18:07.845834+00:00, run_id=dataset_triggered__2026-02-15T09:18:07.845834+00:00, run_start_date=2026-02-15 09:18:10.966958+00:00, run_end_date=2026-02-15 09:18:17.734565+00:00, run_duration=6.767607, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-15 09:18:02.962311+00:00, data_interval_end=2026-02-15 09:18:02.962311+00:00, dag_hash=4bfcc7af7a5b312e79e6f8e335db1b32
2026-02-15 17:19:46,387 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:24:48,987 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:29:50,029 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:34:51,907 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:40:42,141 INFO - Heartbeat recovered after 51.66 seconds
2026-02-15 17:40:42,145 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:47:25,644 INFO - Heartbeat recovered after 214.23 seconds
2026-02-15 17:49:08,019 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 17:54:08,175 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 18:02:28,100 INFO - Heartbeat recovered after 217.74 seconds
2026-02-15 18:02:41,040 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-15 18:07:03,147 INFO - Exiting gracefully upon receiving signal 15
2026-02-15 18:07:04,216 INFO - Sending Signals.SIGTERM to group 1011. PIDs of all processes in the group: [1011]
2026-02-15 18:07:04,227 INFO - Sending the signal Signals.SIGTERM to group 1011
2026-02-15 18:07:04,325 INFO - Process psutil.Process(pid=1011, status='terminated', exitcode=<Negsignal.SIGTERM: -15>, started='15:57:54') (1011) terminated with exit code Negsignal.SIGTERM
2026-02-15 18:07:04,329 INFO - Sending Signals.SIGTERM to group 1011. PIDs of all processes in the group: []
2026-02-15 18:07:04,329 INFO - Sending the signal Signals.SIGTERM to group 1011
2026-02-15 18:07:04,331 INFO - Sending the signal Signals.SIGTERM to process 1011 as process group is missing.
2026-02-15 18:07:04,332 INFO - Exited execute loop
2026-02-23 18:47:08,381 INFO - Loaded executor: SequentialExecutor
2026-02-23 18:47:09,216 INFO - Starting the scheduler
2026-02-23 18:47:09,219 INFO - Processing each file at most -1 times
2026-02-23 18:47:09,228 INFO - Launched DagFileProcessorManager with pid: 1273
2026-02-23 18:47:09,236 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 18:49:28,524 INFO - Exiting gracefully upon receiving signal 15
2026-02-23 18:49:29,099 INFO - Sending Signals.SIGTERM to group 1273. PIDs of all processes in the group: []
2026-02-23 18:49:29,100 INFO - Sending the signal Signals.SIGTERM to group 1273
2026-02-23 18:49:29,101 INFO - Sending the signal Signals.SIGTERM to process 1273 as process group is missing.
2026-02-23 18:49:29,108 INFO - Sending Signals.SIGTERM to group 1273. PIDs of all processes in the group: []
2026-02-23 18:49:29,109 INFO - Sending the signal Signals.SIGTERM to group 1273
2026-02-23 18:49:29,110 INFO - Sending the signal Signals.SIGTERM to process 1273 as process group is missing.
2026-02-23 18:49:29,111 INFO - Exited execute loop
2026-02-23 18:49:36,590 INFO - Loaded executor: SequentialExecutor
2026-02-23 18:49:37,127 INFO - Starting the scheduler
2026-02-23 18:49:37,128 INFO - Processing each file at most -1 times
2026-02-23 18:49:37,136 INFO - Launched DagFileProcessorManager with pid: 1404
2026-02-23 18:49:37,140 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 18:54:37,399 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 18:59:38,484 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:00:29,265 INFO - 1 tasks up for execution:
	<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-23T11:00:25.848592+00:00 [scheduled]>
2026-02-23 19:00:29,266 INFO - DAG producer_variable_sync has 0/16 running and queued tasks
2026-02-23 19:00:29,267 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-23T11:00:25.848592+00:00 [scheduled]>
2026-02-23 19:00:29,270 INFO - Trying to enqueue tasks: [<TaskInstance: producer_variable_sync.producer_variable_save_data manual__2026-02-23T11:00:25.848592+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:00:29,271 INFO - Sending TaskInstanceKey(dag_id='producer_variable_sync', task_id='producer_variable_save_data', run_id='manual__2026-02-23T11:00:25.848592+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:00:29,272 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'producer_variable_save_data', 'manual__2026-02-23T11:00:25.848592+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-23 19:00:29,274 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_variable_sync', 'producer_variable_save_data', 'manual__2026-02-23T11:00:25.848592+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-23 19:00:33,267 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_variable_sync', task_id='producer_variable_save_data', run_id='manual__2026-02-23T11:00:25.848592+00:00', try_number=1, map_index=-1)
2026-02-23 19:00:33,281 INFO - TaskInstance Finished: dag_id=producer_variable_sync, task_id=producer_variable_save_data, run_id=manual__2026-02-23T11:00:25.848592+00:00, map_index=-1, run_start_date=2026-02-23 11:00:32.224422+00:00, run_end_date=2026-02-23 11:00:32.622058+00:00, run_duration=0.397636, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=146, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:00:29.268877+00:00, queued_by_job_id=145, pid=1818
2026-02-23 19:00:35,871 INFO - Marking run <DagRun producer_variable_sync @ 2026-02-23 11:00:25.848592+00:00: manual__2026-02-23T11:00:25.848592+00:00, state:running, queued_at: 2026-02-23 11:00:25.863231+00:00. externally triggered: True> successful
2026-02-23 19:00:35,873 INFO - DagRun Finished: dag_id=producer_variable_sync, execution_date=2026-02-23 11:00:25.848592+00:00, run_id=manual__2026-02-23T11:00:25.848592+00:00, run_start_date=2026-02-23 11:00:29.227809+00:00, run_end_date=2026-02-23 11:00:35.873514+00:00, run_duration=6.645705, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:00:25.848592+00:00, data_interval_end=2026-02-23 11:00:25.848592+00:00, dag_hash=47cb4504eff6f0d33ccb9eb1ea3c16ae
2026-02-23 19:00:35,883 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-23T11:00:32.642494+00:00 [scheduled]>
2026-02-23 19:00:35,884 INFO - DAG consumer_variable has 0/16 running and queued tasks
2026-02-23 19:00:35,885 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-23T11:00:32.642494+00:00 [scheduled]>
2026-02-23 19:00:35,887 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_variable.consumer_variable_read_data dataset_triggered__2026-02-23T11:00:32.642494+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:00:35,888 INFO - Sending TaskInstanceKey(dag_id='consumer_variable', task_id='consumer_variable_read_data', run_id='dataset_triggered__2026-02-23T11:00:32.642494+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:00:35,889 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_variable', 'consumer_variable_read_data', 'dataset_triggered__2026-02-23T11:00:32.642494+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-23 19:00:35,891 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_variable', 'consumer_variable_read_data', 'dataset_triggered__2026-02-23T11:00:32.642494+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /dataset_variable.py']
2026-02-23 19:00:39,677 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_variable', task_id='consumer_variable_read_data', run_id='dataset_triggered__2026-02-23T11:00:32.642494+00:00', try_number=1, map_index=-1)
2026-02-23 19:00:39,688 INFO - TaskInstance Finished: dag_id=consumer_variable, task_id=consumer_variable_read_data, run_id=dataset_triggered__2026-02-23T11:00:32.642494+00:00, map_index=-1, run_start_date=2026-02-23 11:00:38.712765+00:00, run_end_date=2026-02-23 11:00:39.091486+00:00, run_duration=0.378721, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=147, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:00:35.886407+00:00, queued_by_job_id=145, pid=1821
2026-02-23 19:00:42,269 INFO - Marking run <DagRun consumer_variable @ 2026-02-23 11:00:32.642494+00:00: dataset_triggered__2026-02-23T11:00:32.642494+00:00, state:running, queued_at: 2026-02-23 11:00:35.838960+00:00. externally triggered: False> successful
2026-02-23 19:00:42,270 INFO - DagRun Finished: dag_id=consumer_variable, execution_date=2026-02-23 11:00:32.642494+00:00, run_id=dataset_triggered__2026-02-23T11:00:32.642494+00:00, run_start_date=2026-02-23 11:00:35.859362+00:00, run_end_date=2026-02-23 11:00:42.270046+00:00, run_duration=6.410684, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 11:00:25.848592+00:00, data_interval_end=2026-02-23 11:00:25.848592+00:00, dag_hash=ea6f50333c860200cf7319bc15b25ef1
2026-02-23 19:04:42,338 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:05:55,419 INFO - Heartbeat recovered after 39.86 seconds
2026-02-23 19:10:15,798 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:15:19,915 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:20:19,853 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:20:15.839625+00:00 [scheduled]>
2026-02-23 19:20:19,854 INFO - DAG producer_1_N_sync has 0/16 running and queued tasks
2026-02-23 19:20:19,854 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:20:15.839625+00:00 [scheduled]>
2026-02-23 19:20:19,858 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:20:15.839625+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:20:19,859 INFO - Sending TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:20:15.839625+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:20:19,860 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:20:15.839625+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:20:19,864 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:20:15.839625+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:20:24,487 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:20:15.839625+00:00', try_number=1, map_index=-1)
2026-02-23 19:20:24,498 INFO - TaskInstance Finished: dag_id=producer_1_N_sync, task_id=producer_1_N_save_data, run_id=manual__2026-02-23T11:20:15.839625+00:00, map_index=-1, run_start_date=2026-02-23 11:20:23.653390+00:00, run_end_date=2026-02-23 11:20:23.973319+00:00, run_duration=0.319929, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=148, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:20:19.856069+00:00, queued_by_job_id=145, pid=3494
2026-02-23 19:20:24,524 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:20:27,219 INFO - Marking run <DagRun producer_1_N_sync @ 2026-02-23 11:20:15.839625+00:00: manual__2026-02-23T11:20:15.839625+00:00, state:running, queued_at: 2026-02-23 11:20:15.873209+00:00. externally triggered: True> successful
2026-02-23 19:20:27,220 INFO - DagRun Finished: dag_id=producer_1_N_sync, execution_date=2026-02-23 11:20:15.839625+00:00, run_id=manual__2026-02-23T11:20:15.839625+00:00, run_start_date=2026-02-23 11:20:19.831494+00:00, run_end_date=2026-02-23 11:20:27.220472+00:00, run_duration=7.388978, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:20:15.839625+00:00, data_interval_end=2026-02-23 11:20:15.839625+00:00, dag_hash=16874b5bf55a4a62eecf7139183a4cad
2026-02-23 19:22:20,309 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:22:16.293098+00:00 [scheduled]>
2026-02-23 19:22:20,310 INFO - DAG producer_1_N_sync has 0/16 running and queued tasks
2026-02-23 19:22:20,311 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:22:16.293098+00:00 [scheduled]>
2026-02-23 19:22:20,314 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:22:16.293098+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:22:20,315 INFO - Sending TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:22:16.293098+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:22:20,316 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:22:16.293098+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:22:20,318 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:22:16.293098+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:22:24,742 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:22:16.293098+00:00', try_number=1, map_index=-1)
2026-02-23 19:22:24,755 INFO - TaskInstance Finished: dag_id=producer_1_N_sync, task_id=producer_1_N_save_data, run_id=manual__2026-02-23T11:22:16.293098+00:00, map_index=-1, run_start_date=2026-02-23 11:22:23.872515+00:00, run_end_date=2026-02-23 11:22:24.187338+00:00, run_duration=0.314823, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=149, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:22:20.312624+00:00, queued_by_job_id=145, pid=3609
2026-02-23 19:22:27,285 INFO - Marking run <DagRun producer_1_N_sync @ 2026-02-23 11:22:16.293098+00:00: manual__2026-02-23T11:22:16.293098+00:00, state:running, queued_at: 2026-02-23 11:22:16.311423+00:00. externally triggered: True> successful
2026-02-23 19:22:27,286 INFO - DagRun Finished: dag_id=producer_1_N_sync, execution_date=2026-02-23 11:22:16.293098+00:00, run_id=manual__2026-02-23T11:22:16.293098+00:00, run_start_date=2026-02-23 11:22:20.290872+00:00, run_end_date=2026-02-23 11:22:27.285978+00:00, run_duration=6.995106, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:22:16.293098+00:00, data_interval_end=2026-02-23 11:22:16.293098+00:00, dag_hash=16874b5bf55a4a62eecf7139183a4cad
2026-02-23 19:25:25,908 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:30:26,204 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:30:48,236 INFO - Exiting gracefully upon receiving signal 15
2026-02-23 19:30:48,776 INFO - Sending Signals.SIGTERM to group 1404. PIDs of all processes in the group: []
2026-02-23 19:30:48,776 INFO - Sending the signal Signals.SIGTERM to group 1404
2026-02-23 19:30:48,777 INFO - Sending the signal Signals.SIGTERM to process 1404 as process group is missing.
2026-02-23 19:30:48,787 INFO - Sending Signals.SIGTERM to group 1404. PIDs of all processes in the group: []
2026-02-23 19:30:48,788 INFO - Sending the signal Signals.SIGTERM to group 1404
2026-02-23 19:30:48,789 INFO - Sending the signal Signals.SIGTERM to process 1404 as process group is missing.
2026-02-23 19:30:48,789 INFO - Exited execute loop
2026-02-23 19:30:50,838 INFO - Loaded executor: SequentialExecutor
2026-02-23 19:30:51,379 INFO - Starting the scheduler
2026-02-23 19:30:51,381 INFO - Processing each file at most -1 times
2026-02-23 19:30:51,388 INFO - Launched DagFileProcessorManager with pid: 4661
2026-02-23 19:30:51,393 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:31:08,536 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:31:05.639910+00:00 [scheduled]>
2026-02-23 19:31:08,537 INFO - DAG producer_1_N_sync has 0/16 running and queued tasks
2026-02-23 19:31:08,538 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:31:05.639910+00:00 [scheduled]>
2026-02-23 19:31:08,541 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:31:05.639910+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:31:08,542 INFO - Sending TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:31:05.639910+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:31:08,543 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:31:05.639910+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:31:08,545 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:31:05.639910+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:31:12,400 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:31:05.639910+00:00', try_number=1, map_index=-1)
2026-02-23 19:31:12,416 INFO - TaskInstance Finished: dag_id=producer_1_N_sync, task_id=producer_1_N_save_data, run_id=manual__2026-02-23T11:31:05.639910+00:00, map_index=-1, run_start_date=2026-02-23 11:31:11.530576+00:00, run_end_date=2026-02-23 11:31:11.829878+00:00, run_duration=0.299302, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=151, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:31:08.539980+00:00, queued_by_job_id=150, pid=4676
2026-02-23 19:31:15,478 INFO - Marking run <DagRun producer_1_N_sync @ 2026-02-23 11:31:05.639910+00:00: manual__2026-02-23T11:31:05.639910+00:00, state:running, queued_at: 2026-02-23 11:31:05.661892+00:00. externally triggered: True> successful
2026-02-23 19:31:15,480 INFO - DagRun Finished: dag_id=producer_1_N_sync, execution_date=2026-02-23 11:31:05.639910+00:00, run_id=manual__2026-02-23T11:31:05.639910+00:00, run_start_date=2026-02-23 11:31:08.365616+00:00, run_end_date=2026-02-23 11:31:15.480006+00:00, run_duration=7.11439, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:31:05.639910+00:00, data_interval_end=2026-02-23 11:31:05.639910+00:00, dag_hash=16874b5bf55a4a62eecf7139183a4cad
2026-02-23 19:33:29,151 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:33:26.048748+00:00 [scheduled]>
2026-02-23 19:33:29,152 INFO - DAG producer_1_N_sync has 0/16 running and queued tasks
2026-02-23 19:33:29,152 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:33:26.048748+00:00 [scheduled]>
2026-02-23 19:33:29,155 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:33:26.048748+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:33:29,156 INFO - Sending TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:33:26.048748+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:33:29,157 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:33:26.048748+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:33:29,159 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:33:26.048748+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:33:33,220 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:33:26.048748+00:00', try_number=1, map_index=-1)
2026-02-23 19:33:33,231 INFO - TaskInstance Finished: dag_id=producer_1_N_sync, task_id=producer_1_N_save_data, run_id=manual__2026-02-23T11:33:26.048748+00:00, map_index=-1, run_start_date=2026-02-23 11:33:32.301245+00:00, run_end_date=2026-02-23 11:33:32.650905+00:00, run_duration=0.34966, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=152, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:33:29.153867+00:00, queued_by_job_id=150, pid=4751
2026-02-23 19:33:35,909 INFO - Marking run <DagRun producer_1_N_sync @ 2026-02-23 11:33:26.048748+00:00: manual__2026-02-23T11:33:26.048748+00:00, state:running, queued_at: 2026-02-23 11:33:26.060265+00:00. externally triggered: True> successful
2026-02-23 19:33:35,910 INFO - DagRun Finished: dag_id=producer_1_N_sync, execution_date=2026-02-23 11:33:26.048748+00:00, run_id=manual__2026-02-23T11:33:26.048748+00:00, run_start_date=2026-02-23 11:33:29.130609+00:00, run_end_date=2026-02-23 11:33:35.910429+00:00, run_duration=6.77982, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:33:26.048748+00:00, data_interval_end=2026-02-23 11:33:26.048748+00:00, dag_hash=67f182f9819b19150e11f40e385a1c4e
2026-02-23 19:33:35,920 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-23T11:33:32.668844+00:00 [scheduled]>
	<TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-23T11:33:32.670665+00:00 [scheduled]>
2026-02-23 19:33:35,921 INFO - DAG consumer_1_N_clean_order_data has 0/16 running and queued tasks
2026-02-23 19:33:35,921 INFO - DAG consumer_1_N_stat_order_data has 0/16 running and queued tasks
2026-02-23 19:33:35,922 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-23T11:33:32.668844+00:00 [scheduled]>
	<TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-23T11:33:32.670665+00:00 [scheduled]>
2026-02-23 19:33:35,925 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-23T11:33:32.668844+00:00 [scheduled]>, <TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-23T11:33:32.670665+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:33:35,927 INFO - Sending TaskInstanceKey(dag_id='consumer_1_N_clean_order_data', task_id='consumer_1_N_read_clean_order_data', run_id='dataset_triggered__2026-02-23T11:33:32.668844+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:33:35,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_data', 'consumer_1_N_read_clean_order_data', 'dataset_triggered__2026-02-23T11:33:32.668844+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:33:35,928 INFO - Sending TaskInstanceKey(dag_id='consumer_1_N_stat_order_data', task_id='consumer_1_N_read_stat_order_data', run_id='dataset_triggered__2026-02-23T11:33:32.670665+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:33:35,929 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1_N_stat_order_data', 'consumer_1_N_read_stat_order_data', 'dataset_triggered__2026-02-23T11:33:32.670665+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:33:35,931 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_data', 'consumer_1_N_read_clean_order_data', 'dataset_triggered__2026-02-23T11:33:32.668844+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:33:39,570 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1_N_stat_order_data', 'consumer_1_N_read_stat_order_data', 'dataset_triggered__2026-02-23T11:33:32.670665+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:33:43,208 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1_N_clean_order_data', task_id='consumer_1_N_read_clean_order_data', run_id='dataset_triggered__2026-02-23T11:33:32.668844+00:00', try_number=1, map_index=-1)
2026-02-23 19:33:43,212 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1_N_stat_order_data', task_id='consumer_1_N_read_stat_order_data', run_id='dataset_triggered__2026-02-23T11:33:32.670665+00:00', try_number=1, map_index=-1)
2026-02-23 19:33:43,224 INFO - TaskInstance Finished: dag_id=consumer_1_N_stat_order_data, task_id=consumer_1_N_read_stat_order_data, run_id=dataset_triggered__2026-02-23T11:33:32.670665+00:00, map_index=-1, run_start_date=2026-02-23 11:33:42.309512+00:00, run_end_date=2026-02-23 11:33:42.623384+00:00, run_duration=0.313872, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=154, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:33:35.923913+00:00, queued_by_job_id=150, pid=4756
2026-02-23 19:33:43,226 INFO - TaskInstance Finished: dag_id=consumer_1_N_clean_order_data, task_id=consumer_1_N_read_clean_order_data, run_id=dataset_triggered__2026-02-23T11:33:32.668844+00:00, map_index=-1, run_start_date=2026-02-23 11:33:38.675074+00:00, run_end_date=2026-02-23 11:33:38.998445+00:00, run_duration=0.323371, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=153, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:33:35.923913+00:00, queued_by_job_id=150, pid=4754
2026-02-23 19:33:45,872 INFO - Marking run <DagRun consumer_1_N_clean_order_data @ 2026-02-23 11:33:32.668844+00:00: dataset_triggered__2026-02-23T11:33:32.668844+00:00, state:running, queued_at: 2026-02-23 11:33:35.865590+00:00. externally triggered: False> successful
2026-02-23 19:33:45,873 INFO - DagRun Finished: dag_id=consumer_1_N_clean_order_data, execution_date=2026-02-23 11:33:32.668844+00:00, run_id=dataset_triggered__2026-02-23T11:33:32.668844+00:00, run_start_date=2026-02-23 11:33:35.891030+00:00, run_end_date=2026-02-23 11:33:45.873286+00:00, run_duration=9.982256, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 11:20:15.839625+00:00, data_interval_end=2026-02-23 11:33:26.048748+00:00, dag_hash=aa50dbfb8bf5e155ff929257d180aa84
2026-02-23 19:33:45,878 INFO - Marking run <DagRun consumer_1_N_stat_order_data @ 2026-02-23 11:33:32.670665+00:00: dataset_triggered__2026-02-23T11:33:32.670665+00:00, state:running, queued_at: 2026-02-23 11:33:35.878815+00:00. externally triggered: False> successful
2026-02-23 19:33:45,879 INFO - DagRun Finished: dag_id=consumer_1_N_stat_order_data, execution_date=2026-02-23 11:33:32.670665+00:00, run_id=dataset_triggered__2026-02-23T11:33:32.670665+00:00, run_start_date=2026-02-23 11:33:35.891194+00:00, run_end_date=2026-02-23 11:33:45.879075+00:00, run_duration=9.987881, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 11:20:15.839625+00:00, data_interval_end=2026-02-23 11:33:26.048748+00:00, dag_hash=1d32b8a27c451df14b079631212c82ae
2026-02-23 19:35:54,193 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:40:56,585 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:45:58,655 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:48:58,528 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T11:48:54.792682+00:00 [scheduled]>
2026-02-23 19:48:58,529 INFO - DAG producer_1p_1n_1n_DAG has 0/16 running and queued tasks
2026-02-23 19:48:58,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T11:48:54.792682+00:00 [scheduled]>
2026-02-23 19:48:58,532 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T11:48:54.792682+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:48:58,533 INFO - Sending TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T11:48:54.792682+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:48:58,534 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T11:48:54.792682+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 19:48:58,536 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T11:48:54.792682+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 19:49:02,848 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T11:48:54.792682+00:00', try_number=1, map_index=-1)
2026-02-23 19:49:02,860 INFO - TaskInstance Finished: dag_id=producer_1p_1n_1n_DAG, task_id=producer_1p_1n_1n_TASK, run_id=manual__2026-02-23T11:48:54.792682+00:00, map_index=-1, run_start_date=2026-02-23 11:49:01.893867+00:00, run_end_date=2026-02-23 11:49:02.275950+00:00, run_duration=0.382083, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=155, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:48:58.531348+00:00, queued_by_job_id=150, pid=5406
2026-02-23 19:49:05,442 INFO - Marking run <DagRun producer_1p_1n_1n_DAG @ 2026-02-23 11:48:54.792682+00:00: manual__2026-02-23T11:48:54.792682+00:00, state:running, queued_at: 2026-02-23 11:48:54.809930+00:00. externally triggered: True> successful
2026-02-23 19:49:05,443 INFO - DagRun Finished: dag_id=producer_1p_1n_1n_DAG, execution_date=2026-02-23 11:48:54.792682+00:00, run_id=manual__2026-02-23T11:48:54.792682+00:00, run_start_date=2026-02-23 11:48:58.511379+00:00, run_end_date=2026-02-23 11:49:05.443554+00:00, run_duration=6.932175, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:48:54.792682+00:00, data_interval_end=2026-02-23 11:48:54.792682+00:00, dag_hash=7f60ec962ce128ab31b18c3357478d92
2026-02-23 19:50:58,720 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 19:51:51,378 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:51:49.749086+00:00 [scheduled]>
2026-02-23 19:51:51,378 INFO - DAG producer_1_N_sync has 0/16 running and queued tasks
2026-02-23 19:51:51,379 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:51:49.749086+00:00 [scheduled]>
2026-02-23 19:51:51,381 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1_N_sync.producer_1_N_save_data manual__2026-02-23T11:51:49.749086+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:51:51,382 INFO - Sending TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:51:49.749086+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:51:51,383 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:51:49.749086+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:51:51,385 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1_N_sync', 'producer_1_N_save_data', 'manual__2026-02-23T11:51:49.749086+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:51:55,245 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1_N_sync', task_id='producer_1_N_save_data', run_id='manual__2026-02-23T11:51:49.749086+00:00', try_number=1, map_index=-1)
2026-02-23 19:51:55,257 INFO - TaskInstance Finished: dag_id=producer_1_N_sync, task_id=producer_1_N_save_data, run_id=manual__2026-02-23T11:51:49.749086+00:00, map_index=-1, run_start_date=2026-02-23 11:51:54.372425+00:00, run_end_date=2026-02-23 11:51:54.661002+00:00, run_duration=0.288577, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=156, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:51:51.380677+00:00, queued_by_job_id=150, pid=5499
2026-02-23 19:51:57,895 INFO - Marking run <DagRun producer_1_N_sync @ 2026-02-23 11:51:49.749086+00:00: manual__2026-02-23T11:51:49.749086+00:00, state:running, queued_at: 2026-02-23 11:51:49.767051+00:00. externally triggered: True> successful
2026-02-23 19:51:57,896 INFO - DagRun Finished: dag_id=producer_1_N_sync, execution_date=2026-02-23 11:51:49.749086+00:00, run_id=manual__2026-02-23T11:51:49.749086+00:00, run_start_date=2026-02-23 11:51:51.355542+00:00, run_end_date=2026-02-23 11:51:57.896514+00:00, run_duration=6.540972, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:51:49.749086+00:00, data_interval_end=2026-02-23 11:51:49.749086+00:00, dag_hash=67f182f9819b19150e11f40e385a1c4e
2026-02-23 19:51:57,908 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-23T11:51:54.679326+00:00 [scheduled]>
	<TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-23T11:51:54.680799+00:00 [scheduled]>
2026-02-23 19:51:57,908 INFO - DAG consumer_1_N_clean_order_data has 0/16 running and queued tasks
2026-02-23 19:51:57,909 INFO - DAG consumer_1_N_stat_order_data has 0/16 running and queued tasks
2026-02-23 19:51:57,910 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-23T11:51:54.679326+00:00 [scheduled]>
	<TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-23T11:51:54.680799+00:00 [scheduled]>
2026-02-23 19:51:57,912 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1_N_clean_order_data.consumer_1_N_read_clean_order_data dataset_triggered__2026-02-23T11:51:54.679326+00:00 [scheduled]>, <TaskInstance: consumer_1_N_stat_order_data.consumer_1_N_read_stat_order_data dataset_triggered__2026-02-23T11:51:54.680799+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:51:57,914 INFO - Sending TaskInstanceKey(dag_id='consumer_1_N_clean_order_data', task_id='consumer_1_N_read_clean_order_data', run_id='dataset_triggered__2026-02-23T11:51:54.679326+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:51:57,914 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_data', 'consumer_1_N_read_clean_order_data', 'dataset_triggered__2026-02-23T11:51:54.679326+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:51:57,915 INFO - Sending TaskInstanceKey(dag_id='consumer_1_N_stat_order_data', task_id='consumer_1_N_read_stat_order_data', run_id='dataset_triggered__2026-02-23T11:51:54.680799+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:51:57,916 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1_N_stat_order_data', 'consumer_1_N_read_stat_order_data', 'dataset_triggered__2026-02-23T11:51:54.680799+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:51:57,918 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_data', 'consumer_1_N_read_clean_order_data', 'dataset_triggered__2026-02-23T11:51:54.679326+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:52:01,528 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1_N_stat_order_data', 'consumer_1_N_read_stat_order_data', 'dataset_triggered__2026-02-23T11:51:54.680799+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer.py']
2026-02-23 19:52:05,273 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1_N_clean_order_data', task_id='consumer_1_N_read_clean_order_data', run_id='dataset_triggered__2026-02-23T11:51:54.679326+00:00', try_number=1, map_index=-1)
2026-02-23 19:52:05,276 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1_N_stat_order_data', task_id='consumer_1_N_read_stat_order_data', run_id='dataset_triggered__2026-02-23T11:51:54.680799+00:00', try_number=1, map_index=-1)
2026-02-23 19:52:05,284 INFO - TaskInstance Finished: dag_id=consumer_1_N_stat_order_data, task_id=consumer_1_N_read_stat_order_data, run_id=dataset_triggered__2026-02-23T11:51:54.680799+00:00, map_index=-1, run_start_date=2026-02-23 11:52:04.350395+00:00, run_end_date=2026-02-23 11:52:04.672817+00:00, run_duration=0.322422, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=158, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:51:57.911422+00:00, queued_by_job_id=150, pid=5507
2026-02-23 19:52:05,286 INFO - TaskInstance Finished: dag_id=consumer_1_N_clean_order_data, task_id=consumer_1_N_read_clean_order_data, run_id=dataset_triggered__2026-02-23T11:51:54.679326+00:00, map_index=-1, run_start_date=2026-02-23 11:52:00.628102+00:00, run_end_date=2026-02-23 11:52:00.938439+00:00, run_duration=0.310337, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=157, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:51:57.911422+00:00, queued_by_job_id=150, pid=5505
2026-02-23 19:52:07,718 INFO - Marking run <DagRun consumer_1_N_clean_order_data @ 2026-02-23 11:51:54.679326+00:00: dataset_triggered__2026-02-23T11:51:54.679326+00:00, state:running, queued_at: 2026-02-23 11:51:57.856446+00:00. externally triggered: False> successful
2026-02-23 19:52:07,719 INFO - DagRun Finished: dag_id=consumer_1_N_clean_order_data, execution_date=2026-02-23 11:51:54.679326+00:00, run_id=dataset_triggered__2026-02-23T11:51:54.679326+00:00, run_start_date=2026-02-23 11:51:57.878291+00:00, run_end_date=2026-02-23 11:52:07.719493+00:00, run_duration=9.841202, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 11:51:49.749086+00:00, data_interval_end=2026-02-23 11:51:49.749086+00:00, dag_hash=aa50dbfb8bf5e155ff929257d180aa84
2026-02-23 19:52:07,724 INFO - Marking run <DagRun consumer_1_N_stat_order_data @ 2026-02-23 11:51:54.680799+00:00: dataset_triggered__2026-02-23T11:51:54.680799+00:00, state:running, queued_at: 2026-02-23 11:51:57.864434+00:00. externally triggered: False> successful
2026-02-23 19:52:07,725 INFO - DagRun Finished: dag_id=consumer_1_N_stat_order_data, execution_date=2026-02-23 11:51:54.680799+00:00, run_id=dataset_triggered__2026-02-23T11:51:54.680799+00:00, run_start_date=2026-02-23 11:51:57.878415+00:00, run_end_date=2026-02-23 11:52:07.725034+00:00, run_duration=9.846619, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 11:51:49.749086+00:00, data_interval_end=2026-02-23 11:51:49.749086+00:00, dag_hash=1d32b8a27c451df14b079631212c82ae
2026-02-23 19:52:29,852 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T11:52:27.668366+00:00 [scheduled]>
2026-02-23 19:52:29,853 INFO - DAG producer_1p_1n_1n_DAG has 0/16 running and queued tasks
2026-02-23 19:52:29,853 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T11:52:27.668366+00:00 [scheduled]>
2026-02-23 19:52:29,855 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T11:52:27.668366+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 19:52:29,856 INFO - Sending TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T11:52:27.668366+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 19:52:29,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T11:52:27.668366+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 19:52:29,860 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T11:52:27.668366+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 19:52:33,618 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T11:52:27.668366+00:00', try_number=1, map_index=-1)
2026-02-23 19:52:33,628 INFO - TaskInstance Finished: dag_id=producer_1p_1n_1n_DAG, task_id=producer_1p_1n_1n_TASK, run_id=manual__2026-02-23T11:52:27.668366+00:00, map_index=-1, run_start_date=2026-02-23 11:52:32.556986+00:00, run_end_date=2026-02-23 11:52:32.920060+00:00, run_duration=0.363074, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=159, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 11:52:29.854618+00:00, queued_by_job_id=150, pid=5517
2026-02-23 19:52:36,408 INFO - Marking run <DagRun producer_1p_1n_1n_DAG @ 2026-02-23 11:52:27.668366+00:00: manual__2026-02-23T11:52:27.668366+00:00, state:running, queued_at: 2026-02-23 11:52:27.679520+00:00. externally triggered: True> successful
2026-02-23 19:52:36,409 INFO - DagRun Finished: dag_id=producer_1p_1n_1n_DAG, execution_date=2026-02-23 11:52:27.668366+00:00, run_id=manual__2026-02-23T11:52:27.668366+00:00, run_start_date=2026-02-23 11:52:29.828842+00:00, run_end_date=2026-02-23 11:52:36.409126+00:00, run_duration=6.580284, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 11:52:27.668366+00:00, data_interval_end=2026-02-23 11:52:27.668366+00:00, dag_hash=7f60ec962ce128ab31b18c3357478d92
2026-02-23 19:56:01,105 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:01:00,565 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:11:44,325 INFO - Heartbeat recovered after 550.55 seconds
2026-02-23 20:12:27,301 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:12:23.281493+00:00 [scheduled]>
2026-02-23 20:12:27,302 INFO - DAG producer_1p_1n_1n_DAG has 0/16 running and queued tasks
2026-02-23 20:12:27,303 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:12:23.281493+00:00 [scheduled]>
2026-02-23 20:12:27,305 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:12:23.281493+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:12:27,306 INFO - Sending TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:12:23.281493+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:12:27,307 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:12:23.281493+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:12:27,309 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:12:23.281493+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:12:31,186 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:12:23.281493+00:00', try_number=1, map_index=-1)
2026-02-23 20:12:31,198 INFO - TaskInstance Finished: dag_id=producer_1p_1n_1n_DAG, task_id=producer_1p_1n_1n_TASK, run_id=manual__2026-02-23T12:12:23.281493+00:00, map_index=-1, run_start_date=2026-02-23 12:12:30.121039+00:00, run_end_date=2026-02-23 12:12:30.519751+00:00, run_duration=0.398712, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=160, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:12:27.304615+00:00, queued_by_job_id=150, pid=5879
2026-02-23 20:12:33,849 INFO - Marking run <DagRun producer_1p_1n_1n_DAG @ 2026-02-23 12:12:23.281493+00:00: manual__2026-02-23T12:12:23.281493+00:00, state:running, queued_at: 2026-02-23 12:12:23.309560+00:00. externally triggered: True> successful
2026-02-23 20:12:33,850 INFO - DagRun Finished: dag_id=producer_1p_1n_1n_DAG, execution_date=2026-02-23 12:12:23.281493+00:00, run_id=manual__2026-02-23T12:12:23.281493+00:00, run_start_date=2026-02-23 12:12:27.281350+00:00, run_end_date=2026-02-23 12:12:33.850394+00:00, run_duration=6.569044, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:12:23.281493+00:00, data_interval_end=2026-02-23 12:12:23.281493+00:00, dag_hash=7f60ec962ce128ab31b18c3357478d92
2026-02-23 20:13:48,821 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:13:46.055370+00:00 [scheduled]>
2026-02-23 20:13:48,822 INFO - DAG producer_1p_1n_1n_DAG has 0/16 running and queued tasks
2026-02-23 20:13:48,823 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:13:46.055370+00:00 [scheduled]>
2026-02-23 20:13:48,825 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:13:46.055370+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:13:48,827 INFO - Sending TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:13:46.055370+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:13:48,828 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:13:46.055370+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:13:48,830 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:13:46.055370+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:13:52,860 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:13:46.055370+00:00', try_number=1, map_index=-1)
2026-02-23 20:13:52,872 INFO - TaskInstance Finished: dag_id=producer_1p_1n_1n_DAG, task_id=producer_1p_1n_1n_TASK, run_id=manual__2026-02-23T12:13:46.055370+00:00, map_index=-1, run_start_date=2026-02-23 12:13:51.799927+00:00, run_end_date=2026-02-23 12:13:52.168567+00:00, run_duration=0.36864, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=161, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:13:48.824201+00:00, queued_by_job_id=150, pid=5950
2026-02-23 20:13:55,550 INFO - Marking run <DagRun producer_1p_1n_1n_DAG @ 2026-02-23 12:13:46.055370+00:00: manual__2026-02-23T12:13:46.055370+00:00, state:running, queued_at: 2026-02-23 12:13:46.083322+00:00. externally triggered: True> successful
2026-02-23 20:13:55,552 INFO - DagRun Finished: dag_id=producer_1p_1n_1n_DAG, execution_date=2026-02-23 12:13:46.055370+00:00, run_id=manual__2026-02-23T12:13:46.055370+00:00, run_start_date=2026-02-23 12:13:48.801856+00:00, run_end_date=2026-02-23 12:13:55.551909+00:00, run_duration=6.750053, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:13:46.055370+00:00, data_interval_end=2026-02-23 12:13:46.055370+00:00, dag_hash=cd25e327cac86005e1f2f0c7d1074890
2026-02-23 20:15:08,107 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:16:59,843 INFO - Exiting gracefully upon receiving signal 15
2026-02-23 20:17:00,678 INFO - Sending Signals.SIGTERM to group 4661. PIDs of all processes in the group: []
2026-02-23 20:17:00,679 INFO - Sending the signal Signals.SIGTERM to group 4661
2026-02-23 20:17:00,681 INFO - Sending the signal Signals.SIGTERM to process 4661 as process group is missing.
2026-02-23 20:17:00,695 INFO - Sending Signals.SIGTERM to group 4661. PIDs of all processes in the group: []
2026-02-23 20:17:00,696 INFO - Sending the signal Signals.SIGTERM to group 4661
2026-02-23 20:17:00,697 INFO - Sending the signal Signals.SIGTERM to process 4661 as process group is missing.
2026-02-23 20:17:00,698 INFO - Exited execute loop
2026-02-23 20:17:02,930 INFO - Loaded executor: SequentialExecutor
2026-02-23 20:17:03,485 INFO - Starting the scheduler
2026-02-23 20:17:03,486 INFO - Processing each file at most -1 times
2026-02-23 20:17:03,494 INFO - Launched DagFileProcessorManager with pid: 6785
2026-02-23 20:17:03,499 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:17:20,181 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:17:19.792368+00:00 [scheduled]>
2026-02-23 20:17:20,182 INFO - DAG producer_1p_1n_1n_DAG has 0/16 running and queued tasks
2026-02-23 20:17:20,184 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:17:19.792368+00:00 [scheduled]>
2026-02-23 20:17:20,191 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:17:19.792368+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:17:20,192 INFO - Sending TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:17:19.792368+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:17:20,193 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:17:19.792368+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:17:20,196 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:17:19.792368+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:17:24,244 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:17:19.792368+00:00', try_number=1, map_index=-1)
2026-02-23 20:17:24,259 INFO - TaskInstance Finished: dag_id=producer_1p_1n_1n_DAG, task_id=producer_1p_1n_1n_TASK, run_id=manual__2026-02-23T12:17:19.792368+00:00, map_index=-1, run_start_date=2026-02-23 12:17:23.196252+00:00, run_end_date=2026-02-23 12:17:23.571464+00:00, run_duration=0.375212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=163, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:17:20.186273+00:00, queued_by_job_id=162, pid=6806
2026-02-23 20:17:26,819 INFO - Marking run <DagRun producer_1p_1n_1n_DAG @ 2026-02-23 12:17:19.792368+00:00: manual__2026-02-23T12:17:19.792368+00:00, state:running, queued_at: 2026-02-23 12:17:19.818633+00:00. externally triggered: True> successful
2026-02-23 20:17:26,821 INFO - DagRun Finished: dag_id=producer_1p_1n_1n_DAG, execution_date=2026-02-23 12:17:19.792368+00:00, run_id=manual__2026-02-23T12:17:19.792368+00:00, run_start_date=2026-02-23 12:17:20.028177+00:00, run_end_date=2026-02-23 12:17:26.821290+00:00, run_duration=6.793113, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:17:19.792368+00:00, data_interval_end=2026-02-23 12:17:19.792368+00:00, dag_hash=a2df129e5daaf22663e9a567dc4f3f06
2026-02-23 20:18:06,283 INFO - Orphaning unreferenced dataset 'dataset://mysql/1p_1n_1n'
2026-02-23 20:20:49,725 INFO - Exiting gracefully upon receiving signal 15
2026-02-23 20:20:50,523 INFO - Sending Signals.SIGTERM to group 6785. PIDs of all processes in the group: []
2026-02-23 20:20:50,524 INFO - Sending the signal Signals.SIGTERM to group 6785
2026-02-23 20:20:50,525 INFO - Sending the signal Signals.SIGTERM to process 6785 as process group is missing.
2026-02-23 20:20:50,538 INFO - Sending Signals.SIGTERM to group 6785. PIDs of all processes in the group: []
2026-02-23 20:20:50,539 INFO - Sending the signal Signals.SIGTERM to group 6785
2026-02-23 20:20:50,540 INFO - Sending the signal Signals.SIGTERM to process 6785 as process group is missing.
2026-02-23 20:20:50,541 INFO - Exited execute loop
2026-02-23 20:20:52,804 INFO - Loaded executor: SequentialExecutor
2026-02-23 20:20:53,323 INFO - Starting the scheduler
2026-02-23 20:20:53,324 INFO - Processing each file at most -1 times
2026-02-23 20:20:53,331 INFO - Launched DagFileProcessorManager with pid: 6919
2026-02-23 20:20:53,336 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:21:13,578 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:21:11.058403+00:00 [scheduled]>
2026-02-23 20:21:13,579 INFO - DAG producer_1p_1n_1n_DAG has 0/16 running and queued tasks
2026-02-23 20:21:13,580 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:21:11.058403+00:00 [scheduled]>
2026-02-23 20:21:13,583 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:21:11.058403+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:21:13,584 INFO - Sending TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:21:11.058403+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:21:13,584 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:21:11.058403+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:21:13,587 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:21:11.058403+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:21:17,431 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:21:11.058403+00:00', try_number=1, map_index=-1)
2026-02-23 20:21:17,448 INFO - TaskInstance Finished: dag_id=producer_1p_1n_1n_DAG, task_id=producer_1p_1n_1n_TASK, run_id=manual__2026-02-23T12:21:11.058403+00:00, map_index=-1, run_start_date=2026-02-23 12:21:16.347044+00:00, run_end_date=2026-02-23 12:21:16.720956+00:00, run_duration=0.373912, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=165, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:21:13.581235+00:00, queued_by_job_id=164, pid=6947
2026-02-23 20:21:20,105 INFO - Marking run <DagRun producer_1p_1n_1n_DAG @ 2026-02-23 12:21:11.058403+00:00: manual__2026-02-23T12:21:11.058403+00:00, state:running, queued_at: 2026-02-23 12:21:11.083633+00:00. externally triggered: True> successful
2026-02-23 20:21:20,107 INFO - DagRun Finished: dag_id=producer_1p_1n_1n_DAG, execution_date=2026-02-23 12:21:11.058403+00:00, run_id=manual__2026-02-23T12:21:11.058403+00:00, run_start_date=2026-02-23 12:21:13.400915+00:00, run_end_date=2026-02-23 12:21:20.107015+00:00, run_duration=6.7061, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:21:11.058403+00:00, data_interval_end=2026-02-23 12:21:11.058403+00:00, dag_hash=0668088bbb31448c0150ccfb187b0b3b
2026-02-23 20:25:55,926 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:27:19,257 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1_N_DAG.producer_1_N_save_TASK manual__2026-02-23T12:27:15.701229+00:00 [scheduled]>
2026-02-23 20:27:19,258 INFO - DAG producer_1_N_DAG has 0/16 running and queued tasks
2026-02-23 20:27:19,259 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1_N_DAG.producer_1_N_save_TASK manual__2026-02-23T12:27:15.701229+00:00 [scheduled]>
2026-02-23 20:27:19,261 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1_N_DAG.producer_1_N_save_TASK manual__2026-02-23T12:27:15.701229+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:27:19,262 INFO - Sending TaskInstanceKey(dag_id='producer_1_N_DAG', task_id='producer_1_N_save_TASK', run_id='manual__2026-02-23T12:27:15.701229+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:27:19,263 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1_N_DAG', 'producer_1_N_save_TASK', 'manual__2026-02-23T12:27:15.701229+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:27:19,265 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1_N_DAG', 'producer_1_N_save_TASK', 'manual__2026-02-23T12:27:15.701229+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:27:23,055 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1_N_DAG', task_id='producer_1_N_save_TASK', run_id='manual__2026-02-23T12:27:15.701229+00:00', try_number=1, map_index=-1)
2026-02-23 20:27:23,067 INFO - TaskInstance Finished: dag_id=producer_1_N_DAG, task_id=producer_1_N_save_TASK, run_id=manual__2026-02-23T12:27:15.701229+00:00, map_index=-1, run_start_date=2026-02-23 12:27:22.115623+00:00, run_end_date=2026-02-23 12:27:22.500813+00:00, run_duration=0.38519, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=166, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:27:19.260378+00:00, queued_by_job_id=164, pid=7141
2026-02-23 20:27:25,866 INFO - Marking run <DagRun producer_1_N_DAG @ 2026-02-23 12:27:15.701229+00:00: manual__2026-02-23T12:27:15.701229+00:00, state:running, queued_at: 2026-02-23 12:27:15.723523+00:00. externally triggered: True> successful
2026-02-23 20:27:25,867 INFO - DagRun Finished: dag_id=producer_1_N_DAG, execution_date=2026-02-23 12:27:15.701229+00:00, run_id=manual__2026-02-23T12:27:15.701229+00:00, run_start_date=2026-02-23 12:27:19.237909+00:00, run_end_date=2026-02-23 12:27:25.866971+00:00, run_duration=6.629062, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:27:15.701229+00:00, data_interval_end=2026-02-23 12:27:15.701229+00:00, dag_hash=b211071d00cf88176e2d79e172154d28
2026-02-23 20:27:25,877 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_1_N_clean_order_DAG.consumer_1_N_read_clean_order_TASK dataset_triggered__2026-02-23T12:27:22.517861+00:00 [scheduled]>
2026-02-23 20:27:25,878 INFO - DAG consumer_1_N_clean_order_DAG has 0/16 running and queued tasks
2026-02-23 20:27:25,879 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1_N_clean_order_DAG.consumer_1_N_read_clean_order_TASK dataset_triggered__2026-02-23T12:27:22.517861+00:00 [scheduled]>
2026-02-23 20:27:25,882 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1_N_clean_order_DAG.consumer_1_N_read_clean_order_TASK dataset_triggered__2026-02-23T12:27:22.517861+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:27:25,883 INFO - Sending TaskInstanceKey(dag_id='consumer_1_N_clean_order_DAG', task_id='consumer_1_N_read_clean_order_TASK', run_id='dataset_triggered__2026-02-23T12:27:22.517861+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:27:25,884 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_DAG', 'consumer_1_N_read_clean_order_TASK', 'dataset_triggered__2026-02-23T12:27:22.517861+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:27:25,899 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1_N_clean_order_DAG', 'consumer_1_N_read_clean_order_TASK', 'dataset_triggered__2026-02-23T12:27:22.517861+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:27:29,536 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1_N_clean_order_DAG', task_id='consumer_1_N_read_clean_order_TASK', run_id='dataset_triggered__2026-02-23T12:27:22.517861+00:00', try_number=1, map_index=-1)
2026-02-23 20:27:29,547 INFO - TaskInstance Finished: dag_id=consumer_1_N_clean_order_DAG, task_id=consumer_1_N_read_clean_order_TASK, run_id=dataset_triggered__2026-02-23T12:27:22.517861+00:00, map_index=-1, run_start_date=2026-02-23 12:27:28.585951+00:00, run_end_date=2026-02-23 12:27:28.972626+00:00, run_duration=0.386675, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=167, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:27:25.881333+00:00, queued_by_job_id=164, pid=7144
2026-02-23 20:27:32,552 INFO - Marking run <DagRun consumer_1_N_clean_order_DAG @ 2026-02-23 12:27:22.517861+00:00: dataset_triggered__2026-02-23T12:27:22.517861+00:00, state:running, queued_at: 2026-02-23 12:27:25.832429+00:00. externally triggered: False> successful
2026-02-23 20:27:32,554 INFO - DagRun Finished: dag_id=consumer_1_N_clean_order_DAG, execution_date=2026-02-23 12:27:22.517861+00:00, run_id=dataset_triggered__2026-02-23T12:27:22.517861+00:00, run_start_date=2026-02-23 12:27:25.852335+00:00, run_end_date=2026-02-23 12:27:32.553956+00:00, run_duration=6.701621, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:27:15.701229+00:00, data_interval_end=2026-02-23 12:27:15.701229+00:00, dag_hash=f5f40795c8ffc8aaddffb97149f9b5dc
2026-02-23 20:30:34,270 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:30:32.913130+00:00 [scheduled]>
2026-02-23 20:30:34,271 INFO - DAG producer_1p_1n_1n_DAG has 0/16 running and queued tasks
2026-02-23 20:30:34,272 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:30:32.913130+00:00 [scheduled]>
2026-02-23 20:30:34,274 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p_1n_1n_DAG.producer_1p_1n_1n_TASK manual__2026-02-23T12:30:32.913130+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:30:34,277 INFO - Sending TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:30:32.913130+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:30:34,277 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:30:32.913130+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:30:34,280 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p_1n_1n_DAG', 'producer_1p_1n_1n_TASK', 'manual__2026-02-23T12:30:32.913130+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p_1n_1n.py']
2026-02-23 20:30:38,565 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p_1n_1n_DAG', task_id='producer_1p_1n_1n_TASK', run_id='manual__2026-02-23T12:30:32.913130+00:00', try_number=1, map_index=-1)
2026-02-23 20:30:38,576 INFO - TaskInstance Finished: dag_id=producer_1p_1n_1n_DAG, task_id=producer_1p_1n_1n_TASK, run_id=manual__2026-02-23T12:30:32.913130+00:00, map_index=-1, run_start_date=2026-02-23 12:30:37.484847+00:00, run_end_date=2026-02-23 12:30:37.855549+00:00, run_duration=0.370702, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=168, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:30:34.273791+00:00, queued_by_job_id=164, pid=7226
2026-02-23 20:30:41,240 INFO - Marking run <DagRun producer_1p_1n_1n_DAG @ 2026-02-23 12:30:32.913130+00:00: manual__2026-02-23T12:30:32.913130+00:00, state:running, queued_at: 2026-02-23 12:30:32.933578+00:00. externally triggered: True> successful
2026-02-23 20:30:41,241 INFO - DagRun Finished: dag_id=producer_1p_1n_1n_DAG, execution_date=2026-02-23 12:30:32.913130+00:00, run_id=manual__2026-02-23T12:30:32.913130+00:00, run_start_date=2026-02-23 12:30:34.250160+00:00, run_end_date=2026-02-23 12:30:41.241086+00:00, run_duration=6.990926, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:30:32.913130+00:00, data_interval_end=2026-02-23 12:30:32.913130+00:00, dag_hash=0668088bbb31448c0150ccfb187b0b3b
2026-02-23 20:30:58,830 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:36:01,634 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:36:45,764 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p1n1n_DAG.producer_1p1n1n_TASK manual__2026-02-23T12:36:42.067898+00:00 [scheduled]>
2026-02-23 20:36:45,765 INFO - DAG producer_1p1n1n_DAG has 0/16 running and queued tasks
2026-02-23 20:36:45,766 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p1n1n_DAG.producer_1p1n1n_TASK manual__2026-02-23T12:36:42.067898+00:00 [scheduled]>
2026-02-23 20:36:45,768 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p1n1n_DAG.producer_1p1n1n_TASK manual__2026-02-23T12:36:42.067898+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:36:45,769 INFO - Sending TaskInstanceKey(dag_id='producer_1p1n1n_DAG', task_id='producer_1p1n1n_TASK', run_id='manual__2026-02-23T12:36:42.067898+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:36:45,770 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG', 'producer_1p1n1n_TASK', 'manual__2026-02-23T12:36:42.067898+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:36:45,772 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG', 'producer_1p1n1n_TASK', 'manual__2026-02-23T12:36:42.067898+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:36:49,699 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p1n1n_DAG', task_id='producer_1p1n1n_TASK', run_id='manual__2026-02-23T12:36:42.067898+00:00', try_number=1, map_index=-1)
2026-02-23 20:36:49,710 INFO - TaskInstance Finished: dag_id=producer_1p1n1n_DAG, task_id=producer_1p1n1n_TASK, run_id=manual__2026-02-23T12:36:42.067898+00:00, map_index=-1, run_start_date=2026-02-23 12:36:48.718285+00:00, run_end_date=2026-02-23 12:36:49.095870+00:00, run_duration=0.377585, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=169, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:36:45.767107+00:00, queued_by_job_id=164, pid=7418
2026-02-23 20:36:52,568 INFO - Marking run <DagRun producer_1p1n1n_DAG @ 2026-02-23 12:36:42.067898+00:00: manual__2026-02-23T12:36:42.067898+00:00, state:running, queued_at: 2026-02-23 12:36:42.100555+00:00. externally triggered: True> successful
2026-02-23 20:36:52,569 INFO - DagRun Finished: dag_id=producer_1p1n1n_DAG, execution_date=2026-02-23 12:36:42.067898+00:00, run_id=manual__2026-02-23T12:36:42.067898+00:00, run_start_date=2026-02-23 12:36:45.745761+00:00, run_end_date=2026-02-23 12:36:52.569726+00:00, run_duration=6.823965, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-23 12:36:42.067898+00:00, dag_hash=73eff315c4e370fe2fee9d0c70db841f
2026-02-23 20:41:04,025 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:42:46,838 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:42:43.289053+00:00 [scheduled]>
2026-02-23 20:42:46,839 INFO - DAG producer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:42:46,840 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:42:43.289053+00:00 [scheduled]>
2026-02-23 20:42:46,842 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:42:43.289053+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:42:46,843 INFO - Sending TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:42:43.289053+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:42:46,844 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:42:43.289053+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:42:46,847 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:42:43.289053+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:42:51,030 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:42:43.289053+00:00', try_number=1, map_index=-1)
2026-02-23 20:42:51,042 INFO - TaskInstance Finished: dag_id=producer_1p1n1n_DAG2, task_id=producer_1p1n1n_TASK2, run_id=manual__2026-02-23T12:42:43.289053+00:00, map_index=-1, run_start_date=2026-02-23 12:42:50.030507+00:00, run_end_date=2026-02-23 12:42:50.409909+00:00, run_duration=0.379402, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=170, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:42:46.841417+00:00, queued_by_job_id=164, pid=7611
2026-02-23 20:42:53,854 INFO - Marking run <DagRun producer_1p1n1n_DAG2 @ 2026-02-23 12:42:43.289053+00:00: manual__2026-02-23T12:42:43.289053+00:00, state:running, queued_at: 2026-02-23 12:42:43.299780+00:00. externally triggered: True> successful
2026-02-23 20:42:53,855 INFO - DagRun Finished: dag_id=producer_1p1n1n_DAG2, execution_date=2026-02-23 12:42:43.289053+00:00, run_id=manual__2026-02-23T12:42:43.289053+00:00, run_start_date=2026-02-23 12:42:46.817996+00:00, run_end_date=2026-02-23 12:42:53.855545+00:00, run_duration=7.037549, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:42:43.289053+00:00, data_interval_end=2026-02-23 12:42:43.289053+00:00, dag_hash=54a8a8f7dac833eb3120bed1fc344456
2026-02-23 20:42:53,865 INFO - 1 tasks up for execution:
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:42:50.427346+00:00 [scheduled]>
2026-02-23 20:42:53,865 INFO - DAG consumer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:42:53,866 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:42:50.427346+00:00 [scheduled]>
2026-02-23 20:42:53,868 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:42:50.427346+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:42:53,870 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:42:50.427346+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:42:53,870 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:42:50.427346+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:42:53,872 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:42:50.427346+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:42:57,575 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:42:50.427346+00:00', try_number=1, map_index=-1)
2026-02-23 20:42:57,586 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_DAG2, task_id=consumer_1p1n1n_TASK, run_id=dataset_triggered__2026-02-23T12:42:50.427346+00:00, map_index=-1, run_start_date=2026-02-23 12:42:56.613066+00:00, run_end_date=2026-02-23 12:42:57.010439+00:00, run_duration=0.397373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=171, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:42:53.867508+00:00, queued_by_job_id=164, pid=7615
2026-02-23 20:43:00,439 INFO - Marking run <DagRun consumer_1p1n1n_DAG2 @ 2026-02-23 12:42:50.427346+00:00: dataset_triggered__2026-02-23T12:42:50.427346+00:00, state:running, queued_at: 2026-02-23 12:42:53.818389+00:00. externally triggered: False> successful
2026-02-23 20:43:00,440 INFO - DagRun Finished: dag_id=consumer_1p1n1n_DAG2, execution_date=2026-02-23 12:42:50.427346+00:00, run_id=dataset_triggered__2026-02-23T12:42:50.427346+00:00, run_start_date=2026-02-23 12:42:53.841849+00:00, run_end_date=2026-02-23 12:43:00.440342+00:00, run_duration=6.598493, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-23 12:42:43.289053+00:00, dag_hash=0e218173cd11ca6528128f8aadab625f
2026-02-23 20:44:47,681 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:44:44.367568+00:00 [scheduled]>
2026-02-23 20:44:47,682 INFO - DAG producer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:44:47,682 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:44:44.367568+00:00 [scheduled]>
2026-02-23 20:44:47,684 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:44:44.367568+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:44:47,685 INFO - Sending TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:44:44.367568+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:44:47,686 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:44:44.367568+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:44:47,688 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:44:44.367568+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:44:51,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:44:44.367568+00:00', try_number=1, map_index=-1)
2026-02-23 20:44:51,801 INFO - TaskInstance Finished: dag_id=producer_1p1n1n_DAG2, task_id=producer_1p1n1n_TASK2, run_id=manual__2026-02-23T12:44:44.367568+00:00, map_index=-1, run_start_date=2026-02-23 12:44:50.769522+00:00, run_end_date=2026-02-23 12:44:51.155398+00:00, run_duration=0.385876, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=172, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:44:47.683745+00:00, queued_by_job_id=164, pid=7687
2026-02-23 20:44:54,322 INFO - Marking run <DagRun producer_1p1n1n_DAG2 @ 2026-02-23 12:44:44.367568+00:00: manual__2026-02-23T12:44:44.367568+00:00, state:running, queued_at: 2026-02-23 12:44:44.379953+00:00. externally triggered: True> successful
2026-02-23 20:44:54,324 INFO - DagRun Finished: dag_id=producer_1p1n1n_DAG2, execution_date=2026-02-23 12:44:44.367568+00:00, run_id=manual__2026-02-23T12:44:44.367568+00:00, run_start_date=2026-02-23 12:44:47.658753+00:00, run_end_date=2026-02-23 12:44:54.324019+00:00, run_duration=6.665266, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:44:44.367568+00:00, data_interval_end=2026-02-23 12:44:44.367568+00:00, dag_hash=54a8a8f7dac833eb3120bed1fc344456
2026-02-23 20:44:54,334 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:44:51.172956+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:44:51.175494+00:00 [scheduled]>
2026-02-23 20:44:54,335 INFO - DAG consumer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:44:54,335 INFO - DAG consumer_1p1n1n_2_DAG2 has 0/16 running and queued tasks
2026-02-23 20:44:54,336 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:44:51.172956+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:44:51.175494+00:00 [scheduled]>
2026-02-23 20:44:54,339 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:44:51.172956+00:00 [scheduled]>, <TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:44:51.175494+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:44:54,340 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:44:51.172956+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:44:54,341 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:44:51.172956+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:44:54,342 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:44:51.175494+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:44:54,342 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:44:51.175494+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:44:54,345 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:44:51.172956+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:44:58,172 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:44:51.175494+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:45:01,888 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:44:51.172956+00:00', try_number=1, map_index=-1)
2026-02-23 20:45:01,892 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:44:51.175494+00:00', try_number=1, map_index=-1)
2026-02-23 20:45:01,904 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_DAG2, task_id=consumer_1p1n1n_TASK, run_id=dataset_triggered__2026-02-23T12:44:51.172956+00:00, map_index=-1, run_start_date=2026-02-23 12:44:57.084589+00:00, run_end_date=2026-02-23 12:44:57.494667+00:00, run_duration=0.410078, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=173, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:44:54.337606+00:00, queued_by_job_id=164, pid=7692
2026-02-23 20:45:01,905 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_2_DAG2, task_id=consumer_1p1n1n_2_TASK, run_id=dataset_triggered__2026-02-23T12:44:51.175494+00:00, map_index=-1, run_start_date=2026-02-23 12:45:00.866084+00:00, run_end_date=2026-02-23 12:45:01.289128+00:00, run_duration=0.423044, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=174, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:44:54.337606+00:00, queued_by_job_id=164, pid=7697
2026-02-23 20:45:05,940 INFO - Marking run <DagRun consumer_1p1n1n_DAG2 @ 2026-02-23 12:44:51.172956+00:00: dataset_triggered__2026-02-23T12:44:51.172956+00:00, state:running, queued_at: 2026-02-23 12:44:54.285542+00:00. externally triggered: False> successful
2026-02-23 20:45:05,941 INFO - DagRun Finished: dag_id=consumer_1p1n1n_DAG2, execution_date=2026-02-23 12:44:51.172956+00:00, run_id=dataset_triggered__2026-02-23T12:44:51.172956+00:00, run_start_date=2026-02-23 12:44:54.306404+00:00, run_end_date=2026-02-23 12:45:05.941225+00:00, run_duration=11.634821, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:44:44.367568+00:00, data_interval_end=2026-02-23 12:44:44.367568+00:00, dag_hash=0e218173cd11ca6528128f8aadab625f
2026-02-23 20:45:05,956 INFO - Marking run <DagRun consumer_1p1n1n_2_DAG2 @ 2026-02-23 12:44:51.175494+00:00: dataset_triggered__2026-02-23T12:44:51.175494+00:00, state:running, queued_at: 2026-02-23 12:44:54.295007+00:00. externally triggered: False> successful
2026-02-23 20:45:05,959 INFO - DagRun Finished: dag_id=consumer_1p1n1n_2_DAG2, execution_date=2026-02-23 12:44:51.175494+00:00, run_id=dataset_triggered__2026-02-23T12:44:51.175494+00:00, run_start_date=2026-02-23 12:44:54.306517+00:00, run_end_date=2026-02-23 12:45:05.959922+00:00, run_duration=11.653405, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-23 12:44:44.367568+00:00, dag_hash=1dec3ea4c62eae8079bc8fe8ab2f2619
2026-02-23 20:46:05,126 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:47:38,954 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:47:37.536170+00:00 [scheduled]>
2026-02-23 20:47:38,954 INFO - DAG producer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:47:38,955 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:47:37.536170+00:00 [scheduled]>
2026-02-23 20:47:38,957 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:47:37.536170+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:47:38,958 INFO - Sending TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:47:37.536170+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:47:38,959 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:47:37.536170+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:47:38,961 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:47:37.536170+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:47:42,907 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:47:37.536170+00:00', try_number=1, map_index=-1)
2026-02-23 20:47:42,918 INFO - TaskInstance Finished: dag_id=producer_1p1n1n_DAG2, task_id=producer_1p1n1n_TASK2, run_id=manual__2026-02-23T12:47:37.536170+00:00, map_index=-1, run_start_date=2026-02-23 12:47:41.838649+00:00, run_end_date=2026-02-23 12:47:42.212661+00:00, run_duration=0.374012, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=175, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:47:38.956640+00:00, queued_by_job_id=164, pid=7789
2026-02-23 20:47:45,655 INFO - Marking run <DagRun producer_1p1n1n_DAG2 @ 2026-02-23 12:47:37.536170+00:00: manual__2026-02-23T12:47:37.536170+00:00, state:running, queued_at: 2026-02-23 12:47:37.547703+00:00. externally triggered: True> successful
2026-02-23 20:47:45,656 INFO - DagRun Finished: dag_id=producer_1p1n1n_DAG2, execution_date=2026-02-23 12:47:37.536170+00:00, run_id=manual__2026-02-23T12:47:37.536170+00:00, run_start_date=2026-02-23 12:47:38.933495+00:00, run_end_date=2026-02-23 12:47:45.656878+00:00, run_duration=6.723383, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:47:37.536170+00:00, data_interval_end=2026-02-23 12:47:37.536170+00:00, dag_hash=54a8a8f7dac833eb3120bed1fc344456
2026-02-23 20:47:45,666 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:47:42.229098+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:47:42.230542+00:00 [scheduled]>
2026-02-23 20:47:45,667 INFO - DAG consumer_1p1n1n_2_DAG2 has 0/16 running and queued tasks
2026-02-23 20:47:45,668 INFO - DAG consumer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:47:45,669 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:47:42.229098+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:47:42.230542+00:00 [scheduled]>
2026-02-23 20:47:45,671 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:47:42.229098+00:00 [scheduled]>, <TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:47:42.230542+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:47:45,672 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:47:42.229098+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:47:45,673 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:47:42.229098+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:47:45,674 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:47:42.230542+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:47:45,675 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:47:42.230542+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:47:45,677 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:47:42.229098+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:47:49,508 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:47:42.230542+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:47:53,462 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:47:42.229098+00:00', try_number=1, map_index=-1)
2026-02-23 20:47:53,466 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:47:42.230542+00:00', try_number=1, map_index=-1)
2026-02-23 20:47:53,475 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_DAG2, task_id=consumer_1p1n1n_TASK, run_id=dataset_triggered__2026-02-23T12:47:42.230542+00:00, map_index=-1, run_start_date=2026-02-23 12:47:52.336654+00:00, run_end_date=2026-02-23 12:47:52.758501+00:00, run_duration=0.421847, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=177, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:47:45.670492+00:00, queued_by_job_id=164, pid=7794
2026-02-23 20:47:53,476 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_2_DAG2, task_id=consumer_1p1n1n_2_TASK, run_id=dataset_triggered__2026-02-23T12:47:42.229098+00:00, map_index=-1, run_start_date=2026-02-23 12:47:48.454975+00:00, run_end_date=2026-02-23 12:47:48.835320+00:00, run_duration=0.380345, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=176, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:47:45.670492+00:00, queued_by_job_id=164, pid=7792
2026-02-23 20:47:55,904 INFO - Marking run <DagRun consumer_1p1n1n_2_DAG2 @ 2026-02-23 12:47:42.229098+00:00: dataset_triggered__2026-02-23T12:47:42.229098+00:00, state:running, queued_at: 2026-02-23 12:47:45.625390+00:00. externally triggered: False> successful
2026-02-23 20:47:55,905 INFO - DagRun Finished: dag_id=consumer_1p1n1n_2_DAG2, execution_date=2026-02-23 12:47:42.229098+00:00, run_id=dataset_triggered__2026-02-23T12:47:42.229098+00:00, run_start_date=2026-02-23 12:47:45.638055+00:00, run_end_date=2026-02-23 12:47:55.905428+00:00, run_duration=10.267373, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:47:37.536170+00:00, data_interval_end=2026-02-23 12:47:37.536170+00:00, dag_hash=1dec3ea4c62eae8079bc8fe8ab2f2619
2026-02-23 20:47:55,912 ERROR - Marking run <DagRun consumer_1p1n1n_DAG2 @ 2026-02-23 12:47:42.230542+00:00: dataset_triggered__2026-02-23T12:47:42.230542+00:00, state:running, queued_at: 2026-02-23 12:47:45.617308+00:00. externally triggered: False> failed
2026-02-23 20:47:55,913 INFO - DagRun Finished: dag_id=consumer_1p1n1n_DAG2, execution_date=2026-02-23 12:47:42.230542+00:00, run_id=dataset_triggered__2026-02-23T12:47:42.230542+00:00, run_start_date=2026-02-23 12:47:45.638161+00:00, run_end_date=2026-02-23 12:47:55.913509+00:00, run_duration=10.275348, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:47:37.536170+00:00, data_interval_end=2026-02-23 12:47:37.536170+00:00, dag_hash=0e218173cd11ca6528128f8aadab625f
2026-02-23 20:48:38,761 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:48:35.015388+00:00 [scheduled]>
2026-02-23 20:48:38,762 INFO - DAG producer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:48:38,763 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:48:35.015388+00:00 [scheduled]>
2026-02-23 20:48:38,765 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:48:35.015388+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:48:38,766 INFO - Sending TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:48:35.015388+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:48:38,767 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:48:35.015388+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:48:38,769 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:48:35.015388+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:48:42,813 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:48:35.015388+00:00', try_number=1, map_index=-1)
2026-02-23 20:48:42,824 INFO - TaskInstance Finished: dag_id=producer_1p1n1n_DAG2, task_id=producer_1p1n1n_TASK2, run_id=manual__2026-02-23T12:48:35.015388+00:00, map_index=-1, run_start_date=2026-02-23 12:48:41.643936+00:00, run_end_date=2026-02-23 12:48:42.041275+00:00, run_duration=0.397339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=178, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:48:38.764393+00:00, queued_by_job_id=164, pid=7829
2026-02-23 20:48:45,461 INFO - Marking run <DagRun producer_1p1n1n_DAG2 @ 2026-02-23 12:48:35.015388+00:00: manual__2026-02-23T12:48:35.015388+00:00, state:running, queued_at: 2026-02-23 12:48:35.029627+00:00. externally triggered: True> successful
2026-02-23 20:48:45,462 INFO - DagRun Finished: dag_id=producer_1p1n1n_DAG2, execution_date=2026-02-23 12:48:35.015388+00:00, run_id=manual__2026-02-23T12:48:35.015388+00:00, run_start_date=2026-02-23 12:48:38.743692+00:00, run_end_date=2026-02-23 12:48:45.462597+00:00, run_duration=6.718905, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:48:35.015388+00:00, data_interval_end=2026-02-23 12:48:35.015388+00:00, dag_hash=54a8a8f7dac833eb3120bed1fc344456
2026-02-23 20:48:45,473 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:48:42.060509+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:48:42.062035+00:00 [scheduled]>
2026-02-23 20:48:45,474 INFO - DAG consumer_1p1n1n_2_DAG2 has 0/16 running and queued tasks
2026-02-23 20:48:45,474 INFO - DAG consumer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:48:45,475 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:48:42.060509+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:48:42.062035+00:00 [scheduled]>
2026-02-23 20:48:45,478 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:48:42.060509+00:00 [scheduled]>, <TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:48:42.062035+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:48:45,479 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:48:42.060509+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:48:45,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:48:42.060509+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:48:45,480 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:48:42.062035+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:48:45,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:48:42.062035+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:48:45,483 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:48:42.060509+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:48:49,364 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:48:42.062035+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:48:53,063 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:48:42.060509+00:00', try_number=1, map_index=-1)
2026-02-23 20:48:53,066 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:48:42.062035+00:00', try_number=1, map_index=-1)
2026-02-23 20:48:53,075 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_DAG2, task_id=consumer_1p1n1n_TASK, run_id=dataset_triggered__2026-02-23T12:48:42.062035+00:00, map_index=-1, run_start_date=2026-02-23 12:48:52.028771+00:00, run_end_date=2026-02-23 12:48:52.409983+00:00, run_duration=0.381212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=180, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:48:45.476693+00:00, queued_by_job_id=164, pid=7834
2026-02-23 20:48:53,076 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_2_DAG2, task_id=consumer_1p1n1n_2_TASK, run_id=dataset_triggered__2026-02-23T12:48:42.060509+00:00, map_index=-1, run_start_date=2026-02-23 12:48:48.245563+00:00, run_end_date=2026-02-23 12:48:48.650219+00:00, run_duration=0.404656, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=179, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:48:45.476693+00:00, queued_by_job_id=164, pid=7832
2026-02-23 20:48:55,877 INFO - Marking run <DagRun consumer_1p1n1n_2_DAG2 @ 2026-02-23 12:48:42.060509+00:00: dataset_triggered__2026-02-23T12:48:42.060509+00:00, state:running, queued_at: 2026-02-23 12:48:45.431483+00:00. externally triggered: False> successful
2026-02-23 20:48:55,878 INFO - DagRun Finished: dag_id=consumer_1p1n1n_2_DAG2, execution_date=2026-02-23 12:48:42.060509+00:00, run_id=dataset_triggered__2026-02-23T12:48:42.060509+00:00, run_start_date=2026-02-23 12:48:45.444466+00:00, run_end_date=2026-02-23 12:48:55.878238+00:00, run_duration=10.433772, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:48:35.015388+00:00, data_interval_end=2026-02-23 12:48:35.015388+00:00, dag_hash=1dec3ea4c62eae8079bc8fe8ab2f2619
2026-02-23 20:48:55,883 INFO - Marking run <DagRun consumer_1p1n1n_DAG2 @ 2026-02-23 12:48:42.062035+00:00: dataset_triggered__2026-02-23T12:48:42.062035+00:00, state:running, queued_at: 2026-02-23 12:48:45.422572+00:00. externally triggered: False> successful
2026-02-23 20:48:55,884 INFO - DagRun Finished: dag_id=consumer_1p1n1n_DAG2, execution_date=2026-02-23 12:48:42.062035+00:00, run_id=dataset_triggered__2026-02-23T12:48:42.062035+00:00, run_start_date=2026-02-23 12:48:45.444583+00:00, run_end_date=2026-02-23 12:48:55.884490+00:00, run_duration=10.439907, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:48:35.015388+00:00, data_interval_end=2026-02-23 12:48:35.015388+00:00, dag_hash=0e218173cd11ca6528128f8aadab625f
2026-02-23 20:51:05,744 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:56:05,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 20:57:44,167 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:57:40.059074+00:00 [scheduled]>
2026-02-23 20:57:44,168 INFO - DAG producer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:57:44,169 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:57:40.059074+00:00 [scheduled]>
2026-02-23 20:57:44,171 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T12:57:40.059074+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:57:44,172 INFO - Sending TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:57:40.059074+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:57:44,173 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:57:40.059074+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:57:44,176 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T12:57:40.059074+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:57:48,337 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T12:57:40.059074+00:00', try_number=1, map_index=-1)
2026-02-23 20:57:48,348 INFO - TaskInstance Finished: dag_id=producer_1p1n1n_DAG2, task_id=producer_1p1n1n_TASK2, run_id=manual__2026-02-23T12:57:40.059074+00:00, map_index=-1, run_start_date=2026-02-23 12:57:47.256474+00:00, run_end_date=2026-02-23 12:57:47.640973+00:00, run_duration=0.384499, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=181, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:57:44.170339+00:00, queued_by_job_id=164, pid=8119
2026-02-23 20:57:50,896 INFO - Marking run <DagRun producer_1p1n1n_DAG2 @ 2026-02-23 12:57:40.059074+00:00: manual__2026-02-23T12:57:40.059074+00:00, state:running, queued_at: 2026-02-23 12:57:40.076516+00:00. externally triggered: True> successful
2026-02-23 20:57:50,897 INFO - DagRun Finished: dag_id=producer_1p1n1n_DAG2, execution_date=2026-02-23 12:57:40.059074+00:00, run_id=manual__2026-02-23T12:57:40.059074+00:00, run_start_date=2026-02-23 12:57:44.146568+00:00, run_end_date=2026-02-23 12:57:50.897618+00:00, run_duration=6.75105, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 12:57:40.059074+00:00, data_interval_end=2026-02-23 12:57:40.059074+00:00, dag_hash=54a8a8f7dac833eb3120bed1fc344456
2026-02-23 20:57:50,907 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:57:47.658868+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:57:47.660222+00:00 [scheduled]>
2026-02-23 20:57:50,908 INFO - DAG consumer_1p1n1n_2_DAG2 has 0/16 running and queued tasks
2026-02-23 20:57:50,909 INFO - DAG consumer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 20:57:50,910 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:57:47.658868+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:57:47.660222+00:00 [scheduled]>
2026-02-23 20:57:50,913 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T12:57:47.658868+00:00 [scheduled]>, <TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T12:57:47.660222+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 20:57:50,914 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:57:47.658868+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:57:50,914 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:57:47.658868+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:57:50,915 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:57:47.660222+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 20:57:50,916 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:57:47.660222+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:57:50,918 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T12:57:47.658868+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:57:54,804 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T12:57:47.660222+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1_producer_N_consumer2.py']
2026-02-23 20:57:58,631 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T12:57:47.658868+00:00', try_number=1, map_index=-1)
2026-02-23 20:57:58,634 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T12:57:47.660222+00:00', try_number=1, map_index=-1)
2026-02-23 20:57:58,645 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_DAG2, task_id=consumer_1p1n1n_TASK, run_id=dataset_triggered__2026-02-23T12:57:47.660222+00:00, map_index=-1, run_start_date=2026-02-23 12:57:57.592466+00:00, run_end_date=2026-02-23 12:57:57.980252+00:00, run_duration=0.387786, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=183, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:57:50.911672+00:00, queued_by_job_id=164, pid=8124
2026-02-23 20:57:58,646 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_2_DAG2, task_id=consumer_1p1n1n_2_TASK, run_id=dataset_triggered__2026-02-23T12:57:47.658868+00:00, map_index=-1, run_start_date=2026-02-23 12:57:53.713484+00:00, run_end_date=2026-02-23 12:57:54.122157+00:00, run_duration=0.408673, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=182, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 12:57:50.911672+00:00, queued_by_job_id=164, pid=8122
2026-02-23 20:58:01,321 INFO - Marking run <DagRun consumer_1p1n1n_2_DAG2 @ 2026-02-23 12:57:47.658868+00:00: dataset_triggered__2026-02-23T12:57:47.658868+00:00, state:running, queued_at: 2026-02-23 12:57:50.865017+00:00. externally triggered: False> successful
2026-02-23 20:58:01,322 INFO - DagRun Finished: dag_id=consumer_1p1n1n_2_DAG2, execution_date=2026-02-23 12:57:47.658868+00:00, run_id=dataset_triggered__2026-02-23T12:57:47.658868+00:00, run_start_date=2026-02-23 12:57:50.878467+00:00, run_end_date=2026-02-23 12:58:01.322407+00:00, run_duration=10.44394, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:57:40.059074+00:00, data_interval_end=2026-02-23 12:57:40.059074+00:00, dag_hash=1dec3ea4c62eae8079bc8fe8ab2f2619
2026-02-23 20:58:01,328 INFO - Marking run <DagRun consumer_1p1n1n_DAG2 @ 2026-02-23 12:57:47.660222+00:00: dataset_triggered__2026-02-23T12:57:47.660222+00:00, state:running, queued_at: 2026-02-23 12:57:50.855560+00:00. externally triggered: False> successful
2026-02-23 20:58:01,329 INFO - DagRun Finished: dag_id=consumer_1p1n1n_DAG2, execution_date=2026-02-23 12:57:47.660222+00:00, run_id=dataset_triggered__2026-02-23T12:57:47.660222+00:00, run_start_date=2026-02-23 12:57:50.878575+00:00, run_end_date=2026-02-23 12:58:01.329360+00:00, run_duration=10.450785, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:57:40.059074+00:00, data_interval_end=2026-02-23 12:57:40.059074+00:00, dag_hash=0e218173cd11ca6528128f8aadab625f
2026-02-23 21:01:07,925 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:05:56,889 INFO - 1 tasks up for execution:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T13:05:54.745009+00:00 [scheduled]>
2026-02-23 21:05:56,890 INFO - DAG producer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 21:05:56,891 INFO - Setting the following tasks to queued state:
	<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T13:05:54.745009+00:00 [scheduled]>
2026-02-23 21:05:56,893 INFO - Trying to enqueue tasks: [<TaskInstance: producer_1p1n1n_DAG2.producer_1p1n1n_TASK2 manual__2026-02-23T13:05:54.745009+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:05:56,894 INFO - Sending TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T13:05:54.745009+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:05:56,895 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T13:05:54.745009+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:05:56,897 INFO - Executing command: ['airflow', 'tasks', 'run', 'producer_1p1n1n_DAG2', 'producer_1p1n1n_TASK2', 'manual__2026-02-23T13:05:54.745009+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:06:01,164 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='producer_1p1n1n_DAG2', task_id='producer_1p1n1n_TASK2', run_id='manual__2026-02-23T13:05:54.745009+00:00', try_number=1, map_index=-1)
2026-02-23 21:06:01,177 INFO - TaskInstance Finished: dag_id=producer_1p1n1n_DAG2, task_id=producer_1p1n1n_TASK2, run_id=manual__2026-02-23T13:05:54.745009+00:00, map_index=-1, run_start_date=2026-02-23 13:06:00.077113+00:00, run_end_date=2026-02-23 13:06:00.433427+00:00, run_duration=0.356314, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=184, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:05:56.892275+00:00, queued_by_job_id=164, pid=8388
2026-02-23 21:06:03,985 INFO - Marking run <DagRun producer_1p1n1n_DAG2 @ 2026-02-23 13:05:54.745009+00:00: manual__2026-02-23T13:05:54.745009+00:00, state:running, queued_at: 2026-02-23 13:05:54.757991+00:00. externally triggered: True> successful
2026-02-23 21:06:03,986 INFO - DagRun Finished: dag_id=producer_1p1n1n_DAG2, execution_date=2026-02-23 13:05:54.745009+00:00, run_id=manual__2026-02-23T13:05:54.745009+00:00, run_start_date=2026-02-23 13:05:56.866943+00:00, run_end_date=2026-02-23 13:06:03.986864+00:00, run_duration=7.119921, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:05:54.745009+00:00, data_interval_end=2026-02-23 13:05:54.745009+00:00, dag_hash=afab7f3ad8e780ea6c3bfb9334342fad
2026-02-23 21:06:03,996 INFO - 2 tasks up for execution:
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T13:06:00.449957+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T13:06:00.451215+00:00 [scheduled]>
2026-02-23 21:06:03,997 INFO - DAG consumer_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 21:06:03,998 INFO - DAG consumer_1p1n1n_2_DAG2 has 0/16 running and queued tasks
2026-02-23 21:06:03,999 INFO - Setting the following tasks to queued state:
	<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T13:06:00.449957+00:00 [scheduled]>
	<TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T13:06:00.451215+00:00 [scheduled]>
2026-02-23 21:06:04,001 INFO - Trying to enqueue tasks: [<TaskInstance: consumer_1p1n1n_DAG2.consumer_1p1n1n_TASK dataset_triggered__2026-02-23T13:06:00.449957+00:00 [scheduled]>, <TaskInstance: consumer_1p1n1n_2_DAG2.consumer_1p1n1n_2_TASK dataset_triggered__2026-02-23T13:06:00.451215+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:06:04,002 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T13:06:00.449957+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:06:04,003 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T13:06:00.449957+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:06:04,004 INFO - Sending TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T13:06:00.451215+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:06:04,005 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T13:06:00.451215+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:06:04,008 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_DAG2', 'consumer_1p1n1n_TASK', 'dataset_triggered__2026-02-23T13:06:00.449957+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:06:07,727 INFO - Executing command: ['airflow', 'tasks', 'run', 'consumer_1p1n1n_2_DAG2', 'consumer_1p1n1n_2_TASK', 'dataset_triggered__2026-02-23T13:06:00.451215+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:06:11,587 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_DAG2', task_id='consumer_1p1n1n_TASK', run_id='dataset_triggered__2026-02-23T13:06:00.449957+00:00', try_number=1, map_index=-1)
2026-02-23 21:06:11,590 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='consumer_1p1n1n_2_DAG2', task_id='consumer_1p1n1n_2_TASK', run_id='dataset_triggered__2026-02-23T13:06:00.451215+00:00', try_number=1, map_index=-1)
2026-02-23 21:06:11,599 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_DAG2, task_id=consumer_1p1n1n_TASK, run_id=dataset_triggered__2026-02-23T13:06:00.449957+00:00, map_index=-1, run_start_date=2026-02-23 13:06:06.682007+00:00, run_end_date=2026-02-23 13:06:07.064336+00:00, run_duration=0.382329, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=185, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:06:04.000229+00:00, queued_by_job_id=164, pid=8395
2026-02-23 21:06:11,600 INFO - TaskInstance Finished: dag_id=consumer_1p1n1n_2_DAG2, task_id=consumer_1p1n1n_2_TASK, run_id=dataset_triggered__2026-02-23T13:06:00.451215+00:00, map_index=-1, run_start_date=2026-02-23 13:06:10.512219+00:00, run_end_date=2026-02-23 13:06:10.882436+00:00, run_duration=0.370217, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=186, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:06:04.000229+00:00, queued_by_job_id=164, pid=8397
2026-02-23 21:06:11,630 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:06:14,246 INFO - Marking run <DagRun consumer_1p1n1n_DAG2 @ 2026-02-23 13:06:00.449957+00:00: dataset_triggered__2026-02-23T13:06:00.449957+00:00, state:running, queued_at: 2026-02-23 13:06:03.945720+00:00. externally triggered: False> successful
2026-02-23 21:06:14,247 INFO - DagRun Finished: dag_id=consumer_1p1n1n_DAG2, execution_date=2026-02-23 13:06:00.449957+00:00, run_id=dataset_triggered__2026-02-23T13:06:00.449957+00:00, run_start_date=2026-02-23 13:06:03.969085+00:00, run_end_date=2026-02-23 13:06:14.247827+00:00, run_duration=10.278742, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:05:54.745009+00:00, data_interval_end=2026-02-23 13:05:54.745009+00:00, dag_hash=55a5868a6acc4dd0b1aaea6c342baf1f
2026-02-23 21:06:14,252 INFO - Marking run <DagRun consumer_1p1n1n_2_DAG2 @ 2026-02-23 13:06:00.451215+00:00: dataset_triggered__2026-02-23T13:06:00.451215+00:00, state:running, queued_at: 2026-02-23 13:06:03.954555+00:00. externally triggered: False> successful
2026-02-23 21:06:14,253 INFO - DagRun Finished: dag_id=consumer_1p1n1n_2_DAG2, execution_date=2026-02-23 13:06:00.451215+00:00, run_id=dataset_triggered__2026-02-23T13:06:00.451215+00:00, run_start_date=2026-02-23 13:06:03.969224+00:00, run_end_date=2026-02-23 13:06:14.253253+00:00, run_duration=10.284029, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:05:54.745009+00:00, data_interval_end=2026-02-23 13:05:54.745009+00:00, dag_hash=00ef0ba92dda97741bce243dcc0589ef
2026-02-23 21:11:13,281 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:16:15,112 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:18:50,210 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:18:49.137091+00:00 [scheduled]>
2026-02-23 21:18:50,211 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-23 21:18:50,212 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:18:49.137091+00:00 [scheduled]>
2026-02-23 21:18:50,215 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:18:49.137091+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:18:50,217 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:18:49.137091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:18:50,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:18:49.137091+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:18:50,220 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:18:49.137091+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:18:54,394 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:18:49.137091+00:00', try_number=1, map_index=-1)
2026-02-23 21:18:54,409 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-23T13:18:49.137091+00:00, map_index=-1, run_start_date=2026-02-23 13:18:53.426174+00:00, run_end_date=2026-02-23 13:18:53.793030+00:00, run_duration=0.366856, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=187, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:18:50.214607+00:00, queued_by_job_id=164, pid=8813
2026-02-23 21:18:57,414 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:18:57,454 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-23 13:18:49.137091+00:00: manual__2026-02-23T13:18:49.137091+00:00, state:running, queued_at: 2026-02-23 13:18:49.148228+00:00. externally triggered: True> successful
2026-02-23 21:18:57,455 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-23 13:18:49.137091+00:00, run_id=manual__2026-02-23T13:18:49.137091+00:00, run_start_date=2026-02-23 13:18:50.190129+00:00, run_end_date=2026-02-23 13:18:57.455109+00:00, run_duration=7.26498, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:18:49.137091+00:00, data_interval_end=2026-02-23 13:18:49.137091+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-23 21:18:57,465 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_1_DAGs.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:18:53.809970+00:00 [scheduled]>
2026-02-23 21:18:57,466 INFO - DAG c_1p1n1n_1_DAGs has 0/16 running and queued tasks
2026-02-23 21:18:57,467 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_1_DAGs.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:18:53.809970+00:00 [scheduled]>
2026-02-23 21:18:57,469 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_1_DAGs.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:18:53.809970+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:18:57,470 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_1_DAGs', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:18:53.809970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:18:57,471 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_1_DAGs', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:18:53.809970+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:18:57,473 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_1_DAGs', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:18:53.809970+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:19:01,272 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_1_DAGs', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:18:53.809970+00:00', try_number=1, map_index=-1)
2026-02-23 21:19:01,282 INFO - TaskInstance Finished: dag_id=c_1p1n1n_1_DAGs, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-23T13:18:53.809970+00:00, map_index=-1, run_start_date=2026-02-23 13:19:00.304786+00:00, run_end_date=2026-02-23 13:19:00.690528+00:00, run_duration=0.385742, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=188, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:18:57.468149+00:00, queued_by_job_id=164, pid=8818
2026-02-23 21:19:04,413 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:04,430 INFO - Marking run <DagRun c_1p1n1n_1_DAGs @ 2026-02-23 13:18:53.809970+00:00: dataset_triggered__2026-02-23T13:18:53.809970+00:00, state:running, queued_at: 2026-02-23 13:18:57.424835+00:00. externally triggered: False> successful
2026-02-23 21:19:04,432 INFO - DagRun Finished: dag_id=c_1p1n1n_1_DAGs, execution_date=2026-02-23 13:18:53.809970+00:00, run_id=dataset_triggered__2026-02-23T13:18:53.809970+00:00, run_start_date=2026-02-23 13:18:57.441030+00:00, run_end_date=2026-02-23 13:19:04.432380+00:00, run_duration=6.99135, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-23 13:18:49.137091+00:00, dag_hash=0c0646a7d506eccf16b3d0f38735f60f
2026-02-23 21:19:08,723 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:13,033 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:16,776 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:20,794 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:24,997 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:28,959 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:33,425 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:37,739 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:41,533 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:44,529 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:19:48,305 ERROR - DAG 'c_1p1n1n_DAGs' not found in serialized_dag table
2026-02-23 21:20:33,632 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:20:30.038826+00:00 [scheduled]>
2026-02-23 21:20:33,633 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-23 21:20:33,634 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:20:30.038826+00:00 [scheduled]>
2026-02-23 21:20:33,636 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:20:30.038826+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:20:33,637 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:20:30.038826+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:20:33,638 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:20:30.038826+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:20:33,640 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:20:30.038826+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:20:37,759 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:20:30.038826+00:00', try_number=1, map_index=-1)
2026-02-23 21:20:37,770 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-23T13:20:30.038826+00:00, map_index=-1, run_start_date=2026-02-23 13:20:36.626837+00:00, run_end_date=2026-02-23 13:20:37.068065+00:00, run_duration=0.441228, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=189, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:20:33.635423+00:00, queued_by_job_id=164, pid=8877
2026-02-23 21:20:40,472 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-23 13:20:30.038826+00:00: manual__2026-02-23T13:20:30.038826+00:00, state:running, queued_at: 2026-02-23 13:20:30.050255+00:00. externally triggered: True> successful
2026-02-23 21:20:40,473 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-23 13:20:30.038826+00:00, run_id=manual__2026-02-23T13:20:30.038826+00:00, run_start_date=2026-02-23 13:20:33.612090+00:00, run_end_date=2026-02-23 13:20:40.473035+00:00, run_duration=6.860945, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:20:30.038826+00:00, data_interval_end=2026-02-23 13:20:30.038826+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-23 21:20:40,483 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p1n1n_2_DAGs.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:20:37.085461+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_1_DAGs.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:20:37.087075+00:00 [scheduled]>
2026-02-23 21:20:40,484 INFO - DAG c_1p1n1n_2_DAGs has 0/16 running and queued tasks
2026-02-23 21:20:40,484 INFO - DAG c_1p1n1n_1_DAGs has 0/16 running and queued tasks
2026-02-23 21:20:40,485 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_2_DAGs.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:20:37.085461+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_1_DAGs.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:20:37.087075+00:00 [scheduled]>
2026-02-23 21:20:40,488 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_2_DAGs.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:20:37.085461+00:00 [scheduled]>, <TaskInstance: c_1p1n1n_1_DAGs.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:20:37.087075+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:20:40,489 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_2_DAGs', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-23T13:20:37.085461+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:20:40,490 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_2_DAGs', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-23T13:20:37.085461+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:20:40,490 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_1_DAGs', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:20:37.087075+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:20:40,491 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_1_DAGs', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:20:37.087075+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:20:40,493 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_2_DAGs', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-23T13:20:37.085461+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:20:44,216 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_1_DAGs', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:20:37.087075+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:20:47,995 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_2_DAGs', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-23T13:20:37.085461+00:00', try_number=1, map_index=-1)
2026-02-23 21:20:47,999 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_1_DAGs', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:20:37.087075+00:00', try_number=1, map_index=-1)
2026-02-23 21:20:48,008 INFO - TaskInstance Finished: dag_id=c_1p1n1n_1_DAGs, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-23T13:20:37.087075+00:00, map_index=-1, run_start_date=2026-02-23 13:20:46.931299+00:00, run_end_date=2026-02-23 13:20:47.313717+00:00, run_duration=0.382418, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=191, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:20:40.486847+00:00, queued_by_job_id=164, pid=8882
2026-02-23 21:20:48,010 INFO - TaskInstance Finished: dag_id=c_1p1n1n_2_DAGs, task_id=c_1p1n1n_TASK2, run_id=dataset_triggered__2026-02-23T13:20:37.085461+00:00, map_index=-1, run_start_date=2026-02-23 13:20:43.257948+00:00, run_end_date=2026-02-23 13:20:43.658625+00:00, run_duration=0.400677, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=190, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:20:40.486847+00:00, queued_by_job_id=164, pid=8880
2026-02-23 21:20:50,961 INFO - Marking run <DagRun c_1p1n1n_2_DAGs @ 2026-02-23 13:20:37.085461+00:00: dataset_triggered__2026-02-23T13:20:37.085461+00:00, state:running, queued_at: 2026-02-23 13:20:40.440889+00:00. externally triggered: False> successful
2026-02-23 21:20:50,962 INFO - DagRun Finished: dag_id=c_1p1n1n_2_DAGs, execution_date=2026-02-23 13:20:37.085461+00:00, run_id=dataset_triggered__2026-02-23T13:20:37.085461+00:00, run_start_date=2026-02-23 13:20:40.455103+00:00, run_end_date=2026-02-23 13:20:50.962424+00:00, run_duration=10.507321, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-23 13:20:30.038826+00:00, dag_hash=8016e1e417c02ba35d885e5df125f601
2026-02-23 21:20:50,970 INFO - Marking run <DagRun c_1p1n1n_1_DAGs @ 2026-02-23 13:20:37.087075+00:00: dataset_triggered__2026-02-23T13:20:37.087075+00:00, state:running, queued_at: 2026-02-23 13:20:40.427938+00:00. externally triggered: False> successful
2026-02-23 21:20:50,971 INFO - DagRun Finished: dag_id=c_1p1n1n_1_DAGs, execution_date=2026-02-23 13:20:37.087075+00:00, run_id=dataset_triggered__2026-02-23T13:20:37.087075+00:00, run_start_date=2026-02-23 13:20:40.455208+00:00, run_end_date=2026-02-23 13:20:50.971687+00:00, run_duration=10.516479, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:20:30.038826+00:00, data_interval_end=2026-02-23 13:20:30.038826+00:00, dag_hash=0c0646a7d506eccf16b3d0f38735f60f
2026-02-23 21:21:18,164 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:26:18,420 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:29:19,453 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:29:18.234249+00:00 [scheduled]>
2026-02-23 21:29:19,454 INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
2026-02-23 21:29:19,455 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:29:18.234249+00:00 [scheduled]>
2026-02-23 21:29:19,458 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:29:18.234249+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:29:19,459 INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:29:18.234249+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:29:19,460 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:29:18.234249+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:29:19,464 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:29:18.234249+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:29:23,883 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:29:18.234249+00:00', try_number=1, map_index=-1)
2026-02-23 21:29:23,896 INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-23T13:29:18.234249+00:00, map_index=-1, run_start_date=2026-02-23 13:29:22.928509+00:00, run_end_date=2026-02-23 13:29:23.324867+00:00, run_duration=0.396358, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=192, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:29:19.457028+00:00, queued_by_job_id=164, pid=9161
2026-02-23 21:29:27,104 INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-23 13:29:18.234249+00:00: manual__2026-02-23T13:29:18.234249+00:00, state:running, queued_at: 2026-02-23 13:29:18.247767+00:00. externally triggered: True> successful
2026-02-23 21:29:27,105 INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-23 13:29:18.234249+00:00, run_id=manual__2026-02-23T13:29:18.234249+00:00, run_start_date=2026-02-23 13:29:19.433367+00:00, run_end_date=2026-02-23 13:29:27.105695+00:00, run_duration=7.672328, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:29:18.234249+00:00, data_interval_end=2026-02-23 13:29:18.234249+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
2026-02-23 21:31:19,598 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:32:29,876 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:32:26.175750+00:00 [scheduled]>
2026-02-23 21:32:29,877 INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
2026-02-23 21:32:29,878 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:32:26.175750+00:00 [scheduled]>
2026-02-23 21:32:29,880 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:32:26.175750+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:32:29,881 INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:32:26.175750+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:32:29,882 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:32:26.175750+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:32:29,884 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:32:26.175750+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:32:34,105 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:32:26.175750+00:00', try_number=1, map_index=-1)
2026-02-23 21:32:34,115 INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-23T13:32:26.175750+00:00, map_index=-1, run_start_date=2026-02-23 13:32:33.064195+00:00, run_end_date=2026-02-23 13:32:33.442117+00:00, run_duration=0.377922, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=193, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:32:29.879206+00:00, queued_by_job_id=164, pid=9270
2026-02-23 21:32:37,073 INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-23 13:32:26.175750+00:00: manual__2026-02-23T13:32:26.175750+00:00, state:running, queued_at: 2026-02-23 13:32:26.190045+00:00. externally triggered: True> successful
2026-02-23 21:32:37,074 INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-23 13:32:26.175750+00:00, run_id=manual__2026-02-23T13:32:26.175750+00:00, run_start_date=2026-02-23 13:32:29.856149+00:00, run_end_date=2026-02-23 13:32:37.074262+00:00, run_duration=7.218113, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:32:26.175750+00:00, data_interval_end=2026-02-23 13:32:26.175750+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
2026-02-23 21:32:37,083 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:32:33.460676+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:32:33.462182+00:00 [scheduled]>
2026-02-23 21:32:37,084 INFO - DAG c_1p2n_DAG2 has 0/16 running and queued tasks
2026-02-23 21:32:37,085 INFO - DAG c_1p2n_DAG1 has 0/16 running and queued tasks
2026-02-23 21:32:37,086 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:32:33.460676+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:32:33.462182+00:00 [scheduled]>
2026-02-23 21:32:37,088 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:32:33.460676+00:00 [scheduled]>, <TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:32:33.462182+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:32:37,089 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-23T13:32:33.460676+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:32:37,090 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-23T13:32:33.460676+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:32:37,091 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-23T13:32:33.462182+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:32:37,092 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-23T13:32:33.462182+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:32:37,094 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-23T13:32:33.460676+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:32:40,937 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-23T13:32:33.462182+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:32:44,603 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-23T13:32:33.460676+00:00', try_number=1, map_index=-1)
2026-02-23 21:32:44,605 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-23T13:32:33.462182+00:00', try_number=1, map_index=-1)
2026-02-23 21:32:44,613 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG2, task_id=c_1p2n_TASK2, run_id=dataset_triggered__2026-02-23T13:32:33.460676+00:00, map_index=-1, run_start_date=2026-02-23 13:32:39.941758+00:00, run_end_date=2026-02-23 13:32:40.333680+00:00, run_duration=0.391922, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=194, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:32:37.087183+00:00, queued_by_job_id=164, pid=9273
2026-02-23 21:32:44,615 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG1, task_id=c_1p2n_TASK1, run_id=dataset_triggered__2026-02-23T13:32:33.462182+00:00, map_index=-1, run_start_date=2026-02-23 13:32:43.601951+00:00, run_end_date=2026-02-23 13:32:43.968855+00:00, run_duration=0.366904, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=195, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:32:37.087183+00:00, queued_by_job_id=164, pid=9275
2026-02-23 21:32:47,388 INFO - Marking run <DagRun c_1p2n_DAG2 @ 2026-02-23 13:32:33.460676+00:00: dataset_triggered__2026-02-23T13:32:33.460676+00:00, state:running, queued_at: 2026-02-23 13:32:37.033464+00:00. externally triggered: False> successful
2026-02-23 21:32:47,389 INFO - DagRun Finished: dag_id=c_1p2n_DAG2, execution_date=2026-02-23 13:32:33.460676+00:00, run_id=dataset_triggered__2026-02-23T13:32:33.460676+00:00, run_start_date=2026-02-23 13:32:37.055947+00:00, run_end_date=2026-02-23 13:32:47.388884+00:00, run_duration=10.332937, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:29:18.234249+00:00, data_interval_end=2026-02-23 13:32:26.175750+00:00, dag_hash=354e8496efd6843df9de6fdd1d1833e5
2026-02-23 21:32:47,394 INFO - Marking run <DagRun c_1p2n_DAG1 @ 2026-02-23 13:32:33.462182+00:00: dataset_triggered__2026-02-23T13:32:33.462182+00:00, state:running, queued_at: 2026-02-23 13:32:37.041668+00:00. externally triggered: False> successful
2026-02-23 21:32:47,395 INFO - DagRun Finished: dag_id=c_1p2n_DAG1, execution_date=2026-02-23 13:32:33.462182+00:00, run_id=dataset_triggered__2026-02-23T13:32:33.462182+00:00, run_start_date=2026-02-23 13:32:37.056054+00:00, run_end_date=2026-02-23 13:32:47.395757+00:00, run_duration=10.339703, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:29:18.234249+00:00, data_interval_end=2026-02-23 13:32:26.175750+00:00, dag_hash=4a31cc71e5398c53fad0c9cea1feb380
2026-02-23 21:34:38,752 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:34:36.159302+00:00 [scheduled]>
2026-02-23 21:34:38,753 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-23 21:34:38,753 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:34:36.159302+00:00 [scheduled]>
2026-02-23 21:34:38,756 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:34:36.159302+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:34:38,757 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:34:36.159302+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:34:38,758 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:34:36.159302+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:34:38,760 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:34:36.159302+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:34:42,626 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:34:36.159302+00:00', try_number=1, map_index=-1)
2026-02-23 21:34:42,636 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-23T13:34:36.159302+00:00, map_index=-1, run_start_date=2026-02-23 13:34:41.565426+00:00, run_end_date=2026-02-23 13:34:41.928499+00:00, run_duration=0.363073, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=196, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:34:38.755521+00:00, queued_by_job_id=164, pid=9350
2026-02-23 21:34:45,465 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-23 13:34:36.159302+00:00: manual__2026-02-23T13:34:36.159302+00:00, state:running, queued_at: 2026-02-23 13:34:36.172852+00:00. externally triggered: True> successful
2026-02-23 21:34:45,466 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-23 13:34:36.159302+00:00, run_id=manual__2026-02-23T13:34:36.159302+00:00, run_start_date=2026-02-23 13:34:38.732650+00:00, run_end_date=2026-02-23 13:34:45.466376+00:00, run_duration=6.733726, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:34:36.159302+00:00, data_interval_end=2026-02-23 13:34:36.159302+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-23 21:34:45,475 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:34:41.945741+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:34:41.947304+00:00 [scheduled]>
2026-02-23 21:34:45,477 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-23 21:34:45,477 INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 21:34:45,478 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:34:41.945741+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:34:41.947304+00:00 [scheduled]>
2026-02-23 21:34:45,481 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:34:41.945741+00:00 [scheduled]>, <TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:34:41.947304+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:34:45,482 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:34:41.945741+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:34:45,483 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:34:41.945741+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:34:45,484 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-23T13:34:41.947304+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:34:45,485 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-23T13:34:41.947304+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:34:45,487 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:34:41.945741+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:34:49,126 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-23T13:34:41.947304+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:34:52,958 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:34:41.945741+00:00', try_number=1, map_index=-1)
2026-02-23 21:34:52,960 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-23T13:34:41.947304+00:00', try_number=1, map_index=-1)
2026-02-23 21:34:52,968 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-23T13:34:41.945741+00:00, map_index=-1, run_start_date=2026-02-23 13:34:48.139521+00:00, run_end_date=2026-02-23 13:34:48.517613+00:00, run_duration=0.378092, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=197, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:34:45.479801+00:00, queued_by_job_id=164, pid=9353
2026-02-23 21:34:52,969 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=dataset_triggered__2026-02-23T13:34:41.947304+00:00, map_index=-1, run_start_date=2026-02-23 13:34:51.989866+00:00, run_end_date=2026-02-23 13:34:52.352972+00:00, run_duration=0.363106, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=198, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:34:45.479801+00:00, queued_by_job_id=164, pid=9355
2026-02-23 21:34:55,659 INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-23 13:34:41.945741+00:00: dataset_triggered__2026-02-23T13:34:41.945741+00:00, state:running, queued_at: 2026-02-23 13:34:45.425948+00:00. externally triggered: False> successful
2026-02-23 21:34:55,660 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-23 13:34:41.945741+00:00, run_id=dataset_triggered__2026-02-23T13:34:41.945741+00:00, run_start_date=2026-02-23 13:34:45.447230+00:00, run_end_date=2026-02-23 13:34:55.660567+00:00, run_duration=10.213337, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-23 13:34:36.159302+00:00, dag_hash=c3144e87e37f9ff1a9f0e648fbb0f19d
2026-02-23 21:34:55,665 INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-23 13:34:41.947304+00:00: dataset_triggered__2026-02-23T13:34:41.947304+00:00, state:running, queued_at: 2026-02-23 13:34:45.433527+00:00. externally triggered: False> successful
2026-02-23 21:34:55,666 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-23 13:34:41.947304+00:00, run_id=dataset_triggered__2026-02-23T13:34:41.947304+00:00, run_start_date=2026-02-23 13:34:45.447332+00:00, run_end_date=2026-02-23 13:34:55.666192+00:00, run_duration=10.21886, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-23 13:34:36.159302+00:00, dag_hash=0a3439ce80be51d3a7ac788a7442a9b6
2026-02-23 21:36:05,856 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:36:03.025632+00:00 [scheduled]>
2026-02-23 21:36:05,857 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-23 21:36:05,858 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:36:03.025632+00:00 [scheduled]>
2026-02-23 21:36:05,861 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-23T13:36:03.025632+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:36:05,862 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:36:03.025632+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:36:05,862 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:36:03.025632+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:36:05,865 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-23T13:36:03.025632+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:36:09,833 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-23T13:36:03.025632+00:00', try_number=1, map_index=-1)
2026-02-23 21:36:09,843 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-23T13:36:03.025632+00:00, map_index=-1, run_start_date=2026-02-23 13:36:08.792358+00:00, run_end_date=2026-02-23 13:36:09.166914+00:00, run_duration=0.374556, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=199, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:36:05.859763+00:00, queued_by_job_id=164, pid=9417
2026-02-23 21:36:12,487 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-23 13:36:03.025632+00:00: manual__2026-02-23T13:36:03.025632+00:00, state:running, queued_at: 2026-02-23 13:36:03.038215+00:00. externally triggered: True> successful
2026-02-23 21:36:12,488 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-23 13:36:03.025632+00:00, run_id=manual__2026-02-23T13:36:03.025632+00:00, run_start_date=2026-02-23 13:36:05.836577+00:00, run_end_date=2026-02-23 13:36:12.488322+00:00, run_duration=6.651745, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:36:03.025632+00:00, data_interval_end=2026-02-23 13:36:03.025632+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-23 21:36:12,497 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:36:09.183970+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:36:09.186015+00:00 [scheduled]>
2026-02-23 21:36:12,498 INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-23 21:36:12,499 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-23 21:36:12,500 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:36:09.183970+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:36:09.186015+00:00 [scheduled]>
2026-02-23 21:36:12,503 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-23T13:36:09.183970+00:00 [scheduled]>, <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-23T13:36:09.186015+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:36:12,504 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-23T13:36:09.183970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:36:12,504 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-23T13:36:09.183970+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:36:12,505 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:36:09.186015+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:36:12,506 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:36:09.186015+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:36:12,508 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-23T13:36:09.183970+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:36:16,264 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-23T13:36:09.186015+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-23 21:36:20,272 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-23T13:36:09.183970+00:00', try_number=1, map_index=-1)
2026-02-23 21:36:20,275 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-23T13:36:09.186015+00:00', try_number=1, map_index=-1)
2026-02-23 21:36:20,285 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-23T13:36:09.186015+00:00, map_index=-1, run_start_date=2026-02-23 13:36:19.215000+00:00, run_end_date=2026-02-23 13:36:19.616450+00:00, run_duration=0.40145, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=201, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:36:12.501718+00:00, queued_by_job_id=164, pid=9422
2026-02-23 21:36:20,286 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=dataset_triggered__2026-02-23T13:36:09.183970+00:00, map_index=-1, run_start_date=2026-02-23 13:36:15.190298+00:00, run_end_date=2026-02-23 13:36:15.588045+00:00, run_duration=0.397747, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=200, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:36:12.501718+00:00, queued_by_job_id=164, pid=9420
2026-02-23 21:36:20,329 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:36:22,988 INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-23 13:36:09.183970+00:00: dataset_triggered__2026-02-23T13:36:09.183970+00:00, state:running, queued_at: 2026-02-23 13:36:12.448754+00:00. externally triggered: False> successful
2026-02-23 21:36:22,989 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-23 13:36:09.183970+00:00, run_id=dataset_triggered__2026-02-23T13:36:09.183970+00:00, run_start_date=2026-02-23 13:36:12.470753+00:00, run_end_date=2026-02-23 13:36:22.989775+00:00, run_duration=10.519022, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:36:03.025632+00:00, data_interval_end=2026-02-23 13:36:03.025632+00:00, dag_hash=0a3439ce80be51d3a7ac788a7442a9b6
2026-02-23 21:36:22,994 INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-23 13:36:09.186015+00:00: dataset_triggered__2026-02-23T13:36:09.186015+00:00, state:running, queued_at: 2026-02-23 13:36:12.457059+00:00. externally triggered: False> successful
2026-02-23 21:36:22,995 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-23 13:36:09.186015+00:00, run_id=dataset_triggered__2026-02-23T13:36:09.186015+00:00, run_start_date=2026-02-23 13:36:12.470866+00:00, run_end_date=2026-02-23 13:36:22.995336+00:00, run_duration=10.52447, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:36:03.025632+00:00, data_interval_end=2026-02-23 13:36:03.025632+00:00, dag_hash=c3144e87e37f9ff1a9f0e648fbb0f19d
2026-02-23 21:41:20,642 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:46:22,282 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:51:24,964 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 21:51:28,928 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:51:24.624654+00:00 [scheduled]>
2026-02-23 21:51:28,928 INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
2026-02-23 21:51:28,929 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:51:24.624654+00:00 [scheduled]>
2026-02-23 21:51:28,932 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:51:24.624654+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:51:28,933 INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:51:24.624654+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:51:28,933 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:51:24.624654+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:51:28,936 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:51:24.624654+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:51:33,176 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:51:24.624654+00:00', try_number=1, map_index=-1)
2026-02-23 21:51:33,185 INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-23T13:51:24.624654+00:00, map_index=-1, run_start_date=2026-02-23 13:51:32.021032+00:00, run_end_date=2026-02-23 13:51:32.515704+00:00, run_duration=0.494672, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=202, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:51:28.931029+00:00, queued_by_job_id=164, pid=9847
2026-02-23 21:51:36,009 WARNING - Serialized DAG c_1p2n_DAG2 no longer exists
2026-02-23 21:51:36,010 ERROR - DAG 'c_1p2n_DAG2' not found in serialized_dag table
2026-02-23 21:51:36,045 INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-23 13:51:24.624654+00:00: manual__2026-02-23T13:51:24.624654+00:00, state:running, queued_at: 2026-02-23 13:51:24.638049+00:00. externally triggered: True> successful
2026-02-23 21:51:36,046 INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-23 13:51:24.624654+00:00, run_id=manual__2026-02-23T13:51:24.624654+00:00, run_start_date=2026-02-23 13:51:28.906710+00:00, run_end_date=2026-02-23 13:51:36.046923+00:00, run_duration=7.140213, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:51:24.624654+00:00, data_interval_end=2026-02-23 13:51:24.624654+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
2026-02-23 21:51:36,056 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:51:32.536269+00:00 [scheduled]>
2026-02-23 21:51:36,057 INFO - DAG c_1p2n_DAG1 has 0/16 running and queued tasks
2026-02-23 21:51:36,058 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:51:32.536269+00:00 [scheduled]>
2026-02-23 21:51:36,061 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:51:32.536269+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:51:36,061 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-23T13:51:32.536269+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:51:36,062 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-23T13:51:32.536269+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:51:36,065 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-23T13:51:32.536269+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:51:39,977 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-23T13:51:32.536269+00:00', try_number=1, map_index=-1)
2026-02-23 21:51:39,988 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG1, task_id=c_1p2n_TASK1, run_id=dataset_triggered__2026-02-23T13:51:32.536269+00:00, map_index=-1, run_start_date=2026-02-23 13:51:39.029429+00:00, run_end_date=2026-02-23 13:51:39.408262+00:00, run_duration=0.378833, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=203, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:51:36.059556+00:00, queued_by_job_id=164, pid=9850
2026-02-23 21:51:42,693 ERROR - DAG 'c_1p2n_DAG2' not found in serialized_dag table
2026-02-23 21:51:42,706 INFO - Marking run <DagRun c_1p2n_DAG1 @ 2026-02-23 13:51:32.536269+00:00: dataset_triggered__2026-02-23T13:51:32.536269+00:00, state:running, queued_at: 2026-02-23 13:51:36.017109+00:00. externally triggered: False> successful
2026-02-23 21:51:42,706 INFO - DagRun Finished: dag_id=c_1p2n_DAG1, execution_date=2026-02-23 13:51:32.536269+00:00, run_id=dataset_triggered__2026-02-23T13:51:32.536269+00:00, run_start_date=2026-02-23 13:51:36.032735+00:00, run_end_date=2026-02-23 13:51:42.706896+00:00, run_duration=6.674161, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:51:24.624654+00:00, data_interval_end=2026-02-23 13:51:24.624654+00:00, dag_hash=4a31cc71e5398c53fad0c9cea1feb380
2026-02-23 21:51:46,490 ERROR - DAG 'c_1p2n_DAG2' not found in serialized_dag table
2026-02-23 21:51:50,419 ERROR - DAG 'c_1p2n_DAG2' not found in serialized_dag table
2026-02-23 21:51:54,682 ERROR - DAG 'c_1p2n_DAG2' not found in serialized_dag table
2026-02-23 21:52:12,955 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:51:32.534137+00:00 [scheduled]>
2026-02-23 21:52:12,956 INFO - DAG c_1p2n_DAG2 has 0/16 running and queued tasks
2026-02-23 21:52:12,957 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:51:32.534137+00:00 [scheduled]>
2026-02-23 21:52:12,959 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:51:32.534137+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:52:12,960 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-23T13:51:32.534137+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:52:12,961 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-23T13:51:32.534137+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:12,964 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-23T13:51:32.534137+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:17,275 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-23T13:51:32.534137+00:00', try_number=1, map_index=-1)
2026-02-23 21:52:17,285 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG2, task_id=c_1p2n_TASK2, run_id=dataset_triggered__2026-02-23T13:51:32.534137+00:00, map_index=-1, run_start_date=2026-02-23 13:52:16.141349+00:00, run_end_date=2026-02-23 13:52:16.556638+00:00, run_duration=0.415289, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=204, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:52:12.958854+00:00, queued_by_job_id=164, pid=9884
2026-02-23 21:52:20,376 INFO - Marking run <DagRun c_1p2n_DAG2 @ 2026-02-23 13:51:32.534137+00:00: dataset_triggered__2026-02-23T13:51:32.534137+00:00, state:running, queued_at: 2026-02-23 13:52:12.923844+00:00. externally triggered: False> successful
2026-02-23 21:52:20,377 INFO - DagRun Finished: dag_id=c_1p2n_DAG2, execution_date=2026-02-23 13:51:32.534137+00:00, run_id=dataset_triggered__2026-02-23T13:51:32.534137+00:00, run_start_date=2026-02-23 13:52:12.936886+00:00, run_end_date=2026-02-23 13:52:20.377448+00:00, run_duration=7.440562, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:51:24.624654+00:00, data_interval_end=2026-02-23 13:51:24.624654+00:00, dag_hash=f0222c6725e6517a46dc479b0aa002a2
2026-02-23 21:52:20,389 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:52:19.053228+00:00 [scheduled]>
2026-02-23 21:52:20,389 INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
2026-02-23 21:52:20,390 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:52:19.053228+00:00 [scheduled]>
2026-02-23 21:52:20,393 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-23T13:52:19.053228+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:52:20,394 INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:52:19.053228+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:52:20,395 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:52:19.053228+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:20,398 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-23T13:52:19.053228+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:24,251 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-23T13:52:19.053228+00:00', try_number=1, map_index=-1)
2026-02-23 21:52:24,260 INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-23T13:52:19.053228+00:00, map_index=-1, run_start_date=2026-02-23 13:52:23.187193+00:00, run_end_date=2026-02-23 13:52:23.559310+00:00, run_duration=0.372117, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=205, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:52:20.391915+00:00, queued_by_job_id=164, pid=9887
2026-02-23 21:52:26,841 INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-23 13:52:19.053228+00:00: manual__2026-02-23T13:52:19.053228+00:00, state:running, queued_at: 2026-02-23 13:52:19.065167+00:00. externally triggered: True> successful
2026-02-23 21:52:26,843 INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-23 13:52:19.053228+00:00, run_id=manual__2026-02-23T13:52:19.053228+00:00, run_start_date=2026-02-23 13:52:20.357736+00:00, run_end_date=2026-02-23 13:52:26.843131+00:00, run_duration=6.485395, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-23 13:52:19.053228+00:00, data_interval_end=2026-02-23 13:52:19.053228+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
2026-02-23 21:52:26,854 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:52:23.576229+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:52:23.577764+00:00 [scheduled]>
2026-02-23 21:52:26,854 INFO - DAG c_1p2n_DAG2 has 0/16 running and queued tasks
2026-02-23 21:52:26,855 INFO - DAG c_1p2n_DAG1 has 0/16 running and queued tasks
2026-02-23 21:52:26,856 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:52:23.576229+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:52:23.577764+00:00 [scheduled]>
2026-02-23 21:52:26,859 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-23T13:52:23.576229+00:00 [scheduled]>, <TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-23T13:52:23.577764+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-23 21:52:26,860 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-23T13:52:23.576229+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:52:26,861 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-23T13:52:23.576229+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:26,862 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-23T13:52:23.577764+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-23 21:52:26,862 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-23T13:52:23.577764+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:26,865 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-23T13:52:23.576229+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:30,683 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-23T13:52:23.577764+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-23 21:52:34,755 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-23T13:52:23.576229+00:00', try_number=1, map_index=-1)
2026-02-23 21:52:34,759 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-23T13:52:23.577764+00:00', try_number=1, map_index=-1)
2026-02-23 21:52:34,770 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG2, task_id=c_1p2n_TASK2, run_id=dataset_triggered__2026-02-23T13:52:23.576229+00:00, map_index=-1, run_start_date=2026-02-23 13:52:29.652625+00:00, run_end_date=2026-02-23 13:52:30.028010+00:00, run_duration=0.375385, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=206, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:52:26.857434+00:00, queued_by_job_id=164, pid=9890
2026-02-23 21:52:34,771 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG1, task_id=c_1p2n_TASK1, run_id=dataset_triggered__2026-02-23T13:52:23.577764+00:00, map_index=-1, run_start_date=2026-02-23 13:52:33.543342+00:00, run_end_date=2026-02-23 13:52:33.938541+00:00, run_duration=0.395199, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=207, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-23 13:52:26.857434+00:00, queued_by_job_id=164, pid=9892
2026-02-23 21:52:38,129 INFO - Marking run <DagRun c_1p2n_DAG2 @ 2026-02-23 13:52:23.576229+00:00: dataset_triggered__2026-02-23T13:52:23.576229+00:00, state:running, queued_at: 2026-02-23 13:52:26.800079+00:00. externally triggered: False> successful
2026-02-23 21:52:38,130 INFO - DagRun Finished: dag_id=c_1p2n_DAG2, execution_date=2026-02-23 13:52:23.576229+00:00, run_id=dataset_triggered__2026-02-23T13:52:23.576229+00:00, run_start_date=2026-02-23 13:52:26.823591+00:00, run_end_date=2026-02-23 13:52:38.130142+00:00, run_duration=11.306551, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:52:19.053228+00:00, data_interval_end=2026-02-23 13:52:19.053228+00:00, dag_hash=f0222c6725e6517a46dc479b0aa002a2
2026-02-23 21:52:38,135 INFO - Marking run <DagRun c_1p2n_DAG1 @ 2026-02-23 13:52:23.577764+00:00: dataset_triggered__2026-02-23T13:52:23.577764+00:00, state:running, queued_at: 2026-02-23 13:52:26.808496+00:00. externally triggered: False> successful
2026-02-23 21:52:38,136 INFO - DagRun Finished: dag_id=c_1p2n_DAG1, execution_date=2026-02-23 13:52:23.577764+00:00, run_id=dataset_triggered__2026-02-23T13:52:23.577764+00:00, run_start_date=2026-02-23 13:52:26.823719+00:00, run_end_date=2026-02-23 13:52:38.136523+00:00, run_duration=11.312804, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 13:52:19.053228+00:00, data_interval_end=2026-02-23 13:52:19.053228+00:00, dag_hash=4a31cc71e5398c53fad0c9cea1feb380
2026-02-23 21:56:25,208 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 22:01:25,425 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 22:06:25,633 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 22:11:26,742 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 22:17:00,314 INFO - Heartbeat recovered after 249.18 seconds
2026-02-23 22:20:30,502 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-23 22:21:51,848 INFO - Exiting gracefully upon receiving signal 15
2026-02-23 22:21:52,852 INFO - Sending Signals.SIGTERM to group 6919. PIDs of all processes in the group: [6919]
2026-02-23 22:21:52,859 INFO - Sending the signal Signals.SIGTERM to group 6919
2026-02-23 22:21:52,918 INFO - Process psutil.Process(pid=6919, status='terminated', exitcode=<Negsignal.SIGTERM: -15>, started='20:20:53') (6919) terminated with exit code Negsignal.SIGTERM
2026-02-23 22:21:52,922 INFO - Sending Signals.SIGTERM to group 6919. PIDs of all processes in the group: []
2026-02-23 22:21:52,923 INFO - Sending the signal Signals.SIGTERM to group 6919
2026-02-23 22:21:52,929 INFO - Sending the signal Signals.SIGTERM to process 6919 as process group is missing.
2026-02-23 22:21:52,930 INFO - Exited execute loop
2026-02-24 09:52:37,402 INFO - Loaded executor: SequentialExecutor
2026-02-24 09:52:38,078 INFO - Starting the scheduler
2026-02-24 09:52:38,081 INFO - Processing each file at most -1 times
2026-02-24 09:52:38,092 INFO - Launched DagFileProcessorManager with pid: 3447
2026-02-24 09:52:38,100 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 09:57:39,321 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:02:41,861 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:07:44,445 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:12:45,205 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:15:41,378 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T02:15:38.592389+00:00 [scheduled]>
2026-02-24 10:15:41,379 INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
2026-02-24 10:15:41,380 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T02:15:38.592389+00:00 [scheduled]>
2026-02-24 10:15:41,383 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T02:15:38.592389+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:15:41,384 INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T02:15:38.592389+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:15:41,385 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T02:15:38.592389+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 10:15:41,387 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T02:15:38.592389+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 10:15:46,050 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T02:15:38.592389+00:00', try_number=1, map_index=-1)
2026-02-24 10:15:46,067 INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-24T02:15:38.592389+00:00, map_index=-1, run_start_date=2026-02-24 02:15:45.185232+00:00, run_end_date=2026-02-24 02:15:45.404882+00:00, run_duration=0.21965, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=209, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:15:41.381883+00:00, queued_by_job_id=208, pid=4653
2026-02-24 10:15:48,882 INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-24 02:15:38.592389+00:00: manual__2026-02-24T02:15:38.592389+00:00, state:running, queued_at: 2026-02-24 02:15:38.624858+00:00. externally triggered: True> successful
2026-02-24 10:15:48,884 INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-24 02:15:38.592389+00:00, run_id=manual__2026-02-24T02:15:38.592389+00:00, run_start_date=2026-02-24 02:15:41.342270+00:00, run_end_date=2026-02-24 02:15:48.884184+00:00, run_duration=7.541914, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:15:38.592389+00:00, data_interval_end=2026-02-24 02:15:38.592389+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
2026-02-24 10:15:48,896 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-24T02:15:45.425754+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-24T02:15:45.427353+00:00 [scheduled]>
2026-02-24 10:15:48,897 INFO - DAG c_1p2n_DAG2 has 0/16 running and queued tasks
2026-02-24 10:15:48,898 INFO - DAG c_1p2n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:15:48,899 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-24T02:15:45.425754+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-24T02:15:45.427353+00:00 [scheduled]>
2026-02-24 10:15:48,902 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG2.c_1p2n_TASK2 dataset_triggered__2026-02-24T02:15:45.425754+00:00 [scheduled]>, <TaskInstance: c_1p2n_DAG1.c_1p2n_TASK1 dataset_triggered__2026-02-24T02:15:45.427353+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:15:48,903 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-24T02:15:45.425754+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:15:48,904 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-24T02:15:45.425754+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 10:15:48,904 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-24T02:15:45.427353+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:15:48,905 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-24T02:15:45.427353+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 10:15:48,909 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_TASK2', 'dataset_triggered__2026-02-24T02:15:45.425754+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 10:15:53,243 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_TASK1', 'dataset_triggered__2026-02-24T02:15:45.427353+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 10:15:57,642 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_TASK2', run_id='dataset_triggered__2026-02-24T02:15:45.425754+00:00', try_number=1, map_index=-1)
2026-02-24 10:15:57,645 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_TASK1', run_id='dataset_triggered__2026-02-24T02:15:45.427353+00:00', try_number=1, map_index=-1)
2026-02-24 10:15:57,661 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG2, task_id=c_1p2n_TASK2, run_id=dataset_triggered__2026-02-24T02:15:45.425754+00:00, map_index=-1, run_start_date=2026-02-24 02:15:52.357179+00:00, run_end_date=2026-02-24 02:15:52.585118+00:00, run_duration=0.227939, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=210, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:15:48.900774+00:00, queued_by_job_id=208, pid=4656
2026-02-24 10:15:57,662 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG1, task_id=c_1p2n_TASK1, run_id=dataset_triggered__2026-02-24T02:15:45.427353+00:00, map_index=-1, run_start_date=2026-02-24 02:15:56.749072+00:00, run_end_date=2026-02-24 02:15:56.972493+00:00, run_duration=0.223421, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=211, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:15:48.900774+00:00, queued_by_job_id=208, pid=4658
2026-02-24 10:16:00,739 INFO - Marking run <DagRun c_1p2n_DAG2 @ 2026-02-24 02:15:45.425754+00:00: dataset_triggered__2026-02-24T02:15:45.425754+00:00, state:running, queued_at: 2026-02-24 02:15:48.834997+00:00. externally triggered: False> successful
2026-02-24 10:16:00,740 INFO - DagRun Finished: dag_id=c_1p2n_DAG2, execution_date=2026-02-24 02:15:45.425754+00:00, run_id=dataset_triggered__2026-02-24T02:15:45.425754+00:00, run_start_date=2026-02-24 02:15:48.864141+00:00, run_end_date=2026-02-24 02:16:00.740398+00:00, run_duration=11.876257, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:15:38.592389+00:00, data_interval_end=2026-02-24 02:15:38.592389+00:00, dag_hash=f0222c6725e6517a46dc479b0aa002a2
2026-02-24 10:16:00,746 INFO - Marking run <DagRun c_1p2n_DAG1 @ 2026-02-24 02:15:45.427353+00:00: dataset_triggered__2026-02-24T02:15:45.427353+00:00, state:running, queued_at: 2026-02-24 02:15:48.850142+00:00. externally triggered: False> successful
2026-02-24 10:16:00,748 INFO - DagRun Finished: dag_id=c_1p2n_DAG1, execution_date=2026-02-24 02:15:45.427353+00:00, run_id=dataset_triggered__2026-02-24T02:15:45.427353+00:00, run_start_date=2026-02-24 02:15:48.864236+00:00, run_end_date=2026-02-24 02:16:00.748251+00:00, run_duration=11.884015, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:15:38.592389+00:00, data_interval_end=2026-02-24 02:15:38.592389+00:00, dag_hash=4a31cc71e5398c53fad0c9cea1feb380
2026-02-24 10:17:47,677 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:22:50,393 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:24:00,028 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:23:56.268900+00:00 [scheduled]>
2026-02-24 10:24:00,030 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-24 10:24:00,031 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:23:56.268900+00:00 [scheduled]>
2026-02-24 10:24:00,033 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:23:56.268900+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:24:00,035 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:23:56.268900+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:24:00,035 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:23:56.268900+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:24:00,038 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:23:56.268900+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:24:04,451 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:23:56.268900+00:00', try_number=1, map_index=-1)
2026-02-24 10:24:04,462 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:23:56.268900+00:00, map_index=-1, run_start_date=2026-02-24 02:24:03.605108+00:00, run_end_date=2026-02-24 02:24:03.816128+00:00, run_duration=0.21102, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=212, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:24:00.032260+00:00, queued_by_job_id=208, pid=4931
2026-02-24 10:24:07,836 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:23:56.268900+00:00: manual__2026-02-24T02:23:56.268900+00:00, state:running, queued_at: 2026-02-24 02:23:56.287475+00:00. externally triggered: True> successful
2026-02-24 10:24:07,837 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:23:56.268900+00:00, run_id=manual__2026-02-24T02:23:56.268900+00:00, run_start_date=2026-02-24 02:24:00.005427+00:00, run_end_date=2026-02-24 02:24:07.837296+00:00, run_duration=7.831869, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:23:56.268900+00:00, data_interval_end=2026-02-24 02:23:56.268900+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-24 10:24:07,847 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-24T02:24:03.837397+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:24:03.838921+00:00 [scheduled]>
2026-02-24 10:24:07,848 INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-24 10:24:07,848 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:24:07,849 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-24T02:24:03.837397+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:24:03.838921+00:00 [scheduled]>
2026-02-24 10:24:07,852 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 dataset_triggered__2026-02-24T02:24:03.837397+00:00 [scheduled]>, <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:24:03.838921+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:24:07,853 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-24T02:24:03.837397+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:24:07,854 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-24T02:24:03.837397+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:24:07,855 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:24:03.838921+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:24:07,855 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:24:03.838921+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:24:07,858 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'dataset_triggered__2026-02-24T02:24:03.837397+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:24:12,253 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:24:03.838921+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:24:17,299 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='dataset_triggered__2026-02-24T02:24:03.837397+00:00', try_number=1, map_index=-1)
2026-02-24 10:24:17,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:24:03.838921+00:00', try_number=1, map_index=-1)
2026-02-24 10:24:17,315 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-24T02:24:03.838921+00:00, map_index=-1, run_start_date=2026-02-24 02:24:16.305519+00:00, run_end_date=2026-02-24 02:24:16.606146+00:00, run_duration=0.300627, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=214, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:24:07.850675+00:00, queued_by_job_id=208, pid=4936
2026-02-24 10:24:17,317 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=dataset_triggered__2026-02-24T02:24:03.837397+00:00, map_index=-1, run_start_date=2026-02-24 02:24:11.378194+00:00, run_end_date=2026-02-24 02:24:11.604727+00:00, run_duration=0.226533, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=213, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:24:07.850675+00:00, queued_by_job_id=208, pid=4934
2026-02-24 10:24:20,734 INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-24 02:24:03.837397+00:00: dataset_triggered__2026-02-24T02:24:03.837397+00:00, state:running, queued_at: 2026-02-24 02:24:07.804984+00:00. externally triggered: False> successful
2026-02-24 10:24:20,735 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-24 02:24:03.837397+00:00, run_id=dataset_triggered__2026-02-24T02:24:03.837397+00:00, run_start_date=2026-02-24 02:24:07.818788+00:00, run_end_date=2026-02-24 02:24:20.735600+00:00, run_duration=12.916812, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:23:56.268900+00:00, data_interval_end=2026-02-24 02:23:56.268900+00:00, dag_hash=0a3439ce80be51d3a7ac788a7442a9b6
2026-02-24 10:24:20,741 INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-24 02:24:03.838921+00:00: dataset_triggered__2026-02-24T02:24:03.838921+00:00, state:running, queued_at: 2026-02-24 02:24:07.796259+00:00. externally triggered: False> successful
2026-02-24 10:24:20,742 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-24 02:24:03.838921+00:00, run_id=dataset_triggered__2026-02-24T02:24:03.838921+00:00, run_start_date=2026-02-24 02:24:07.818925+00:00, run_end_date=2026-02-24 02:24:20.742770+00:00, run_duration=12.923845, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:23:56.268900+00:00, data_interval_end=2026-02-24 02:23:56.268900+00:00, dag_hash=c3144e87e37f9ff1a9f0e648fbb0f19d
2026-02-24 10:27:51,203 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:31:26,711 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:31:24.359252+00:00 [scheduled]>
2026-02-24 10:31:26,713 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-24 10:31:26,713 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:31:24.359252+00:00 [scheduled]>
2026-02-24 10:31:26,716 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:31:24.359252+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:31:26,717 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:31:24.359252+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:31:26,718 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:31:24.359252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:31:26,720 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:31:24.359252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:31:31,133 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:31:24.359252+00:00', try_number=1, map_index=-1)
2026-02-24 10:31:31,145 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:31:24.359252+00:00, map_index=-1, run_start_date=2026-02-24 02:31:30.295385+00:00, run_end_date=2026-02-24 02:31:30.496544+00:00, run_duration=0.201159, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=215, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:31:26.714763+00:00, queued_by_job_id=208, pid=5197
2026-02-24 10:31:33,929 WARNING - Exception when importing 'airflow.providers.standard.operators.trigger_dagrun.TriggerDagRunLink' from 'apache-airflow-providers-standard' package
Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers_manager.py", line 327, in _correctness_check
    imported_class = import_string(class_name)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/standard/operators/trigger_dagrun.py", line 35, in <module>
    from airflow.providers.common.compat.sdk import (
ImportError: cannot import name 'AirflowException' from 'airflow.providers.common.compat.sdk' (/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/common/compat/sdk.py)
2026-02-24 10:31:33,934 WARNING - Exception when importing 'airflow.providers.standard.sensors.external_task.ExternalDagLink' from 'apache-airflow-providers-standard' package
Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers_manager.py", line 327, in _correctness_check
    imported_class = import_string(class_name)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/utils/module_loading.py", line 39, in import_string
    module = import_module(module_path)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/standard/sensors/external_task.py", line 27, in <module>
    from airflow.providers.common.compat.sdk import (
ImportError: cannot import name 'AirflowSkipException' from 'airflow.providers.common.compat.sdk' (/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/providers/common/compat/sdk.py)
2026-02-24 10:31:33,995 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:31:24.359252+00:00: manual__2026-02-24T02:31:24.359252+00:00, state:running, queued_at: 2026-02-24 02:31:24.372587+00:00. externally triggered: True> successful
2026-02-24 10:31:33,996 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:31:24.359252+00:00, run_id=manual__2026-02-24T02:31:24.359252+00:00, run_start_date=2026-02-24 02:31:26.691889+00:00, run_end_date=2026-02-24 02:31:33.996646+00:00, run_duration=7.304757, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:31:24.359252+00:00, data_interval_end=2026-02-24 02:31:24.359252+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-24 10:31:34,008 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.wait_for_consumer1 dataset_triggered__2026-02-24T02:31:30.518493+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:31:30.520347+00:00 [scheduled]>
2026-02-24 10:31:34,008 INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-24 10:31:34,009 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:31:34,010 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.wait_for_consumer1 dataset_triggered__2026-02-24T02:31:30.518493+00:00 [scheduled]>
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:31:30.520347+00:00 [scheduled]>
2026-02-24 10:31:34,013 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.wait_for_consumer1 dataset_triggered__2026-02-24T02:31:30.518493+00:00 [scheduled]>, <TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:31:30.520347+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:31:34,015 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='wait_for_consumer1', run_id='dataset_triggered__2026-02-24T02:31:30.518493+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 10:31:34,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'wait_for_consumer1', 'dataset_triggered__2026-02-24T02:31:30.518493+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:31:34,016 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:31:30.520347+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:31:34,017 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:31:30.520347+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:31:34,020 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'wait_for_consumer1', 'dataset_triggered__2026-02-24T02:31:30.518493+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:38:41,519 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:31:30.520347+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:38:45,845 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:31:30.520347+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']' returned non-zero exit status 1..
2026-02-24 10:38:45,852 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='wait_for_consumer1', run_id='dataset_triggered__2026-02-24T02:31:30.518493+00:00', try_number=1, map_index=-1)
2026-02-24 10:38:45,853 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:31:30.520347+00:00', try_number=1, map_index=-1)
2026-02-24 10:38:45,871 ERROR - DagFileProcessorManager (PID=3447) last sent a heartbeat 431.96 seconds ago! Restarting it
2026-02-24 10:38:45,882 INFO - Sending Signals.SIGTERM to group 3447. PIDs of all processes in the group: [3447]
2026-02-24 10:38:45,883 INFO - Sending the signal Signals.SIGTERM to group 3447
2026-02-24 10:38:46,429 INFO - Process psutil.Process(pid=3447, status='terminated', exitcode=0, started='09:52:38') (3447) terminated with exit code 0
2026-02-24 10:38:46,436 INFO - Launched DagFileProcessorManager with pid: 5320
2026-02-24 10:38:46,453 INFO - Heartbeat recovered after 435.29 seconds
2026-02-24 10:38:46,472 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:38:52,080 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:38:44.096710+00:00 [scheduled]>
2026-02-24 10:38:52,081 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-24 10:38:52,082 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:38:44.096710+00:00 [scheduled]>
2026-02-24 10:38:52,084 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:38:44.096710+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:38:52,086 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:38:44.096710+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:38:52,087 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:38:44.096710+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:38:52,089 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:38:44.096710+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:38:56,563 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:38:44.096710+00:00', try_number=1, map_index=-1)
2026-02-24 10:38:56,574 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:38:44.096710+00:00, map_index=-1, run_start_date=2026-02-24 02:38:55.666271+00:00, run_end_date=2026-02-24 02:38:55.858686+00:00, run_duration=0.192415, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=217, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:38:52.083287+00:00, queued_by_job_id=208, pid=5323
2026-02-24 10:39:00,153 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:38:44.096710+00:00: manual__2026-02-24T02:38:44.096710+00:00, state:running, queued_at: 2026-02-24 02:38:44.111189+00:00. externally triggered: True> successful
2026-02-24 10:39:00,154 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:38:44.096710+00:00, run_id=manual__2026-02-24T02:38:44.096710+00:00, run_start_date=2026-02-24 02:38:52.057556+00:00, run_end_date=2026-02-24 02:39:00.154204+00:00, run_duration=8.096648, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:38:44.096710+00:00, data_interval_end=2026-02-24 02:38:44.096710+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-24 10:39:00,164 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
2026-02-24 10:39:00,165 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:39:00,166 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
2026-02-24 10:39:00,168 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:39:00,169 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 10:39:00,170 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:39:00,173 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:39:04,525 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1)
2026-02-24 10:39:04,535 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-24T02:38:55.878244+00:00, map_index=-1, run_start_date=2026-02-24 02:39:03.621683+00:00, run_end_date=2026-02-24 02:39:03.835379+00:00, run_duration=0.213696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=218, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:39:00.167525+00:00, queued_by_job_id=208, pid=5329
2026-02-24 10:39:07,153 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
2026-02-24 10:39:07,154 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:39:07,155 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>
2026-02-24 10:39:07,157 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:38:55.878244+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:39:07,159 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:39:07,159 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:39:07,162 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:38:55.878244+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:39:11,558 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:38:55.878244+00:00', try_number=1, map_index=-1)
2026-02-24 10:39:11,569 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=trigger_consumer2, run_id=dataset_triggered__2026-02-24T02:38:55.878244+00:00, map_index=-1, run_start_date=2026-02-24 02:39:10.658067+00:00, run_end_date=2026-02-24 02:39:10.878931+00:00, run_duration=0.220864, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=219, pool=default_pool, queue=default, priority_weight=1, operator=TriggerDagRunOperator, queued_dttm=2026-02-24 02:39:07.156601+00:00, queued_by_job_id=208, pid=5332
2026-02-24 10:39:14,490 INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-24 02:38:55.878244+00:00: dataset_triggered__2026-02-24T02:38:55.878244+00:00, state:running, queued_at: 2026-02-24 02:39:00.118569+00:00. externally triggered: False> successful
2026-02-24 10:39:14,491 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-24 02:38:55.878244+00:00, run_id=dataset_triggered__2026-02-24T02:38:55.878244+00:00, run_start_date=2026-02-24 02:39:00.136804+00:00, run_end_date=2026-02-24 02:39:14.491524+00:00, run_duration=14.35472, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-23 12:36:42.067898+00:00, data_interval_end=2026-02-24 02:38:44.096710+00:00, dag_hash=1e5120c8d126ef18ce6c14bf6e8820e1
2026-02-24 10:39:14,503 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:39:10.827985+00:00 [scheduled]>
2026-02-24 10:39:14,504 INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-24 10:39:14,505 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:39:10.827985+00:00 [scheduled]>
2026-02-24 10:39:14,509 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:39:10.827985+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:39:14,510 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:39:10.827985+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:39:14,511 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:39:10.827985+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:39:14,513 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:39:10.827985+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:39:18,813 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:39:10.827985+00:00', try_number=1, map_index=-1)
2026-02-24 10:39:18,825 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=manual__2026-02-24T02:39:10.827985+00:00, map_index=-1, run_start_date=2026-02-24 02:39:17.994893+00:00, run_end_date=2026-02-24 02:39:18.199075+00:00, run_duration=0.204182, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=220, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:39:14.507283+00:00, queued_by_job_id=208, pid=5335
2026-02-24 10:39:21,677 INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-24 02:39:10.827985+00:00: manual__2026-02-24T02:39:10.827985+00:00, state:running, queued_at: 2026-02-24 02:39:10.844540+00:00. externally triggered: True> successful
2026-02-24 10:39:21,678 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-24 02:39:10.827985+00:00, run_id=manual__2026-02-24T02:39:10.827985+00:00, run_start_date=2026-02-24 02:39:14.466997+00:00, run_end_date=2026-02-24 02:39:21.678646+00:00, run_duration=7.211649, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:39:10.827985+00:00, data_interval_end=2026-02-24 02:39:10.827985+00:00, dag_hash=3db0a33148c3d6ae46448fe2fe476bd0
2026-02-24 10:43:47,478 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:46:42,488 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:46:41.375756+00:00 [scheduled]>
2026-02-24 10:46:42,488 INFO - DAG p_1p1n1n_DAGs has 0/16 running and queued tasks
2026-02-24 10:46:42,489 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:46:41.375756+00:00 [scheduled]>
2026-02-24 10:46:42,491 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n1n_DAGs.p_1p1n1n_TASK manual__2026-02-24T02:46:41.375756+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:46:42,493 INFO - Sending TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:46:41.375756+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:46:42,494 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:46:41.375756+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:46:42,496 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n1n_DAGs', 'p_1p1n1n_TASK', 'manual__2026-02-24T02:46:41.375756+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:46:47,129 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n1n_DAGs', task_id='p_1p1n1n_TASK', run_id='manual__2026-02-24T02:46:41.375756+00:00', try_number=1, map_index=-1)
2026-02-24 10:46:47,141 INFO - TaskInstance Finished: dag_id=p_1p1n1n_DAGs, task_id=p_1p1n1n_TASK, run_id=manual__2026-02-24T02:46:41.375756+00:00, map_index=-1, run_start_date=2026-02-24 02:46:46.194789+00:00, run_end_date=2026-02-24 02:46:46.440884+00:00, run_duration=0.246095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=221, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:46:42.490744+00:00, queued_by_job_id=208, pid=5566
2026-02-24 10:46:49,917 INFO - Marking run <DagRun p_1p1n1n_DAGs @ 2026-02-24 02:46:41.375756+00:00: manual__2026-02-24T02:46:41.375756+00:00, state:running, queued_at: 2026-02-24 02:46:41.390828+00:00. externally triggered: True> successful
2026-02-24 10:46:49,918 INFO - DagRun Finished: dag_id=p_1p1n1n_DAGs, execution_date=2026-02-24 02:46:41.375756+00:00, run_id=manual__2026-02-24T02:46:41.375756+00:00, run_start_date=2026-02-24 02:46:42.465033+00:00, run_end_date=2026-02-24 02:46:49.918687+00:00, run_duration=7.453654, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:46:41.375756+00:00, data_interval_end=2026-02-24 02:46:41.375756+00:00, dag_hash=27f14b92c1fec47bd0d9b691229d87b8
2026-02-24 10:46:49,929 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
2026-02-24 10:46:49,930 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:46:49,931 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
2026-02-24 10:46:49,933 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.c_1p1n1n_TASK1 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:46:49,934 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 10:46:49,935 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:46:49,938 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'c_1p1n1n_TASK1', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:46:54,236 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='c_1p1n1n_TASK1', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1)
2026-02-24 10:46:54,247 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=c_1p1n1n_TASK1, run_id=dataset_triggered__2026-02-24T02:46:46.462237+00:00, map_index=-1, run_start_date=2026-02-24 02:46:53.397409+00:00, run_end_date=2026-02-24 02:46:53.608585+00:00, run_duration=0.211176, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=222, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:46:49.932553+00:00, queued_by_job_id=208, pid=5569
2026-02-24 10:46:57,228 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
2026-02-24 10:46:57,229 INFO - DAG c_1p1n1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:46:57,230 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>
2026-02-24 10:46:57,233 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG1.trigger_consumer2 dataset_triggered__2026-02-24T02:46:46.462237+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:46:57,234 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:46:57,234 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:46:57,237 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG1', 'trigger_consumer2', 'dataset_triggered__2026-02-24T02:46:46.462237+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:47:01,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG1', task_id='trigger_consumer2', run_id='dataset_triggered__2026-02-24T02:46:46.462237+00:00', try_number=1, map_index=-1)
2026-02-24 10:47:01,784 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG1, task_id=trigger_consumer2, run_id=dataset_triggered__2026-02-24T02:46:46.462237+00:00, map_index=-1, run_start_date=2026-02-24 02:47:00.883385+00:00, run_end_date=2026-02-24 02:47:01.130534+00:00, run_duration=0.247149, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=223, pool=default_pool, queue=default, priority_weight=1, operator=TriggerDagRunOperator, queued_dttm=2026-02-24 02:46:57.231701+00:00, queued_by_job_id=208, pid=5577
2026-02-24 10:47:04,665 INFO - Marking run <DagRun c_1p1n1n_DAG1 @ 2026-02-24 02:46:46.462237+00:00: dataset_triggered__2026-02-24T02:46:46.462237+00:00, state:running, queued_at: 2026-02-24 02:46:49.888066+00:00. externally triggered: False> successful
2026-02-24 10:47:04,666 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG1, execution_date=2026-02-24 02:46:46.462237+00:00, run_id=dataset_triggered__2026-02-24T02:46:46.462237+00:00, run_start_date=2026-02-24 02:46:49.901810+00:00, run_end_date=2026-02-24 02:47:04.666253+00:00, run_duration=14.764443, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:46:41.375756+00:00, data_interval_end=2026-02-24 02:46:41.375756+00:00, dag_hash=1e5120c8d126ef18ce6c14bf6e8820e1
2026-02-24 10:47:04,677 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
2026-02-24 10:47:04,678 INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-24 10:47:04,679 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
2026-02-24 10:47:04,681 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.c_1p1n1n_TASK2 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:47:04,682 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 10:47:04,683 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:47:04,686 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'c_1p1n1n_TASK2', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:47:09,064 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='c_1p1n1n_TASK2', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1)
2026-02-24 10:47:09,076 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=c_1p1n1n_TASK2, run_id=manual__2026-02-24T02:47:01.072084+00:00, map_index=-1, run_start_date=2026-02-24 02:47:08.184985+00:00, run_end_date=2026-02-24 02:47:08.397610+00:00, run_duration=0.212625, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=224, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:47:04.680532+00:00, queued_by_job_id=208, pid=5580
2026-02-24 10:47:11,974 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG2.trigger_consumer3 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
2026-02-24 10:47:11,975 INFO - DAG c_1p1n1n_DAG2 has 0/16 running and queued tasks
2026-02-24 10:47:11,976 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG2.trigger_consumer3 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>
2026-02-24 10:47:11,978 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG2.trigger_consumer3 manual__2026-02-24T02:47:01.072084+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:47:11,979 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='trigger_consumer3', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:47:11,980 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'trigger_consumer3', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:47:11,982 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG2', 'trigger_consumer3', 'manual__2026-02-24T02:47:01.072084+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:47:16,316 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG2', task_id='trigger_consumer3', run_id='manual__2026-02-24T02:47:01.072084+00:00', try_number=1, map_index=-1)
2026-02-24 10:47:16,326 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG2, task_id=trigger_consumer3, run_id=manual__2026-02-24T02:47:01.072084+00:00, map_index=-1, run_start_date=2026-02-24 02:47:15.418680+00:00, run_end_date=2026-02-24 02:47:15.644727+00:00, run_duration=0.226047, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=225, pool=default_pool, queue=default, priority_weight=1, operator=TriggerDagRunOperator, queued_dttm=2026-02-24 02:47:11.977155+00:00, queued_by_job_id=208, pid=5583
2026-02-24 10:47:19,273 INFO - Marking run <DagRun c_1p1n1n_DAG2 @ 2026-02-24 02:47:01.072084+00:00: manual__2026-02-24T02:47:01.072084+00:00, state:running, queued_at: 2026-02-24 02:47:01.095124+00:00. externally triggered: True> successful
2026-02-24 10:47:19,274 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG2, execution_date=2026-02-24 02:47:01.072084+00:00, run_id=manual__2026-02-24T02:47:01.072084+00:00, run_start_date=2026-02-24 02:47:04.644252+00:00, run_end_date=2026-02-24 02:47:19.274880+00:00, run_duration=14.630628, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:47:01.072084+00:00, data_interval_end=2026-02-24 02:47:01.072084+00:00, dag_hash=2432b578155b6ddfdba45496256889cf
2026-02-24 10:47:19,286 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n1n_DAG3.c_1p1n1n_TASK3 manual__2026-02-24T02:47:15.592938+00:00 [scheduled]>
2026-02-24 10:47:19,287 INFO - DAG c_1p1n1n_DAG3 has 0/16 running and queued tasks
2026-02-24 10:47:19,288 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n1n_DAG3.c_1p1n1n_TASK3 manual__2026-02-24T02:47:15.592938+00:00 [scheduled]>
2026-02-24 10:47:19,290 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n1n_DAG3.c_1p1n1n_TASK3 manual__2026-02-24T02:47:15.592938+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:47:19,291 INFO - Sending TaskInstanceKey(dag_id='c_1p1n1n_DAG3', task_id='c_1p1n1n_TASK3', run_id='manual__2026-02-24T02:47:15.592938+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:47:19,292 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG3', 'c_1p1n1n_TASK3', 'manual__2026-02-24T02:47:15.592938+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:47:19,295 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n1n_DAG3', 'c_1p1n1n_TASK3', 'manual__2026-02-24T02:47:15.592938+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n1n.py']
2026-02-24 10:47:23,517 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n1n_DAG3', task_id='c_1p1n1n_TASK3', run_id='manual__2026-02-24T02:47:15.592938+00:00', try_number=1, map_index=-1)
2026-02-24 10:47:23,528 INFO - TaskInstance Finished: dag_id=c_1p1n1n_DAG3, task_id=c_1p1n1n_TASK3, run_id=manual__2026-02-24T02:47:15.592938+00:00, map_index=-1, run_start_date=2026-02-24 02:47:22.636064+00:00, run_end_date=2026-02-24 02:47:22.839282+00:00, run_duration=0.203218, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=226, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:47:19.289274+00:00, queued_by_job_id=208, pid=5586
2026-02-24 10:47:26,214 INFO - Marking run <DagRun c_1p1n1n_DAG3 @ 2026-02-24 02:47:15.592938+00:00: manual__2026-02-24T02:47:15.592938+00:00, state:running, queued_at: 2026-02-24 02:47:15.609141+00:00. externally triggered: True> successful
2026-02-24 10:47:26,216 INFO - DagRun Finished: dag_id=c_1p1n1n_DAG3, execution_date=2026-02-24 02:47:15.592938+00:00, run_id=manual__2026-02-24T02:47:15.592938+00:00, run_start_date=2026-02-24 02:47:19.259742+00:00, run_end_date=2026-02-24 02:47:26.215942+00:00, run_duration=6.9562, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:47:15.592938+00:00, data_interval_end=2026-02-24 02:47:15.592938+00:00, dag_hash=6d824235d565eea177e2112d44bf1810
2026-02-24 10:48:49,119 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:53:49,161 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 10:54:19,239 INFO - Orphaning unreferenced dataset 'dataset://1p1n/'
2026-02-24 10:58:18,526 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T02:58:15.047252+00:00 [scheduled]>
2026-02-24 10:58:18,527 INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
2026-02-24 10:58:18,528 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T02:58:15.047252+00:00 [scheduled]>
2026-02-24 10:58:18,531 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T02:58:15.047252+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:58:18,532 INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T02:58:15.047252+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:58:18,533 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T02:58:15.047252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 10:58:18,535 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T02:58:15.047252+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 10:58:23,121 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T02:58:15.047252+00:00', try_number=1, map_index=-1)
2026-02-24 10:58:23,134 INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T02:58:15.047252+00:00, map_index=-1, run_start_date=2026-02-24 02:58:22.279604+00:00, run_end_date=2026-02-24 02:58:22.488864+00:00, run_duration=0.20926, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=227, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:58:18.529949+00:00, queued_by_job_id=208, pid=5930
2026-02-24 10:58:26,802 INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 02:58:15.047252+00:00: manual__2026-02-24T02:58:15.047252+00:00, state:running, queued_at: 2026-02-24 02:58:15.057739+00:00. externally triggered: True> successful
2026-02-24 10:58:26,803 INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 02:58:15.047252+00:00, run_id=manual__2026-02-24T02:58:15.047252+00:00, run_start_date=2026-02-24 02:58:18.501752+00:00, run_end_date=2026-02-24 02:58:26.803419+00:00, run_duration=8.301667, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 02:58:15.047252+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
2026-02-24 10:58:26,814 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
2026-02-24 10:58:26,814 INFO - DAG c_1p1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:58:26,815 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
2026-02-24 10:58:26,818 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:58:26,819 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 10:58:26,821 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 10:58:26,824 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 10:58:31,326 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1)
2026-02-24 10:58:31,337 INFO - TaskInstance Finished: dag_id=c_1p1n_DAG1, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T02:58:22.508864+00:00, map_index=-1, run_start_date=2026-02-24 02:58:30.415840+00:00, run_end_date=2026-02-24 02:58:30.623561+00:00, run_duration=0.207721, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=228, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 02:58:26.817109+00:00, queued_by_job_id=208, pid=5933
2026-02-24 10:58:35,149 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK2 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
2026-02-24 10:58:35,150 INFO - DAG c_1p1n_DAG1 has 0/16 running and queued tasks
2026-02-24 10:58:35,151 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK2 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>
2026-02-24 10:58:35,154 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK2 dataset_triggered__2026-02-24T02:58:22.508864+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 10:58:35,156 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 10:58:35,157 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 10:58:35,159 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T02:58:22.508864+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 10:58:40,462 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T02:58:22.508864+00:00', try_number=1, map_index=-1)
2026-02-24 10:58:40,474 INFO - TaskInstance Finished: dag_id=c_1p1n_DAG1, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T02:58:22.508864+00:00, map_index=-1, run_start_date=2026-02-24 02:58:39.592972+00:00, run_end_date=2026-02-24 02:58:39.815558+00:00, run_duration=0.222586, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=229, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 02:58:35.152989+00:00, queued_by_job_id=208, pid=5942
2026-02-24 10:58:44,410 INFO - Marking run <DagRun c_1p1n_DAG1 @ 2026-02-24 02:58:22.508864+00:00: dataset_triggered__2026-02-24T02:58:22.508864+00:00, state:running, queued_at: 2026-02-24 02:58:26.770174+00:00. externally triggered: False> successful
2026-02-24 10:58:44,411 INFO - DagRun Finished: dag_id=c_1p1n_DAG1, execution_date=2026-02-24 02:58:22.508864+00:00, run_id=dataset_triggered__2026-02-24T02:58:22.508864+00:00, run_start_date=2026-02-24 02:58:26.787601+00:00, run_end_date=2026-02-24 02:58:44.411574+00:00, run_duration=17.623973, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 02:58:15.047252+00:00, dag_hash=85fbbd816b13cfbff4860f745427d6cc
2026-02-24 10:58:51,951 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:03:53,521 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:04:58,669 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:04:55.254749+00:00 [scheduled]>
2026-02-24 11:04:58,670 INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
2026-02-24 11:04:58,670 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:04:55.254749+00:00 [scheduled]>
2026-02-24 11:04:58,672 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:04:55.254749+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:04:58,673 INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:04:55.254749+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:04:58,674 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:04:55.254749+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:04:58,676 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:04:55.254749+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:05:02,959 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:04:55.254749+00:00', try_number=1, map_index=-1)
2026-02-24 11:05:02,971 INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:04:55.254749+00:00, map_index=-1, run_start_date=2026-02-24 03:05:02.112795+00:00, run_end_date=2026-02-24 03:05:02.314182+00:00, run_duration=0.201387, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=230, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:04:58.671850+00:00, queued_by_job_id=208, pid=6236
2026-02-24 11:05:05,651 INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:04:55.254749+00:00: manual__2026-02-24T03:04:55.254749+00:00, state:running, queued_at: 2026-02-24 03:04:55.274143+00:00. externally triggered: True> successful
2026-02-24 11:05:05,653 INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:04:55.254749+00:00, run_id=manual__2026-02-24T03:04:55.254749+00:00, run_start_date=2026-02-24 03:04:58.645593+00:00, run_end_date=2026-02-24 03:05:05.653062+00:00, run_duration=7.007469, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:04:55.254749+00:00, data_interval_end=2026-02-24 03:04:55.254749+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
2026-02-24 11:05:05,663 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:05:02.335454+00:00 [scheduled]>
2026-02-24 11:05:05,664 INFO - DAG c_1p1n_DAG1 has 0/16 running and queued tasks
2026-02-24 11:05:05,664 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:05:02.335454+00:00 [scheduled]>
2026-02-24 11:05:05,667 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_DAG1.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:05:02.335454+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:05:05,668 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:05:02.335454+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 11:05:05,669 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:05:02.335454+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:05:05,671 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_DAG1', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:05:02.335454+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:05:09,998 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_DAG1', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:05:02.335454+00:00', try_number=1, map_index=-1)
2026-02-24 11:05:10,011 INFO - TaskInstance Finished: dag_id=c_1p1n_DAG1, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:05:02.335454+00:00, map_index=-1, run_start_date=2026-02-24 03:05:09.087275+00:00, run_end_date=2026-02-24 03:05:09.292617+00:00, run_duration=0.205342, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=231, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:05:05.666441+00:00, queued_by_job_id=208, pid=6239
2026-02-24 11:05:12,589 ERROR - Marking run <DagRun c_1p1n_DAG1 @ 2026-02-24 03:05:02.335454+00:00: dataset_triggered__2026-02-24T03:05:02.335454+00:00, state:running, queued_at: 2026-02-24 03:05:05.620892+00:00. externally triggered: False> failed
2026-02-24 11:05:12,590 INFO - DagRun Finished: dag_id=c_1p1n_DAG1, execution_date=2026-02-24 03:05:02.335454+00:00, run_id=dataset_triggered__2026-02-24T03:05:02.335454+00:00, run_start_date=2026-02-24 03:05:05.636691+00:00, run_end_date=2026-02-24 03:05:12.590700+00:00, run_duration=6.954009, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:04:55.254749+00:00, data_interval_end=2026-02-24 03:04:55.254749+00:00, dag_hash=85fbbd816b13cfbff4860f745427d6cc
2026-02-24 11:08:54,405 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:08:51.230534+00:00 [scheduled]>
2026-02-24 11:08:54,406 INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
2026-02-24 11:08:54,407 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:08:51.230534+00:00 [scheduled]>
2026-02-24 11:08:54,409 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:08:51.230534+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:08:54,410 INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:08:51.230534+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:08:54,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:08:51.230534+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:08:54,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:08:51.230534+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:08:59,133 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:08:51.230534+00:00', try_number=1, map_index=-1)
2026-02-24 11:08:59,143 INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:08:51.230534+00:00, map_index=-1, run_start_date=2026-02-24 03:08:58.272417+00:00, run_end_date=2026-02-24 03:08:58.479888+00:00, run_duration=0.207471, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=232, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:08:54.408134+00:00, queued_by_job_id=208, pid=6378
2026-02-24 11:08:59,170 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:09:01,710 INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:08:51.230534+00:00: manual__2026-02-24T03:08:51.230534+00:00, state:running, queued_at: 2026-02-24 03:08:51.246154+00:00. externally triggered: True> successful
2026-02-24 11:09:01,711 INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:08:51.230534+00:00, run_id=manual__2026-02-24T03:08:51.230534+00:00, run_start_date=2026-02-24 03:08:54.384340+00:00, run_end_date=2026-02-24 03:09:01.711557+00:00, run_duration=7.327217, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:08:51.230534+00:00, data_interval_end=2026-02-24 03:08:51.230534+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
2026-02-24 11:09:01,721 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
2026-02-24 11:09:01,721 INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
2026-02-24 11:09:01,722 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
2026-02-24 11:09:01,724 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:09:01,725 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 11:09:01,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:09:01,728 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:09:06,054 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1)
2026-02-24 11:09:06,065 INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:08:58.500559+00:00, map_index=-1, run_start_date=2026-02-24 03:09:05.153623+00:00, run_end_date=2026-02-24 03:09:05.363846+00:00, run_duration=0.210223, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=233, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:09:01.723619+00:00, queued_by_job_id=208, pid=6384
2026-02-24 11:09:08,689 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
2026-02-24 11:09:08,690 INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
2026-02-24 11:09:08,691 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>
2026-02-24 11:09:08,693 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:08:58.500559+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:09:08,694 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:09:08,695 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:09:08,697 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:08:58.500559+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:09:13,194 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:08:58.500559+00:00', try_number=1, map_index=-1)
2026-02-24 11:09:13,204 INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T03:08:58.500559+00:00, map_index=-1, run_start_date=2026-02-24 03:09:12.289618+00:00, run_end_date=2026-02-24 03:09:12.500226+00:00, run_duration=0.210608, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=234, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:09:08.692190+00:00, queued_by_job_id=208, pid=6387
2026-02-24 11:09:16,730 INFO - Marking run <DagRun c_1p1n_2t @ 2026-02-24 03:08:58.500559+00:00: dataset_triggered__2026-02-24T03:08:58.500559+00:00, state:running, queued_at: 2026-02-24 03:09:01.682094+00:00. externally triggered: False> successful
2026-02-24 11:09:16,731 INFO - DagRun Finished: dag_id=c_1p1n_2t, execution_date=2026-02-24 03:08:58.500559+00:00, run_id=dataset_triggered__2026-02-24T03:08:58.500559+00:00, run_start_date=2026-02-24 03:09:01.696303+00:00, run_end_date=2026-02-24 03:09:16.731463+00:00, run_duration=15.03516, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 03:08:51.230534+00:00, dag_hash=91e76cce63cbec992d6382966ab78e6d
2026-02-24 11:11:01,790 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:10:57.126854+00:00 [scheduled]>
2026-02-24 11:11:01,792 INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
2026-02-24 11:11:01,793 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:10:57.126854+00:00 [scheduled]>
2026-02-24 11:11:01,797 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:10:57.126854+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:11:01,800 INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:10:57.126854+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:11:01,801 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:10:57.126854+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:11:01,805 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:10:57.126854+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:11:06,826 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:10:57.126854+00:00', try_number=1, map_index=-1)
2026-02-24 11:11:06,837 INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:10:57.126854+00:00, map_index=-1, run_start_date=2026-02-24 03:11:05.969069+00:00, run_end_date=2026-02-24 03:11:06.179247+00:00, run_duration=0.210178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=235, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:11:01.795610+00:00, queued_by_job_id=208, pid=6444
2026-02-24 11:11:09,902 INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:10:57.126854+00:00: manual__2026-02-24T03:10:57.126854+00:00, state:running, queued_at: 2026-02-24 03:10:57.139887+00:00. externally triggered: True> successful
2026-02-24 11:11:09,903 INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:10:57.126854+00:00, run_id=manual__2026-02-24T03:10:57.126854+00:00, run_start_date=2026-02-24 03:11:01.756573+00:00, run_end_date=2026-02-24 03:11:09.903004+00:00, run_duration=8.146431, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:10:57.126854+00:00, data_interval_end=2026-02-24 03:10:57.126854+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
2026-02-24 11:11:09,913 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
2026-02-24 11:11:09,914 INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
2026-02-24 11:11:09,915 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
2026-02-24 11:11:09,917 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:11:09,919 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 11:11:09,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:11:09,922 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:11:14,655 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1)
2026-02-24 11:11:14,668 INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:11:06.198605+00:00, map_index=-1, run_start_date=2026-02-24 03:11:13.747223+00:00, run_end_date=2026-02-24 03:11:13.984757+00:00, run_duration=0.237534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=236, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:11:09.916261+00:00, queued_by_job_id=208, pid=6447
2026-02-24 11:11:17,629 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
2026-02-24 11:11:17,630 INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
2026-02-24 11:11:17,632 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>
2026-02-24 11:11:17,635 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:11:06.198605+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:11:17,636 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:11:17,637 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:11:17,639 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:11:06.198605+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:11:22,222 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:11:06.198605+00:00', try_number=1, map_index=-1)
2026-02-24 11:11:22,235 INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T03:11:06.198605+00:00, map_index=-1, run_start_date=2026-02-24 03:11:21.368567+00:00, run_end_date=2026-02-24 03:11:21.575473+00:00, run_duration=0.206906, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=237, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:11:17.633669+00:00, queued_by_job_id=208, pid=6456
2026-02-24 11:11:25,355 ERROR - Marking run <DagRun c_1p1n_2t @ 2026-02-24 03:11:06.198605+00:00: dataset_triggered__2026-02-24T03:11:06.198605+00:00, state:running, queued_at: 2026-02-24 03:11:09.870512+00:00. externally triggered: False> failed
2026-02-24 11:11:25,356 INFO - DagRun Finished: dag_id=c_1p1n_2t, execution_date=2026-02-24 03:11:06.198605+00:00, run_id=dataset_triggered__2026-02-24T03:11:06.198605+00:00, run_start_date=2026-02-24 03:11:09.885451+00:00, run_end_date=2026-02-24 03:11:25.356031+00:00, run_duration=15.47058, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:10:57.126854+00:00, data_interval_end=2026-02-24 03:10:57.126854+00:00, dag_hash=91e76cce63cbec992d6382966ab78e6d
2026-02-24 11:14:02,349 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:15:26,821 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:15:22.633791+00:00 [scheduled]>
2026-02-24 11:15:26,822 INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
2026-02-24 11:15:26,823 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:15:22.633791+00:00 [scheduled]>
2026-02-24 11:15:26,825 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T03:15:22.633791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:15:26,826 INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:15:22.633791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:15:26,827 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:15:22.633791+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:15:26,830 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T03:15:22.633791+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:15:32,047 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T03:15:22.633791+00:00', try_number=1, map_index=-1)
2026-02-24 11:15:32,073 INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T03:15:22.633791+00:00, map_index=-1, run_start_date=2026-02-24 03:15:30.882783+00:00, run_end_date=2026-02-24 03:15:31.157893+00:00, run_duration=0.27511, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=238, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:15:26.824556+00:00, queued_by_job_id=208, pid=6609
2026-02-24 11:15:36,278 INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 03:15:22.633791+00:00: manual__2026-02-24T03:15:22.633791+00:00, state:running, queued_at: 2026-02-24 03:15:22.646096+00:00. externally triggered: True> successful
2026-02-24 11:15:36,279 INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 03:15:22.633791+00:00, run_id=manual__2026-02-24T03:15:22.633791+00:00, run_start_date=2026-02-24 03:15:26.799878+00:00, run_end_date=2026-02-24 03:15:36.279276+00:00, run_duration=9.479398, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:15:22.633791+00:00, data_interval_end=2026-02-24 03:15:22.633791+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
2026-02-24 11:15:36,289 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
2026-02-24 11:15:36,291 INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
2026-02-24 11:15:36,291 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
2026-02-24 11:15:36,294 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK1 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:15:36,295 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 11:15:36,296 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:15:36,299 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:15:41,058 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1)
2026-02-24 11:15:41,069 INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T03:15:31.176510+00:00, map_index=-1, run_start_date=2026-02-24 03:15:40.070398+00:00, run_end_date=2026-02-24 03:15:40.291483+00:00, run_duration=0.221085, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=239, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 03:15:36.293235+00:00, queued_by_job_id=208, pid=6612
2026-02-24 11:15:44,641 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
2026-02-24 11:15:44,643 INFO - DAG c_1p1n_2t has 0/16 running and queued tasks
2026-02-24 11:15:44,644 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>
2026-02-24 11:15:44,646 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n_2t.c_1p1n_TASK2 dataset_triggered__2026-02-24T03:15:31.176510+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:15:44,647 INFO - Sending TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:15:44,648 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:15:44,651 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n_2t', 'c_1p1n_TASK2', 'dataset_triggered__2026-02-24T03:15:31.176510+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 11:15:49,169 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n_2t', task_id='c_1p1n_TASK2', run_id='dataset_triggered__2026-02-24T03:15:31.176510+00:00', try_number=1, map_index=-1)
2026-02-24 11:15:49,180 INFO - TaskInstance Finished: dag_id=c_1p1n_2t, task_id=c_1p1n_TASK2, run_id=dataset_triggered__2026-02-24T03:15:31.176510+00:00, map_index=-1, run_start_date=2026-02-24 03:15:48.232112+00:00, run_end_date=2026-02-24 03:15:48.442896+00:00, run_duration=0.210784, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=240, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:15:44.645572+00:00, queued_by_job_id=208, pid=6615
2026-02-24 11:15:52,313 INFO - Marking run <DagRun c_1p1n_2t @ 2026-02-24 03:15:31.176510+00:00: dataset_triggered__2026-02-24T03:15:31.176510+00:00, state:running, queued_at: 2026-02-24 03:15:36.247564+00:00. externally triggered: False> successful
2026-02-24 11:15:52,314 INFO - DagRun Finished: dag_id=c_1p1n_2t, execution_date=2026-02-24 03:15:31.176510+00:00, run_id=dataset_triggered__2026-02-24T03:15:31.176510+00:00, run_start_date=2026-02-24 03:15:36.263605+00:00, run_end_date=2026-02-24 03:15:52.314839+00:00, run_duration=16.051234, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:15:22.633791+00:00, data_interval_end=2026-02-24 03:15:22.633791+00:00, dag_hash=91e76cce63cbec992d6382966ab78e6d
2026-02-24 11:19:05,480 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:24:08,422 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:26:26,154 INFO - 1 tasks up for execution:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:26:24.274565+00:00 [scheduled]>
2026-02-24 11:26:26,155 INFO - DAG p_2p1n_dw_user_sync has 0/16 running and queued tasks
2026-02-24 11:26:26,155 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:26:24.274565+00:00 [scheduled]>
2026-02-24 11:26:26,158 INFO - Trying to enqueue tasks: [<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:26:24.274565+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:26:26,159 INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:26:24.274565+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:26:26,160 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:26:24.274565+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:26:26,163 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:26:24.274565+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:26:30,451 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:26:24.274565+00:00', try_number=1, map_index=-1)
2026-02-24 11:26:30,463 INFO - TaskInstance Finished: dag_id=p_2p1n_dw_user_sync, task_id=sync_user_data, run_id=manual__2026-02-24T03:26:24.274565+00:00, map_index=-1, run_start_date=2026-02-24 03:26:29.549835+00:00, run_end_date=2026-02-24 03:26:29.931646+00:00, run_duration=0.381811, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=241, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:26:26.157102+00:00, queued_by_job_id=208, pid=6937
2026-02-24 11:26:33,807 INFO - Marking run <DagRun p_2p1n_dw_user_sync @ 2026-02-24 03:26:24.274565+00:00: manual__2026-02-24T03:26:24.274565+00:00, state:running, queued_at: 2026-02-24 03:26:24.295081+00:00. externally triggered: True> successful
2026-02-24 11:26:33,808 INFO - DagRun Finished: dag_id=p_2p1n_dw_user_sync, execution_date=2026-02-24 03:26:24.274565+00:00, run_id=manual__2026-02-24T03:26:24.274565+00:00, run_start_date=2026-02-24 03:26:26.132724+00:00, run_end_date=2026-02-24 03:26:33.808412+00:00, run_duration=7.675688, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:26:24.274565+00:00, data_interval_end=2026-02-24 03:26:24.274565+00:00, dag_hash=be49d27b980a51dd9a3ddd841863cbd6
2026-02-24 11:26:33,818 INFO - 1 tasks up for execution:
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:26:32.522691+00:00 [scheduled]>
2026-02-24 11:26:33,820 INFO - DAG p_2p1n_dw_order_sync has 0/16 running and queued tasks
2026-02-24 11:26:33,821 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:26:32.522691+00:00 [scheduled]>
2026-02-24 11:26:33,823 INFO - Trying to enqueue tasks: [<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:26:32.522691+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:26:33,824 INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:26:32.522691+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:26:33,825 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:26:32.522691+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:26:33,828 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:26:32.522691+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:26:37,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:26:32.522691+00:00', try_number=1, map_index=-1)
2026-02-24 11:26:37,605 INFO - TaskInstance Finished: dag_id=p_2p1n_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-24T03:26:32.522691+00:00, map_index=-1, run_start_date=2026-02-24 03:26:36.620475+00:00, run_end_date=2026-02-24 03:26:37.000651+00:00, run_duration=0.380176, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=242, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:26:33.822622+00:00, queued_by_job_id=208, pid=6941
2026-02-24 11:26:40,555 INFO - Marking run <DagRun p_2p1n_dw_order_sync @ 2026-02-24 03:26:32.522691+00:00: manual__2026-02-24T03:26:32.522691+00:00, state:running, queued_at: 2026-02-24 03:26:32.543836+00:00. externally triggered: True> successful
2026-02-24 11:26:40,556 INFO - DagRun Finished: dag_id=p_2p1n_dw_order_sync, execution_date=2026-02-24 03:26:32.522691+00:00, run_id=manual__2026-02-24T03:26:32.522691+00:00, run_start_date=2026-02-24 03:26:33.791747+00:00, run_end_date=2026-02-24 03:26:40.556842+00:00, run_duration=6.765095, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:26:32.522691+00:00, data_interval_end=2026-02-24 03:26:32.522691+00:00, dag_hash=a1f7ed216d49cad639f28b36f1b0251d
2026-02-24 11:29:11,370 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:31:31,467 INFO - 2 tasks up for execution:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:31:27.744326+00:00 [scheduled]>
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:31:30.764172+00:00 [scheduled]>
2026-02-24 11:31:31,468 INFO - DAG p_2p1n_dw_user_sync has 0/16 running and queued tasks
2026-02-24 11:31:31,469 INFO - DAG p_2p1n_dw_order_sync has 0/16 running and queued tasks
2026-02-24 11:31:31,469 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:31:27.744326+00:00 [scheduled]>
	<TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:31:30.764172+00:00 [scheduled]>
2026-02-24 11:31:31,472 INFO - Trying to enqueue tasks: [<TaskInstance: p_2p1n_dw_user_sync.sync_user_data manual__2026-02-24T03:31:27.744326+00:00 [scheduled]>, <TaskInstance: p_2p1n_dw_order_sync.sync_order_data manual__2026-02-24T03:31:30.764172+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:31:31,473 INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:31:27.744326+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:31:31,474 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:31:27.744326+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:31:31,475 INFO - Sending TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:31:30.764172+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:31:31,476 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:31:30.764172+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:31:31,478 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_user_sync', 'sync_user_data', 'manual__2026-02-24T03:31:27.744326+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:31:35,699 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_2p1n_dw_order_sync', 'sync_order_data', 'manual__2026-02-24T03:31:30.764172+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:31:39,524 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_user_sync', task_id='sync_user_data', run_id='manual__2026-02-24T03:31:27.744326+00:00', try_number=1, map_index=-1)
2026-02-24 11:31:39,527 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_2p1n_dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-24T03:31:30.764172+00:00', try_number=1, map_index=-1)
2026-02-24 11:31:39,536 INFO - TaskInstance Finished: dag_id=p_2p1n_dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-24T03:31:30.764172+00:00, map_index=-1, run_start_date=2026-02-24 03:31:38.565512+00:00, run_end_date=2026-02-24 03:31:38.933381+00:00, run_duration=0.367869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=244, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:31:31.471151+00:00, queued_by_job_id=208, pid=7106
2026-02-24 11:31:39,538 INFO - TaskInstance Finished: dag_id=p_2p1n_dw_user_sync, task_id=sync_user_data, run_id=manual__2026-02-24T03:31:27.744326+00:00, map_index=-1, run_start_date=2026-02-24 03:31:34.699792+00:00, run_end_date=2026-02-24 03:31:35.080248+00:00, run_duration=0.380456, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=243, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:31:31.471151+00:00, queued_by_job_id=208, pid=7104
2026-02-24 11:31:42,975 INFO - Marking run <DagRun p_2p1n_dw_user_sync @ 2026-02-24 03:31:27.744326+00:00: manual__2026-02-24T03:31:27.744326+00:00, state:running, queued_at: 2026-02-24 03:31:27.755996+00:00. externally triggered: True> successful
2026-02-24 11:31:42,976 INFO - DagRun Finished: dag_id=p_2p1n_dw_user_sync, execution_date=2026-02-24 03:31:27.744326+00:00, run_id=manual__2026-02-24T03:31:27.744326+00:00, run_start_date=2026-02-24 03:31:31.437969+00:00, run_end_date=2026-02-24 03:31:42.976688+00:00, run_duration=11.538719, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:31:27.744326+00:00, data_interval_end=2026-02-24 03:31:27.744326+00:00, dag_hash=be49d27b980a51dd9a3ddd841863cbd6
2026-02-24 11:31:42,981 INFO - Marking run <DagRun p_2p1n_dw_order_sync @ 2026-02-24 03:31:30.764172+00:00: manual__2026-02-24T03:31:30.764172+00:00, state:running, queued_at: 2026-02-24 03:31:30.778284+00:00. externally triggered: True> successful
2026-02-24 11:31:42,982 INFO - DagRun Finished: dag_id=p_2p1n_dw_order_sync, execution_date=2026-02-24 03:31:30.764172+00:00, run_id=manual__2026-02-24T03:31:30.764172+00:00, run_start_date=2026-02-24 03:31:31.440412+00:00, run_end_date=2026-02-24 03:31:42.982286+00:00, run_duration=11.541874, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:31:30.764172+00:00, data_interval_end=2026-02-24 03:31:30.764172+00:00, dag_hash=a1f7ed216d49cad639f28b36f1b0251d
2026-02-24 11:31:42,993 INFO - 1 tasks up for execution:
	<TaskInstance: c_2p1n_order_user_analysis.analyze_order_user dataset_triggered__2026-02-24T03:31:38.953370+00:00 [scheduled]>
2026-02-24 11:31:42,994 INFO - DAG c_2p1n_order_user_analysis has 0/16 running and queued tasks
2026-02-24 11:31:42,995 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_2p1n_order_user_analysis.analyze_order_user dataset_triggered__2026-02-24T03:31:38.953370+00:00 [scheduled]>
2026-02-24 11:31:42,997 INFO - Trying to enqueue tasks: [<TaskInstance: c_2p1n_order_user_analysis.analyze_order_user dataset_triggered__2026-02-24T03:31:38.953370+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:31:42,998 INFO - Sending TaskInstanceKey(dag_id='c_2p1n_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-24T03:31:38.953370+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:31:42,999 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_2p1n_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-24T03:31:38.953370+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:31:43,002 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_2p1n_order_user_analysis', 'analyze_order_user', 'dataset_triggered__2026-02-24T03:31:38.953370+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /2p1n.py']
2026-02-24 11:31:47,236 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_2p1n_order_user_analysis', task_id='analyze_order_user', run_id='dataset_triggered__2026-02-24T03:31:38.953370+00:00', try_number=1, map_index=-1)
2026-02-24 11:31:47,246 INFO - TaskInstance Finished: dag_id=c_2p1n_order_user_analysis, task_id=analyze_order_user, run_id=dataset_triggered__2026-02-24T03:31:38.953370+00:00, map_index=-1, run_start_date=2026-02-24 03:31:46.235523+00:00, run_end_date=2026-02-24 03:31:46.652691+00:00, run_duration=0.417168, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=245, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:31:42.996296+00:00, queued_by_job_id=208, pid=7109
2026-02-24 11:31:50,529 INFO - Marking run <DagRun c_2p1n_order_user_analysis @ 2026-02-24 03:31:38.953370+00:00: dataset_triggered__2026-02-24T03:31:38.953370+00:00, state:running, queued_at: 2026-02-24 03:31:42.936350+00:00. externally triggered: False> successful
2026-02-24 11:31:50,530 INFO - DagRun Finished: dag_id=c_2p1n_order_user_analysis, execution_date=2026-02-24 03:31:38.953370+00:00, run_id=dataset_triggered__2026-02-24T03:31:38.953370+00:00, run_start_date=2026-02-24 03:31:42.960563+00:00, run_end_date=2026-02-24 03:31:50.530768+00:00, run_duration=7.570205, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-14 03:36:00.776536+00:00, data_interval_end=2026-02-24 03:31:30.764172+00:00, dag_hash=c0431e4500d4b89e73ba3af5030b2402
2026-02-24 11:34:12,301 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:39:13,143 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:44:15,862 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:49:19,153 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:50:43,410 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T03:50:42.943391+00:00 [scheduled]>
2026-02-24 11:50:43,412 INFO - DAG p_1p2n_DAGs has 0/16 running and queued tasks
2026-02-24 11:50:43,414 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T03:50:42.943391+00:00 [scheduled]>
2026-02-24 11:50:43,417 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p2n_DAGs.p_1p2n_TASK manual__2026-02-24T03:50:42.943391+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:50:43,419 INFO - Sending TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T03:50:42.943391+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:50:43,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T03:50:42.943391+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 11:50:43,428 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p2n_DAGs', 'p_1p2n_TASK', 'manual__2026-02-24T03:50:42.943391+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 11:50:48,731 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p2n_DAGs', task_id='p_1p2n_TASK', run_id='manual__2026-02-24T03:50:42.943391+00:00', try_number=1, map_index=-1)
2026-02-24 11:50:48,742 INFO - TaskInstance Finished: dag_id=p_1p2n_DAGs, task_id=p_1p2n_TASK, run_id=manual__2026-02-24T03:50:42.943391+00:00, map_index=-1, run_start_date=2026-02-24 03:50:47.690668+00:00, run_end_date=2026-02-24 03:50:47.933070+00:00, run_duration=0.242402, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=246, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:50:43.415677+00:00, queued_by_job_id=208, pid=7734
2026-02-24 11:50:51,617 INFO - Marking run <DagRun p_1p2n_DAGs @ 2026-02-24 03:50:42.943391+00:00: manual__2026-02-24T03:50:42.943391+00:00, state:running, queued_at: 2026-02-24 03:50:42.955287+00:00. externally triggered: True> successful
2026-02-24 11:50:51,618 INFO - DagRun Finished: dag_id=p_1p2n_DAGs, execution_date=2026-02-24 03:50:42.943391+00:00, run_id=manual__2026-02-24T03:50:42.943391+00:00, run_start_date=2026-02-24 03:50:43.387147+00:00, run_end_date=2026-02-24 03:50:51.618208+00:00, run_duration=8.231061, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 03:50:42.943391+00:00, data_interval_end=2026-02-24 03:50:42.943391+00:00, dag_hash=bcc79dc6c0926a8d58a1f7ccd0ba8898
2026-02-24 11:50:51,629 INFO - 2 tasks up for execution:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_DAG2_TASK1 dataset_triggered__2026-02-24T03:50:47.957041+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_DAG1_TASK1 dataset_triggered__2026-02-24T03:50:47.958959+00:00 [scheduled]>
2026-02-24 11:50:51,630 INFO - DAG c_1p2n_DAG2 has 0/16 running and queued tasks
2026-02-24 11:50:51,630 INFO - DAG c_1p2n_DAG1 has 0/16 running and queued tasks
2026-02-24 11:50:51,631 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p2n_DAG2.c_1p2n_DAG2_TASK1 dataset_triggered__2026-02-24T03:50:47.957041+00:00 [scheduled]>
	<TaskInstance: c_1p2n_DAG1.c_1p2n_DAG1_TASK1 dataset_triggered__2026-02-24T03:50:47.958959+00:00 [scheduled]>
2026-02-24 11:50:51,634 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p2n_DAG2.c_1p2n_DAG2_TASK1 dataset_triggered__2026-02-24T03:50:47.957041+00:00 [scheduled]>, <TaskInstance: c_1p2n_DAG1.c_1p2n_DAG1_TASK1 dataset_triggered__2026-02-24T03:50:47.958959+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 11:50:51,635 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_DAG2_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.957041+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:50:51,636 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_DAG2_TASK1', 'dataset_triggered__2026-02-24T03:50:47.957041+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 11:50:51,637 INFO - Sending TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_DAG1_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.958959+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 11:50:51,637 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_DAG1_TASK1', 'dataset_triggered__2026-02-24T03:50:47.958959+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 11:50:51,640 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG2', 'c_1p2n_DAG2_TASK1', 'dataset_triggered__2026-02-24T03:50:47.957041+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 11:50:55,915 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p2n_DAG1', 'c_1p2n_DAG1_TASK1', 'dataset_triggered__2026-02-24T03:50:47.958959+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p2n.py']
2026-02-24 11:51:00,281 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG2', task_id='c_1p2n_DAG2_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.957041+00:00', try_number=1, map_index=-1)
2026-02-24 11:51:00,283 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p2n_DAG1', task_id='c_1p2n_DAG1_TASK1', run_id='dataset_triggered__2026-02-24T03:50:47.958959+00:00', try_number=1, map_index=-1)
2026-02-24 11:51:00,293 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG2, task_id=c_1p2n_DAG2_TASK1, run_id=dataset_triggered__2026-02-24T03:50:47.957041+00:00, map_index=-1, run_start_date=2026-02-24 03:50:55.058578+00:00, run_end_date=2026-02-24 03:50:55.273166+00:00, run_duration=0.214588, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=247, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:50:51.632952+00:00, queued_by_job_id=208, pid=7739
2026-02-24 11:51:00,295 INFO - TaskInstance Finished: dag_id=c_1p2n_DAG1, task_id=c_1p2n_DAG1_TASK1, run_id=dataset_triggered__2026-02-24T03:50:47.958959+00:00, map_index=-1, run_start_date=2026-02-24 03:50:59.385135+00:00, run_end_date=2026-02-24 03:50:59.601145+00:00, run_duration=0.21601, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=248, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 03:50:51.632952+00:00, queued_by_job_id=208, pid=7741
2026-02-24 11:51:03,217 INFO - Marking run <DagRun c_1p2n_DAG2 @ 2026-02-24 03:50:47.957041+00:00: dataset_triggered__2026-02-24T03:50:47.957041+00:00, state:running, queued_at: 2026-02-24 03:50:51.587139+00:00. externally triggered: False> successful
2026-02-24 11:51:03,218 INFO - DagRun Finished: dag_id=c_1p2n_DAG2, execution_date=2026-02-24 03:50:47.957041+00:00, run_id=dataset_triggered__2026-02-24T03:50:47.957041+00:00, run_start_date=2026-02-24 03:50:51.600394+00:00, run_end_date=2026-02-24 03:51:03.218415+00:00, run_duration=11.618021, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:50:42.943391+00:00, data_interval_end=2026-02-24 03:50:42.943391+00:00, dag_hash=98275d99bdc42b085c239e856f4230f4
2026-02-24 11:51:03,224 INFO - Marking run <DagRun c_1p2n_DAG1 @ 2026-02-24 03:50:47.958959+00:00: dataset_triggered__2026-02-24T03:50:47.958959+00:00, state:running, queued_at: 2026-02-24 03:50:51.576980+00:00. externally triggered: False> successful
2026-02-24 11:51:03,225 INFO - DagRun Finished: dag_id=c_1p2n_DAG1, execution_date=2026-02-24 03:50:47.958959+00:00, run_id=dataset_triggered__2026-02-24T03:50:47.958959+00:00, run_start_date=2026-02-24 03:50:51.600498+00:00, run_end_date=2026-02-24 03:51:03.225059+00:00, run_duration=11.624561, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 03:50:42.943391+00:00, data_interval_end=2026-02-24 03:50:42.943391+00:00, dag_hash=5a65660f9e489d59e87932edad18febb
2026-02-24 11:54:19,775 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 11:54:32,597 INFO - Orphaning unreferenced dataset 'dataset://1p1n2t/'
2026-02-24 11:59:21,680 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:00:31,790 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T04:00:27.880872+00:00 [scheduled]>
2026-02-24 12:00:31,791 INFO - DAG p_1p1n_DAGs has 0/16 running and queued tasks
2026-02-24 12:00:31,792 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T04:00:27.880872+00:00 [scheduled]>
2026-02-24 12:00:31,794 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n_DAGs.p_1p1n_TASK manual__2026-02-24T04:00:27.880872+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 12:00:31,795 INFO - Sending TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T04:00:27.880872+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 12:00:31,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T04:00:27.880872+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 12:00:31,798 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n_DAGs', 'p_1p1n_TASK', 'manual__2026-02-24T04:00:27.880872+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 12:00:36,874 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n_DAGs', task_id='p_1p1n_TASK', run_id='manual__2026-02-24T04:00:27.880872+00:00', try_number=1, map_index=-1)
2026-02-24 12:00:36,883 INFO - TaskInstance Finished: dag_id=p_1p1n_DAGs, task_id=p_1p1n_TASK, run_id=manual__2026-02-24T04:00:27.880872+00:00, map_index=-1, run_start_date=2026-02-24 04:00:36.000200+00:00, run_end_date=2026-02-24 04:00:36.208573+00:00, run_duration=0.208373, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=249, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:00:31.793298+00:00, queued_by_job_id=208, pid=8080
2026-02-24 12:00:39,879 INFO - Marking run <DagRun p_1p1n_DAGs @ 2026-02-24 04:00:27.880872+00:00: manual__2026-02-24T04:00:27.880872+00:00, state:running, queued_at: 2026-02-24 04:00:27.893270+00:00. externally triggered: True> successful
2026-02-24 12:00:39,880 INFO - DagRun Finished: dag_id=p_1p1n_DAGs, execution_date=2026-02-24 04:00:27.880872+00:00, run_id=manual__2026-02-24T04:00:27.880872+00:00, run_start_date=2026-02-24 04:00:31.771790+00:00, run_end_date=2026-02-24 04:00:39.880652+00:00, run_duration=8.108862, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 04:00:27.880872+00:00, data_interval_end=2026-02-24 04:00:27.880872+00:00, dag_hash=1c407148170c3feae9e39cd6ba58c072
2026-02-24 12:00:39,890 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n.c_1p1n_TASK1 dataset_triggered__2026-02-24T04:00:36.228926+00:00 [scheduled]>
2026-02-24 12:00:39,891 INFO - DAG c_1p1n has 0/16 running and queued tasks
2026-02-24 12:00:39,891 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n.c_1p1n_TASK1 dataset_triggered__2026-02-24T04:00:36.228926+00:00 [scheduled]>
2026-02-24 12:00:39,894 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n.c_1p1n_TASK1 dataset_triggered__2026-02-24T04:00:36.228926+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 12:00:39,895 INFO - Sending TaskInstanceKey(dag_id='c_1p1n', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T04:00:36.228926+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 12:00:39,896 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T04:00:36.228926+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 12:00:39,898 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n', 'c_1p1n_TASK1', 'dataset_triggered__2026-02-24T04:00:36.228926+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n.py']
2026-02-24 12:00:44,453 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n', task_id='c_1p1n_TASK1', run_id='dataset_triggered__2026-02-24T04:00:36.228926+00:00', try_number=1, map_index=-1)
2026-02-24 12:00:44,463 INFO - TaskInstance Finished: dag_id=c_1p1n, task_id=c_1p1n_TASK1, run_id=dataset_triggered__2026-02-24T04:00:36.228926+00:00, map_index=-1, run_start_date=2026-02-24 04:00:43.493721+00:00, run_end_date=2026-02-24 04:00:43.707552+00:00, run_duration=0.213831, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=250, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:00:39.892958+00:00, queued_by_job_id=208, pid=8094
2026-02-24 12:00:44,495 INFO - Orphaning unreferenced dataset 'dataset://1p1n2t/'
2026-02-24 12:00:47,342 INFO - Marking run <DagRun c_1p1n @ 2026-02-24 04:00:36.228926+00:00: dataset_triggered__2026-02-24T04:00:36.228926+00:00, state:running, queued_at: 2026-02-24 04:00:39.852048+00:00. externally triggered: False> successful
2026-02-24 12:00:47,343 INFO - DagRun Finished: dag_id=c_1p1n, execution_date=2026-02-24 04:00:36.228926+00:00, run_id=dataset_triggered__2026-02-24T04:00:36.228926+00:00, run_start_date=2026-02-24 04:00:39.865712+00:00, run_end_date=2026-02-24 04:00:47.343345+00:00, run_duration=7.477633, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 02:58:15.047252+00:00, data_interval_end=2026-02-24 04:00:27.880872+00:00, dag_hash=2232c17af953533597ba3e1a46132e55
2026-02-24 12:02:17,376 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:02:16.315580+00:00 [scheduled]>
2026-02-24 12:02:17,377 INFO - DAG p_1p1n2t_DAGs has 0/16 running and queued tasks
2026-02-24 12:02:17,379 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:02:16.315580+00:00 [scheduled]>
2026-02-24 12:02:17,381 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:02:16.315580+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 12:02:17,382 INFO - Sending TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:02:16.315580+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 12:02:17,383 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:02:16.315580+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:02:17,386 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:02:16.315580+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:02:22,017 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:02:16.315580+00:00', try_number=1, map_index=-1)
2026-02-24 12:02:22,027 INFO - TaskInstance Finished: dag_id=p_1p1n2t_DAGs, task_id=p_1p1n2t_TASK, run_id=manual__2026-02-24T04:02:16.315580+00:00, map_index=-1, run_start_date=2026-02-24 04:02:21.104590+00:00, run_end_date=2026-02-24 04:02:21.307444+00:00, run_duration=0.202854, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=251, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:02:17.380417+00:00, queued_by_job_id=208, pid=8179
2026-02-24 12:02:24,769 INFO - Marking run <DagRun p_1p1n2t_DAGs @ 2026-02-24 04:02:16.315580+00:00: manual__2026-02-24T04:02:16.315580+00:00, state:running, queued_at: 2026-02-24 04:02:16.335974+00:00. externally triggered: True> successful
2026-02-24 12:02:24,770 INFO - DagRun Finished: dag_id=p_1p1n2t_DAGs, execution_date=2026-02-24 04:02:16.315580+00:00, run_id=manual__2026-02-24T04:02:16.315580+00:00, run_start_date=2026-02-24 04:02:17.350390+00:00, run_end_date=2026-02-24 04:02:24.770434+00:00, run_duration=7.420044, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 04:02:16.315580+00:00, data_interval_end=2026-02-24 04:02:16.315580+00:00, dag_hash=a270c45e740615b98a97f7f70d3a8a7b
2026-02-24 12:04:10,573 INFO - 1 tasks up for execution:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:04:07.825997+00:00 [scheduled]>
2026-02-24 12:04:10,574 INFO - DAG p_1p1n2t_DAGs has 0/16 running and queued tasks
2026-02-24 12:04:10,575 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:04:07.825997+00:00 [scheduled]>
2026-02-24 12:04:10,577 INFO - Trying to enqueue tasks: [<TaskInstance: p_1p1n2t_DAGs.p_1p1n2t_TASK manual__2026-02-24T04:04:07.825997+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 12:04:10,578 INFO - Sending TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:04:07.825997+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 12:04:10,579 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:04:07.825997+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:04:10,581 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_1p1n2t_DAGs', 'p_1p1n2t_TASK', 'manual__2026-02-24T04:04:07.825997+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:04:15,124 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_1p1n2t_DAGs', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T04:04:07.825997+00:00', try_number=1, map_index=-1)
2026-02-24 12:04:15,133 INFO - TaskInstance Finished: dag_id=p_1p1n2t_DAGs, task_id=p_1p1n2t_TASK, run_id=manual__2026-02-24T04:04:07.825997+00:00, map_index=-1, run_start_date=2026-02-24 04:04:14.261320+00:00, run_end_date=2026-02-24 04:04:14.469966+00:00, run_duration=0.208646, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=252, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:04:10.576335+00:00, queued_by_job_id=208, pid=8233
2026-02-24 12:04:17,684 INFO - Marking run <DagRun p_1p1n2t_DAGs @ 2026-02-24 04:04:07.825997+00:00: manual__2026-02-24T04:04:07.825997+00:00, state:running, queued_at: 2026-02-24 04:04:07.839352+00:00. externally triggered: True> successful
2026-02-24 12:04:17,685 INFO - DagRun Finished: dag_id=p_1p1n2t_DAGs, execution_date=2026-02-24 04:04:07.825997+00:00, run_id=manual__2026-02-24T04:04:07.825997+00:00, run_start_date=2026-02-24 04:04:10.551499+00:00, run_end_date=2026-02-24 04:04:17.685145+00:00, run_duration=7.133646, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 04:04:07.825997+00:00, data_interval_end=2026-02-24 04:04:07.825997+00:00, dag_hash=a270c45e740615b98a97f7f70d3a8a7b
2026-02-24 12:04:17,694 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK1 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
2026-02-24 12:04:17,695 INFO - DAG c_1p1n2t has 0/16 running and queued tasks
2026-02-24 12:04:17,696 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK1 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
2026-02-24 12:04:17,698 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n2t.c_1p1n2t_TASK1 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 12:04:17,698 INFO - Sending TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK1', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 12:04:17,699 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK1', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:04:17,701 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK1', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:04:21,903 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK1', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1)
2026-02-24 12:04:21,912 INFO - TaskInstance Finished: dag_id=c_1p1n2t, task_id=c_1p1n2t_TASK1, run_id=dataset_triggered__2026-02-24T04:04:14.489596+00:00, map_index=-1, run_start_date=2026-02-24 04:04:21.062298+00:00, run_end_date=2026-02-24 04:04:21.267076+00:00, run_duration=0.204778, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=253, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 04:04:17.696953+00:00, queued_by_job_id=208, pid=8236
2026-02-24 12:04:21,939 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:04:25,290 INFO - 1 tasks up for execution:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK2 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
2026-02-24 12:04:25,292 INFO - DAG c_1p1n2t has 0/16 running and queued tasks
2026-02-24 12:04:25,292 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_1p1n2t.c_1p1n2t_TASK2 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>
2026-02-24 12:04:25,295 INFO - Trying to enqueue tasks: [<TaskInstance: c_1p1n2t.c_1p1n2t_TASK2 dataset_triggered__2026-02-24T04:04:14.489596+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 12:04:25,296 INFO - Sending TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK2', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 12:04:25,296 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK2', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:04:25,298 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_1p1n2t', 'c_1p1n2t_TASK2', 'dataset_triggered__2026-02-24T04:04:14.489596+00:00', '--local', '--subdir', 'DAGS_FOLDER/producer_consumer /1p1n2t.py']
2026-02-24 12:04:29,516 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_1p1n2t', task_id='c_1p1n2t_TASK2', run_id='dataset_triggered__2026-02-24T04:04:14.489596+00:00', try_number=1, map_index=-1)
2026-02-24 12:04:29,525 INFO - TaskInstance Finished: dag_id=c_1p1n2t, task_id=c_1p1n2t_TASK2, run_id=dataset_triggered__2026-02-24T04:04:14.489596+00:00, map_index=-1, run_start_date=2026-02-24 04:04:28.702307+00:00, run_end_date=2026-02-24 04:04:28.894827+00:00, run_duration=0.19252, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=254, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 04:04:25.293823+00:00, queued_by_job_id=208, pid=8240
2026-02-24 12:04:33,027 INFO - Marking run <DagRun c_1p1n2t @ 2026-02-24 04:04:14.489596+00:00: dataset_triggered__2026-02-24T04:04:14.489596+00:00, state:running, queued_at: 2026-02-24 04:04:17.654551+00:00. externally triggered: False> successful
2026-02-24 12:04:33,028 INFO - DagRun Finished: dag_id=c_1p1n2t, execution_date=2026-02-24 04:04:14.489596+00:00, run_id=dataset_triggered__2026-02-24T04:04:14.489596+00:00, run_start_date=2026-02-24 04:04:17.670611+00:00, run_end_date=2026-02-24 04:04:33.028516+00:00, run_duration=15.357905, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 04:02:16.315580+00:00, data_interval_end=2026-02-24 04:04:07.825997+00:00, dag_hash=62e8b6b36b717686055a70f697d10f6c
2026-02-24 12:09:23,268 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:14:23,918 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:19:24,332 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:24:25,149 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:29:27,380 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:34:28,330 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:39:29,665 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:44:30,724 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:49:33,793 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:54:34,154 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 12:59:35,533 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:04:41,355 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:09:45,521 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:14:46,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:19:49,991 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:24:50,022 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:29:52,125 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:34:54,223 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:39:55,041 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:44:57,944 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:49:58,885 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 13:55:02,336 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:00:04,637 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:05:06,947 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:10:08,203 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:15:09,735 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:20:10,030 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:25:12,605 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:30:17,539 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:35:19,722 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:40:20,919 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:45:22,276 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:50:25,234 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 14:55:28,035 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:00:29,450 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:05:31,893 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:10:33,880 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:15:35,044 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:20:38,097 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:25:39,251 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:27:02,518 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_1p1n2t_TASK manual__2026-02-24T07:26:58.766819+00:00 [scheduled]>
2026-02-24 15:27:02,519 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 15:27:02,520 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_1p1n2t_TASK manual__2026-02-24T07:26:58.766819+00:00 [scheduled]>
2026-02-24 15:27:02,522 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_1p1n2t_TASK manual__2026-02-24T07:26:58.766819+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:27:02,526 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T07:26:58.766819+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:27:02,527 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_1p1n2t_TASK', 'manual__2026-02-24T07:26:58.766819+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:27:02,530 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_1p1n2t_TASK', 'manual__2026-02-24T07:26:58.766819+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:27:08,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_1p1n2t_TASK', run_id='manual__2026-02-24T07:26:58.766819+00:00', try_number=1, map_index=-1)
2026-02-24 15:27:08,604 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_1p1n2t_TASK, run_id=manual__2026-02-24T07:26:58.766819+00:00, map_index=-1, run_start_date=2026-02-24 07:27:07.233635+00:00, run_end_date=2026-02-24 07:27:07.797169+00:00, run_duration=0.563534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=255, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:27:02.521515+00:00, queued_by_job_id=208, pid=16080
2026-02-24 15:27:11,520 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:26:58.766819+00:00: manual__2026-02-24T07:26:58.766819+00:00, state:running, queued_at: 2026-02-24 07:26:58.793392+00:00. externally triggered: True> successful
2026-02-24 15:27:11,521 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:26:58.766819+00:00, run_id=manual__2026-02-24T07:26:58.766819+00:00, run_start_date=2026-02-24 07:27:02.493335+00:00, run_end_date=2026-02-24 07:27:11.521801+00:00, run_duration=9.028466, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 07:26:58.766819+00:00, dag_hash=98f4e7056a3b8e0f8abf30ba6b4eceb0
2026-02-24 15:28:52,424 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:28:51.102548+00:00 [scheduled]>
2026-02-24 15:28:52,425 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 15:28:52,426 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:28:51.102548+00:00 [scheduled]>
2026-02-24 15:28:52,428 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:28:51.102548+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:28:52,431 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:28:51.102548+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:28:52,431 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:28:51.102548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:28:52,435 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:28:51.102548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:28:57,585 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:28:51.102548+00:00', try_number=1, map_index=-1)
2026-02-24 15:28:57,595 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:28:51.102548+00:00, map_index=-1, run_start_date=2026-02-24 07:28:56.363371+00:00, run_end_date=2026-02-24 07:28:56.878627+00:00, run_duration=0.515256, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=256, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:28:52.427520+00:00, queued_by_job_id=208, pid=16134
2026-02-24 15:29:00,274 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:28:51.102548+00:00: manual__2026-02-24T07:28:51.102548+00:00, state:running, queued_at: 2026-02-24 07:28:51.115567+00:00. externally triggered: True> successful
2026-02-24 15:29:00,275 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:28:51.102548+00:00, run_id=manual__2026-02-24T07:28:51.102548+00:00, run_start_date=2026-02-24 07:28:52.404965+00:00, run_end_date=2026-02-24 07:29:00.275519+00:00, run_duration=7.870554, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:28:51.102548+00:00, data_interval_end=2026-02-24 07:28:51.102548+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 15:30:40,231 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:30:44,105 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:30:40.865017+00:00 [scheduled]>
2026-02-24 15:30:44,106 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 15:30:44,106 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:30:40.865017+00:00 [scheduled]>
2026-02-24 15:30:44,109 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:30:40.865017+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:30:44,110 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:30:40.865017+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:30:44,111 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:30:40.865017+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:30:44,114 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:30:40.865017+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:30:49,497 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:30:40.865017+00:00', try_number=1, map_index=-1)
2026-02-24 15:30:49,506 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:30:40.865017+00:00, map_index=-1, run_start_date=2026-02-24 07:30:48.233106+00:00, run_end_date=2026-02-24 07:30:48.764702+00:00, run_duration=0.531596, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=257, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:30:44.108033+00:00, queued_by_job_id=208, pid=16195
2026-02-24 15:30:52,111 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:30:40.865017+00:00: manual__2026-02-24T07:30:40.865017+00:00, state:running, queued_at: 2026-02-24 07:30:40.885388+00:00. externally triggered: True> successful
2026-02-24 15:30:52,112 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:30:40.865017+00:00, run_id=manual__2026-02-24T07:30:40.865017+00:00, run_start_date=2026-02-24 07:30:44.084649+00:00, run_end_date=2026-02-24 07:30:52.112860+00:00, run_duration=8.028211, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:30:40.865017+00:00, data_interval_end=2026-02-24 07:30:40.865017+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 15:30:52,124 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
2026-02-24 15:30:52,125 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:30:52,125 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
2026-02-24 15:30:52,128 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:30:52,131 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 15:30:52,132 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:30:52,135 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:30:57,245 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1)
2026-02-24 15:30:57,257 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:30:48.784706+00:00, map_index=-1, run_start_date=2026-02-24 07:30:56.021572+00:00, run_end_date=2026-02-24 07:30:56.488053+00:00, run_duration=0.466481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=258, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:30:52.126931+00:00, queued_by_job_id=208, pid=16198
2026-02-24 15:31:00,096 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
2026-02-24 15:31:00,097 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:31:00,098 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>
2026-02-24 15:31:00,100 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:30:48.784706+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:31:00,102 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:31:00,103 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:31:00,106 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:30:48.784706+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:31:05,141 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:30:48.784706+00:00', try_number=1, map_index=-1)
2026-02-24 15:31:05,150 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:30:48.784706+00:00, map_index=-1, run_start_date=2026-02-24 07:31:03.955956+00:00, run_end_date=2026-02-24 07:31:04.421463+00:00, run_duration=0.465507, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=259, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:31:00.099572+00:00, queued_by_job_id=208, pid=16207
2026-02-24 15:31:08,191 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:30:48.784706+00:00: dataset_triggered__2026-02-24T07:30:48.784706+00:00, state:running, queued_at: 2026-02-24 07:30:52.077306+00:00. externally triggered: False> successful
2026-02-24 15:31:08,192 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:30:48.784706+00:00, run_id=dataset_triggered__2026-02-24T07:30:48.784706+00:00, run_start_date=2026-02-24 07:30:52.095279+00:00, run_end_date=2026-02-24 07:31:08.192022+00:00, run_duration=16.096743, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 07:30:40.865017+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 15:33:16,333 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:33:14.106948+00:00 [scheduled]>
2026-02-24 15:33:16,335 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 15:33:16,336 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:33:14.106948+00:00 [scheduled]>
2026-02-24 15:33:16,338 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:33:14.106948+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:33:16,339 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:33:14.106948+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:33:16,340 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:33:14.106948+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:33:16,343 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:33:14.106948+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:33:21,797 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:33:14.106948+00:00', try_number=1, map_index=-1)
2026-02-24 15:33:21,807 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:33:14.106948+00:00, map_index=-1, run_start_date=2026-02-24 07:33:20.402141+00:00, run_end_date=2026-02-24 07:33:21.021691+00:00, run_duration=0.61955, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=260, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:33:16.337594+00:00, queued_by_job_id=208, pid=16290
2026-02-24 15:33:24,557 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:33:14.106948+00:00: manual__2026-02-24T07:33:14.106948+00:00, state:running, queued_at: 2026-02-24 07:33:14.119261+00:00. externally triggered: True> successful
2026-02-24 15:33:24,558 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:33:14.106948+00:00, run_id=manual__2026-02-24T07:33:14.106948+00:00, run_start_date=2026-02-24 07:33:16.312795+00:00, run_end_date=2026-02-24 07:33:24.558238+00:00, run_duration=8.245443, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:33:14.106948+00:00, data_interval_end=2026-02-24 07:33:14.106948+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 15:33:24,569 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
2026-02-24 15:33:24,570 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:33:24,570 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
2026-02-24 15:33:24,573 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:33:24,574 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 15:33:24,575 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:33:24,578 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:33:29,980 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1)
2026-02-24 15:33:29,991 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:33:21.044248+00:00, map_index=-1, run_start_date=2026-02-24 07:33:28.447381+00:00, run_end_date=2026-02-24 07:33:29.089560+00:00, run_duration=0.642179, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=261, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:33:24.572057+00:00, queued_by_job_id=208, pid=16293
2026-02-24 15:33:32,867 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
2026-02-24 15:33:32,868 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:33:32,869 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>
2026-02-24 15:33:32,871 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:33:21.044248+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:33:32,873 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:33:32,875 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:33:32,878 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:33:21.044248+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:33:38,318 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:33:21.044248+00:00', try_number=1, map_index=-1)
2026-02-24 15:33:38,328 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:33:21.044248+00:00, map_index=-1, run_start_date=2026-02-24 07:33:37.072577+00:00, run_end_date=2026-02-24 07:33:37.537020+00:00, run_duration=0.464443, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=262, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:33:32.870313+00:00, queued_by_job_id=208, pid=16301
2026-02-24 15:33:41,733 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:33:21.044248+00:00: dataset_triggered__2026-02-24T07:33:21.044248+00:00, state:running, queued_at: 2026-02-24 07:33:24.523761+00:00. externally triggered: False> successful
2026-02-24 15:33:41,734 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:33:21.044248+00:00, run_id=dataset_triggered__2026-02-24T07:33:21.044248+00:00, run_start_date=2026-02-24 07:33:24.541524+00:00, run_end_date=2026-02-24 07:33:41.734797+00:00, run_duration=17.193273, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:33:14.106948+00:00, data_interval_end=2026-02-24 07:33:14.106948+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 15:34:36,551 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:34:32.175427+00:00 [scheduled]>
2026-02-24 15:34:36,552 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 15:34:36,553 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:34:32.175427+00:00 [scheduled]>
2026-02-24 15:34:36,556 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:34:32.175427+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:34:36,557 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:34:32.175427+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:34:36,558 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:34:32.175427+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:34:36,561 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:34:32.175427+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:34:41,766 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:34:32.175427+00:00', try_number=1, map_index=-1)
2026-02-24 15:34:41,776 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:34:32.175427+00:00, map_index=-1, run_start_date=2026-02-24 07:34:40.440703+00:00, run_end_date=2026-02-24 07:34:40.977232+00:00, run_duration=0.536529, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=263, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:34:36.555298+00:00, queued_by_job_id=208, pid=16333
2026-02-24 15:34:44,909 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:34:32.175427+00:00: manual__2026-02-24T07:34:32.175427+00:00, state:running, queued_at: 2026-02-24 07:34:32.194969+00:00. externally triggered: True> successful
2026-02-24 15:34:44,910 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:34:32.175427+00:00, run_id=manual__2026-02-24T07:34:32.175427+00:00, run_start_date=2026-02-24 07:34:36.529825+00:00, run_end_date=2026-02-24 07:34:44.910730+00:00, run_duration=8.380905, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:34:32.175427+00:00, data_interval_end=2026-02-24 07:34:32.175427+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 15:34:44,923 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
2026-02-24 15:34:44,924 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:34:44,925 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
2026-02-24 15:34:44,927 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:34:44,928 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 15:34:44,929 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:34:44,932 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:34:50,052 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1)
2026-02-24 15:34:50,061 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:34:40.995967+00:00, map_index=-1, run_start_date=2026-02-24 07:34:48.766215+00:00, run_end_date=2026-02-24 07:34:49.297215+00:00, run_duration=0.531, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=264, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:34:44.926045+00:00, queued_by_job_id=208, pid=16337
2026-02-24 15:34:53,197 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
2026-02-24 15:34:53,198 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:34:53,199 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>
2026-02-24 15:34:53,201 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:34:40.995967+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:34:53,202 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:34:53,203 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:34:53,205 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:34:40.995967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:34:58,181 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:34:40.995967+00:00', try_number=1, map_index=-1)
2026-02-24 15:34:58,191 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:34:40.995967+00:00, map_index=-1, run_start_date=2026-02-24 07:34:56.964234+00:00, run_end_date=2026-02-24 07:34:57.415604+00:00, run_duration=0.45137, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=265, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:34:53.199925+00:00, queued_by_job_id=208, pid=16340
2026-02-24 15:35:01,239 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:34:40.995967+00:00: dataset_triggered__2026-02-24T07:34:40.995967+00:00, state:running, queued_at: 2026-02-24 07:34:44.875512+00:00. externally triggered: False> successful
2026-02-24 15:35:01,240 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:34:40.995967+00:00, run_id=dataset_triggered__2026-02-24T07:34:40.995967+00:00, run_start_date=2026-02-24 07:34:44.893469+00:00, run_end_date=2026-02-24 07:35:01.240410+00:00, run_duration=16.346941, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:34:32.175427+00:00, data_interval_end=2026-02-24 07:34:32.175427+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 15:35:42,865 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:40:45,347 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:45:46,840 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:50:50,213 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:55:53,010 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 15:58:04,728 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:03.932405+00:00 [scheduled]>
2026-02-24 15:58:04,729 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 15:58:04,730 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:03.932405+00:00 [scheduled]>
2026-02-24 15:58:04,734 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:03.932405+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:58:04,735 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:03.932405+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:58:04,735 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:03.932405+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:58:04,738 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:03.932405+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:58:10,188 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:03.932405+00:00', try_number=1, map_index=-1)
2026-02-24 15:58:10,201 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:58:03.932405+00:00, map_index=-1, run_start_date=2026-02-24 07:58:08.937943+00:00, run_end_date=2026-02-24 07:58:09.455877+00:00, run_duration=0.517934, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=266, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:58:04.731400+00:00, queued_by_job_id=208, pid=17039
2026-02-24 15:58:13,890 ERROR - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:58:03.932405+00:00: manual__2026-02-24T07:58:03.932405+00:00, state:running, queued_at: 2026-02-24 07:58:03.946906+00:00. externally triggered: True> failed
2026-02-24 15:58:13,892 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:58:03.932405+00:00, run_id=manual__2026-02-24T07:58:03.932405+00:00, run_start_date=2026-02-24 07:58:04.701436+00:00, run_end_date=2026-02-24 07:58:13.891966+00:00, run_duration=9.19053, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:58:03.932405+00:00, data_interval_end=2026-02-24 07:58:03.932405+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 15:59:01,370 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:58.235400+00:00 [scheduled]>
2026-02-24 15:59:01,371 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 15:59:01,371 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:58.235400+00:00 [scheduled]>
2026-02-24 15:59:01,373 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T07:58:58.235400+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:59:01,375 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:58.235400+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:59:01,375 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:58.235400+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:59:01,378 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T07:58:58.235400+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:59:06,947 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T07:58:58.235400+00:00', try_number=1, map_index=-1)
2026-02-24 15:59:06,959 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T07:58:58.235400+00:00, map_index=-1, run_start_date=2026-02-24 07:59:05.651614+00:00, run_end_date=2026-02-24 07:59:06.203149+00:00, run_duration=0.551535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=267, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:59:01.372870+00:00, queued_by_job_id=208, pid=17074
2026-02-24 15:59:09,591 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 07:58:58.235400+00:00: manual__2026-02-24T07:58:58.235400+00:00, state:running, queued_at: 2026-02-24 07:58:58.252017+00:00. externally triggered: True> successful
2026-02-24 15:59:09,592 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 07:58:58.235400+00:00, run_id=manual__2026-02-24T07:58:58.235400+00:00, run_start_date=2026-02-24 07:59:01.346713+00:00, run_end_date=2026-02-24 07:59:09.592034+00:00, run_duration=8.245321, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 07:58:58.235400+00:00, data_interval_end=2026-02-24 07:58:58.235400+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 15:59:09,603 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
2026-02-24 15:59:09,604 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:59:09,605 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
2026-02-24 15:59:09,607 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:59:09,608 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 15:59:09,609 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:59:09,611 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:59:14,680 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1)
2026-02-24 15:59:14,691 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T07:59:06.225233+00:00, map_index=-1, run_start_date=2026-02-24 07:59:13.430306+00:00, run_end_date=2026-02-24 07:59:13.938778+00:00, run_duration=0.508472, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=268, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 07:59:09.606273+00:00, queued_by_job_id=208, pid=17077
2026-02-24 15:59:18,241 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
2026-02-24 15:59:18,242 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 15:59:18,243 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>
2026-02-24 15:59:18,246 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T07:59:06.225233+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 15:59:18,247 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 15:59:18,248 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:59:18,251 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T07:59:06.225233+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 15:59:23,476 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T07:59:06.225233+00:00', try_number=1, map_index=-1)
2026-02-24 15:59:23,488 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T07:59:06.225233+00:00, map_index=-1, run_start_date=2026-02-24 07:59:22.209780+00:00, run_end_date=2026-02-24 07:59:22.758051+00:00, run_duration=0.548271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=269, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 07:59:18.244739+00:00, queued_by_job_id=208, pid=17080
2026-02-24 15:59:27,360 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 07:59:06.225233+00:00: dataset_triggered__2026-02-24T07:59:06.225233+00:00, state:running, queued_at: 2026-02-24 07:59:09.559120+00:00. externally triggered: False> successful
2026-02-24 15:59:27,361 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 07:59:06.225233+00:00, run_id=dataset_triggered__2026-02-24T07:59:06.225233+00:00, run_start_date=2026-02-24 07:59:09.575809+00:00, run_end_date=2026-02-24 07:59:27.361109+00:00, run_duration=17.7853, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:58:58.235400+00:00, data_interval_end=2026-02-24 07:58:58.235400+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:00:55,503 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:02:13,974 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:02:10.947235+00:00 [scheduled]>
2026-02-24 16:02:13,975 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:02:13,976 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:02:10.947235+00:00 [scheduled]>
2026-02-24 16:02:13,978 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:02:10.947235+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:02:13,979 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:02:10.947235+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:02:13,980 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:02:10.947235+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:02:13,982 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:02:10.947235+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:02:19,460 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:02:10.947235+00:00', try_number=1, map_index=-1)
2026-02-24 16:02:19,471 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:02:10.947235+00:00, map_index=-1, run_start_date=2026-02-24 08:02:18.166064+00:00, run_end_date=2026-02-24 08:02:18.709079+00:00, run_duration=0.543015, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=270, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:02:13.977253+00:00, queued_by_job_id=208, pid=17235
2026-02-24 16:02:23,065 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:02:10.947235+00:00: manual__2026-02-24T08:02:10.947235+00:00, state:running, queued_at: 2026-02-24 08:02:10.965773+00:00. externally triggered: True> successful
2026-02-24 16:02:23,066 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:02:10.947235+00:00, run_id=manual__2026-02-24T08:02:10.947235+00:00, run_start_date=2026-02-24 08:02:13.951841+00:00, run_end_date=2026-02-24 08:02:23.066827+00:00, run_duration=9.114986, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:02:10.947235+00:00, data_interval_end=2026-02-24 08:02:10.947235+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:02:23,077 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
2026-02-24 16:02:23,078 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:02:23,078 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
2026-02-24 16:02:23,081 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:02:23,082 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:02:23,082 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:02:23,085 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:02:28,049 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1)
2026-02-24 16:02:28,062 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:02:18.727987+00:00, map_index=-1, run_start_date=2026-02-24 08:02:26.848805+00:00, run_end_date=2026-02-24 08:02:27.297173+00:00, run_duration=0.448368, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=271, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:02:23.079906+00:00, queued_by_job_id=208, pid=17240
2026-02-24 16:02:31,606 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
2026-02-24 16:02:31,607 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:02:31,608 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>
2026-02-24 16:02:31,610 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:02:18.727987+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:02:31,612 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:02:31,612 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:02:31,615 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:02:18.727987+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:02:36,564 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:02:18.727987+00:00', try_number=1, map_index=-1)
2026-02-24 16:02:36,576 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:02:18.727987+00:00, map_index=-1, run_start_date=2026-02-24 08:02:35.363016+00:00, run_end_date=2026-02-24 08:02:35.813831+00:00, run_duration=0.450815, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=272, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:02:31.609709+00:00, queued_by_job_id=208, pid=17244
2026-02-24 16:02:40,298 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:02:18.727987+00:00: dataset_triggered__2026-02-24T08:02:18.727987+00:00, state:running, queued_at: 2026-02-24 08:02:23.033576+00:00. externally triggered: False> successful
2026-02-24 16:02:40,299 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:02:18.727987+00:00, run_id=dataset_triggered__2026-02-24T08:02:18.727987+00:00, run_start_date=2026-02-24 08:02:23.050961+00:00, run_end_date=2026-02-24 08:02:40.299417+00:00, run_duration=17.248456, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:02:10.947235+00:00, data_interval_end=2026-02-24 08:02:10.947235+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:03:27,857 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:03:25.307661+00:00 [scheduled]>
2026-02-24 16:03:27,859 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:03:27,859 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:03:25.307661+00:00 [scheduled]>
2026-02-24 16:03:27,862 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:03:25.307661+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:03:27,863 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:03:25.307661+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:03:27,864 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:03:25.307661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:03:27,866 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:03:25.307661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:03:33,093 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:03:25.307661+00:00', try_number=1, map_index=-1)
2026-02-24 16:03:33,105 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:03:25.307661+00:00, map_index=-1, run_start_date=2026-02-24 08:03:31.839974+00:00, run_end_date=2026-02-24 08:03:32.378739+00:00, run_duration=0.538765, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=273, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:03:27.861085+00:00, queued_by_job_id=208, pid=17283
2026-02-24 16:03:36,678 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:03:25.307661+00:00: manual__2026-02-24T08:03:25.307661+00:00, state:running, queued_at: 2026-02-24 08:03:25.320183+00:00. externally triggered: True> successful
2026-02-24 16:03:36,679 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:03:25.307661+00:00, run_id=manual__2026-02-24T08:03:25.307661+00:00, run_start_date=2026-02-24 08:03:27.831856+00:00, run_end_date=2026-02-24 08:03:36.679587+00:00, run_duration=8.847731, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:03:25.307661+00:00, data_interval_end=2026-02-24 08:03:25.307661+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:03:36,690 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
2026-02-24 16:03:36,691 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:03:36,692 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
2026-02-24 16:03:36,694 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:03:36,695 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:03:36,696 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:03:36,699 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:03:41,703 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1)
2026-02-24 16:03:41,713 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:03:32.398970+00:00, map_index=-1, run_start_date=2026-02-24 08:03:40.578448+00:00, run_end_date=2026-02-24 08:03:41.024692+00:00, run_duration=0.446244, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=274, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:03:36.693088+00:00, queued_by_job_id=208, pid=17293
2026-02-24 16:03:44,713 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
2026-02-24 16:03:44,715 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:03:44,715 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>
2026-02-24 16:03:44,718 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:03:32.398970+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:03:44,720 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:03:44,721 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:03:44,723 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:03:32.398970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:03:50,140 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:03:32.398970+00:00', try_number=1, map_index=-1)
2026-02-24 16:03:50,153 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:03:32.398970+00:00, map_index=-1, run_start_date=2026-02-24 08:03:48.867388+00:00, run_end_date=2026-02-24 08:03:49.406526+00:00, run_duration=0.539138, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=275, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:03:44.717014+00:00, queued_by_job_id=208, pid=17297
2026-02-24 16:03:53,437 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:03:32.398970+00:00: dataset_triggered__2026-02-24T08:03:32.398970+00:00, state:running, queued_at: 2026-02-24 08:03:36.649314+00:00. externally triggered: False> successful
2026-02-24 16:03:53,439 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:03:32.398970+00:00, run_id=dataset_triggered__2026-02-24T08:03:32.398970+00:00, run_start_date=2026-02-24 08:03:36.664224+00:00, run_end_date=2026-02-24 08:03:53.438939+00:00, run_duration=16.774715, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:03:25.307661+00:00, data_interval_end=2026-02-24 08:03:25.307661+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:05:57,671 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:06:16,963 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:06:14.548837+00:00 [scheduled]>
2026-02-24 16:06:16,964 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:06:16,965 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:06:14.548837+00:00 [scheduled]>
2026-02-24 16:06:16,968 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:06:14.548837+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:06:16,969 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:06:14.548837+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:06:16,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:06:14.548837+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:06:16,975 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:06:14.548837+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:06:23,392 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:06:14.548837+00:00', try_number=1, map_index=-1)
2026-02-24 16:06:23,404 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:06:14.548837+00:00, map_index=-1, run_start_date=2026-02-24 08:06:22.039945+00:00, run_end_date=2026-02-24 08:06:22.627789+00:00, run_duration=0.587844, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=276, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:06:16.967061+00:00, queued_by_job_id=208, pid=17409
2026-02-24 16:06:27,077 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:06:14.548837+00:00: manual__2026-02-24T08:06:14.548837+00:00, state:running, queued_at: 2026-02-24 08:06:14.561606+00:00. externally triggered: True> successful
2026-02-24 16:06:27,078 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:06:14.548837+00:00, run_id=manual__2026-02-24T08:06:14.548837+00:00, run_start_date=2026-02-24 08:06:16.939065+00:00, run_end_date=2026-02-24 08:06:27.078682+00:00, run_duration=10.139617, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:06:14.548837+00:00, data_interval_end=2026-02-24 08:06:14.548837+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:06:27,090 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
2026-02-24 16:06:27,091 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:06:27,092 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
2026-02-24 16:06:27,094 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:06:27,095 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:06:27,097 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:06:27,099 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:06:32,058 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1)
2026-02-24 16:06:32,069 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:06:22.647848+00:00, map_index=-1, run_start_date=2026-02-24 08:06:30.883685+00:00, run_end_date=2026-02-24 08:06:31.335049+00:00, run_duration=0.451364, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=277, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:06:27.093400+00:00, queued_by_job_id=208, pid=17419
2026-02-24 16:06:35,817 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
2026-02-24 16:06:35,819 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:06:35,820 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>
2026-02-24 16:06:35,822 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:06:22.647848+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:06:35,823 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:06:35,824 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:06:35,827 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:06:22.647848+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:06:40,750 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:06:22.647848+00:00', try_number=1, map_index=-1)
2026-02-24 16:06:40,761 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:06:22.647848+00:00, map_index=-1, run_start_date=2026-02-24 08:06:39.614460+00:00, run_end_date=2026-02-24 08:06:40.058741+00:00, run_duration=0.444281, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=278, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:06:35.821078+00:00, queued_by_job_id=208, pid=17425
2026-02-24 16:06:44,545 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:06:22.647848+00:00: dataset_triggered__2026-02-24T08:06:22.647848+00:00, state:running, queued_at: 2026-02-24 08:06:27.042280+00:00. externally triggered: False> successful
2026-02-24 16:06:44,547 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:06:22.647848+00:00, run_id=dataset_triggered__2026-02-24T08:06:22.647848+00:00, run_start_date=2026-02-24 08:06:27.061167+00:00, run_end_date=2026-02-24 08:06:44.546906+00:00, run_duration=17.485739, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:06:14.548837+00:00, data_interval_end=2026-02-24 08:06:14.548837+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:09:26,701 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:09:24.784213+00:00 [scheduled]>
2026-02-24 16:09:26,702 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:09:26,703 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:09:24.784213+00:00 [scheduled]>
2026-02-24 16:09:26,705 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:09:24.784213+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:09:26,706 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:09:24.784213+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:09:26,707 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:09:24.784213+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:09:26,709 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:09:24.784213+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:09:32,206 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:09:24.784213+00:00', try_number=1, map_index=-1)
2026-02-24 16:09:32,217 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:09:24.784213+00:00, map_index=-1, run_start_date=2026-02-24 08:09:30.892087+00:00, run_end_date=2026-02-24 08:09:31.459780+00:00, run_duration=0.567693, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=279, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:09:26.704245+00:00, queued_by_job_id=208, pid=17522
2026-02-24 16:09:35,111 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:09:24.784213+00:00: manual__2026-02-24T08:09:24.784213+00:00, state:running, queued_at: 2026-02-24 08:09:24.797695+00:00. externally triggered: True> successful
2026-02-24 16:09:35,113 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:09:24.784213+00:00, run_id=manual__2026-02-24T08:09:24.784213+00:00, run_start_date=2026-02-24 08:09:26.683092+00:00, run_end_date=2026-02-24 08:09:35.112938+00:00, run_duration=8.429846, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:09:24.784213+00:00, data_interval_end=2026-02-24 08:09:24.784213+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:09:35,123 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
2026-02-24 16:09:35,124 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:09:35,125 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
2026-02-24 16:09:35,128 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:09:35,129 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:09:35,130 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:09:35,133 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:09:40,133 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1)
2026-02-24 16:09:40,144 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:09:31.479340+00:00, map_index=-1, run_start_date=2026-02-24 08:09:38.960696+00:00, run_end_date=2026-02-24 08:09:39.417156+00:00, run_duration=0.45646, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=280, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:09:35.126788+00:00, queued_by_job_id=208, pid=17525
2026-02-24 16:09:42,793 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
2026-02-24 16:09:42,794 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:09:42,795 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>
2026-02-24 16:09:42,798 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:09:31.479340+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:09:42,799 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:09:42,800 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:09:42,803 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:09:31.479340+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:09:47,909 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:09:31.479340+00:00', try_number=1, map_index=-1)
2026-02-24 16:09:47,921 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:09:31.479340+00:00, map_index=-1, run_start_date=2026-02-24 08:09:46.746106+00:00, run_end_date=2026-02-24 08:09:47.184585+00:00, run_duration=0.438479, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=281, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:09:42.797214+00:00, queued_by_job_id=208, pid=17541
2026-02-24 16:09:50,703 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:09:31.479340+00:00: dataset_triggered__2026-02-24T08:09:31.479340+00:00, state:running, queued_at: 2026-02-24 08:09:35.079081+00:00. externally triggered: False> successful
2026-02-24 16:09:50,704 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:09:31.479340+00:00, run_id=dataset_triggered__2026-02-24T08:09:31.479340+00:00, run_start_date=2026-02-24 08:09:35.096215+00:00, run_end_date=2026-02-24 08:09:50.704602+00:00, run_duration=15.608387, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:09:24.784213+00:00, data_interval_end=2026-02-24 08:09:24.784213+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:11:00,843 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:11:48,528 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:11:46.761729+00:00 [scheduled]>
2026-02-24 16:11:48,529 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:11:48,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:11:46.761729+00:00 [scheduled]>
2026-02-24 16:11:48,532 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:11:46.761729+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:11:48,533 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:11:46.761729+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:11:48,534 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:11:46.761729+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:11:48,536 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:11:46.761729+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:11:53,762 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:11:46.761729+00:00', try_number=1, map_index=-1)
2026-02-24 16:11:53,773 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:11:46.761729+00:00, map_index=-1, run_start_date=2026-02-24 08:11:52.454928+00:00, run_end_date=2026-02-24 08:11:52.988042+00:00, run_duration=0.533114, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=282, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:11:48.530968+00:00, queued_by_job_id=208, pid=17642
2026-02-24 16:11:56,425 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:11:46.761729+00:00: manual__2026-02-24T08:11:46.761729+00:00, state:running, queued_at: 2026-02-24 08:11:46.774015+00:00. externally triggered: True> successful
2026-02-24 16:11:56,426 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:11:46.761729+00:00, run_id=manual__2026-02-24T08:11:46.761729+00:00, run_start_date=2026-02-24 08:11:48.506455+00:00, run_end_date=2026-02-24 08:11:56.426195+00:00, run_duration=7.91974, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:11:46.761729+00:00, data_interval_end=2026-02-24 08:11:46.761729+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:11:56,437 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
2026-02-24 16:11:56,438 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:11:56,439 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
2026-02-24 16:11:56,441 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:11:56,443 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:11:56,443 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:11:56,447 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:12:01,424 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1)
2026-02-24 16:12:01,434 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:11:53.008824+00:00, map_index=-1, run_start_date=2026-02-24 08:12:00.228846+00:00, run_end_date=2026-02-24 08:12:00.686924+00:00, run_duration=0.458078, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=283, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:11:56.440337+00:00, queued_by_job_id=208, pid=17645
2026-02-24 16:12:04,247 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
2026-02-24 16:12:04,248 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:12:04,249 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>
2026-02-24 16:12:04,252 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:11:53.008824+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:12:04,254 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:12:04,255 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:12:04,257 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:11:53.008824+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:12:09,750 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:11:53.008824+00:00', try_number=1, map_index=-1)
2026-02-24 16:12:09,762 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:11:53.008824+00:00, map_index=-1, run_start_date=2026-02-24 08:12:08.397985+00:00, run_end_date=2026-02-24 08:12:08.882569+00:00, run_duration=0.484584, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=284, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:12:04.250987+00:00, queued_by_job_id=208, pid=17651
2026-02-24 16:12:12,658 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:11:53.008824+00:00: dataset_triggered__2026-02-24T08:11:53.008824+00:00, state:running, queued_at: 2026-02-24 08:11:56.393171+00:00. externally triggered: False> successful
2026-02-24 16:12:12,660 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:11:53.008824+00:00, run_id=dataset_triggered__2026-02-24T08:11:53.008824+00:00, run_start_date=2026-02-24 08:11:56.409780+00:00, run_end_date=2026-02-24 08:12:12.659934+00:00, run_duration=16.250154, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:11:46.761729+00:00, data_interval_end=2026-02-24 08:11:46.761729+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:16:04,769 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:18:02,612 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:18:00.484964+00:00 [scheduled]>
2026-02-24 16:18:02,614 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:18:02,615 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:18:00.484964+00:00 [scheduled]>
2026-02-24 16:18:02,617 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:18:00.484964+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:18:02,619 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:18:00.484964+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:18:02,619 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:18:00.484964+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:18:02,622 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:18:00.484964+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:18:08,159 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:18:00.484964+00:00', try_number=1, map_index=-1)
2026-02-24 16:18:08,170 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:18:00.484964+00:00, map_index=-1, run_start_date=2026-02-24 08:18:06.895003+00:00, run_end_date=2026-02-24 08:18:07.427383+00:00, run_duration=0.53238, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=285, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:18:02.616347+00:00, queued_by_job_id=208, pid=17836
2026-02-24 16:18:10,931 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:18:00.484964+00:00: manual__2026-02-24T08:18:00.484964+00:00, state:running, queued_at: 2026-02-24 08:18:00.497863+00:00. externally triggered: True> successful
2026-02-24 16:18:10,932 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:18:00.484964+00:00, run_id=manual__2026-02-24T08:18:00.484964+00:00, run_start_date=2026-02-24 08:18:02.592841+00:00, run_end_date=2026-02-24 08:18:10.932201+00:00, run_duration=8.33936, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:18:00.484964+00:00, data_interval_end=2026-02-24 08:18:00.484964+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:18:10,943 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
2026-02-24 16:18:10,944 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:18:10,944 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
2026-02-24 16:18:10,947 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:18:10,948 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:18:10,948 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:18:10,951 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:18:16,154 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1)
2026-02-24 16:18:16,164 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:18:07.446791+00:00, map_index=-1, run_start_date=2026-02-24 08:18:14.932685+00:00, run_end_date=2026-02-24 08:18:15.374382+00:00, run_duration=0.441697, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=286, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:18:10.945981+00:00, queued_by_job_id=208, pid=17839
2026-02-24 16:18:19,009 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
2026-02-24 16:18:19,010 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:18:19,011 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>
2026-02-24 16:18:19,013 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:18:07.446791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:18:19,014 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:18:19,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:18:19,018 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:18:07.446791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:18:24,737 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:18:07.446791+00:00', try_number=1, map_index=-1)
2026-02-24 16:18:24,749 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:18:07.446791+00:00, map_index=-1, run_start_date=2026-02-24 08:18:23.502102+00:00, run_end_date=2026-02-24 08:18:23.969578+00:00, run_duration=0.467476, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=287, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:18:19.012487+00:00, queued_by_job_id=208, pid=17843
2026-02-24 16:18:27,913 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:18:07.446791+00:00: dataset_triggered__2026-02-24T08:18:07.446791+00:00, state:running, queued_at: 2026-02-24 08:18:10.901465+00:00. externally triggered: False> successful
2026-02-24 16:18:27,914 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:18:07.446791+00:00, run_id=dataset_triggered__2026-02-24T08:18:07.446791+00:00, run_start_date=2026-02-24 08:18:10.916664+00:00, run_end_date=2026-02-24 08:18:27.914094+00:00, run_duration=16.99743, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:18:00.484964+00:00, data_interval_end=2026-02-24 08:18:00.484964+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:20:41,264 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:20:38.481972+00:00 [scheduled]>
2026-02-24 16:20:41,265 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:20:41,266 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:20:38.481972+00:00 [scheduled]>
2026-02-24 16:20:41,268 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:20:38.481972+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:20:41,269 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:20:38.481972+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:20:41,270 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:20:38.481972+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:20:41,272 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:20:38.481972+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:20:47,049 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:20:38.481972+00:00', try_number=1, map_index=-1)
2026-02-24 16:20:47,061 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:20:38.481972+00:00, map_index=-1, run_start_date=2026-02-24 08:20:45.729342+00:00, run_end_date=2026-02-24 08:20:46.329463+00:00, run_duration=0.600121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=288, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:20:41.267413+00:00, queued_by_job_id=208, pid=17939
2026-02-24 16:20:49,772 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:20:38.481972+00:00: manual__2026-02-24T08:20:38.481972+00:00, state:running, queued_at: 2026-02-24 08:20:38.494859+00:00. externally triggered: True> successful
2026-02-24 16:20:49,773 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:20:38.481972+00:00, run_id=manual__2026-02-24T08:20:38.481972+00:00, run_start_date=2026-02-24 08:20:41.242794+00:00, run_end_date=2026-02-24 08:20:49.773133+00:00, run_duration=8.530339, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:20:38.481972+00:00, data_interval_end=2026-02-24 08:20:38.481972+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:20:49,784 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
2026-02-24 16:20:49,785 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:20:49,786 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
2026-02-24 16:20:49,788 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:20:49,789 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:20:49,790 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:20:49,792 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:20:54,792 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1)
2026-02-24 16:20:54,802 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:20:46.350292+00:00, map_index=-1, run_start_date=2026-02-24 08:20:53.678735+00:00, run_end_date=2026-02-24 08:20:54.125303+00:00, run_duration=0.446568, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=289, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:20:49.787151+00:00, queued_by_job_id=208, pid=17942
2026-02-24 16:20:58,916 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
2026-02-24 16:20:58,917 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:20:58,918 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>
2026-02-24 16:20:58,920 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:20:46.350292+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:20:58,922 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:20:58,923 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:20:58,925 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:20:46.350292+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:21:04,680 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:20:46.350292+00:00', try_number=1, map_index=-1)
2026-02-24 16:21:04,691 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:20:46.350292+00:00, map_index=-1, run_start_date=2026-02-24 08:21:03.481684+00:00, run_end_date=2026-02-24 08:21:03.927989+00:00, run_duration=0.446305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=290, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:20:58.919687+00:00, queued_by_job_id=208, pid=17949
2026-02-24 16:21:07,547 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:20:46.350292+00:00: dataset_triggered__2026-02-24T08:20:46.350292+00:00, state:running, queued_at: 2026-02-24 08:20:49.738139+00:00. externally triggered: False> successful
2026-02-24 16:21:07,548 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:20:46.350292+00:00, run_id=dataset_triggered__2026-02-24T08:20:46.350292+00:00, run_start_date=2026-02-24 08:20:49.755264+00:00, run_end_date=2026-02-24 08:21:07.548578+00:00, run_duration=17.793314, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:20:38.481972+00:00, data_interval_end=2026-02-24 08:20:38.481972+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:21:07,571 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:26:10,553 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:26:46,736 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:26:42.181391+00:00 [scheduled]>
2026-02-24 16:26:46,737 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:26:46,738 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:26:42.181391+00:00 [scheduled]>
2026-02-24 16:26:46,740 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:26:42.181391+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:26:46,741 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:26:42.181391+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:26:46,742 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:26:42.181391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:26:46,745 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:26:42.181391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:26:52,230 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:26:42.181391+00:00', try_number=1, map_index=-1)
2026-02-24 16:26:52,239 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:26:42.181391+00:00, map_index=-1, run_start_date=2026-02-24 08:26:50.964642+00:00, run_end_date=2026-02-24 08:26:51.473880+00:00, run_duration=0.509238, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=291, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:26:46.739693+00:00, queued_by_job_id=208, pid=18191
2026-02-24 16:26:55,850 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:26:42.181391+00:00: manual__2026-02-24T08:26:42.181391+00:00, state:running, queued_at: 2026-02-24 08:26:42.193726+00:00. externally triggered: True> successful
2026-02-24 16:26:55,851 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:26:42.181391+00:00, run_id=manual__2026-02-24T08:26:42.181391+00:00, run_start_date=2026-02-24 08:26:46.714246+00:00, run_end_date=2026-02-24 08:26:55.851232+00:00, run_duration=9.136986, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:26:42.181391+00:00, data_interval_end=2026-02-24 08:26:42.181391+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:26:55,864 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
2026-02-24 16:26:55,866 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:26:55,866 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
2026-02-24 16:26:55,869 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:26:55,871 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-24 16:26:55,872 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:26:55,874 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:27:00,965 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1)
2026-02-24 16:27:00,977 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:26:51.493847+00:00, map_index=-1, run_start_date=2026-02-24 08:26:59.792283+00:00, run_end_date=2026-02-24 08:27:00.257898+00:00, run_duration=0.465615, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=292, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-24 08:26:55.868126+00:00, queued_by_job_id=208, pid=18199
2026-02-24 16:27:03,797 INFO - 1 tasks up for execution:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
2026-02-24 16:27:03,798 INFO - DAG c_cdrd has 0/16 running and queued tasks
2026-02-24 16:27:03,799 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>
2026-02-24 16:27:03,801 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:26:51.493847+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:27:03,802 INFO - Sending TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:27:03,803 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:27:03,806 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:26:51.493847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:27:08,779 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:26:51.493847+00:00', try_number=1, map_index=-1)
2026-02-24 16:27:08,788 INFO - TaskInstance Finished: dag_id=c_cdrd, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:26:51.493847+00:00, map_index=-1, run_start_date=2026-02-24 08:27:07.574829+00:00, run_end_date=2026-02-24 08:27:08.032543+00:00, run_duration=0.457714, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=293, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:27:03.800346+00:00, queued_by_job_id=208, pid=18206
2026-02-24 16:27:11,881 INFO - Marking run <DagRun c_cdrd @ 2026-02-24 08:26:51.493847+00:00: dataset_triggered__2026-02-24T08:26:51.493847+00:00, state:running, queued_at: 2026-02-24 08:26:55.813998+00:00. externally triggered: False> successful
2026-02-24 16:27:11,882 INFO - DagRun Finished: dag_id=c_cdrd, execution_date=2026-02-24 08:26:51.493847+00:00, run_id=dataset_triggered__2026-02-24T08:26:51.493847+00:00, run_start_date=2026-02-24 08:26:55.832119+00:00, run_end_date=2026-02-24 08:27:11.882249+00:00, run_duration=16.05013, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:26:42.181391+00:00, data_interval_end=2026-02-24 08:26:42.181391+00:00, dag_hash=353648209cc11795c15df8e148af83f2
2026-02-24 16:31:12,815 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:36:16,110 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:40:42,779 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:40:39.544036+00:00 [scheduled]>
2026-02-24 16:40:42,782 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:40:42,783 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:40:39.544036+00:00 [scheduled]>
2026-02-24 16:40:42,785 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:40:39.544036+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:40:42,786 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:40:39.544036+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:40:42,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:40:39.544036+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:40:42,789 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:40:39.544036+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:40:48,566 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:40:39.544036+00:00', try_number=1, map_index=-1)
2026-02-24 16:40:48,575 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:40:39.544036+00:00, map_index=-1, run_start_date=2026-02-24 08:40:47.272437+00:00, run_end_date=2026-02-24 08:40:47.804209+00:00, run_duration=0.531772, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=294, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:40:42.784109+00:00, queued_by_job_id=208, pid=18913
2026-02-24 16:40:51,989 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:40:39.544036+00:00: manual__2026-02-24T08:40:39.544036+00:00, state:running, queued_at: 2026-02-24 08:40:39.557299+00:00. externally triggered: True> successful
2026-02-24 16:40:51,990 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:40:39.544036+00:00, run_id=manual__2026-02-24T08:40:39.544036+00:00, run_start_date=2026-02-24 08:40:42.756344+00:00, run_end_date=2026-02-24 08:40:51.990694+00:00, run_duration=9.23435, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:40:39.544036+00:00, data_interval_end=2026-02-24 08:40:39.544036+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:41:18,862 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:41:45,965 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:41:42.161413+00:00 [scheduled]>
2026-02-24 16:41:45,966 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:41:45,967 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:41:42.161413+00:00 [scheduled]>
2026-02-24 16:41:45,970 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:41:42.161413+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:41:45,971 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:41:42.161413+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:41:45,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:41:42.161413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:41:45,974 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:41:42.161413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:41:51,133 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:41:42.161413+00:00', try_number=1, map_index=-1)
2026-02-24 16:41:51,154 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:41:42.161413+00:00, map_index=-1, run_start_date=2026-02-24 08:41:49.802294+00:00, run_end_date=2026-02-24 08:41:50.336648+00:00, run_duration=0.534354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=295, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:41:45.968753+00:00, queued_by_job_id=208, pid=18947
2026-02-24 16:41:53,953 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:41:42.161413+00:00: manual__2026-02-24T08:41:42.161413+00:00, state:running, queued_at: 2026-02-24 08:41:42.176173+00:00. externally triggered: True> successful
2026-02-24 16:41:53,954 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:41:42.161413+00:00, run_id=manual__2026-02-24T08:41:42.161413+00:00, run_start_date=2026-02-24 08:41:45.944303+00:00, run_end_date=2026-02-24 08:41:53.954263+00:00, run_duration=8.00996, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:41:42.161413+00:00, data_interval_end=2026-02-24 08:41:42.161413+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:41:53,965 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:41:50.358657+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:41:50.360304+00:00 [scheduled]>
2026-02-24 16:41:53,965 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 16:41:53,966 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 16:41:53,967 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:41:50.358657+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:41:50.360304+00:00 [scheduled]>
2026-02-24 16:41:53,969 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:41:50.358657+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:41:50.360304+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:41:53,970 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:41:50.358657+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:41:53,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:41:50.358657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:41:53,972 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:41:50.360304+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:41:53,972 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:41:50.360304+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:41:53,975 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:41:50.358657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:41:58,915 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:41:50.360304+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:42:04,469 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:41:50.358657+00:00', try_number=1, map_index=-1)
2026-02-24 16:42:04,471 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:41:50.360304+00:00', try_number=1, map_index=-1)
2026-02-24 16:42:04,479 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:41:50.360304+00:00, map_index=-1, run_start_date=2026-02-24 08:42:02.697034+00:00, run_end_date=2026-02-24 08:42:03.732092+00:00, run_duration=1.035058, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=297, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:41:53.968532+00:00, queued_by_job_id=208, pid=18965
2026-02-24 16:42:04,481 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:41:50.358657+00:00, map_index=-1, run_start_date=2026-02-24 08:41:57.692559+00:00, run_end_date=2026-02-24 08:41:58.185184+00:00, run_duration=0.492625, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=296, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:41:53.968532+00:00, queued_by_job_id=208, pid=18959
2026-02-24 16:42:07,389 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:41:50.358657+00:00: dataset_triggered__2026-02-24T08:41:50.358657+00:00, state:running, queued_at: 2026-02-24 08:41:53.910019+00:00. externally triggered: False> successful
2026-02-24 16:42:07,390 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:41:50.358657+00:00, run_id=dataset_triggered__2026-02-24T08:41:50.358657+00:00, run_start_date=2026-02-24 08:41:53.935015+00:00, run_end_date=2026-02-24 08:42:07.390030+00:00, run_duration=13.455015, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 08:41:42.161413+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 16:42:07,397 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:41:50.360304+00:00: dataset_triggered__2026-02-24T08:41:50.360304+00:00, state:running, queued_at: 2026-02-24 08:41:53.919004+00:00. externally triggered: False> successful
2026-02-24 16:42:07,398 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:41:50.360304+00:00, run_id=dataset_triggered__2026-02-24T08:41:50.360304+00:00, run_start_date=2026-02-24 08:41:53.935127+00:00, run_end_date=2026-02-24 08:42:07.398423+00:00, run_duration=13.463296, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:26:58.766819+00:00, data_interval_end=2026-02-24 08:41:42.161413+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 16:46:22,783 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:47:52,156 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:47:50.274813+00:00 [scheduled]>
2026-02-24 16:47:52,157 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:47:52,158 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:47:50.274813+00:00 [scheduled]>
2026-02-24 16:47:52,160 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:47:50.274813+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:47:52,161 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:47:50.274813+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:47:52,162 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:47:50.274813+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:47:52,164 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:47:50.274813+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:47:57,385 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:47:50.274813+00:00', try_number=1, map_index=-1)
2026-02-24 16:47:57,395 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:47:50.274813+00:00, map_index=-1, run_start_date=2026-02-24 08:47:56.107856+00:00, run_end_date=2026-02-24 08:47:56.640725+00:00, run_duration=0.532869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=298, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:47:52.159156+00:00, queued_by_job_id=208, pid=19205
2026-02-24 16:48:00,063 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:47:50.274813+00:00: manual__2026-02-24T08:47:50.274813+00:00, state:running, queued_at: 2026-02-24 08:47:50.295858+00:00. externally triggered: True> successful
2026-02-24 16:48:00,064 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:47:50.274813+00:00, run_id=manual__2026-02-24T08:47:50.274813+00:00, run_start_date=2026-02-24 08:47:52.136145+00:00, run_end_date=2026-02-24 08:48:00.064911+00:00, run_duration=7.928766, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:47:50.274813+00:00, data_interval_end=2026-02-24 08:47:50.274813+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:48:00,076 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:47:56.663455+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:47:56.664661+00:00 [scheduled]>
2026-02-24 16:48:00,077 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 16:48:00,077 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 16:48:00,078 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:47:56.663455+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:47:56.664661+00:00 [scheduled]>
2026-02-24 16:48:00,081 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:47:56.663455+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:47:56.664661+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:48:00,082 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:47:56.663455+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:48:00,083 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:47:56.663455+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:48:00,084 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:47:56.664661+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:48:00,085 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:47:56.664661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:48:00,087 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:47:56.663455+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:48:05,047 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:47:56.664661+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:48:09,958 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:47:56.663455+00:00', try_number=1, map_index=-1)
2026-02-24 16:48:09,960 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:47:56.664661+00:00', try_number=1, map_index=-1)
2026-02-24 16:48:09,969 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:47:56.663455+00:00, map_index=-1, run_start_date=2026-02-24 08:48:03.872190+00:00, run_end_date=2026-02-24 08:48:04.332282+00:00, run_duration=0.460092, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=299, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:48:00.079958+00:00, queued_by_job_id=208, pid=19211
2026-02-24 16:48:09,971 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:47:56.664661+00:00, map_index=-1, run_start_date=2026-02-24 08:48:08.708748+00:00, run_end_date=2026-02-24 08:48:09.241306+00:00, run_duration=0.532558, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=300, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:48:00.079958+00:00, queued_by_job_id=208, pid=19213
2026-02-24 16:48:13,767 ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:47:56.663455+00:00: dataset_triggered__2026-02-24T08:47:56.663455+00:00, state:running, queued_at: 2026-02-24 08:48:00.021915+00:00. externally triggered: False> failed
2026-02-24 16:48:13,768 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:47:56.663455+00:00, run_id=dataset_triggered__2026-02-24T08:47:56.663455+00:00, run_start_date=2026-02-24 08:48:00.046424+00:00, run_end_date=2026-02-24 08:48:13.768884+00:00, run_duration=13.72246, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:47:50.274813+00:00, data_interval_end=2026-02-24 08:47:50.274813+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 16:48:13,774 ERROR - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:47:56.664661+00:00: dataset_triggered__2026-02-24T08:47:56.664661+00:00, state:running, queued_at: 2026-02-24 08:48:00.033819+00:00. externally triggered: False> failed
2026-02-24 16:48:13,775 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:47:56.664661+00:00, run_id=dataset_triggered__2026-02-24T08:47:56.664661+00:00, run_start_date=2026-02-24 08:48:00.046546+00:00, run_end_date=2026-02-24 08:48:13.775126+00:00, run_duration=13.72858, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:47:50.274813+00:00, data_interval_end=2026-02-24 08:47:50.274813+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 16:49:19,406 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:49:18.547830+00:00 [scheduled]>
2026-02-24 16:49:19,407 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:49:19,408 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:49:18.547830+00:00 [scheduled]>
2026-02-24 16:49:19,416 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:49:18.547830+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:49:19,418 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:49:18.547830+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:49:19,419 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:49:18.547830+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:49:19,422 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:49:18.547830+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:49:24,808 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:49:18.547830+00:00', try_number=1, map_index=-1)
2026-02-24 16:49:24,818 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:49:18.547830+00:00, map_index=-1, run_start_date=2026-02-24 08:49:23.533971+00:00, run_end_date=2026-02-24 08:49:24.060480+00:00, run_duration=0.526509, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=301, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:49:19.409731+00:00, queued_by_job_id=208, pid=19250
2026-02-24 16:49:28,529 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:49:18.547830+00:00: manual__2026-02-24T08:49:18.547830+00:00, state:running, queued_at: 2026-02-24 08:49:18.560790+00:00. externally triggered: True> successful
2026-02-24 16:49:28,530 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:49:18.547830+00:00, run_id=manual__2026-02-24T08:49:18.547830+00:00, run_start_date=2026-02-24 08:49:19.383942+00:00, run_end_date=2026-02-24 08:49:28.530468+00:00, run_duration=9.146526, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:49:18.547830+00:00, data_interval_end=2026-02-24 08:49:18.547830+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:49:28,541 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:49:24.079651+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:49:24.082042+00:00 [scheduled]>
2026-02-24 16:49:28,542 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 16:49:28,542 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 16:49:28,543 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:49:24.079651+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:49:24.082042+00:00 [scheduled]>
2026-02-24 16:49:28,546 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:49:24.079651+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:49:24.082042+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:49:28,547 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:49:24.079651+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:49:28,548 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:49:24.079651+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:49:28,549 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:49:24.082042+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:49:28,549 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:49:24.082042+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:49:28,552 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:49:24.079651+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:49:33,971 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:49:24.082042+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:49:39,010 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:49:24.079651+00:00', try_number=1, map_index=-1)
2026-02-24 16:49:39,012 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:49:24.082042+00:00', try_number=1, map_index=-1)
2026-02-24 16:49:39,021 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:49:24.079651+00:00, map_index=-1, run_start_date=2026-02-24 08:49:32.304094+00:00, run_end_date=2026-02-24 08:49:33.227839+00:00, run_duration=0.923745, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=302, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:49:28.544789+00:00, queued_by_job_id=208, pid=19253
2026-02-24 16:49:39,023 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:49:24.082042+00:00, map_index=-1, run_start_date=2026-02-24 08:49:37.781835+00:00, run_end_date=2026-02-24 08:49:38.300910+00:00, run_duration=0.519075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=303, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:49:28.544789+00:00, queued_by_job_id=208, pid=19256
2026-02-24 16:49:42,009 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:49:24.079651+00:00: dataset_triggered__2026-02-24T08:49:24.079651+00:00, state:running, queued_at: 2026-02-24 08:49:28.487021+00:00. externally triggered: False> successful
2026-02-24 16:49:42,010 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:49:24.079651+00:00, run_id=dataset_triggered__2026-02-24T08:49:24.079651+00:00, run_start_date=2026-02-24 08:49:28.510736+00:00, run_end_date=2026-02-24 08:49:42.010443+00:00, run_duration=13.499707, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:49:18.547830+00:00, data_interval_end=2026-02-24 08:49:18.547830+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 16:49:42,015 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:49:24.082042+00:00: dataset_triggered__2026-02-24T08:49:24.082042+00:00, state:running, queued_at: 2026-02-24 08:49:28.496058+00:00. externally triggered: False> successful
2026-02-24 16:49:42,016 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:49:24.082042+00:00, run_id=dataset_triggered__2026-02-24T08:49:24.082042+00:00, run_start_date=2026-02-24 08:49:28.510863+00:00, run_end_date=2026-02-24 08:49:42.016777+00:00, run_duration=13.505914, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:49:18.547830+00:00, data_interval_end=2026-02-24 08:49:18.547830+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 16:51:22,880 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:53:59,431 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:53:57.107668+00:00 [scheduled]>
2026-02-24 16:53:59,431 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:53:59,432 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:53:57.107668+00:00 [scheduled]>
2026-02-24 16:53:59,434 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:53:57.107668+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:53:59,435 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:53:57.107668+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:53:59,436 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:53:57.107668+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:53:59,438 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:53:57.107668+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:54:04,790 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:53:57.107668+00:00', try_number=1, map_index=-1)
2026-02-24 16:54:04,799 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:53:57.107668+00:00, map_index=-1, run_start_date=2026-02-24 08:54:03.533997+00:00, run_end_date=2026-02-24 08:54:04.061191+00:00, run_duration=0.527194, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=304, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:53:59.433623+00:00, queued_by_job_id=208, pid=19420
2026-02-24 16:54:08,254 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:53:57.107668+00:00: manual__2026-02-24T08:53:57.107668+00:00, state:running, queued_at: 2026-02-24 08:53:57.121462+00:00. externally triggered: True> successful
2026-02-24 16:54:08,256 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:53:57.107668+00:00, run_id=manual__2026-02-24T08:53:57.107668+00:00, run_start_date=2026-02-24 08:53:59.411139+00:00, run_end_date=2026-02-24 08:54:08.256164+00:00, run_duration=8.845025, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:53:57.107668+00:00, data_interval_end=2026-02-24 08:53:57.107668+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:54:08,267 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:54:04.079781+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:54:04.081771+00:00 [scheduled]>
2026-02-24 16:54:08,268 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 16:54:08,268 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 16:54:08,269 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:54:04.079781+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:54:04.081771+00:00 [scheduled]>
2026-02-24 16:54:08,273 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:54:04.079781+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:54:04.081771+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:54:08,274 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:54:04.079781+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:54:08,274 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:54:04.079781+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:54:08,275 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:54:04.081771+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:54:08,276 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:54:04.081771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:54:08,279 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:54:04.079781+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:54:13,193 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:54:04.081771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:54:18,534 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:54:04.079781+00:00', try_number=1, map_index=-1)
2026-02-24 16:54:18,536 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:54:04.081771+00:00', try_number=1, map_index=-1)
2026-02-24 16:54:18,545 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:54:04.081771+00:00, map_index=-1, run_start_date=2026-02-24 08:54:16.907975+00:00, run_end_date=2026-02-24 08:54:17.850975+00:00, run_duration=0.943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=306, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:54:08.270882+00:00, queued_by_job_id=208, pid=19426
2026-02-24 16:54:18,547 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:54:04.079781+00:00, map_index=-1, run_start_date=2026-02-24 08:54:12.002562+00:00, run_end_date=2026-02-24 08:54:12.499482+00:00, run_duration=0.49692, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=305, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:54:08.270882+00:00, queued_by_job_id=208, pid=19423
2026-02-24 16:54:22,188 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:54:04.079781+00:00: dataset_triggered__2026-02-24T08:54:04.079781+00:00, state:running, queued_at: 2026-02-24 08:54:08.212297+00:00. externally triggered: False> successful
2026-02-24 16:54:22,189 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:54:04.079781+00:00, run_id=dataset_triggered__2026-02-24T08:54:04.079781+00:00, run_start_date=2026-02-24 08:54:08.237233+00:00, run_end_date=2026-02-24 08:54:22.188930+00:00, run_duration=13.951697, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:53:57.107668+00:00, data_interval_end=2026-02-24 08:53:57.107668+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 16:54:22,195 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:54:04.081771+00:00: dataset_triggered__2026-02-24T08:54:04.081771+00:00, state:running, queued_at: 2026-02-24 08:54:08.225116+00:00. externally triggered: False> successful
2026-02-24 16:54:22,196 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:54:04.081771+00:00, run_id=dataset_triggered__2026-02-24T08:54:04.081771+00:00, run_start_date=2026-02-24 08:54:08.237350+00:00, run_end_date=2026-02-24 08:54:22.196512+00:00, run_duration=13.959162, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:53:57.107668+00:00, data_interval_end=2026-02-24 08:53:57.107668+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 16:56:01,186 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:55:59.503214+00:00 [scheduled]>
2026-02-24 16:56:01,187 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:56:01,188 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:55:59.503214+00:00 [scheduled]>
2026-02-24 16:56:01,191 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:55:59.503214+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:56:01,192 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:55:59.503214+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:56:01,193 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:55:59.503214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:56:01,195 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:55:59.503214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:56:06,794 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:55:59.503214+00:00', try_number=1, map_index=-1)
2026-02-24 16:56:06,803 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:55:59.503214+00:00, map_index=-1, run_start_date=2026-02-24 08:56:05.482425+00:00, run_end_date=2026-02-24 08:56:06.009711+00:00, run_duration=0.527286, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=307, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:56:01.189917+00:00, queued_by_job_id=208, pid=19486
2026-02-24 16:56:09,392 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:55:59.503214+00:00: manual__2026-02-24T08:55:59.503214+00:00, state:running, queued_at: 2026-02-24 08:55:59.517244+00:00. externally triggered: True> successful
2026-02-24 16:56:09,393 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:55:59.503214+00:00, run_id=manual__2026-02-24T08:55:59.503214+00:00, run_start_date=2026-02-24 08:56:01.162210+00:00, run_end_date=2026-02-24 08:56:09.393148+00:00, run_duration=8.230938, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:55:59.503214+00:00, data_interval_end=2026-02-24 08:55:59.503214+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:56:09,402 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:56:06.030062+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:56:06.031554+00:00 [scheduled]>
2026-02-24 16:56:09,404 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 16:56:09,405 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 16:56:09,405 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:56:06.030062+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:56:06.031554+00:00 [scheduled]>
2026-02-24 16:56:09,408 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:56:06.030062+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:56:06.031554+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:56:09,409 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:56:06.030062+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:56:09,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:56:06.030062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:56:09,411 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:56:06.031554+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:56:09,412 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:56:06.031554+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:56:09,415 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:56:06.030062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:56:22,335 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:56:06.031554+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:56:27,644 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:56:06.030062+00:00', try_number=1, map_index=-1)
2026-02-24 16:56:27,645 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:56:06.031554+00:00', try_number=1, map_index=-1)
2026-02-24 16:56:27,655 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:56:06.030062+00:00, map_index=-1, run_start_date=2026-02-24 08:56:13.061965+00:00, run_end_date=2026-02-24 08:56:21.623314+00:00, run_duration=8.561349, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=308, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:56:09.407104+00:00, queued_by_job_id=208, pid=19489
2026-02-24 16:56:27,657 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:56:06.031554+00:00, map_index=-1, run_start_date=2026-02-24 08:56:26.400282+00:00, run_end_date=2026-02-24 08:56:26.903230+00:00, run_duration=0.502948, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=309, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:56:09.407104+00:00, queued_by_job_id=208, pid=19510
2026-02-24 16:56:27,690 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 16:56:31,321 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:56:06.030062+00:00: dataset_triggered__2026-02-24T08:56:06.030062+00:00, state:running, queued_at: 2026-02-24 08:56:09.363092+00:00. externally triggered: False> successful
2026-02-24 16:56:31,322 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:56:06.030062+00:00, run_id=dataset_triggered__2026-02-24T08:56:06.030062+00:00, run_start_date=2026-02-24 08:56:09.376224+00:00, run_end_date=2026-02-24 08:56:31.322355+00:00, run_duration=21.946131, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:55:59.503214+00:00, data_interval_end=2026-02-24 08:55:59.503214+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 16:56:31,328 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:56:06.031554+00:00: dataset_triggered__2026-02-24T08:56:06.031554+00:00, state:running, queued_at: 2026-02-24 08:56:09.353356+00:00. externally triggered: False> successful
2026-02-24 16:56:31,329 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:56:06.031554+00:00, run_id=dataset_triggered__2026-02-24T08:56:06.031554+00:00, run_start_date=2026-02-24 08:56:09.376333+00:00, run_end_date=2026-02-24 08:56:31.329438+00:00, run_duration=21.953105, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:55:59.503214+00:00, data_interval_end=2026-02-24 08:55:59.503214+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 16:57:18,224 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:57:16.502452+00:00 [scheduled]>
2026-02-24 16:57:18,225 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:57:18,226 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:57:16.502452+00:00 [scheduled]>
2026-02-24 16:57:18,228 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:57:16.502452+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:57:18,229 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:57:16.502452+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:57:18,230 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:57:16.502452+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:57:18,232 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:57:16.502452+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:57:23,051 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:57:16.502452+00:00', try_number=1, map_index=-1)
2026-02-24 16:57:23,061 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:57:16.502452+00:00, map_index=-1, run_start_date=2026-02-24 08:57:21.820460+00:00, run_end_date=2026-02-24 08:57:22.329510+00:00, run_duration=0.50905, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=310, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:57:18.227523+00:00, queued_by_job_id=208, pid=19550
2026-02-24 16:57:25,712 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:57:16.502452+00:00: manual__2026-02-24T08:57:16.502452+00:00, state:running, queued_at: 2026-02-24 08:57:16.514869+00:00. externally triggered: True> successful
2026-02-24 16:57:25,713 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:57:16.502452+00:00, run_id=manual__2026-02-24T08:57:16.502452+00:00, run_start_date=2026-02-24 08:57:18.202760+00:00, run_end_date=2026-02-24 08:57:25.713352+00:00, run_duration=7.510592, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:57:16.502452+00:00, data_interval_end=2026-02-24 08:57:16.502452+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:57:25,724 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:57:22.348970+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:57:22.350419+00:00 [scheduled]>
2026-02-24 16:57:25,725 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 16:57:25,725 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 16:57:25,726 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:57:22.348970+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:57:22.350419+00:00 [scheduled]>
2026-02-24 16:57:25,728 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:57:22.348970+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:57:22.350419+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:57:25,730 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:57:22.348970+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:57:25,730 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:57:22.348970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:57:25,731 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:57:22.350419+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:57:25,732 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:57:22.350419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:57:25,734 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:57:22.348970+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:57:30,453 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:57:22.350419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:57:42,885 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:57:22.348970+00:00', try_number=1, map_index=-1)
2026-02-24 16:57:42,889 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:57:22.350419+00:00', try_number=1, map_index=-1)
2026-02-24 16:57:42,898 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:57:22.350419+00:00, map_index=-1, run_start_date=2026-02-24 08:57:34.029228+00:00, run_end_date=2026-02-24 08:57:42.199783+00:00, run_duration=8.170555, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=312, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:57:25.727464+00:00, queued_by_job_id=208, pid=19555
2026-02-24 16:57:42,899 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:57:22.348970+00:00, map_index=-1, run_start_date=2026-02-24 08:57:29.320439+00:00, run_end_date=2026-02-24 08:57:29.777168+00:00, run_duration=0.456729, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=311, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:57:25.727464+00:00, queued_by_job_id=208, pid=19553
2026-02-24 16:57:47,547 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:57:22.348970+00:00: dataset_triggered__2026-02-24T08:57:22.348970+00:00, state:running, queued_at: 2026-02-24 08:57:25.682340+00:00. externally triggered: False> successful
2026-02-24 16:57:47,548 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:57:22.348970+00:00, run_id=dataset_triggered__2026-02-24T08:57:22.348970+00:00, run_start_date=2026-02-24 08:57:25.695758+00:00, run_end_date=2026-02-24 08:57:47.548444+00:00, run_duration=21.852686, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:57:16.502452+00:00, data_interval_end=2026-02-24 08:57:16.502452+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 16:57:47,555 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:57:22.350419+00:00: dataset_triggered__2026-02-24T08:57:22.350419+00:00, state:running, queued_at: 2026-02-24 08:57:25.673980+00:00. externally triggered: False> successful
2026-02-24 16:57:47,556 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:57:22.350419+00:00, run_id=dataset_triggered__2026-02-24T08:57:22.350419+00:00, run_start_date=2026-02-24 08:57:25.695866+00:00, run_end_date=2026-02-24 08:57:47.556330+00:00, run_duration=21.860464, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:57:16.502452+00:00, data_interval_end=2026-02-24 08:57:16.502452+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 16:58:37,424 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:58:34.370641+00:00 [scheduled]>
2026-02-24 16:58:37,425 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:58:37,426 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:58:34.370641+00:00 [scheduled]>
2026-02-24 16:58:37,428 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:58:34.370641+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:58:37,429 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:58:34.370641+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:58:37,430 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:58:34.370641+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:58:37,432 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:58:34.370641+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:58:42,537 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:58:34.370641+00:00', try_number=1, map_index=-1)
2026-02-24 16:58:42,546 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:58:34.370641+00:00, map_index=-1, run_start_date=2026-02-24 08:58:41.309534+00:00, run_end_date=2026-02-24 08:58:41.821515+00:00, run_duration=0.511981, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=313, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:58:37.427428+00:00, queued_by_job_id=208, pid=19621
2026-02-24 16:58:45,324 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:58:34.370641+00:00: manual__2026-02-24T08:58:34.370641+00:00, state:running, queued_at: 2026-02-24 08:58:34.382642+00:00. externally triggered: True> successful
2026-02-24 16:58:45,325 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:58:34.370641+00:00, run_id=manual__2026-02-24T08:58:34.370641+00:00, run_start_date=2026-02-24 08:58:37.402358+00:00, run_end_date=2026-02-24 08:58:45.325299+00:00, run_duration=7.922941, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:58:34.370641+00:00, data_interval_end=2026-02-24 08:58:34.370641+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 16:58:45,338 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:58:41.840896+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:58:41.842498+00:00 [scheduled]>
2026-02-24 16:58:45,340 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 16:58:45,341 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 16:58:45,341 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:58:41.840896+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:58:41.842498+00:00 [scheduled]>
2026-02-24 16:58:45,344 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T08:58:41.840896+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T08:58:41.842498+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:58:45,345 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:58:41.840896+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:58:45,346 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:58:41.840896+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:58:45,347 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:58:41.842498+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:58:45,347 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:58:41.842498+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:58:45,351 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T08:58:41.840896+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:58:57,837 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T08:58:41.842498+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:59:02,953 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T08:58:41.840896+00:00', try_number=1, map_index=-1)
2026-02-24 16:59:02,955 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T08:58:41.842498+00:00', try_number=1, map_index=-1)
2026-02-24 16:59:02,964 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T08:58:41.840896+00:00, map_index=-1, run_start_date=2026-02-24 08:58:49.127512+00:00, run_end_date=2026-02-24 08:58:57.123186+00:00, run_duration=7.995674, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=314, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:58:45.343057+00:00, queued_by_job_id=208, pid=19624
2026-02-24 16:59:02,966 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T08:58:41.842498+00:00, map_index=-1, run_start_date=2026-02-24 08:59:01.712258+00:00, run_end_date=2026-02-24 08:59:02.224244+00:00, run_duration=0.511986, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=315, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:58:45.343057+00:00, queued_by_job_id=208, pid=19650
2026-02-24 16:59:05,945 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 08:58:41.840896+00:00: dataset_triggered__2026-02-24T08:58:41.840896+00:00, state:running, queued_at: 2026-02-24 08:58:45.280530+00:00. externally triggered: False> successful
2026-02-24 16:59:05,946 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 08:58:41.840896+00:00, run_id=dataset_triggered__2026-02-24T08:58:41.840896+00:00, run_start_date=2026-02-24 08:58:45.304550+00:00, run_end_date=2026-02-24 08:59:05.946266+00:00, run_duration=20.641716, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:58:34.370641+00:00, data_interval_end=2026-02-24 08:58:34.370641+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 16:59:05,951 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 08:58:41.842498+00:00: dataset_triggered__2026-02-24T08:58:41.842498+00:00, state:running, queued_at: 2026-02-24 08:58:45.289726+00:00. externally triggered: False> successful
2026-02-24 16:59:05,952 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 08:58:41.842498+00:00, run_id=dataset_triggered__2026-02-24T08:58:41.842498+00:00, run_start_date=2026-02-24 08:58:45.304676+00:00, run_end_date=2026-02-24 08:59:05.952870+00:00, run_duration=20.648194, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:58:34.370641+00:00, data_interval_end=2026-02-24 08:58:34.370641+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 16:59:57,535 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:59:54.143585+00:00 [scheduled]>
2026-02-24 16:59:57,536 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 16:59:57,537 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:59:54.143585+00:00 [scheduled]>
2026-02-24 16:59:57,540 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T08:59:54.143585+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 16:59:57,541 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:59:54.143585+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 16:59:57,542 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:59:54.143585+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 16:59:57,544 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T08:59:54.143585+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:00:02,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T08:59:54.143585+00:00', try_number=1, map_index=-1)
2026-02-24 17:00:02,603 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T08:59:54.143585+00:00, map_index=-1, run_start_date=2026-02-24 09:00:01.332741+00:00, run_end_date=2026-02-24 09:00:01.846606+00:00, run_duration=0.513865, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=316, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 08:59:57.538757+00:00, queued_by_job_id=208, pid=19691
2026-02-24 17:00:05,441 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 08:59:54.143585+00:00: manual__2026-02-24T08:59:54.143585+00:00, state:running, queued_at: 2026-02-24 08:59:54.156670+00:00. externally triggered: True> successful
2026-02-24 17:00:05,442 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 08:59:54.143585+00:00, run_id=manual__2026-02-24T08:59:54.143585+00:00, run_start_date=2026-02-24 08:59:57.515229+00:00, run_end_date=2026-02-24 09:00:05.442193+00:00, run_duration=7.926964, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 08:59:54.143585+00:00, data_interval_end=2026-02-24 08:59:54.143585+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:00:05,453 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:00:01.867374+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:00:01.868783+00:00 [scheduled]>
2026-02-24 17:00:05,454 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:00:05,455 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:00:05,456 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:00:01.867374+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:00:01.868783+00:00 [scheduled]>
2026-02-24 17:00:05,459 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:00:01.867374+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:00:01.868783+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:00:05,460 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:00:01.867374+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:00:05,461 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:00:01.867374+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:00:05,462 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:00:01.868783+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:00:05,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:00:01.868783+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:00:05,466 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:00:01.867374+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:00:17,936 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:00:01.868783+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:00:28,821 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:00:01.867374+00:00', try_number=1, map_index=-1)
2026-02-24 17:00:28,823 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:00:01.868783+00:00', try_number=1, map_index=-1)
2026-02-24 17:00:28,833 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:00:01.867374+00:00, map_index=-1, run_start_date=2026-02-24 09:00:09.246809+00:00, run_end_date=2026-02-24 09:00:17.239403+00:00, run_duration=7.992594, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=317, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:00:05.457919+00:00, queued_by_job_id=208, pid=19701
2026-02-24 17:00:28,834 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:00:01.868783+00:00, map_index=-1, run_start_date=2026-02-24 09:00:21.778912+00:00, run_end_date=2026-02-24 09:00:28.182573+00:00, run_duration=6.403661, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=318, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:00:05.457919+00:00, queued_by_job_id=208, pid=19724
2026-02-24 17:00:31,896 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:00:01.867374+00:00: dataset_triggered__2026-02-24T09:00:01.867374+00:00, state:running, queued_at: 2026-02-24 09:00:05.409059+00:00. externally triggered: False> successful
2026-02-24 17:00:31,898 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:00:01.867374+00:00, run_id=dataset_triggered__2026-02-24T09:00:01.867374+00:00, run_start_date=2026-02-24 09:00:05.421851+00:00, run_end_date=2026-02-24 09:00:31.898817+00:00, run_duration=26.476966, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:59:54.143585+00:00, data_interval_end=2026-02-24 08:59:54.143585+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:00:31,904 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:00:01.868783+00:00: dataset_triggered__2026-02-24T09:00:01.868783+00:00, state:running, queued_at: 2026-02-24 09:00:05.399271+00:00. externally triggered: False> successful
2026-02-24 17:00:31,905 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:00:01.868783+00:00, run_id=dataset_triggered__2026-02-24T09:00:01.868783+00:00, run_start_date=2026-02-24 09:00:05.421955+00:00, run_end_date=2026-02-24 09:00:31.905134+00:00, run_duration=26.483179, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 08:59:54.143585+00:00, data_interval_end=2026-02-24 08:59:54.143585+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:01:30,945 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:06:09,077 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:06:06.826492+00:00 [scheduled]>
2026-02-24 17:06:09,078 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 17:06:09,079 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:06:06.826492+00:00 [scheduled]>
2026-02-24 17:06:09,082 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:06:06.826492+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:06:09,083 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:06:06.826492+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:06:09,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:06:06.826492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:06:09,086 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:06:06.826492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:06:14,805 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:06:06.826492+00:00', try_number=1, map_index=-1)
2026-02-24 17:06:14,815 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:06:06.826492+00:00, map_index=-1, run_start_date=2026-02-24 09:06:13.558159+00:00, run_end_date=2026-02-24 09:06:14.080437+00:00, run_duration=0.522278, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=319, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:06:09.080791+00:00, queued_by_job_id=208, pid=19989
2026-02-24 17:06:17,435 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:06:06.826492+00:00: manual__2026-02-24T09:06:06.826492+00:00, state:running, queued_at: 2026-02-24 09:06:06.840482+00:00. externally triggered: True> successful
2026-02-24 17:06:17,436 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:06:06.826492+00:00, run_id=manual__2026-02-24T09:06:06.826492+00:00, run_start_date=2026-02-24 09:06:09.055991+00:00, run_end_date=2026-02-24 09:06:17.436290+00:00, run_duration=8.380299, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:06:06.826492+00:00, data_interval_end=2026-02-24 09:06:06.826492+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:06:17,447 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:06:14.099955+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:06:14.101475+00:00 [scheduled]>
2026-02-24 17:06:17,448 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:06:17,448 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:06:17,449 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:06:14.099955+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:06:14.101475+00:00 [scheduled]>
2026-02-24 17:06:17,452 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:06:14.099955+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:06:14.101475+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:06:17,453 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:06:14.099955+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:06:17,454 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:06:14.099955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:06:17,455 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:06:14.101475+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:06:17,456 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:06:14.101475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:06:17,459 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:06:14.099955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:06:28,922 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:06:14.101475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:06:41,290 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:06:14.099955+00:00', try_number=1, map_index=-1)
2026-02-24 17:06:41,291 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:06:14.101475+00:00', try_number=1, map_index=-1)
2026-02-24 17:06:41,300 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:06:14.101475+00:00, map_index=-1, run_start_date=2026-02-24 09:06:32.933167+00:00, run_end_date=2026-02-24 09:06:40.578490+00:00, run_duration=7.645323, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=321, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:06:17.450975+00:00, queued_by_job_id=208, pid=20023
2026-02-24 17:06:41,302 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:06:14.099955+00:00, map_index=-1, run_start_date=2026-02-24 09:06:21.236444+00:00, run_end_date=2026-02-24 09:06:28.238297+00:00, run_duration=7.001853, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=320, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:06:17.450975+00:00, queued_by_job_id=208, pid=19998
2026-02-24 17:06:41,332 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:06:44,432 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:06:14.099955+00:00: dataset_triggered__2026-02-24T09:06:14.099955+00:00, state:running, queued_at: 2026-02-24 09:06:17.406757+00:00. externally triggered: False> successful
2026-02-24 17:06:44,433 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:06:14.099955+00:00, run_id=dataset_triggered__2026-02-24T09:06:14.099955+00:00, run_start_date=2026-02-24 09:06:17.418221+00:00, run_end_date=2026-02-24 09:06:44.433034+00:00, run_duration=27.014813, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:06:06.826492+00:00, data_interval_end=2026-02-24 09:06:06.826492+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:06:44,437 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:06:14.101475+00:00: dataset_triggered__2026-02-24T09:06:14.101475+00:00, state:running, queued_at: 2026-02-24 09:06:17.391262+00:00. externally triggered: False> successful
2026-02-24 17:06:44,439 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:06:14.101475+00:00, run_id=dataset_triggered__2026-02-24T09:06:14.101475+00:00, run_start_date=2026-02-24 09:06:17.418330+00:00, run_end_date=2026-02-24 09:06:44.439030+00:00, run_duration=27.0207, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:06:06.826492+00:00, data_interval_end=2026-02-24 09:06:06.826492+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:10:06,530 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:10:04.515914+00:00 [scheduled]>
2026-02-24 17:10:06,531 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 17:10:06,531 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:10:04.515914+00:00 [scheduled]>
2026-02-24 17:10:06,533 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:10:04.515914+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:10:06,534 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:10:04.515914+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:10:06,535 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:10:04.515914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:10:06,538 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:10:04.515914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:10:11,909 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:10:04.515914+00:00', try_number=1, map_index=-1)
2026-02-24 17:10:11,919 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:10:04.515914+00:00, map_index=-1, run_start_date=2026-02-24 09:10:10.666073+00:00, run_end_date=2026-02-24 09:10:11.195320+00:00, run_duration=0.529247, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=322, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:10:06.532728+00:00, queued_by_job_id=208, pid=20159
2026-02-24 17:10:15,818 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:10:04.515914+00:00: manual__2026-02-24T09:10:04.515914+00:00, state:running, queued_at: 2026-02-24 09:10:04.532913+00:00. externally triggered: True> successful
2026-02-24 17:10:15,819 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:10:04.515914+00:00, run_id=manual__2026-02-24T09:10:04.515914+00:00, run_start_date=2026-02-24 09:10:06.509626+00:00, run_end_date=2026-02-24 09:10:15.819205+00:00, run_duration=9.309579, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:10:04.515914+00:00, data_interval_end=2026-02-24 09:10:04.515914+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:10:15,829 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:10:11.215597+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:10:11.217924+00:00 [scheduled]>
2026-02-24 17:10:15,830 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:10:15,830 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:10:15,831 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:10:11.215597+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:10:11.217924+00:00 [scheduled]>
2026-02-24 17:10:15,835 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:10:11.215597+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:10:11.217924+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:10:15,836 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:10:11.215597+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:10:15,836 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:10:11.215597+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:10:15,837 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:10:11.217924+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:10:15,838 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:10:11.217924+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:10:15,840 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:10:11.215597+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:10:26,241 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:10:11.217924+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:10:37,076 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:10:11.215597+00:00', try_number=1, map_index=-1)
2026-02-24 17:10:37,080 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:10:11.217924+00:00', try_number=1, map_index=-1)
2026-02-24 17:10:37,091 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:10:11.217924+00:00, map_index=-1, run_start_date=2026-02-24 09:10:29.876201+00:00, run_end_date=2026-02-24 09:10:36.391462+00:00, run_duration=6.515261, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=324, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:10:15.833396+00:00, queued_by_job_id=208, pid=20178
2026-02-24 17:10:37,092 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:10:11.215597+00:00, map_index=-1, run_start_date=2026-02-24 09:10:19.585191+00:00, run_end_date=2026-02-24 09:10:25.501828+00:00, run_duration=5.916637, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=323, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:10:15.833396+00:00, queued_by_job_id=208, pid=20164
2026-02-24 17:10:40,214 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:10:11.215597+00:00: dataset_triggered__2026-02-24T09:10:11.215597+00:00, state:running, queued_at: 2026-02-24 09:10:15.744586+00:00. externally triggered: False> successful
2026-02-24 17:10:40,215 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:10:11.215597+00:00, run_id=dataset_triggered__2026-02-24T09:10:11.215597+00:00, run_start_date=2026-02-24 09:10:15.789505+00:00, run_end_date=2026-02-24 09:10:40.215726+00:00, run_duration=24.426221, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:10:04.515914+00:00, data_interval_end=2026-02-24 09:10:04.515914+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:10:40,221 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:10:11.217924+00:00: dataset_triggered__2026-02-24T09:10:11.217924+00:00, state:running, queued_at: 2026-02-24 09:10:15.707784+00:00. externally triggered: False> successful
2026-02-24 17:10:40,222 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:10:11.217924+00:00, run_id=dataset_triggered__2026-02-24T09:10:11.217924+00:00, run_start_date=2026-02-24 09:10:15.789807+00:00, run_end_date=2026-02-24 09:10:40.222513+00:00, run_duration=24.432706, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:10:04.515914+00:00, data_interval_end=2026-02-24 09:10:04.515914+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:11:44,245 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:16:45,212 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:21:45,358 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:26:45,835 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:31:48,221 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:32:50,177 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:32:45.789302+00:00 [scheduled]>
2026-02-24 17:32:50,178 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 17:32:50,179 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:32:45.789302+00:00 [scheduled]>
2026-02-24 17:32:50,182 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:32:45.789302+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:32:50,184 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:32:45.789302+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:32:50,185 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:32:45.789302+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:32:50,188 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:32:45.789302+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:32:55,563 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:32:45.789302+00:00', try_number=1, map_index=-1)
2026-02-24 17:32:55,573 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:32:45.789302+00:00, map_index=-1, run_start_date=2026-02-24 09:32:54.481974+00:00, run_end_date=2026-02-24 09:32:54.763307+00:00, run_duration=0.281333, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=325, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:32:50.180814+00:00, queued_by_job_id=208, pid=20919
2026-02-24 17:32:59,055 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:32:45.789302+00:00: manual__2026-02-24T09:32:45.789302+00:00, state:running, queued_at: 2026-02-24 09:32:45.813017+00:00. externally triggered: True> successful
2026-02-24 17:32:59,057 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:32:45.789302+00:00, run_id=manual__2026-02-24T09:32:45.789302+00:00, run_start_date=2026-02-24 09:32:50.150710+00:00, run_end_date=2026-02-24 09:32:59.056955+00:00, run_duration=8.906245, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:32:45.789302+00:00, data_interval_end=2026-02-24 09:32:45.789302+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:32:59,069 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:32:54.785623+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:32:54.787315+00:00 [scheduled]>
2026-02-24 17:32:59,071 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:32:59,072 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:32:59,073 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:32:54.785623+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:32:54.787315+00:00 [scheduled]>
2026-02-24 17:32:59,076 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:32:54.785623+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:32:54.787315+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:32:59,077 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:32:54.785623+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:32:59,078 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:32:54.785623+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:32:59,079 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:32:54.787315+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:32:59,079 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:32:54.787315+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:32:59,082 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:32:54.785623+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:33:09,581 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:32:54.787315+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:33:19,880 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:32:54.785623+00:00', try_number=1, map_index=-1)
2026-02-24 17:33:19,882 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:32:54.787315+00:00', try_number=1, map_index=-1)
2026-02-24 17:33:19,890 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:32:54.787315+00:00, map_index=-1, run_start_date=2026-02-24 09:33:13.648022+00:00, run_end_date=2026-02-24 09:33:19.248972+00:00, run_duration=5.60095, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=327, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:32:59.074596+00:00, queued_by_job_id=208, pid=20939
2026-02-24 17:33:19,892 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:32:54.785623+00:00, map_index=-1, run_start_date=2026-02-24 09:33:02.987853+00:00, run_end_date=2026-02-24 09:33:08.825974+00:00, run_duration=5.838121, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=326, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:32:59.074596+00:00, queued_by_job_id=208, pid=20925
2026-02-24 17:33:23,467 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:32:54.785623+00:00: dataset_triggered__2026-02-24T09:32:54.785623+00:00, state:running, queued_at: 2026-02-24 09:32:59.009451+00:00. externally triggered: False> successful
2026-02-24 17:33:23,468 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:32:54.785623+00:00, run_id=dataset_triggered__2026-02-24T09:32:54.785623+00:00, run_start_date=2026-02-24 09:32:59.038492+00:00, run_end_date=2026-02-24 09:33:23.468494+00:00, run_duration=24.430002, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:32:45.789302+00:00, data_interval_end=2026-02-24 09:32:45.789302+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:33:23,474 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:32:54.787315+00:00: dataset_triggered__2026-02-24T09:32:54.787315+00:00, state:running, queued_at: 2026-02-24 09:32:59.024507+00:00. externally triggered: False> successful
2026-02-24 17:33:23,475 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:32:54.787315+00:00, run_id=dataset_triggered__2026-02-24T09:32:54.787315+00:00, run_start_date=2026-02-24 09:32:59.038602+00:00, run_end_date=2026-02-24 09:33:23.475741+00:00, run_duration=24.437139, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:32:45.789302+00:00, data_interval_end=2026-02-24 09:32:45.789302+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:36:48,679 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:40:28,479 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:40:23.906460+00:00 [scheduled]>
2026-02-24 17:40:28,480 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 17:40:28,481 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:40:23.906460+00:00 [scheduled]>
2026-02-24 17:40:28,484 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:40:23.906460+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:40:28,485 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:40:23.906460+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:40:28,485 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:40:23.906460+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:40:28,487 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:40:23.906460+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:40:33,685 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:40:23.906460+00:00', try_number=1, map_index=-1)
2026-02-24 17:40:33,694 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:40:23.906460+00:00, map_index=-1, run_start_date=2026-02-24 09:40:32.499692+00:00, run_end_date=2026-02-24 09:40:32.986524+00:00, run_duration=0.486832, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=328, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:40:28.482642+00:00, queued_by_job_id=208, pid=21235
2026-02-24 17:40:37,133 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:40:23.906460+00:00: manual__2026-02-24T09:40:23.906460+00:00, state:running, queued_at: 2026-02-24 09:40:23.920456+00:00. externally triggered: True> successful
2026-02-24 17:40:37,134 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:40:23.906460+00:00, run_id=manual__2026-02-24T09:40:23.906460+00:00, run_start_date=2026-02-24 09:40:28.459967+00:00, run_end_date=2026-02-24 09:40:37.134817+00:00, run_duration=8.67485, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:40:23.906460+00:00, data_interval_end=2026-02-24 09:40:23.906460+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:40:37,146 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:40:33.006091+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:40:33.007771+00:00 [scheduled]>
2026-02-24 17:40:37,147 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:40:37,147 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:40:37,148 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:40:33.006091+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:40:33.007771+00:00 [scheduled]>
2026-02-24 17:40:37,151 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:40:33.006091+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:40:33.007771+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:40:37,152 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:40:33.006091+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:40:37,153 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:40:33.006091+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:40:37,154 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:40:33.007771+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:40:37,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:40:33.007771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:40:37,158 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:40:33.006091+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:40:42,301 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:40:33.007771+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:40:47,361 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:40:33.006091+00:00', try_number=1, map_index=-1)
2026-02-24 17:40:47,365 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:40:33.007771+00:00', try_number=1, map_index=-1)
2026-02-24 17:40:47,374 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:40:33.006091+00:00, map_index=-1, run_start_date=2026-02-24 09:40:41.171742+00:00, run_end_date=2026-02-24 09:40:41.620448+00:00, run_duration=0.448706, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=329, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:40:37.150450+00:00, queued_by_job_id=208, pid=21239
2026-02-24 17:40:47,376 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:40:33.007771+00:00, map_index=-1, run_start_date=2026-02-24 09:40:46.247559+00:00, run_end_date=2026-02-24 09:40:46.669053+00:00, run_duration=0.421494, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=330, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:40:37.150450+00:00, queued_by_job_id=208, pid=21241
2026-02-24 17:40:51,331 ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:40:33.006091+00:00: dataset_triggered__2026-02-24T09:40:33.006091+00:00, state:running, queued_at: 2026-02-24 09:40:37.102501+00:00. externally triggered: False> failed
2026-02-24 17:40:51,332 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:40:33.006091+00:00, run_id=dataset_triggered__2026-02-24T09:40:33.006091+00:00, run_start_date=2026-02-24 09:40:37.115687+00:00, run_end_date=2026-02-24 09:40:51.332678+00:00, run_duration=14.216991, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:40:23.906460+00:00, data_interval_end=2026-02-24 09:40:23.906460+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:40:51,337 ERROR - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:40:33.007771+00:00: dataset_triggered__2026-02-24T09:40:33.007771+00:00, state:running, queued_at: 2026-02-24 09:40:37.088644+00:00. externally triggered: False> failed
2026-02-24 17:40:51,338 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:40:33.007771+00:00, run_id=dataset_triggered__2026-02-24T09:40:33.007771+00:00, run_start_date=2026-02-24 09:40:37.115793+00:00, run_end_date=2026-02-24 09:40:51.338723+00:00, run_duration=14.22293, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:40:23.906460+00:00, data_interval_end=2026-02-24 09:40:23.906460+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:41:40,201 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:41:38.989132+00:00 [scheduled]>
2026-02-24 17:41:40,202 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 17:41:40,204 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:41:38.989132+00:00 [scheduled]>
2026-02-24 17:41:40,207 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:41:38.989132+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:41:40,208 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:41:38.989132+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:41:40,209 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:41:38.989132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:41:40,211 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:41:38.989132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:41:45,694 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:41:38.989132+00:00', try_number=1, map_index=-1)
2026-02-24 17:41:45,704 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:41:38.989132+00:00, map_index=-1, run_start_date=2026-02-24 09:41:44.453339+00:00, run_end_date=2026-02-24 09:41:44.971489+00:00, run_duration=0.51815, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=331, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:41:40.206193+00:00, queued_by_job_id=208, pid=21286
2026-02-24 17:41:49,307 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:41:38.989132+00:00: manual__2026-02-24T09:41:38.989132+00:00, state:running, queued_at: 2026-02-24 09:41:39.002529+00:00. externally triggered: True> successful
2026-02-24 17:41:49,308 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:41:38.989132+00:00, run_id=manual__2026-02-24T09:41:38.989132+00:00, run_start_date=2026-02-24 09:41:40.176348+00:00, run_end_date=2026-02-24 09:41:49.308656+00:00, run_duration=9.132308, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:41:38.989132+00:00, data_interval_end=2026-02-24 09:41:38.989132+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:41:49,319 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:41:44.989189+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:41:44.991139+00:00 [scheduled]>
2026-02-24 17:41:49,320 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:41:49,321 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:41:49,322 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:41:44.989189+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:41:44.991139+00:00 [scheduled]>
2026-02-24 17:41:49,325 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:41:44.989189+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:41:44.991139+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:41:49,326 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:41:44.989189+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:41:49,326 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:41:44.989189+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:41:49,327 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:41:44.991139+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:41:49,328 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:41:44.991139+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:41:49,331 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:41:44.989189+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:42:01,969 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:41:44.991139+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:42:11,909 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:41:44.989189+00:00', try_number=1, map_index=-1)
2026-02-24 17:42:11,911 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:41:44.991139+00:00', try_number=1, map_index=-1)
2026-02-24 17:42:11,920 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:41:44.989189+00:00, map_index=-1, run_start_date=2026-02-24 09:41:53.068684+00:00, run_end_date=2026-02-24 09:42:01.280337+00:00, run_duration=8.211653, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=332, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:41:49.323682+00:00, queued_by_job_id=208, pid=21291
2026-02-24 17:42:11,921 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:41:44.991139+00:00, map_index=-1, run_start_date=2026-02-24 09:42:05.960737+00:00, run_end_date=2026-02-24 09:42:11.197528+00:00, run_duration=5.236791, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=333, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:41:49.323682+00:00, queued_by_job_id=208, pid=21318
2026-02-24 17:42:11,946 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:42:15,652 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:41:44.989189+00:00: dataset_triggered__2026-02-24T09:41:44.989189+00:00, state:running, queued_at: 2026-02-24 09:41:49.265757+00:00. externally triggered: False> successful
2026-02-24 17:42:15,654 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:41:44.989189+00:00, run_id=dataset_triggered__2026-02-24T09:41:44.989189+00:00, run_start_date=2026-02-24 09:41:49.289341+00:00, run_end_date=2026-02-24 09:42:15.653849+00:00, run_duration=26.364508, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:41:38.989132+00:00, data_interval_end=2026-02-24 09:41:38.989132+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:42:15,660 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:41:44.991139+00:00: dataset_triggered__2026-02-24T09:41:44.991139+00:00, state:running, queued_at: 2026-02-24 09:41:49.276187+00:00. externally triggered: False> successful
2026-02-24 17:42:15,661 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:41:44.991139+00:00, run_id=dataset_triggered__2026-02-24T09:41:44.991139+00:00, run_start_date=2026-02-24 09:41:49.289464+00:00, run_end_date=2026-02-24 09:42:15.660995+00:00, run_duration=26.371531, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:41:38.989132+00:00, data_interval_end=2026-02-24 09:41:38.989132+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:46:11,675 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:46:09.019140+00:00 [scheduled]>
2026-02-24 17:46:11,676 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 17:46:11,676 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:46:09.019140+00:00 [scheduled]>
2026-02-24 17:46:11,679 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:46:09.019140+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:46:11,681 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:46:09.019140+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:46:11,682 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:46:09.019140+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:46:11,684 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:46:09.019140+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:46:18,235 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:46:09.019140+00:00', try_number=1, map_index=-1)
2026-02-24 17:46:18,245 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:46:09.019140+00:00, map_index=-1, run_start_date=2026-02-24 09:46:16.939158+00:00, run_end_date=2026-02-24 09:46:17.489333+00:00, run_duration=0.550175, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=334, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:46:11.678142+00:00, queued_by_job_id=208, pid=21446
2026-02-24 17:46:23,111 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:46:09.019140+00:00: manual__2026-02-24T09:46:09.019140+00:00, state:running, queued_at: 2026-02-24 09:46:09.034560+00:00. externally triggered: True> successful
2026-02-24 17:46:23,114 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:46:09.019140+00:00, run_id=manual__2026-02-24T09:46:09.019140+00:00, run_start_date=2026-02-24 09:46:11.654362+00:00, run_end_date=2026-02-24 09:46:23.114260+00:00, run_duration=11.459898, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:46:09.019140+00:00, data_interval_end=2026-02-24 09:46:09.019140+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:46:23,133 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:46:17.525887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:46:17.528214+00:00 [scheduled]>
2026-02-24 17:46:23,134 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:46:23,134 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:46:23,135 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:46:17.525887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:46:17.528214+00:00 [scheduled]>
2026-02-24 17:46:23,141 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:46:17.525887+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:46:17.528214+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:46:23,143 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:46:17.525887+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:46:23,144 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:46:17.525887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:46:23,145 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:46:17.528214+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:46:23,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:46:17.528214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:46:23,152 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:46:17.525887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:46:38,200 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:46:17.528214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:46:53,139 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:46:17.525887+00:00', try_number=1, map_index=-1)
2026-02-24 17:46:53,141 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:46:17.528214+00:00', try_number=1, map_index=-1)
2026-02-24 17:46:53,171 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:46:17.528214+00:00, map_index=-1, run_start_date=2026-02-24 09:46:43.102944+00:00, run_end_date=2026-02-24 09:46:52.408997+00:00, run_duration=9.306053, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=336, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:46:23.137957+00:00, queued_by_job_id=208, pid=21490
2026-02-24 17:46:53,174 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:46:17.525887+00:00, map_index=-1, run_start_date=2026-02-24 09:46:30.987001+00:00, run_end_date=2026-02-24 09:46:37.453097+00:00, run_duration=6.466096, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=335, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:46:23.137957+00:00, queued_by_job_id=208, pid=21469
2026-02-24 17:46:53,202 INFO - Heartbeat recovered after 34.94 seconds
2026-02-24 17:46:56,524 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:46:17.525887+00:00: dataset_triggered__2026-02-24T09:46:17.525887+00:00, state:running, queued_at: 2026-02-24 09:46:23.022534+00:00. externally triggered: False> successful
2026-02-24 17:46:56,526 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:46:17.525887+00:00, run_id=dataset_triggered__2026-02-24T09:46:17.525887+00:00, run_start_date=2026-02-24 09:46:23.048258+00:00, run_end_date=2026-02-24 09:46:56.525877+00:00, run_duration=33.477619, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:46:09.019140+00:00, data_interval_end=2026-02-24 09:46:09.019140+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:46:56,532 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:46:17.528214+00:00: dataset_triggered__2026-02-24T09:46:17.528214+00:00, state:running, queued_at: 2026-02-24 09:46:23.005727+00:00. externally triggered: False> successful
2026-02-24 17:46:56,533 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:46:17.528214+00:00, run_id=dataset_triggered__2026-02-24T09:46:17.528214+00:00, run_start_date=2026-02-24 09:46:23.048460+00:00, run_end_date=2026-02-24 09:46:56.533790+00:00, run_duration=33.48533, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:46:09.019140+00:00, data_interval_end=2026-02-24 09:46:09.019140+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:47:15,662 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:51:16,897 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:51:12.512152+00:00 [scheduled]>
2026-02-24 17:51:16,897 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-24 17:51:16,898 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:51:12.512152+00:00 [scheduled]>
2026-02-24 17:51:16,901 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-24T09:51:12.512152+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:51:16,902 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:51:12.512152+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:51:16,903 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:51:12.512152+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:51:16,905 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-24T09:51:12.512152+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:51:29,257 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-24T09:51:12.512152+00:00', try_number=1, map_index=-1)
2026-02-24 17:51:29,278 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-24T09:51:12.512152+00:00, map_index=-1, run_start_date=2026-02-24 09:51:26.111159+00:00, run_end_date=2026-02-24 09:51:27.009970+00:00, run_duration=0.898811, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=337, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:51:16.899929+00:00, queued_by_job_id=208, pid=21670
2026-02-24 17:51:39,123 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-24 09:51:12.512152+00:00: manual__2026-02-24T09:51:12.512152+00:00, state:running, queued_at: 2026-02-24 09:51:12.527162+00:00. externally triggered: True> successful
2026-02-24 17:51:39,126 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-24 09:51:12.512152+00:00, run_id=manual__2026-02-24T09:51:12.512152+00:00, run_start_date=2026-02-24 09:51:16.874566+00:00, run_end_date=2026-02-24 09:51:39.126151+00:00, run_duration=22.251585, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-24 09:51:12.512152+00:00, data_interval_end=2026-02-24 09:51:12.512152+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-24 17:51:39,176 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:51:27.074289+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:51:27.083642+00:00 [scheduled]>
2026-02-24 17:51:39,178 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-24 17:51:39,182 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-24 17:51:39,188 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:51:27.074289+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:51:27.083642+00:00 [scheduled]>
2026-02-24 17:51:39,200 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-24T09:51:27.074289+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-24T09:51:27.083642+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-24 17:51:39,204 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:51:27.074289+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:51:39,208 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:51:27.074289+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:51:39,217 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:51:27.083642+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-24 17:51:39,221 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:51:27.083642+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:51:39,227 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-24T09:51:27.074289+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:51:55,425 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-24T09:51:27.083642+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-24 17:52:12,648 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-24T09:51:27.074289+00:00', try_number=1, map_index=-1)
2026-02-24 17:52:12,651 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-24T09:51:27.083642+00:00', try_number=1, map_index=-1)
2026-02-24 17:52:12,661 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-24T09:51:27.083642+00:00, map_index=-1, run_start_date=2026-02-24 09:52:01.852727+00:00, run_end_date=2026-02-24 09:52:11.931032+00:00, run_duration=10.078305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=339, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:51:39.194110+00:00, queued_by_job_id=208, pid=21701
2026-02-24 17:52:12,662 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-24T09:51:27.074289+00:00, map_index=-1, run_start_date=2026-02-24 09:51:48.771647+00:00, run_end_date=2026-02-24 09:51:54.747660+00:00, run_duration=5.976013, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=338, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-24 09:51:39.194110+00:00, queued_by_job_id=208, pid=21682
2026-02-24 17:52:12,681 INFO - Heartbeat recovered after 43.38 seconds
2026-02-24 17:52:16,405 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-24 09:51:27.074289+00:00: dataset_triggered__2026-02-24T09:51:27.074289+00:00, state:running, queued_at: 2026-02-24 09:51:39.054733+00:00. externally triggered: False> successful
2026-02-24 17:52:16,406 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-24 09:51:27.074289+00:00, run_id=dataset_triggered__2026-02-24T09:51:27.074289+00:00, run_start_date=2026-02-24 09:51:39.082752+00:00, run_end_date=2026-02-24 09:52:16.406388+00:00, run_duration=37.323636, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:51:12.512152+00:00, data_interval_end=2026-02-24 09:51:12.512152+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-24 17:52:16,411 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-24 09:51:27.083642+00:00: dataset_triggered__2026-02-24T09:51:27.083642+00:00, state:running, queued_at: 2026-02-24 09:51:39.012658+00:00. externally triggered: False> successful
2026-02-24 17:52:16,412 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-24 09:51:27.083642+00:00, run_id=dataset_triggered__2026-02-24T09:51:27.083642+00:00, run_start_date=2026-02-24 09:51:39.082977+00:00, run_end_date=2026-02-24 09:52:16.412186+00:00, run_duration=37.329209, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 09:51:12.512152+00:00, data_interval_end=2026-02-24 09:51:12.512152+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-24 17:52:16,434 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 17:57:17,505 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:02:19,153 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:07:19,619 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:12:22,279 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:17:24,365 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:22:25,207 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:27:28,586 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:32:30,085 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:37:30,635 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:42:32,672 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-24 18:42:49,714 INFO - Exiting gracefully upon receiving signal 15
2026-02-24 18:42:50,540 INFO - Sending Signals.SIGTERM to group 5320. PIDs of all processes in the group: []
2026-02-24 18:42:50,541 INFO - Sending the signal Signals.SIGTERM to group 5320
2026-02-24 18:42:50,542 INFO - Sending the signal Signals.SIGTERM to process 5320 as process group is missing.
2026-02-24 18:42:50,555 INFO - Sending Signals.SIGTERM to group 5320. PIDs of all processes in the group: []
2026-02-24 18:42:50,556 INFO - Sending the signal Signals.SIGTERM to group 5320
2026-02-24 18:42:50,557 INFO - Sending the signal Signals.SIGTERM to process 5320 as process group is missing.
2026-02-24 18:42:50,558 INFO - Exited execute loop
2026-02-25 08:45:11,765 INFO - Loaded executor: SequentialExecutor
2026-02-25 08:45:12,313 INFO - Starting the scheduler
2026-02-25 08:45:12,314 INFO - Processing each file at most -1 times
2026-02-25 08:45:12,319 INFO - Launched DagFileProcessorManager with pid: 1487
2026-02-25 08:45:12,325 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 08:50:14,555 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 08:55:16,808 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:00:20,117 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:01:13,146 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:01:11.694331+00:00 [scheduled]>
2026-02-25 09:01:13,147 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 09:01:13,148 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:01:11.694331+00:00 [scheduled]>
2026-02-25 09:01:13,151 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:01:11.694331+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 09:01:13,152 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:01:11.694331+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 09:01:13,152 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:01:11.694331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:01:13,155 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:01:11.694331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:01:18,175 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:01:11.694331+00:00', try_number=1, map_index=-1)
2026-02-25 09:01:18,190 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T01:01:11.694331+00:00, map_index=-1, run_start_date=2026-02-25 01:01:16.998370+00:00, run_end_date=2026-02-25 01:01:17.490608+00:00, run_duration=0.492238, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=341, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:01:13.149594+00:00, queued_by_job_id=340, pid=2096
2026-02-25 09:01:21,679 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 01:01:11.694331+00:00: manual__2026-02-25T01:01:11.694331+00:00, state:running, queued_at: 2026-02-25 01:01:11.725299+00:00. externally triggered: True> successful
2026-02-25 09:01:21,681 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 01:01:11.694331+00:00, run_id=manual__2026-02-25T01:01:11.694331+00:00, run_start_date=2026-02-25 01:01:13.113741+00:00, run_end_date=2026-02-25 01:01:21.681438+00:00, run_duration=8.567697, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 01:01:11.694331+00:00, data_interval_end=2026-02-25 01:01:11.694331+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 09:01:21,694 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:01:17.507944+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:01:17.509548+00:00 [scheduled]>
2026-02-25 09:01:21,695 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 09:01:21,696 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 09:01:21,697 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:01:17.507944+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:01:17.509548+00:00 [scheduled]>
2026-02-25 09:01:21,700 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:01:17.507944+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:01:17.509548+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 09:01:21,701 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:01:17.507944+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 09:01:21,702 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:01:17.507944+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:01:21,705 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:01:17.509548+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 09:01:21,706 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:01:17.509548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:01:21,715 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:01:17.507944+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:01:34,747 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:01:17.509548+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:01:46,935 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:01:17.507944+00:00', try_number=1, map_index=-1)
2026-02-25 09:01:46,941 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:01:17.509548+00:00', try_number=1, map_index=-1)
2026-02-25 09:01:46,953 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T01:01:17.507944+00:00, map_index=-1, run_start_date=2026-02-25 01:01:25.769215+00:00, run_end_date=2026-02-25 01:01:34.065145+00:00, run_duration=8.29593, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=342, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:01:21.698613+00:00, queued_by_job_id=340, pid=2102
2026-02-25 09:01:46,955 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T01:01:17.509548+00:00, map_index=-1, run_start_date=2026-02-25 01:01:38.662529+00:00, run_end_date=2026-02-25 01:01:46.239032+00:00, run_duration=7.576503, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=343, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:01:21.698613+00:00, queued_by_job_id=340, pid=2134
2026-02-25 09:01:50,714 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 01:01:17.507944+00:00: dataset_triggered__2026-02-25T01:01:17.507944+00:00, state:running, queued_at: 2026-02-25 01:01:21.645233+00:00. externally triggered: False> successful
2026-02-25 09:01:50,715 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 01:01:17.507944+00:00, run_id=dataset_triggered__2026-02-25T01:01:17.507944+00:00, run_start_date=2026-02-25 01:01:21.659727+00:00, run_end_date=2026-02-25 01:01:50.715367+00:00, run_duration=29.05564, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:01:11.694331+00:00, data_interval_end=2026-02-25 01:01:11.694331+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 09:01:50,720 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 01:01:17.509548+00:00: dataset_triggered__2026-02-25T01:01:17.509548+00:00, state:running, queued_at: 2026-02-25 01:01:21.630949+00:00. externally triggered: False> successful
2026-02-25 09:01:50,720 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 01:01:17.509548+00:00, run_id=dataset_triggered__2026-02-25T01:01:17.509548+00:00, run_start_date=2026-02-25 01:01:21.659837+00:00, run_end_date=2026-02-25 01:01:50.720949+00:00, run_duration=29.061112, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:01:11.694331+00:00, data_interval_end=2026-02-25 01:01:11.694331+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 09:25:24,933 INFO - Heartbeat recovered after 1282.81 seconds
2026-02-25 09:25:46,507 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:25:43.764450+00:00 [scheduled]>
2026-02-25 09:25:46,508 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 09:25:46,509 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:25:43.764450+00:00 [scheduled]>
2026-02-25 09:25:46,511 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T01:25:43.764450+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 09:25:46,512 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:25:43.764450+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 09:25:46,513 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:25:43.764450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:25:46,516 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T01:25:43.764450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:25:51,163 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T01:25:43.764450+00:00', try_number=1, map_index=-1)
2026-02-25 09:25:51,175 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T01:25:43.764450+00:00, map_index=-1, run_start_date=2026-02-25 01:25:49.947155+00:00, run_end_date=2026-02-25 01:25:50.436660+00:00, run_duration=0.489505, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=344, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:25:46.510503+00:00, queued_by_job_id=340, pid=2325
2026-02-25 09:25:54,883 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 01:25:43.764450+00:00: manual__2026-02-25T01:25:43.764450+00:00, state:running, queued_at: 2026-02-25 01:25:43.787031+00:00. externally triggered: True> successful
2026-02-25 09:25:54,883 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 01:25:43.764450+00:00, run_id=manual__2026-02-25T01:25:43.764450+00:00, run_start_date=2026-02-25 01:25:46.485532+00:00, run_end_date=2026-02-25 01:25:54.883909+00:00, run_duration=8.398377, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 01:25:43.764450+00:00, data_interval_end=2026-02-25 01:25:43.764450+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 09:25:54,895 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:25:50.455089+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:25:50.457171+00:00 [scheduled]>
2026-02-25 09:25:54,896 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 09:25:54,897 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 09:25:54,898 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:25:50.455089+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:25:50.457171+00:00 [scheduled]>
2026-02-25 09:25:54,901 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T01:25:50.455089+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T01:25:50.457171+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 09:25:54,902 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:25:50.455089+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 09:25:54,903 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:25:50.455089+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:25:54,904 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:25:50.457171+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 09:25:54,904 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:25:50.457171+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:25:54,907 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T01:25:50.455089+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:26:07,970 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T01:25:50.457171+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 09:26:17,442 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T01:25:50.455089+00:00', try_number=1, map_index=-1)
2026-02-25 09:26:17,446 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T01:25:50.457171+00:00', try_number=1, map_index=-1)
2026-02-25 09:26:17,456 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T01:25:50.457171+00:00, map_index=-1, run_start_date=2026-02-25 01:26:11.641318+00:00, run_end_date=2026-02-25 01:26:16.742618+00:00, run_duration=5.1013, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=346, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:25:54.899699+00:00, queued_by_job_id=340, pid=2352
2026-02-25 09:26:17,458 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T01:25:50.455089+00:00, map_index=-1, run_start_date=2026-02-25 01:25:58.470298+00:00, run_end_date=2026-02-25 01:26:07.250876+00:00, run_duration=8.780578, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=345, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 01:25:54.899699+00:00, queued_by_job_id=340, pid=2328
2026-02-25 09:26:19,847 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 01:25:50.455089+00:00: dataset_triggered__2026-02-25T01:25:50.455089+00:00, state:running, queued_at: 2026-02-25 01:25:54.846237+00:00. externally triggered: False> successful
2026-02-25 09:26:19,849 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 01:25:50.455089+00:00, run_id=dataset_triggered__2026-02-25T01:25:50.455089+00:00, run_start_date=2026-02-25 01:25:54.865207+00:00, run_end_date=2026-02-25 01:26:19.848938+00:00, run_duration=24.983731, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:25:43.764450+00:00, data_interval_end=2026-02-25 01:25:43.764450+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 09:26:19,853 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 01:25:50.457171+00:00: dataset_triggered__2026-02-25T01:25:50.457171+00:00, state:running, queued_at: 2026-02-25 01:25:54.853354+00:00. externally triggered: False> successful
2026-02-25 09:26:19,854 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 01:25:50.457171+00:00, run_id=dataset_triggered__2026-02-25T01:25:50.457171+00:00, run_start_date=2026-02-25 01:25:54.865751+00:00, run_end_date=2026-02-25 01:26:19.854812+00:00, run_duration=24.989061, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 01:25:43.764450+00:00, data_interval_end=2026-02-25 01:25:43.764450+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 09:26:37,877 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:31:38,573 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:36:38,581 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:41:41,878 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:46:44,316 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:51:46,002 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 09:56:48,551 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:01:49,059 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:06:50,824 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:11:53,456 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:16:55,655 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:21:56,620 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:26:58,038 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:32:01,062 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:37:02,573 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:42:04,202 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:47:05,021 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:52:07,135 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 10:57:09,668 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:02:11,934 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:07:12,860 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:07:38,029 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:07:34.728947+00:00 [scheduled]>
2026-02-25 11:07:38,030 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:07:38,031 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:07:34.728947+00:00 [scheduled]>
2026-02-25 11:07:38,034 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:07:34.728947+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:07:38,035 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:07:34.728947+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:07:38,036 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:07:34.728947+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:07:38,039 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:07:34.728947+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:07:43,206 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:07:34.728947+00:00', try_number=1, map_index=-1)
2026-02-25 11:07:43,216 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:07:34.728947+00:00, map_index=-1, run_start_date=2026-02-25 03:07:41.944928+00:00, run_end_date=2026-02-25 03:07:42.449445+00:00, run_duration=0.504517, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=347, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:07:38.032902+00:00, queued_by_job_id=340, pid=6127
2026-02-25 11:07:46,650 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:07:34.728947+00:00: manual__2026-02-25T03:07:34.728947+00:00, state:running, queued_at: 2026-02-25 03:07:34.748821+00:00. externally triggered: True> successful
2026-02-25 11:07:46,651 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:07:34.728947+00:00, run_id=manual__2026-02-25T03:07:34.728947+00:00, run_start_date=2026-02-25 03:07:38.004296+00:00, run_end_date=2026-02-25 03:07:46.651867+00:00, run_duration=8.647571, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:07:34.728947+00:00, data_interval_end=2026-02-25 03:07:34.728947+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:07:46,663 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:07:42.467888+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:07:42.469399+00:00 [scheduled]>
2026-02-25 11:07:46,664 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:07:46,665 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:07:46,666 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:07:42.467888+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:07:42.469399+00:00 [scheduled]>
2026-02-25 11:07:46,669 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:07:42.467888+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:07:42.469399+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:07:46,670 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:07:42.467888+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:07:46,671 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:07:42.467888+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:07:46,672 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:07:42.469399+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:07:46,672 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:07:42.469399+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:07:46,675 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:07:42.467888+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:08:00,692 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:07:42.469399+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:08:10,923 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:07:42.467888+00:00', try_number=1, map_index=-1)
2026-02-25 11:08:10,927 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:07:42.469399+00:00', try_number=1, map_index=-1)
2026-02-25 11:08:10,938 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:07:42.469399+00:00, map_index=-1, run_start_date=2026-02-25 03:08:04.885747+00:00, run_end_date=2026-02-25 03:08:10.196140+00:00, run_duration=5.310393, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=349, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:07:46.667792+00:00, queued_by_job_id=340, pid=6167
2026-02-25 11:08:10,939 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:07:42.467888+00:00, map_index=-1, run_start_date=2026-02-25 03:07:50.702051+00:00, run_end_date=2026-02-25 03:07:59.938761+00:00, run_duration=9.23671, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=348, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:07:46.667792+00:00, queued_by_job_id=340, pid=6136
2026-02-25 11:08:14,307 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:07:42.467888+00:00: dataset_triggered__2026-02-25T03:07:42.467888+00:00, state:running, queued_at: 2026-02-25 03:07:46.609861+00:00. externally triggered: False> successful
2026-02-25 11:08:14,308 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:07:42.467888+00:00, run_id=dataset_triggered__2026-02-25T03:07:42.467888+00:00, run_start_date=2026-02-25 03:07:46.632375+00:00, run_end_date=2026-02-25 03:08:14.308557+00:00, run_duration=27.676182, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:07:34.728947+00:00, data_interval_end=2026-02-25 03:07:34.728947+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:08:14,313 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:07:42.469399+00:00: dataset_triggered__2026-02-25T03:07:42.469399+00:00, state:running, queued_at: 2026-02-25 03:07:46.621234+00:00. externally triggered: False> successful
2026-02-25 11:08:14,315 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:07:42.469399+00:00, run_id=dataset_triggered__2026-02-25T03:07:42.469399+00:00, run_start_date=2026-02-25 03:07:46.632474+00:00, run_end_date=2026-02-25 03:08:14.314959+00:00, run_duration=27.682485, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:07:34.728947+00:00, data_interval_end=2026-02-25 03:07:34.728947+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:10:40,110 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:10:39.916905+00:00 [scheduled]>
2026-02-25 11:10:40,111 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:10:40,112 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:10:39.916905+00:00 [scheduled]>
2026-02-25 11:10:40,114 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:10:39.916905+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:10:40,116 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:10:39.916905+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:10:40,116 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:10:39.916905+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:10:40,119 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:10:39.916905+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:10:45,525 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:10:39.916905+00:00', try_number=1, map_index=-1)
2026-02-25 11:10:45,533 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:10:39.916905+00:00, map_index=-1, run_start_date=2026-02-25 03:10:44.316756+00:00, run_end_date=2026-02-25 03:10:44.782850+00:00, run_duration=0.466094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=350, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:10:40.113753+00:00, queued_by_job_id=340, pid=6280
2026-02-25 11:10:48,314 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:10:39.916905+00:00: manual__2026-02-25T03:10:39.916905+00:00, state:running, queued_at: 2026-02-25 03:10:39.930048+00:00. externally triggered: True> successful
2026-02-25 11:10:48,315 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:10:39.916905+00:00, run_id=manual__2026-02-25T03:10:39.916905+00:00, run_start_date=2026-02-25 03:10:40.085485+00:00, run_end_date=2026-02-25 03:10:48.315620+00:00, run_duration=8.230135, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:10:39.916905+00:00, data_interval_end=2026-02-25 03:10:39.916905+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:10:48,325 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:10:44.800451+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:10:44.801967+00:00 [scheduled]>
2026-02-25 11:10:48,326 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:10:48,327 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:10:48,328 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:10:44.800451+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:10:44.801967+00:00 [scheduled]>
2026-02-25 11:10:48,330 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:10:44.800451+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:10:44.801967+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:10:48,331 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:10:44.800451+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:10:48,332 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:10:44.800451+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:10:48,333 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:10:44.801967+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:10:48,333 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:10:44.801967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:10:48,336 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:10:44.800451+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:11:02,761 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:10:44.801967+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:11:13,875 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:10:44.800451+00:00', try_number=1, map_index=-1)
2026-02-25 11:11:13,877 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:10:44.801967+00:00', try_number=1, map_index=-1)
2026-02-25 11:11:13,886 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:10:44.801967+00:00, map_index=-1, run_start_date=2026-02-25 03:11:07.293195+00:00, run_end_date=2026-02-25 03:11:13.153313+00:00, run_duration=5.860118, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=352, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:10:48.329251+00:00, queued_by_job_id=340, pid=6308
2026-02-25 11:11:13,887 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:10:44.800451+00:00, map_index=-1, run_start_date=2026-02-25 03:10:52.030643+00:00, run_end_date=2026-02-25 03:11:01.809133+00:00, run_duration=9.77849, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=351, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:10:48.329251+00:00, queued_by_job_id=340, pid=6284
2026-02-25 11:11:16,816 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:10:44.800451+00:00: dataset_triggered__2026-02-25T03:10:44.800451+00:00, state:running, queued_at: 2026-02-25 03:10:48.285576+00:00. externally triggered: False> successful
2026-02-25 11:11:16,818 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:10:44.800451+00:00, run_id=dataset_triggered__2026-02-25T03:10:44.800451+00:00, run_start_date=2026-02-25 03:10:48.298002+00:00, run_end_date=2026-02-25 03:11:16.818094+00:00, run_duration=28.520092, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:10:39.916905+00:00, data_interval_end=2026-02-25 03:10:39.916905+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:11:16,823 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:10:44.801967+00:00: dataset_triggered__2026-02-25T03:10:44.801967+00:00, state:running, queued_at: 2026-02-25 03:10:48.276034+00:00. externally triggered: False> successful
2026-02-25 11:11:16,824 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:10:44.801967+00:00, run_id=dataset_triggered__2026-02-25T03:10:44.801967+00:00, run_start_date=2026-02-25 03:10:48.298117+00:00, run_end_date=2026-02-25 03:11:16.824602+00:00, run_duration=28.526485, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:10:39.916905+00:00, data_interval_end=2026-02-25 03:10:39.916905+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:12:15,081 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:14:51,790 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:14:48.801353+00:00 [scheduled]>
2026-02-25 11:14:51,791 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:14:51,791 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:14:48.801353+00:00 [scheduled]>
2026-02-25 11:14:51,793 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:14:48.801353+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:14:51,794 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:14:48.801353+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:14:51,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:14:48.801353+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:14:51,798 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:14:48.801353+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:14:56,672 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:14:48.801353+00:00', try_number=1, map_index=-1)
2026-02-25 11:14:56,683 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:14:48.801353+00:00, map_index=-1, run_start_date=2026-02-25 03:14:55.522804+00:00, run_end_date=2026-02-25 03:14:56.030288+00:00, run_duration=0.507484, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=353, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:14:51.792727+00:00, queued_by_job_id=340, pid=6432
2026-02-25 11:15:01,089 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:14:48.801353+00:00: manual__2026-02-25T03:14:48.801353+00:00, state:running, queued_at: 2026-02-25 03:14:48.823204+00:00. externally triggered: True> successful
2026-02-25 11:15:01,091 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:14:48.801353+00:00, run_id=manual__2026-02-25T03:14:48.801353+00:00, run_start_date=2026-02-25 03:14:51.768314+00:00, run_end_date=2026-02-25 03:15:01.091443+00:00, run_duration=9.323129, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:14:48.801353+00:00, data_interval_end=2026-02-25 03:14:48.801353+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:15:01,110 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:14:56.048887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:14:56.051599+00:00 [scheduled]>
2026-02-25 11:15:01,111 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:15:01,112 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:15:01,113 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:14:56.048887+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:14:56.051599+00:00 [scheduled]>
2026-02-25 11:15:01,117 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:14:56.048887+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:14:56.051599+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:15:01,119 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:14:56.048887+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:15:01,121 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:14:56.048887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:15:01,123 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:14:56.051599+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:15:01,124 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:14:56.051599+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:15:01,128 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:14:56.048887+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:15:12,890 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:14:56.051599+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:15:25,583 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:14:56.048887+00:00', try_number=1, map_index=-1)
2026-02-25 11:15:25,585 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:14:56.051599+00:00', try_number=1, map_index=-1)
2026-02-25 11:15:25,598 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:14:56.048887+00:00, map_index=-1, run_start_date=2026-02-25 03:15:05.275409+00:00, run_end_date=2026-02-25 03:15:12.028191+00:00, run_duration=6.752782, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=354, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:15:01.115810+00:00, queued_by_job_id=340, pid=6438
2026-02-25 11:15:25,600 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:14:56.051599+00:00, map_index=-1, run_start_date=2026-02-25 03:15:17.009581+00:00, run_end_date=2026-02-25 03:15:24.866876+00:00, run_duration=7.857295, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=355, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:15:01.115810+00:00, queued_by_job_id=340, pid=6452
2026-02-25 11:15:28,324 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:14:56.048887+00:00: dataset_triggered__2026-02-25T03:14:56.048887+00:00, state:running, queued_at: 2026-02-25 03:15:01.026212+00:00. externally triggered: False> successful
2026-02-25 11:15:28,325 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:14:56.048887+00:00, run_id=dataset_triggered__2026-02-25T03:14:56.048887+00:00, run_start_date=2026-02-25 03:15:01.057165+00:00, run_end_date=2026-02-25 03:15:28.325727+00:00, run_duration=27.268562, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:14:48.801353+00:00, data_interval_end=2026-02-25 03:14:48.801353+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:15:28,331 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:14:56.051599+00:00: dataset_triggered__2026-02-25T03:14:56.051599+00:00, state:running, queued_at: 2026-02-25 03:15:01.038549+00:00. externally triggered: False> successful
2026-02-25 11:15:28,332 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:14:56.051599+00:00, run_id=dataset_triggered__2026-02-25T03:14:56.051599+00:00, run_start_date=2026-02-25 03:15:01.057294+00:00, run_end_date=2026-02-25 03:15:28.332381+00:00, run_duration=27.275087, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:14:48.801353+00:00, data_interval_end=2026-02-25 03:14:48.801353+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:17:19,308 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:20:41,010 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:20:37.356853+00:00 [scheduled]>
2026-02-25 11:20:41,011 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:20:41,012 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:20:37.356853+00:00 [scheduled]>
2026-02-25 11:20:41,014 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:20:37.356853+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:20:41,016 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:20:37.356853+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:20:41,016 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:20:37.356853+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:20:41,019 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:20:37.356853+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:20:46,821 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:20:37.356853+00:00', try_number=1, map_index=-1)
2026-02-25 11:20:46,837 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:20:37.356853+00:00, map_index=-1, run_start_date=2026-02-25 03:20:45.361879+00:00, run_end_date=2026-02-25 03:20:46.095836+00:00, run_duration=0.733957, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=356, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:20:41.013702+00:00, queued_by_job_id=340, pid=6673
2026-02-25 11:20:49,796 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:20:37.356853+00:00: manual__2026-02-25T03:20:37.356853+00:00, state:running, queued_at: 2026-02-25 03:20:37.380706+00:00. externally triggered: True> successful
2026-02-25 11:20:49,798 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:20:37.356853+00:00, run_id=manual__2026-02-25T03:20:37.356853+00:00, run_start_date=2026-02-25 03:20:40.977948+00:00, run_end_date=2026-02-25 03:20:49.797934+00:00, run_duration=8.819986, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:20:37.356853+00:00, data_interval_end=2026-02-25 03:20:37.356853+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:20:49,809 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:20:46.124517+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:20:46.128384+00:00 [scheduled]>
2026-02-25 11:20:49,810 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:20:49,810 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:20:49,812 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:20:46.124517+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:20:46.128384+00:00 [scheduled]>
2026-02-25 11:20:49,815 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:20:46.124517+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:20:46.128384+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:20:49,816 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:20:46.124517+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:20:49,817 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:20:46.124517+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:20:49,817 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:20:46.128384+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:20:49,818 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:20:46.128384+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:20:49,821 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:20:46.124517+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:21:03,565 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:20:46.128384+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:21:13,144 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:20:46.124517+00:00', try_number=1, map_index=-1)
2026-02-25 11:21:13,147 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:20:46.128384+00:00', try_number=1, map_index=-1)
2026-02-25 11:21:13,159 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:20:46.128384+00:00, map_index=-1, run_start_date=2026-02-25 03:21:07.270001+00:00, run_end_date=2026-02-25 03:21:12.447695+00:00, run_duration=5.177694, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=358, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:20:49.813875+00:00, queued_by_job_id=340, pid=6702
2026-02-25 11:21:13,162 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:20:46.124517+00:00, map_index=-1, run_start_date=2026-02-25 03:20:53.742434+00:00, run_end_date=2026-02-25 03:21:02.793104+00:00, run_duration=9.05067, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=357, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:20:49.813875+00:00, queued_by_job_id=340, pid=6676
2026-02-25 11:21:16,123 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:20:46.124517+00:00: dataset_triggered__2026-02-25T03:20:46.124517+00:00, state:running, queued_at: 2026-02-25 03:20:49.755793+00:00. externally triggered: False> successful
2026-02-25 11:21:16,124 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:20:46.124517+00:00, run_id=dataset_triggered__2026-02-25T03:20:46.124517+00:00, run_start_date=2026-02-25 03:20:49.777783+00:00, run_end_date=2026-02-25 03:21:16.124325+00:00, run_duration=26.346542, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:20:37.356853+00:00, data_interval_end=2026-02-25 03:20:37.356853+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:21:16,130 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:20:46.128384+00:00: dataset_triggered__2026-02-25T03:20:46.128384+00:00, state:running, queued_at: 2026-02-25 03:20:49.765664+00:00. externally triggered: False> successful
2026-02-25 11:21:16,131 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:20:46.128384+00:00, run_id=dataset_triggered__2026-02-25T03:20:46.128384+00:00, run_start_date=2026-02-25 03:20:49.777931+00:00, run_end_date=2026-02-25 03:21:16.131091+00:00, run_duration=26.35316, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:20:37.356853+00:00, data_interval_end=2026-02-25 03:20:37.356853+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:22:03,887 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:22:00.163492+00:00 [scheduled]>
2026-02-25 11:22:03,889 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:22:03,889 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:22:00.163492+00:00 [scheduled]>
2026-02-25 11:22:03,892 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:22:00.163492+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:22:03,892 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:22:00.163492+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:22:03,893 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:22:00.163492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:22:03,896 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:22:00.163492+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:22:09,630 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:22:00.163492+00:00', try_number=1, map_index=-1)
2026-02-25 11:22:09,639 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:22:00.163492+00:00, map_index=-1, run_start_date=2026-02-25 03:22:08.343219+00:00, run_end_date=2026-02-25 03:22:08.852087+00:00, run_duration=0.508868, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=359, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:22:03.890844+00:00, queued_by_job_id=340, pid=6740
2026-02-25 11:22:12,300 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:22:00.163492+00:00: manual__2026-02-25T03:22:00.163492+00:00, state:running, queued_at: 2026-02-25 03:22:00.181593+00:00. externally triggered: True> successful
2026-02-25 11:22:12,301 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:22:00.163492+00:00, run_id=manual__2026-02-25T03:22:00.163492+00:00, run_start_date=2026-02-25 03:22:03.866961+00:00, run_end_date=2026-02-25 03:22:12.301202+00:00, run_duration=8.434241, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:22:00.163492+00:00, data_interval_end=2026-02-25 03:22:00.163492+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:22:12,311 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:22:08.871256+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:22:08.872657+00:00 [scheduled]>
2026-02-25 11:22:12,312 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:22:12,313 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:22:12,313 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:22:08.871256+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:22:08.872657+00:00 [scheduled]>
2026-02-25 11:22:12,316 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:22:08.871256+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:22:08.872657+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:22:12,318 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:22:08.871256+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:22:12,318 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:22:08.871256+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:22:12,319 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:22:08.872657+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:22:12,320 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:22:08.872657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:22:12,322 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:22:08.871256+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:22:23,799 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:22:08.872657+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:22:33,466 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:22:08.871256+00:00', try_number=1, map_index=-1)
2026-02-25 11:22:33,470 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:22:08.872657+00:00', try_number=1, map_index=-1)
2026-02-25 11:22:33,479 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:22:08.872657+00:00, map_index=-1, run_start_date=2026-02-25 03:22:27.685576+00:00, run_end_date=2026-02-25 03:22:32.768850+00:00, run_duration=5.083274, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=361, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:22:12.315382+00:00, queued_by_job_id=340, pid=6764
2026-02-25 11:22:33,480 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:22:08.871256+00:00, map_index=-1, run_start_date=2026-02-25 03:22:15.942734+00:00, run_end_date=2026-02-25 03:22:23.073454+00:00, run_duration=7.13072, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=360, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:22:12.315382+00:00, queued_by_job_id=340, pid=6743
2026-02-25 11:22:33,514 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:22:36,509 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:22:08.871256+00:00: dataset_triggered__2026-02-25T03:22:08.871256+00:00, state:running, queued_at: 2026-02-25 03:22:12.270831+00:00. externally triggered: False> successful
2026-02-25 11:22:36,510 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:22:08.871256+00:00, run_id=dataset_triggered__2026-02-25T03:22:08.871256+00:00, run_start_date=2026-02-25 03:22:12.283418+00:00, run_end_date=2026-02-25 03:22:36.510567+00:00, run_duration=24.227149, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:22:00.163492+00:00, data_interval_end=2026-02-25 03:22:00.163492+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:22:36,517 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:22:08.872657+00:00: dataset_triggered__2026-02-25T03:22:08.872657+00:00, state:running, queued_at: 2026-02-25 03:22:12.261248+00:00. externally triggered: False> successful
2026-02-25 11:22:36,518 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:22:08.872657+00:00, run_id=dataset_triggered__2026-02-25T03:22:08.872657+00:00, run_start_date=2026-02-25 03:22:12.283522+00:00, run_end_date=2026-02-25 03:22:36.518534+00:00, run_duration=24.235012, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:22:00.163492+00:00, data_interval_end=2026-02-25 03:22:00.163492+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:26:11,274 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:26:09.850421+00:00 [scheduled]>
2026-02-25 11:26:11,275 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:26:11,276 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:26:09.850421+00:00 [scheduled]>
2026-02-25 11:26:11,279 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:26:09.850421+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:26:11,280 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:26:09.850421+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:26:11,281 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:26:09.850421+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:26:11,284 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:26:09.850421+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:26:17,478 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:26:09.850421+00:00', try_number=1, map_index=-1)
2026-02-25 11:26:17,495 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:26:09.850421+00:00, map_index=-1, run_start_date=2026-02-25 03:26:16.001177+00:00, run_end_date=2026-02-25 03:26:16.524172+00:00, run_duration=0.522995, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=362, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:26:11.278018+00:00, queued_by_job_id=340, pid=6940
2026-02-25 11:26:20,858 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:26:09.850421+00:00: manual__2026-02-25T03:26:09.850421+00:00, state:running, queued_at: 2026-02-25 03:26:09.862864+00:00. externally triggered: True> successful
2026-02-25 11:26:20,859 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:26:09.850421+00:00, run_id=manual__2026-02-25T03:26:09.850421+00:00, run_start_date=2026-02-25 03:26:11.253916+00:00, run_end_date=2026-02-25 03:26:20.859703+00:00, run_duration=9.605787, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:26:09.850421+00:00, data_interval_end=2026-02-25 03:26:09.850421+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:26:20,870 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:26:16.544495+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:26:16.546239+00:00 [scheduled]>
2026-02-25 11:26:20,871 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:26:20,871 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:26:20,872 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:26:16.544495+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:26:16.546239+00:00 [scheduled]>
2026-02-25 11:26:20,875 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:26:16.544495+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:26:16.546239+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:26:20,876 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:26:16.544495+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:26:20,877 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:26:16.544495+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:26:20,878 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:26:16.546239+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:26:20,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:26:16.546239+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:26:20,882 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:26:16.544495+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:26:33,409 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:26:16.546239+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:26:47,080 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:26:16.544495+00:00', try_number=1, map_index=-1)
2026-02-25 11:26:47,083 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:26:16.546239+00:00', try_number=1, map_index=-1)
2026-02-25 11:26:47,095 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:26:16.544495+00:00, map_index=-1, run_start_date=2026-02-25 03:26:25.313998+00:00, run_end_date=2026-02-25 03:26:32.500993+00:00, run_duration=7.186995, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=363, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:26:20.873822+00:00, queued_by_job_id=340, pid=6943
2026-02-25 11:26:47,097 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:26:16.546239+00:00, map_index=-1, run_start_date=2026-02-25 03:26:37.829846+00:00, run_end_date=2026-02-25 03:26:46.134546+00:00, run_duration=8.3047, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=364, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:26:20.873822+00:00, queued_by_job_id=340, pid=6957
2026-02-25 11:26:50,576 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:26:16.544495+00:00: dataset_triggered__2026-02-25T03:26:16.544495+00:00, state:running, queued_at: 2026-02-25 03:26:20.828761+00:00. externally triggered: False> successful
2026-02-25 11:26:50,577 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:26:16.544495+00:00, run_id=dataset_triggered__2026-02-25T03:26:16.544495+00:00, run_start_date=2026-02-25 03:26:20.840013+00:00, run_end_date=2026-02-25 03:26:50.577235+00:00, run_duration=29.737222, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:26:09.850421+00:00, data_interval_end=2026-02-25 03:26:09.850421+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:26:50,581 ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:26:16.546239+00:00: dataset_triggered__2026-02-25T03:26:16.546239+00:00, state:running, queued_at: 2026-02-25 03:26:20.819568+00:00. externally triggered: False> failed
2026-02-25 11:26:50,582 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:26:16.546239+00:00, run_id=dataset_triggered__2026-02-25T03:26:16.546239+00:00, run_start_date=2026-02-25 03:26:20.840120+00:00, run_end_date=2026-02-25 03:26:50.582656+00:00, run_duration=29.742536, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:26:09.850421+00:00, data_interval_end=2026-02-25 03:26:09.850421+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:27:26,545 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:27:24.112471+00:00 [scheduled]>
2026-02-25 11:27:26,546 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:27:26,547 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:27:24.112471+00:00 [scheduled]>
2026-02-25 11:27:26,549 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:27:24.112471+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:27:26,551 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:27:24.112471+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:27:26,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:27:24.112471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:27:26,554 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:27:24.112471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:27:31,347 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:27:24.112471+00:00', try_number=1, map_index=-1)
2026-02-25 11:27:31,356 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:27:24.112471+00:00, map_index=-1, run_start_date=2026-02-25 03:27:30.182772+00:00, run_end_date=2026-02-25 03:27:30.668907+00:00, run_duration=0.486135, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=365, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:27:26.548550+00:00, queued_by_job_id=340, pid=7008
2026-02-25 11:27:34,316 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:27:24.112471+00:00: manual__2026-02-25T03:27:24.112471+00:00, state:running, queued_at: 2026-02-25 03:27:24.128029+00:00. externally triggered: True> successful
2026-02-25 11:27:34,317 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:27:24.112471+00:00, run_id=manual__2026-02-25T03:27:24.112471+00:00, run_start_date=2026-02-25 03:27:26.524056+00:00, run_end_date=2026-02-25 03:27:34.317822+00:00, run_duration=7.793766, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:27:24.112471+00:00, data_interval_end=2026-02-25 03:27:24.112471+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:27:34,328 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:27:30.687416+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:27:30.688841+00:00 [scheduled]>
2026-02-25 11:27:34,329 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:27:34,330 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:27:34,331 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:27:30.687416+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:27:30.688841+00:00 [scheduled]>
2026-02-25 11:27:34,333 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:27:30.687416+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:27:30.688841+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:27:34,334 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:27:30.687416+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:27:34,335 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:27:30.687416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:27:34,336 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:27:30.688841+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:27:34,337 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:27:30.688841+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:27:34,340 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:27:30.687416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:27:44,500 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:27:30.688841+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:27:57,628 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:27:30.687416+00:00', try_number=1, map_index=-1)
2026-02-25 11:27:57,633 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:27:30.688841+00:00', try_number=1, map_index=-1)
2026-02-25 11:27:57,656 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:27:30.687416+00:00, map_index=-1, run_start_date=2026-02-25 03:27:38.438131+00:00, run_end_date=2026-02-25 03:27:43.793043+00:00, run_duration=5.354912, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=366, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:27:34.332376+00:00, queued_by_job_id=340, pid=7020
2026-02-25 11:27:57,659 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:27:30.688841+00:00, map_index=-1, run_start_date=2026-02-25 03:27:49.199191+00:00, run_end_date=2026-02-25 03:27:56.922496+00:00, run_duration=7.723305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=367, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:27:34.332376+00:00, queued_by_job_id=340, pid=7035
2026-02-25 11:27:57,687 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:28:01,296 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:27:30.687416+00:00: dataset_triggered__2026-02-25T03:27:30.687416+00:00, state:running, queued_at: 2026-02-25 03:27:34.285772+00:00. externally triggered: False> successful
2026-02-25 11:28:01,298 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:27:30.687416+00:00, run_id=dataset_triggered__2026-02-25T03:27:30.687416+00:00, run_start_date=2026-02-25 03:27:34.298863+00:00, run_end_date=2026-02-25 03:28:01.297779+00:00, run_duration=26.998916, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:27:24.112471+00:00, data_interval_end=2026-02-25 03:27:24.112471+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:28:01,304 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:27:30.688841+00:00: dataset_triggered__2026-02-25T03:27:30.688841+00:00, state:running, queued_at: 2026-02-25 03:27:34.270908+00:00. externally triggered: False> successful
2026-02-25 11:28:01,305 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:27:30.688841+00:00, run_id=dataset_triggered__2026-02-25T03:27:30.688841+00:00, run_start_date=2026-02-25 03:27:34.298965+00:00, run_end_date=2026-02-25 03:28:01.305152+00:00, run_duration=27.006187, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:27:24.112471+00:00, data_interval_end=2026-02-25 03:27:24.112471+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:32:57,985 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:34:03,438 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:33:58.872489+00:00 [scheduled]>
2026-02-25 11:34:03,439 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:34:03,440 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:33:58.872489+00:00 [scheduled]>
2026-02-25 11:34:03,444 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:33:58.872489+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:34:03,446 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:33:58.872489+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:34:03,447 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:33:58.872489+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:34:03,452 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:33:58.872489+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:34:09,957 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:33:58.872489+00:00', try_number=1, map_index=-1)
2026-02-25 11:34:09,968 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:33:58.872489+00:00, map_index=-1, run_start_date=2026-02-25 03:34:08.837032+00:00, run_end_date=2026-02-25 03:34:09.098897+00:00, run_duration=0.261865, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=368, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:34:03.442608+00:00, queued_by_job_id=340, pid=7335
2026-02-25 11:34:14,068 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:33:58.872489+00:00: manual__2026-02-25T03:33:58.872489+00:00, state:running, queued_at: 2026-02-25 03:33:58.887058+00:00. externally triggered: True> successful
2026-02-25 11:34:14,069 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:33:58.872489+00:00, run_id=manual__2026-02-25T03:33:58.872489+00:00, run_start_date=2026-02-25 03:34:03.410775+00:00, run_end_date=2026-02-25 03:34:14.069862+00:00, run_duration=10.659087, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:33:58.872489+00:00, data_interval_end=2026-02-25 03:33:58.872489+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:34:14,086 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:34:09.176444+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:34:09.182989+00:00 [scheduled]>
2026-02-25 11:34:14,087 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:34:14,088 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:34:14,088 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:34:09.176444+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:34:09.182989+00:00 [scheduled]>
2026-02-25 11:34:14,091 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:34:09.176444+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:34:09.182989+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:34:14,092 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:34:09.176444+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:34:14,093 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:34:09.176444+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:34:14,094 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:34:09.182989+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:34:14,096 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:34:09.182989+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:34:14,098 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:34:09.176444+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:34:24,672 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:34:09.182989+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:34:36,390 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:34:09.176444+00:00', try_number=1, map_index=-1)
2026-02-25 11:34:36,394 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:34:09.182989+00:00', try_number=1, map_index=-1)
2026-02-25 11:34:36,403 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:34:09.176444+00:00, map_index=-1, run_start_date=2026-02-25 03:34:17.892178+00:00, run_end_date=2026-02-25 03:34:23.964117+00:00, run_duration=6.071939, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=369, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:34:14.090063+00:00, queued_by_job_id=340, pid=7345
2026-02-25 11:34:36,404 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:34:09.182989+00:00, map_index=-1, run_start_date=2026-02-25 03:34:28.629040+00:00, run_end_date=2026-02-25 03:34:35.673743+00:00, run_duration=7.044703, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=370, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:34:14.090063+00:00, queued_by_job_id=340, pid=7359
2026-02-25 11:34:39,869 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:34:09.176444+00:00: dataset_triggered__2026-02-25T03:34:09.176444+00:00, state:running, queued_at: 2026-02-25 03:34:14.028689+00:00. externally triggered: False> successful
2026-02-25 11:34:39,870 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:34:09.176444+00:00, run_id=dataset_triggered__2026-02-25T03:34:09.176444+00:00, run_start_date=2026-02-25 03:34:14.050993+00:00, run_end_date=2026-02-25 03:34:39.870861+00:00, run_duration=25.819868, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:33:58.872489+00:00, data_interval_end=2026-02-25 03:33:58.872489+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:34:39,875 ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:34:09.182989+00:00: dataset_triggered__2026-02-25T03:34:09.182989+00:00, state:running, queued_at: 2026-02-25 03:34:14.039068+00:00. externally triggered: False> failed
2026-02-25 11:34:39,876 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:34:09.182989+00:00, run_id=dataset_triggered__2026-02-25T03:34:09.182989+00:00, run_start_date=2026-02-25 03:34:14.051223+00:00, run_end_date=2026-02-25 03:34:39.876310+00:00, run_duration=25.825087, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:33:58.872489+00:00, data_interval_end=2026-02-25 03:33:58.872489+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:36:11,600 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:36:10.000295+00:00 [scheduled]>
2026-02-25 11:36:11,601 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 11:36:11,602 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:36:10.000295+00:00 [scheduled]>
2026-02-25 11:36:11,604 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T03:36:10.000295+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:36:11,605 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:36:10.000295+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:36:11,606 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:36:10.000295+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:36:11,608 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T03:36:10.000295+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:36:16,613 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T03:36:10.000295+00:00', try_number=1, map_index=-1)
2026-02-25 11:36:16,622 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T03:36:10.000295+00:00, map_index=-1, run_start_date=2026-02-25 03:36:15.699537+00:00, run_end_date=2026-02-25 03:36:15.908250+00:00, run_duration=0.208713, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=371, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:36:11.603347+00:00, queued_by_job_id=340, pid=7441
2026-02-25 11:36:20,846 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 03:36:10.000295+00:00: manual__2026-02-25T03:36:10.000295+00:00, state:running, queued_at: 2026-02-25 03:36:10.016365+00:00. externally triggered: True> successful
2026-02-25 11:36:20,847 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 03:36:10.000295+00:00, run_id=manual__2026-02-25T03:36:10.000295+00:00, run_start_date=2026-02-25 03:36:11.578105+00:00, run_end_date=2026-02-25 03:36:20.847711+00:00, run_duration=9.269606, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 03:36:10.000295+00:00, data_interval_end=2026-02-25 03:36:10.000295+00:00, dag_hash=359e757eb08a4ab3d2f7513b0c66adcf
2026-02-25 11:36:20,857 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:36:15.925389+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:36:15.926751+00:00 [scheduled]>
2026-02-25 11:36:20,858 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 11:36:20,859 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 11:36:20,859 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:36:15.925389+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:36:15.926751+00:00 [scheduled]>
2026-02-25 11:36:20,862 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T03:36:15.925389+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T03:36:15.926751+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 11:36:20,863 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:36:15.925389+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:36:20,864 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:36:15.925389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:36:20,864 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:36:15.926751+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 11:36:20,865 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:36:15.926751+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:36:20,868 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T03:36:15.925389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:36:34,420 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T03:36:15.926751+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 11:36:44,130 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T03:36:15.925389+00:00', try_number=1, map_index=-1)
2026-02-25 11:36:44,133 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T03:36:15.926751+00:00', try_number=1, map_index=-1)
2026-02-25 11:36:44,142 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T03:36:15.926751+00:00, map_index=-1, run_start_date=2026-02-25 03:36:38.557973+00:00, run_end_date=2026-02-25 03:36:43.440008+00:00, run_duration=4.882035, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=373, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:36:20.860796+00:00, queued_by_job_id=340, pid=7487
2026-02-25 11:36:44,143 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T03:36:15.925389+00:00, map_index=-1, run_start_date=2026-02-25 03:36:24.625087+00:00, run_end_date=2026-02-25 03:36:33.150885+00:00, run_duration=8.525798, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=372, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 03:36:20.860796+00:00, queued_by_job_id=340, pid=7452
2026-02-25 11:36:47,485 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 03:36:15.925389+00:00: dataset_triggered__2026-02-25T03:36:15.925389+00:00, state:running, queued_at: 2026-02-25 03:36:20.817535+00:00. externally triggered: False> successful
2026-02-25 11:36:47,486 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 03:36:15.925389+00:00, run_id=dataset_triggered__2026-02-25T03:36:15.925389+00:00, run_start_date=2026-02-25 03:36:20.829430+00:00, run_end_date=2026-02-25 03:36:47.486219+00:00, run_duration=26.656789, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:36:10.000295+00:00, data_interval_end=2026-02-25 03:36:10.000295+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 11:36:47,492 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 03:36:15.926751+00:00: dataset_triggered__2026-02-25T03:36:15.926751+00:00, state:running, queued_at: 2026-02-25 03:36:20.809946+00:00. externally triggered: False> successful
2026-02-25 11:36:47,493 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 03:36:15.926751+00:00, run_id=dataset_triggered__2026-02-25T03:36:15.926751+00:00, run_start_date=2026-02-25 03:36:20.829536+00:00, run_end_date=2026-02-25 03:36:47.493270+00:00, run_duration=26.663734, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 03:36:10.000295+00:00, data_interval_end=2026-02-25 03:36:10.000295+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 11:37:58,883 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:43:00,997 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:48:03,396 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:53:06,722 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 11:58:06,987 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:03:09,765 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:08:13,208 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:13:13,295 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:17:38,020 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:17:34.239273+00:00 [scheduled]>
2026-02-25 12:17:38,023 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 12:17:38,024 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:17:34.239273+00:00 [scheduled]>
2026-02-25 12:17:38,026 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:17:34.239273+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:17:38,027 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:17:34.239273+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:17:38,028 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:17:34.239273+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:17:38,031 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:17:34.239273+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:17:43,822 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:17:34.239273+00:00', try_number=1, map_index=-1)
2026-02-25 12:17:43,834 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:17:34.239273+00:00, map_index=-1, run_start_date=2026-02-25 04:17:42.806076+00:00, run_end_date=2026-02-25 04:17:43.033202+00:00, run_duration=0.227126, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=374, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:17:38.025389+00:00, queued_by_job_id=340, pid=8828
2026-02-25 12:17:47,459 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:17:34.239273+00:00: manual__2026-02-25T04:17:34.239273+00:00, state:running, queued_at: 2026-02-25 04:17:34.264781+00:00. externally triggered: True> successful
2026-02-25 12:17:47,460 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:17:34.239273+00:00, run_id=manual__2026-02-25T04:17:34.239273+00:00, run_start_date=2026-02-25 04:17:37.999345+00:00, run_end_date=2026-02-25 04:17:47.460417+00:00, run_duration=9.461072, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:17:34.239273+00:00, data_interval_end=2026-02-25 04:17:34.239273+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 12:17:47,471 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:17:43.056324+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:17:43.058196+00:00 [scheduled]>
2026-02-25 12:17:47,472 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 12:17:47,473 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 12:17:47,473 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:17:43.056324+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:17:43.058196+00:00 [scheduled]>
2026-02-25 12:17:47,476 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:17:43.056324+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:17:43.058196+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:17:47,477 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:17:43.056324+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:17:47,478 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:17:43.056324+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:17:47,479 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:17:43.058196+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:17:47,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:17:43.058196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:17:47,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:17:43.056324+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:17:52,275 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:17:43.058196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:17:57,192 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:17:43.056324+00:00', try_number=1, map_index=-1)
2026-02-25 12:17:57,195 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:17:43.058196+00:00', try_number=1, map_index=-1)
2026-02-25 12:17:57,206 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:17:43.056324+00:00, map_index=-1, run_start_date=2026-02-25 04:17:51.331291+00:00, run_end_date=2026-02-25 04:17:51.561712+00:00, run_duration=0.230421, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=375, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:17:47.474807+00:00, queued_by_job_id=340, pid=8831
2026-02-25 12:17:57,207 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:17:43.058196+00:00, map_index=-1, run_start_date=2026-02-25 04:17:56.233040+00:00, run_end_date=2026-02-25 04:17:56.466871+00:00, run_duration=0.233831, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=376, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:17:47.474807+00:00, queued_by_job_id=340, pid=8833
2026-02-25 12:18:00,800 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:17:43.056324+00:00: dataset_triggered__2026-02-25T04:17:43.056324+00:00, state:running, queued_at: 2026-02-25 04:17:47.427183+00:00. externally triggered: False> successful
2026-02-25 12:18:00,801 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:17:43.056324+00:00, run_id=dataset_triggered__2026-02-25T04:17:43.056324+00:00, run_start_date=2026-02-25 04:17:47.441367+00:00, run_end_date=2026-02-25 04:18:00.801097+00:00, run_duration=13.35973, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:17:34.239273+00:00, data_interval_end=2026-02-25 04:17:34.239273+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 12:18:00,806 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:17:43.058196+00:00: dataset_triggered__2026-02-25T04:17:43.058196+00:00, state:running, queued_at: 2026-02-25 04:17:47.416909+00:00. externally triggered: False> successful
2026-02-25 12:18:00,807 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:17:43.058196+00:00, run_id=dataset_triggered__2026-02-25T04:17:43.058196+00:00, run_start_date=2026-02-25 04:17:47.441488+00:00, run_end_date=2026-02-25 04:18:00.807577+00:00, run_duration=13.366089, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:17:34.239273+00:00, data_interval_end=2026-02-25 04:17:34.239273+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 12:18:16,228 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:20:55,906 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:20:52.685960+00:00 [scheduled]>
2026-02-25 12:20:55,907 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 12:20:55,908 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:20:52.685960+00:00 [scheduled]>
2026-02-25 12:20:55,911 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:20:52.685960+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:20:55,912 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:20:52.685960+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:20:55,913 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:20:52.685960+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:20:55,915 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:20:52.685960+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:21:00,902 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:20:52.685960+00:00', try_number=1, map_index=-1)
2026-02-25 12:21:00,911 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:20:52.685960+00:00, map_index=-1, run_start_date=2026-02-25 04:20:59.977453+00:00, run_end_date=2026-02-25 04:21:00.190301+00:00, run_duration=0.212848, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=377, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:20:55.909843+00:00, queued_by_job_id=340, pid=8936
2026-02-25 12:21:03,567 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:20:52.685960+00:00: manual__2026-02-25T04:20:52.685960+00:00, state:running, queued_at: 2026-02-25 04:20:52.704806+00:00. externally triggered: True> successful
2026-02-25 12:21:03,568 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:20:52.685960+00:00, run_id=manual__2026-02-25T04:20:52.685960+00:00, run_start_date=2026-02-25 04:20:55.888785+00:00, run_end_date=2026-02-25 04:21:03.568843+00:00, run_duration=7.680058, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:20:52.685960+00:00, data_interval_end=2026-02-25 04:20:52.685960+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 12:21:03,579 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:21:00.208815+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:21:00.210341+00:00 [scheduled]>
2026-02-25 12:21:03,580 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 12:21:03,581 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 12:21:03,582 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:21:00.208815+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:21:00.210341+00:00 [scheduled]>
2026-02-25 12:21:03,585 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:21:00.208815+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:21:00.210341+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:21:03,586 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:21:00.208815+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:21:03,587 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:21:00.208815+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:21:03,587 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:21:00.210341+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:21:03,588 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:21:00.210341+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:21:03,591 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:21:00.208815+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:21:17,299 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:21:00.210341+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:21:27,278 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:21:00.208815+00:00', try_number=1, map_index=-1)
2026-02-25 12:21:27,280 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:21:00.210341+00:00', try_number=1, map_index=-1)
2026-02-25 12:21:27,288 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:21:00.210341+00:00, map_index=-1, run_start_date=2026-02-25 04:21:21.403258+00:00, run_end_date=2026-02-25 04:21:26.640914+00:00, run_duration=5.237656, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=379, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:21:03.583722+00:00, queued_by_job_id=340, pid=8970
2026-02-25 12:21:27,290 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:21:00.208815+00:00, map_index=-1, run_start_date=2026-02-25 04:21:07.789874+00:00, run_end_date=2026-02-25 04:21:16.549902+00:00, run_duration=8.760028, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=378, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:21:03.583722+00:00, queued_by_job_id=340, pid=8945
2026-02-25 12:21:30,173 ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:21:00.208815+00:00: dataset_triggered__2026-02-25T04:21:00.208815+00:00, state:running, queued_at: 2026-02-25 04:21:03.537491+00:00. externally triggered: False> failed
2026-02-25 12:21:30,174 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:21:00.208815+00:00, run_id=dataset_triggered__2026-02-25T04:21:00.208815+00:00, run_start_date=2026-02-25 04:21:03.550414+00:00, run_end_date=2026-02-25 04:21:30.174400+00:00, run_duration=26.623986, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:20:52.685960+00:00, data_interval_end=2026-02-25 04:20:52.685960+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 12:21:30,179 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:21:00.210341+00:00: dataset_triggered__2026-02-25T04:21:00.210341+00:00, state:running, queued_at: 2026-02-25 04:21:03.527933+00:00. externally triggered: False> successful
2026-02-25 12:21:30,180 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:21:00.210341+00:00, run_id=dataset_triggered__2026-02-25T04:21:00.210341+00:00, run_start_date=2026-02-25 04:21:03.550542+00:00, run_end_date=2026-02-25 04:21:30.180698+00:00, run_duration=26.630156, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:20:52.685960+00:00, data_interval_end=2026-02-25 04:20:52.685960+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 12:23:17,978 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:23:45,455 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:23:44.062963+00:00 [scheduled]>
2026-02-25 12:23:45,456 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 12:23:45,456 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:23:44.062963+00:00 [scheduled]>
2026-02-25 12:23:45,460 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:23:44.062963+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:23:45,461 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:23:44.062963+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:23:45,461 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:23:44.062963+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:23:45,463 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:23:44.062963+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:23:50,330 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:23:44.062963+00:00', try_number=1, map_index=-1)
2026-02-25 12:23:50,339 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:23:44.062963+00:00, map_index=-1, run_start_date=2026-02-25 04:23:49.379807+00:00, run_end_date=2026-02-25 04:23:49.578240+00:00, run_duration=0.198433, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=380, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:23:45.459114+00:00, queued_by_job_id=340, pid=9065
2026-02-25 12:23:54,230 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:23:44.062963+00:00: manual__2026-02-25T04:23:44.062963+00:00, state:running, queued_at: 2026-02-25 04:23:44.075441+00:00. externally triggered: True> successful
2026-02-25 12:23:54,231 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:23:44.062963+00:00, run_id=manual__2026-02-25T04:23:44.062963+00:00, run_start_date=2026-02-25 04:23:45.434783+00:00, run_end_date=2026-02-25 04:23:54.231727+00:00, run_duration=8.796944, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:23:44.062963+00:00, data_interval_end=2026-02-25 04:23:44.062963+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 12:23:54,241 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:23:49.597392+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:23:49.598752+00:00 [scheduled]>
2026-02-25 12:23:54,242 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 12:23:54,243 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 12:23:54,243 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:23:49.597392+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:23:49.598752+00:00 [scheduled]>
2026-02-25 12:23:54,246 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:23:49.597392+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:23:49.598752+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:23:54,247 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:23:49.597392+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:23:54,247 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:23:49.597392+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:23:54,248 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:23:49.598752+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:23:54,249 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:23:49.598752+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:23:54,252 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:23:49.597392+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:24:05,633 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:23:49.598752+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:24:15,596 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:23:49.597392+00:00', try_number=1, map_index=-1)
2026-02-25 12:24:15,598 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:23:49.598752+00:00', try_number=1, map_index=-1)
2026-02-25 12:24:15,608 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:23:49.598752+00:00, map_index=-1, run_start_date=2026-02-25 04:24:09.649692+00:00, run_end_date=2026-02-25 04:24:14.885375+00:00, run_duration=5.235683, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=382, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:23:54.244758+00:00, queued_by_job_id=340, pid=9092
2026-02-25 12:24:15,609 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:23:49.597392+00:00, map_index=-1, run_start_date=2026-02-25 04:23:58.043111+00:00, run_end_date=2026-02-25 04:24:04.931981+00:00, run_duration=6.88887, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=381, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:23:54.244758+00:00, queued_by_job_id=340, pid=9068
2026-02-25 12:24:18,215 ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:23:49.597392+00:00: dataset_triggered__2026-02-25T04:23:49.597392+00:00, state:running, queued_at: 2026-02-25 04:23:54.192303+00:00. externally triggered: False> failed
2026-02-25 12:24:18,216 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:23:49.597392+00:00, run_id=dataset_triggered__2026-02-25T04:23:49.597392+00:00, run_start_date=2026-02-25 04:23:54.213197+00:00, run_end_date=2026-02-25 04:24:18.216076+00:00, run_duration=24.002879, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:23:44.062963+00:00, data_interval_end=2026-02-25 04:23:44.062963+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 12:24:18,221 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:23:49.598752+00:00: dataset_triggered__2026-02-25T04:23:49.598752+00:00, state:running, queued_at: 2026-02-25 04:23:54.200981+00:00. externally triggered: False> successful
2026-02-25 12:24:18,223 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:23:49.598752+00:00, run_id=dataset_triggered__2026-02-25T04:23:49.598752+00:00, run_start_date=2026-02-25 04:23:54.213305+00:00, run_end_date=2026-02-25 04:24:18.223156+00:00, run_duration=24.009851, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:23:44.062963+00:00, data_interval_end=2026-02-25 04:23:44.062963+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 12:27:23,206 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:27:21.133814+00:00 [scheduled]>
2026-02-25 12:27:23,207 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 12:27:23,207 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:27:21.133814+00:00 [scheduled]>
2026-02-25 12:27:23,209 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T04:27:21.133814+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:27:23,210 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:27:21.133814+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:27:23,211 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:27:21.133814+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:27:23,214 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T04:27:21.133814+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:27:28,085 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T04:27:21.133814+00:00', try_number=1, map_index=-1)
2026-02-25 12:27:28,094 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T04:27:21.133814+00:00, map_index=-1, run_start_date=2026-02-25 04:27:27.153146+00:00, run_end_date=2026-02-25 04:27:27.351238+00:00, run_duration=0.198092, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=383, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:27:23.208780+00:00, queued_by_job_id=340, pid=9200
2026-02-25 12:27:30,771 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 04:27:21.133814+00:00: manual__2026-02-25T04:27:21.133814+00:00, state:running, queued_at: 2026-02-25 04:27:21.146615+00:00. externally triggered: True> successful
2026-02-25 12:27:30,772 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 04:27:21.133814+00:00, run_id=manual__2026-02-25T04:27:21.133814+00:00, run_start_date=2026-02-25 04:27:23.184864+00:00, run_end_date=2026-02-25 04:27:30.772671+00:00, run_duration=7.587807, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 04:27:21.133814+00:00, data_interval_end=2026-02-25 04:27:21.133814+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 12:27:30,781 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:27:27.369878+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:27:27.371258+00:00 [scheduled]>
2026-02-25 12:27:30,782 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 12:27:30,783 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 12:27:30,784 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:27:27.369878+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:27:27.371258+00:00 [scheduled]>
2026-02-25 12:27:30,787 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T04:27:27.369878+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T04:27:27.371258+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 12:27:30,788 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:27:27.369878+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:27:30,789 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:27:27.369878+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:27:30,789 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:27:27.371258+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 12:27:30,790 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:27:27.371258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:27:30,793 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T04:27:27.369878+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:27:40,493 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T04:27:27.371258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 12:27:52,008 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T04:27:27.369878+00:00', try_number=1, map_index=-1)
2026-02-25 12:27:52,010 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T04:27:27.371258+00:00', try_number=1, map_index=-1)
2026-02-25 12:27:52,020 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T04:27:27.369878+00:00, map_index=-1, run_start_date=2026-02-25 04:27:34.607613+00:00, run_end_date=2026-02-25 04:27:39.747657+00:00, run_duration=5.140044, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=384, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:27:30.785476+00:00, queued_by_job_id=340, pid=9203
2026-02-25 12:27:52,021 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T04:27:27.371258+00:00, map_index=-1, run_start_date=2026-02-25 04:27:44.432197+00:00, run_end_date=2026-02-25 04:27:51.282790+00:00, run_duration=6.850593, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=385, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 04:27:30.785476+00:00, queued_by_job_id=340, pid=9221
2026-02-25 12:27:54,915 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 04:27:27.369878+00:00: dataset_triggered__2026-02-25T04:27:27.369878+00:00, state:running, queued_at: 2026-02-25 04:27:30.740866+00:00. externally triggered: False> successful
2026-02-25 12:27:54,916 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 04:27:27.369878+00:00, run_id=dataset_triggered__2026-02-25T04:27:27.369878+00:00, run_start_date=2026-02-25 04:27:30.754186+00:00, run_end_date=2026-02-25 04:27:54.916594+00:00, run_duration=24.162408, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:27:21.133814+00:00, data_interval_end=2026-02-25 04:27:21.133814+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 12:27:54,922 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 04:27:27.371258+00:00: dataset_triggered__2026-02-25T04:27:27.371258+00:00, state:running, queued_at: 2026-02-25 04:27:30.731574+00:00. externally triggered: False> successful
2026-02-25 12:27:54,922 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 04:27:27.371258+00:00, run_id=dataset_triggered__2026-02-25T04:27:27.371258+00:00, run_start_date=2026-02-25 04:27:30.754293+00:00, run_end_date=2026-02-25 04:27:54.922935+00:00, run_duration=24.168642, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 04:27:21.133814+00:00, data_interval_end=2026-02-25 04:27:21.133814+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 12:28:20,431 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:30:54,723 INFO - Heartbeat recovered after 36.60 seconds
2026-02-25 12:33:43,194 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:39:06,184 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:47:31,153 INFO - Heartbeat recovered after 269.29 seconds
2026-02-25 12:48:32,029 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 12:55:49,974 INFO - Heartbeat recovered after 237.89 seconds
2026-02-25 12:57:22,497 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:02:23,026 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:07:25,073 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:12:27,685 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:17:29,969 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:22:31,167 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:26:24,163 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:26:21.543429+00:00 [scheduled]>
2026-02-25 13:26:24,164 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 13:26:24,165 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:26:21.543429+00:00 [scheduled]>
2026-02-25 13:26:24,167 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:26:21.543429+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:26:24,169 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:26:21.543429+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:26:24,170 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:26:21.543429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:26:24,173 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:26:21.543429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:26:29,624 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:26:21.543429+00:00', try_number=1, map_index=-1)
2026-02-25 13:26:29,635 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:26:21.543429+00:00, map_index=-1, run_start_date=2026-02-25 05:26:28.626199+00:00, run_end_date=2026-02-25 05:26:28.862994+00:00, run_duration=0.236795, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=386, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:26:24.166533+00:00, queued_by_job_id=340, pid=11639
2026-02-25 13:26:33,621 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:26:21.543429+00:00: manual__2026-02-25T05:26:21.543429+00:00, state:running, queued_at: 2026-02-25 05:26:21.569156+00:00. externally triggered: True> successful
2026-02-25 13:26:33,622 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:26:21.543429+00:00, run_id=manual__2026-02-25T05:26:21.543429+00:00, run_start_date=2026-02-25 05:26:24.136338+00:00, run_end_date=2026-02-25 05:26:33.622495+00:00, run_duration=9.486157, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:26:21.543429+00:00, data_interval_end=2026-02-25 05:26:21.543429+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 13:26:33,633 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:26:28.886219+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:26:28.887851+00:00 [scheduled]>
2026-02-25 13:26:33,634 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 13:26:33,634 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 13:26:33,635 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:26:28.886219+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:26:28.887851+00:00 [scheduled]>
2026-02-25 13:26:33,638 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:26:28.886219+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:26:28.887851+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:26:33,639 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:26:28.886219+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:26:33,640 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:26:28.886219+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:26:33,641 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:26:28.887851+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:26:33,641 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:26:28.887851+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:26:33,644 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:26:28.886219+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:26:46,088 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:26:28.887851+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:26:58,097 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:26:28.886219+00:00', try_number=1, map_index=-1)
2026-02-25 13:26:58,100 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:26:28.887851+00:00', try_number=1, map_index=-1)
2026-02-25 13:26:58,110 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:26:28.886219+00:00, map_index=-1, run_start_date=2026-02-25 05:26:37.797963+00:00, run_end_date=2026-02-25 05:26:45.341653+00:00, run_duration=7.54369, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=387, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:26:33.636941+00:00, queued_by_job_id=340, pid=11644
2026-02-25 13:26:58,111 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:26:28.887851+00:00, map_index=-1, run_start_date=2026-02-25 05:26:50.269714+00:00, run_end_date=2026-02-25 05:26:57.350280+00:00, run_duration=7.080566, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=388, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:26:33.636941+00:00, queued_by_job_id=340, pid=11669
2026-02-25 13:27:00,779 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:26:28.886219+00:00: dataset_triggered__2026-02-25T05:26:28.886219+00:00, state:running, queued_at: 2026-02-25 05:26:33.578523+00:00. externally triggered: False> successful
2026-02-25 13:27:00,780 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:26:28.886219+00:00, run_id=dataset_triggered__2026-02-25T05:26:28.886219+00:00, run_start_date=2026-02-25 05:26:33.603105+00:00, run_end_date=2026-02-25 05:27:00.779955+00:00, run_duration=27.17685, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:26:21.543429+00:00, data_interval_end=2026-02-25 05:26:21.543429+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 13:27:00,785 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:26:28.887851+00:00: dataset_triggered__2026-02-25T05:26:28.887851+00:00, state:running, queued_at: 2026-02-25 05:26:33.589893+00:00. externally triggered: False> successful
2026-02-25 13:27:00,786 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:26:28.887851+00:00, run_id=dataset_triggered__2026-02-25T05:26:28.887851+00:00, run_start_date=2026-02-25 05:26:33.603213+00:00, run_end_date=2026-02-25 05:27:00.786817+00:00, run_duration=27.183604, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:26:21.543429+00:00, data_interval_end=2026-02-25 05:26:21.543429+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 13:27:31,636 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:32:32,443 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:37:35,732 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:38:59,315 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:38:56.276937+00:00 [scheduled]>
2026-02-25 13:38:59,316 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 13:38:59,317 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:38:56.276937+00:00 [scheduled]>
2026-02-25 13:38:59,319 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:38:56.276937+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:38:59,320 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:38:56.276937+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:38:59,321 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:38:56.276937+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:38:59,325 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:38:56.276937+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:39:05,241 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:38:56.276937+00:00', try_number=1, map_index=-1)
2026-02-25 13:39:05,251 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:38:56.276937+00:00, map_index=-1, run_start_date=2026-02-25 05:39:04.221836+00:00, run_end_date=2026-02-25 05:39:04.458798+00:00, run_duration=0.236962, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=389, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:38:59.318679+00:00, queued_by_job_id=340, pid=12044
2026-02-25 13:39:08,028 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:38:56.276937+00:00: manual__2026-02-25T05:38:56.276937+00:00, state:running, queued_at: 2026-02-25 05:38:56.311253+00:00. externally triggered: True> successful
2026-02-25 13:39:08,029 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:38:56.276937+00:00, run_id=manual__2026-02-25T05:38:56.276937+00:00, run_start_date=2026-02-25 05:38:59.293437+00:00, run_end_date=2026-02-25 05:39:08.029545+00:00, run_duration=8.736108, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:38:56.276937+00:00, data_interval_end=2026-02-25 05:38:56.276937+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 13:39:08,041 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:39:04.478327+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [scheduled]>
2026-02-25 13:39:08,043 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 13:39:08,043 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 13:39:08,044 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:39:04.478327+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [scheduled]>
2026-02-25 13:39:08,047 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:39:04.478327+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:39:08,048 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:39:04.478327+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:39:08,049 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:39:04.478327+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:39:08,049 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:39:04.479998+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:39:08,050 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:39:04.479998+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:39:08,053 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:39:04.478327+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:40:03,704 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:39:04.479998+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:40:09,351 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:39:04.479998+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']' returned non-zero exit status 1..
2026-02-25 13:40:09,356 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:39:04.478327+00:00', try_number=1, map_index=-1)
2026-02-25 13:40:09,357 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:39:04.479998+00:00', try_number=1, map_index=-1)
2026-02-25 13:40:09,365 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:39:04.478327+00:00, map_index=-1, run_start_date=2026-02-25 05:39:12.201148+00:00, run_end_date=2026-02-25 05:40:02.969638+00:00, run_duration=50.76849, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=390, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:39:08.045662+00:00, queued_by_job_id=340, pid=12047
2026-02-25 13:40:09,367 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:39:04.479998+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:39:08.045662+00:00, queued_by_job_id=340, pid=None
2026-02-25 13:40:09,368 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2026-02-25 13:40:09,377 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:39:04.479998+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2026-02-25 13:40:09,414 INFO - Marking task as FAILED. dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:39:04.479998+00:00, execution_date=20260225T053904, start_date=, end_date=20260225T054009
2026-02-25 13:40:09,450 ERROR - DagFileProcessorManager (PID=1487) last sent a heartbeat 61.48 seconds ago! Restarting it
2026-02-25 13:40:09,466 INFO - Sending Signals.SIGTERM to group 1487. PIDs of all processes in the group: [1487]
2026-02-25 13:40:09,467 INFO - Sending the signal Signals.SIGTERM to group 1487
2026-02-25 13:40:10,295 INFO - Process psutil.Process(pid=1487, status='terminated', exitcode=0, started='08:45:12') (1487) terminated with exit code 0
2026-02-25 13:40:10,303 INFO - Launched DagFileProcessorManager with pid: 12093
2026-02-25 13:40:10,315 INFO - Heartbeat recovered after 65.05 seconds
2026-02-25 13:40:16,284 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:39:04.478327+00:00: dataset_triggered__2026-02-25T05:39:04.478327+00:00, state:running, queued_at: 2026-02-25 05:39:07.997238+00:00. externally triggered: False> successful
2026-02-25 13:40:16,285 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:39:04.478327+00:00, run_id=dataset_triggered__2026-02-25T05:39:04.478327+00:00, run_start_date=2026-02-25 05:39:08.009638+00:00, run_end_date=2026-02-25 05:40:16.285178+00:00, run_duration=68.27554, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:38:56.276937+00:00, data_interval_end=2026-02-25 05:38:56.276937+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 13:40:16,290 ERROR - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:39:04.479998+00:00: dataset_triggered__2026-02-25T05:39:04.479998+00:00, state:running, queued_at: 2026-02-25 05:39:07.985482+00:00. externally triggered: False> failed
2026-02-25 13:40:16,291 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:39:04.479998+00:00, run_id=dataset_triggered__2026-02-25T05:39:04.479998+00:00, run_start_date=2026-02-25 05:39:08.009751+00:00, run_end_date=2026-02-25 05:40:16.291670+00:00, run_duration=68.281919, state=failed, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:38:56.276937+00:00, data_interval_end=2026-02-25 05:38:56.276937+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 13:42:27,889 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:42:23.956346+00:00 [scheduled]>
2026-02-25 13:42:27,892 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 13:42:27,893 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:42:23.956346+00:00 [scheduled]>
2026-02-25 13:42:27,895 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:42:23.956346+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:42:27,896 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:42:23.956346+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:42:27,897 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:42:23.956346+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:42:27,900 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:42:23.956346+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:42:35,687 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:42:23.956346+00:00', try_number=1, map_index=-1)
2026-02-25 13:42:35,698 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:42:23.956346+00:00, map_index=-1, run_start_date=2026-02-25 05:42:34.694030+00:00, run_end_date=2026-02-25 05:42:34.912154+00:00, run_duration=0.218124, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=391, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:42:27.894160+00:00, queued_by_job_id=340, pid=12220
2026-02-25 13:42:35,728 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:42:38,975 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:42:23.956346+00:00: manual__2026-02-25T05:42:23.956346+00:00, state:running, queued_at: 2026-02-25 05:42:23.977501+00:00. externally triggered: True> successful
2026-02-25 13:42:38,977 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:42:23.956346+00:00, run_id=manual__2026-02-25T05:42:23.956346+00:00, run_start_date=2026-02-25 05:42:27.868460+00:00, run_end_date=2026-02-25 05:42:38.976897+00:00, run_duration=11.108437, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:42:23.956346+00:00, data_interval_end=2026-02-25 05:42:23.956346+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 13:42:38,989 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:42:34.930730+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:42:34.932463+00:00 [scheduled]>
2026-02-25 13:42:38,990 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 13:42:38,991 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 13:42:38,991 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:42:34.930730+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:42:34.932463+00:00 [scheduled]>
2026-02-25 13:42:38,994 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:42:34.930730+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:42:34.932463+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:42:38,995 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:42:34.930730+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:42:38,995 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:42:34.930730+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:42:38,996 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:42:34.932463+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:42:38,997 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:42:34.932463+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:42:39,000 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:42:34.930730+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:43:18,863 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:42:34.932463+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:43:58,607 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:42:34.930730+00:00', try_number=1, map_index=-1)
2026-02-25 13:43:58,609 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:42:34.932463+00:00', try_number=1, map_index=-1)
2026-02-25 13:43:58,619 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:42:34.932463+00:00, map_index=-1, run_start_date=2026-02-25 05:43:25.042171+00:00, run_end_date=2026-02-25 05:43:57.834442+00:00, run_duration=32.792271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=393, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:42:38.992951+00:00, queued_by_job_id=340, pid=12249
2026-02-25 13:43:58,620 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:42:34.930730+00:00, map_index=-1, run_start_date=2026-02-25 05:42:43.788446+00:00, run_end_date=2026-02-25 05:43:18.119512+00:00, run_duration=34.331066, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=392, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:42:38.992951+00:00, queued_by_job_id=340, pid=12226
2026-02-25 13:43:58,633 ERROR - DagFileProcessorManager (PID=12093) last sent a heartbeat 79.72 seconds ago! Restarting it
2026-02-25 13:43:58,643 INFO - Sending Signals.SIGTERM to group 12093. PIDs of all processes in the group: [12093]
2026-02-25 13:43:58,644 INFO - Sending the signal Signals.SIGTERM to group 12093
2026-02-25 13:43:59,264 INFO - Process psutil.Process(pid=12093, status='terminated', exitcode=0, started='13:40:10') (12093) terminated with exit code 0
2026-02-25 13:43:59,273 INFO - Launched DagFileProcessorManager with pid: 12277
2026-02-25 13:43:59,286 INFO - Heartbeat recovered after 83.57 seconds
2026-02-25 13:44:06,767 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:42:34.930730+00:00: dataset_triggered__2026-02-25T05:42:34.930730+00:00, state:running, queued_at: 2026-02-25 05:42:38.934784+00:00. externally triggered: False> successful
2026-02-25 13:44:06,768 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:42:34.930730+00:00, run_id=dataset_triggered__2026-02-25T05:42:34.930730+00:00, run_start_date=2026-02-25 05:42:38.957247+00:00, run_end_date=2026-02-25 05:44:06.768459+00:00, run_duration=87.811212, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:42:23.956346+00:00, data_interval_end=2026-02-25 05:42:23.956346+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 13:44:06,774 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:42:34.932463+00:00: dataset_triggered__2026-02-25T05:42:34.932463+00:00, state:running, queued_at: 2026-02-25 05:42:38.944600+00:00. externally triggered: False> successful
2026-02-25 13:44:06,775 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:42:34.932463+00:00, run_id=dataset_triggered__2026-02-25T05:42:34.932463+00:00, run_start_date=2026-02-25 05:42:38.957354+00:00, run_end_date=2026-02-25 05:44:06.775397+00:00, run_duration=87.818043, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:42:23.956346+00:00, data_interval_end=2026-02-25 05:42:23.956346+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 13:44:59,723 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:44:55.308652+00:00 [scheduled]>
2026-02-25 13:44:59,724 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 13:44:59,725 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:44:55.308652+00:00 [scheduled]>
2026-02-25 13:44:59,728 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:44:55.308652+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:44:59,729 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:44:55.308652+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:44:59,729 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:44:55.308652+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:44:59,732 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:44:55.308652+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:45:05,812 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:44:55.308652+00:00', try_number=1, map_index=-1)
2026-02-25 13:45:05,823 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:44:55.308652+00:00, map_index=-1, run_start_date=2026-02-25 05:45:04.880399+00:00, run_end_date=2026-02-25 05:45:05.090857+00:00, run_duration=0.210458, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=394, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:44:59.726482+00:00, queued_by_job_id=340, pid=12308
2026-02-25 13:45:08,819 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:44:55.308652+00:00: manual__2026-02-25T05:44:55.308652+00:00, state:running, queued_at: 2026-02-25 05:44:55.345816+00:00. externally triggered: True> successful
2026-02-25 13:45:08,820 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:44:55.308652+00:00, run_id=manual__2026-02-25T05:44:55.308652+00:00, run_start_date=2026-02-25 05:44:59.703230+00:00, run_end_date=2026-02-25 05:45:08.820443+00:00, run_duration=9.117213, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:44:55.308652+00:00, data_interval_end=2026-02-25 05:44:55.308652+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 13:45:08,832 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:45:05.110303+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:45:05.111774+00:00 [scheduled]>
2026-02-25 13:45:08,833 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 13:45:08,834 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 13:45:08,835 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:45:05.110303+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:45:05.111774+00:00 [scheduled]>
2026-02-25 13:45:08,838 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:45:05.110303+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:45:05.111774+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:45:08,839 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:45:05.110303+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:45:08,840 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:45:05.110303+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:45:08,841 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:45:05.111774+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:45:08,842 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:45:05.111774+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:45:08,845 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:45:05.110303+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:45:21,480 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:45:05.111774+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:45:35,752 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:45:05.110303+00:00', try_number=1, map_index=-1)
2026-02-25 13:45:35,756 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:45:05.111774+00:00', try_number=1, map_index=-1)
2026-02-25 13:45:35,765 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:45:05.110303+00:00, map_index=-1, run_start_date=2026-02-25 05:45:12.803845+00:00, run_end_date=2026-02-25 05:45:20.750452+00:00, run_duration=7.946607, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=395, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:45:08.837001+00:00, queued_by_job_id=340, pid=12312
2026-02-25 13:45:35,766 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:45:05.111774+00:00, map_index=-1, run_start_date=2026-02-25 05:45:26.133810+00:00, run_end_date=2026-02-25 05:45:35.042004+00:00, run_duration=8.908194, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=396, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:45:08.837001+00:00, queued_by_job_id=340, pid=12336
2026-02-25 13:45:39,148 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:45:05.110303+00:00: dataset_triggered__2026-02-25T05:45:05.110303+00:00, state:running, queued_at: 2026-02-25 05:45:08.787257+00:00. externally triggered: False> successful
2026-02-25 13:45:39,149 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:45:05.110303+00:00, run_id=dataset_triggered__2026-02-25T05:45:05.110303+00:00, run_start_date=2026-02-25 05:45:08.799124+00:00, run_end_date=2026-02-25 05:45:39.149421+00:00, run_duration=30.350297, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:44:55.308652+00:00, data_interval_end=2026-02-25 05:44:55.308652+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 13:45:39,154 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:45:05.111774+00:00: dataset_triggered__2026-02-25T05:45:05.111774+00:00, state:running, queued_at: 2026-02-25 05:45:08.776795+00:00. externally triggered: False> successful
2026-02-25 13:45:39,156 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:45:05.111774+00:00, run_id=dataset_triggered__2026-02-25T05:45:05.111774+00:00, run_start_date=2026-02-25 05:45:08.799737+00:00, run_end_date=2026-02-25 05:45:39.155951+00:00, run_duration=30.356214, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:44:55.308652+00:00, data_interval_end=2026-02-25 05:44:55.308652+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 13:47:36,640 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:52:40,568 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 13:55:26,396 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:55:25.245471+00:00 [scheduled]>
2026-02-25 13:55:26,397 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 13:55:26,398 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:55:25.245471+00:00 [scheduled]>
2026-02-25 13:55:26,401 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T05:55:25.245471+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:55:26,403 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:55:25.245471+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:55:26,403 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:55:25.245471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:55:26,406 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T05:55:25.245471+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:55:31,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T05:55:25.245471+00:00', try_number=1, map_index=-1)
2026-02-25 13:55:31,801 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T05:55:25.245471+00:00, map_index=-1, run_start_date=2026-02-25 05:55:30.828799+00:00, run_end_date=2026-02-25 05:55:31.040616+00:00, run_duration=0.211817, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=397, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:55:26.400042+00:00, queued_by_job_id=340, pid=12759
2026-02-25 13:55:35,443 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 05:55:25.245471+00:00: manual__2026-02-25T05:55:25.245471+00:00, state:running, queued_at: 2026-02-25 05:55:25.272091+00:00. externally triggered: True> successful
2026-02-25 13:55:35,444 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 05:55:25.245471+00:00, run_id=manual__2026-02-25T05:55:25.245471+00:00, run_start_date=2026-02-25 05:55:26.370562+00:00, run_end_date=2026-02-25 05:55:35.444594+00:00, run_duration=9.074032, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 05:55:25.245471+00:00, data_interval_end=2026-02-25 05:55:25.245471+00:00, dag_hash=dc7846bf5d42b816eea136ae4ec83631
2026-02-25 13:55:35,455 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:55:31.060883+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:55:31.062285+00:00 [scheduled]>
2026-02-25 13:55:35,456 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 13:55:35,456 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 13:55:35,458 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:55:31.060883+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:55:31.062285+00:00 [scheduled]>
2026-02-25 13:55:35,460 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T05:55:31.060883+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T05:55:31.062285+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 13:55:35,461 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:55:31.060883+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:55:35,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:55:31.060883+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:55:35,463 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:55:31.062285+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 13:55:35,463 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:55:31.062285+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:55:35,466 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T05:55:31.060883+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:55:47,754 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T05:55:31.062285+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 13:56:00,109 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T05:55:31.060883+00:00', try_number=1, map_index=-1)
2026-02-25 13:56:00,111 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T05:55:31.062285+00:00', try_number=1, map_index=-1)
2026-02-25 13:56:00,119 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T05:55:31.060883+00:00, map_index=-1, run_start_date=2026-02-25 05:55:39.436999+00:00, run_end_date=2026-02-25 05:55:47.025018+00:00, run_duration=7.588019, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=398, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:55:35.459239+00:00, queued_by_job_id=340, pid=12763
2026-02-25 13:56:00,121 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T05:55:31.062285+00:00, map_index=-1, run_start_date=2026-02-25 05:55:52.047720+00:00, run_end_date=2026-02-25 05:55:59.410537+00:00, run_duration=7.362817, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=399, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 05:55:35.459239+00:00, queued_by_job_id=340, pid=12793
2026-02-25 13:56:03,192 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 05:55:31.060883+00:00: dataset_triggered__2026-02-25T05:55:31.060883+00:00, state:running, queued_at: 2026-02-25 05:55:35.399686+00:00. externally triggered: False> successful
2026-02-25 13:56:03,193 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 05:55:31.060883+00:00, run_id=dataset_triggered__2026-02-25T05:55:31.060883+00:00, run_start_date=2026-02-25 05:55:35.424378+00:00, run_end_date=2026-02-25 05:56:03.193195+00:00, run_duration=27.768817, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:55:25.245471+00:00, data_interval_end=2026-02-25 05:55:25.245471+00:00, dag_hash=8f69c4dbee04235000cbaca06568e122
2026-02-25 13:56:03,199 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 05:55:31.062285+00:00: dataset_triggered__2026-02-25T05:55:31.062285+00:00, state:running, queued_at: 2026-02-25 05:55:35.411051+00:00. externally triggered: False> successful
2026-02-25 13:56:03,200 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 05:55:31.062285+00:00, run_id=dataset_triggered__2026-02-25T05:55:31.062285+00:00, run_start_date=2026-02-25 05:55:35.424513+00:00, run_end_date=2026-02-25 05:56:03.200755+00:00, run_duration=27.776242, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 05:55:25.245471+00:00, data_interval_end=2026-02-25 05:55:25.245471+00:00, dag_hash=acc32762ba4285d09900de565e41e5e5
2026-02-25 13:57:40,959 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:02:44,046 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:07:44,627 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:12:47,127 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:17:48,293 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:22:52,495 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:27:54,651 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:32:58,573 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:38:01,001 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:43:02,553 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:48:02,688 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:53:05,479 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 14:58:07,557 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:03:10,360 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:08:12,422 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:13:15,086 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:18:17,681 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:23:20,359 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:28:22,325 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:33:25,113 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:38:26,324 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:43:26,297 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:48:27,030 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:53:29,868 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 15:58:30,270 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:03:32,206 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:08:33,579 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:13:37,617 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:18:38,538 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:23:41,363 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:28:44,289 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:33:46,006 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:38:46,449 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:43:46,789 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:48:50,956 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:53:51,971 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 16:58:53,508 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:03:56,190 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:08:58,490 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:12:53,556 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:12:50.009957+00:00 [scheduled]>
2026-02-25 17:12:53,557 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 17:12:53,557 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:12:50.009957+00:00 [scheduled]>
2026-02-25 17:12:53,560 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:12:50.009957+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 17:12:53,563 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:12:50.009957+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 17:12:53,564 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:12:50.009957+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:12:53,566 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:12:50.009957+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:12:58,690 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:12:50.009957+00:00', try_number=1, map_index=-1)
2026-02-25 17:12:58,699 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T09:12:50.009957+00:00, map_index=-1, run_start_date=2026-02-25 09:12:57.718217+00:00, run_end_date=2026-02-25 09:12:57.936050+00:00, run_duration=0.217833, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=400, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:12:53.559562+00:00, queued_by_job_id=340, pid=19192
2026-02-25 17:13:01,727 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 09:12:50.009957+00:00: manual__2026-02-25T09:12:50.009957+00:00, state:running, queued_at: 2026-02-25 09:12:50.033363+00:00. externally triggered: True> successful
2026-02-25 17:13:01,728 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 09:12:50.009957+00:00, run_id=manual__2026-02-25T09:12:50.009957+00:00, run_start_date=2026-02-25 09:12:53.530985+00:00, run_end_date=2026-02-25 09:13:01.728490+00:00, run_duration=8.197505, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 09:12:50.009957+00:00, data_interval_end=2026-02-25 09:12:50.009957+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-25 17:13:01,738 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:12:57.956329+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:12:57.958123+00:00 [scheduled]>
2026-02-25 17:13:01,739 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 17:13:01,740 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 17:13:01,741 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:12:57.956329+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:12:57.958123+00:00 [scheduled]>
2026-02-25 17:13:01,746 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:12:57.956329+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:12:57.958123+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 17:13:01,747 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:12:57.956329+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 17:13:01,748 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:12:57.956329+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:13:01,749 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:12:57.958123+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 17:13:01,750 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:12:57.958123+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:13:01,753 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:12:57.956329+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:13:14,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:12:57.958123+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:13:24,886 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:12:57.956329+00:00', try_number=1, map_index=-1)
2026-02-25 17:13:24,888 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:12:57.958123+00:00', try_number=1, map_index=-1)
2026-02-25 17:13:24,896 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T09:12:57.958123+00:00, map_index=-1, run_start_date=2026-02-25 09:13:18.252143+00:00, run_end_date=2026-02-25 09:13:24.186909+00:00, run_duration=5.934766, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=402, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:13:01.744683+00:00, queued_by_job_id=340, pid=19220
2026-02-25 17:13:24,897 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T09:12:57.956329+00:00, map_index=-1, run_start_date=2026-02-25 09:13:05.840199+00:00, run_end_date=2026-02-25 09:13:13.296947+00:00, run_duration=7.456748, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=401, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:13:01.744683+00:00, queued_by_job_id=340, pid=19198
2026-02-25 17:13:27,898 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 09:12:57.956329+00:00: dataset_triggered__2026-02-25T09:12:57.956329+00:00, state:running, queued_at: 2026-02-25 09:13:01.680697+00:00. externally triggered: False> successful
2026-02-25 17:13:27,899 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 09:12:57.956329+00:00, run_id=dataset_triggered__2026-02-25T09:12:57.956329+00:00, run_start_date=2026-02-25 09:13:01.707694+00:00, run_end_date=2026-02-25 09:13:27.899860+00:00, run_duration=26.192166, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:12:50.009957+00:00, data_interval_end=2026-02-25 09:12:50.009957+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-25 17:13:27,906 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 09:12:57.958123+00:00: dataset_triggered__2026-02-25T09:12:57.958123+00:00, state:running, queued_at: 2026-02-25 09:13:01.695599+00:00. externally triggered: False> successful
2026-02-25 17:13:27,907 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 09:12:57.958123+00:00, run_id=dataset_triggered__2026-02-25T09:12:57.958123+00:00, run_start_date=2026-02-25 09:13:01.707803+00:00, run_end_date=2026-02-25 09:13:27.907252+00:00, run_duration=26.199449, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:12:50.009957+00:00, data_interval_end=2026-02-25 09:12:50.009957+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-25 17:13:59,330 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:19:01,622 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:24:02,316 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:29:04,771 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:34:06,330 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:34:20,152 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:34:19.119387+00:00 [scheduled]>
2026-02-25 17:34:20,153 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-25 17:34:20,154 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:34:19.119387+00:00 [scheduled]>
2026-02-25 17:34:20,156 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-25T09:34:19.119387+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 17:34:20,159 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:34:19.119387+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 17:34:20,160 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:34:19.119387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:34:20,164 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-25T09:34:19.119387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:34:27,227 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-25T09:34:19.119387+00:00', try_number=1, map_index=-1)
2026-02-25 17:34:27,238 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-25T09:34:19.119387+00:00, map_index=-1, run_start_date=2026-02-25 09:34:26.189678+00:00, run_end_date=2026-02-25 09:34:26.419055+00:00, run_duration=0.229377, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=403, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:34:20.155327+00:00, queued_by_job_id=340, pid=19950
2026-02-25 17:34:30,910 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-25 09:34:19.119387+00:00: manual__2026-02-25T09:34:19.119387+00:00, state:running, queued_at: 2026-02-25 09:34:19.155536+00:00. externally triggered: True> successful
2026-02-25 17:34:30,912 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-25 09:34:19.119387+00:00, run_id=manual__2026-02-25T09:34:19.119387+00:00, run_start_date=2026-02-25 09:34:20.127745+00:00, run_end_date=2026-02-25 09:34:30.912020+00:00, run_duration=10.784275, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-25 09:34:19.119387+00:00, data_interval_end=2026-02-25 09:34:19.119387+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-25 17:34:30,923 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:34:26.439432+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:34:26.440909+00:00 [scheduled]>
2026-02-25 17:34:30,924 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-25 17:34:30,924 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-25 17:34:30,925 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:34:26.439432+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:34:26.440909+00:00 [scheduled]>
2026-02-25 17:34:30,928 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-25T09:34:26.439432+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-25T09:34:26.440909+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-25 17:34:30,929 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:34:26.439432+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 17:34:30,930 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:34:26.439432+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:34:30,930 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:34:26.440909+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-25 17:34:30,931 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:34:26.440909+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:34:30,934 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-25T09:34:26.439432+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:35:18,025 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-25T09:34:26.440909+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-25 17:35:58,276 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-25T09:34:26.439432+00:00', try_number=1, map_index=-1)
2026-02-25 17:35:58,280 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-25T09:34:26.440909+00:00', try_number=1, map_index=-1)
2026-02-25 17:35:58,289 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-25T09:34:26.440909+00:00, map_index=-1, run_start_date=2026-02-25 09:35:23.015913+00:00, run_end_date=2026-02-25 09:35:57.565079+00:00, run_duration=34.549166, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=405, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:34:30.926918+00:00, queued_by_job_id=340, pid=20000
2026-02-25 17:35:58,291 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-25T09:34:26.439432+00:00, map_index=-1, run_start_date=2026-02-25 09:34:39.201040+00:00, run_end_date=2026-02-25 09:35:17.280205+00:00, run_duration=38.079165, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=404, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-25 09:34:30.926918+00:00, queued_by_job_id=340, pid=19953
2026-02-25 17:35:58,304 ERROR - DagFileProcessorManager (PID=12277) last sent a heartbeat 87.46 seconds ago! Restarting it
2026-02-25 17:35:58,320 INFO - Sending Signals.SIGTERM to group 12277. PIDs of all processes in the group: [12277]
2026-02-25 17:35:58,322 INFO - Sending the signal Signals.SIGTERM to group 12277
2026-02-25 17:35:59,031 INFO - Process psutil.Process(pid=12277, status='terminated', exitcode=0, started='13:43:59') (12277) terminated with exit code 0
2026-02-25 17:35:59,046 INFO - Launched DagFileProcessorManager with pid: 20023
2026-02-25 17:35:59,059 INFO - Heartbeat recovered after 91.80 seconds
2026-02-25 17:36:06,023 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-25 09:34:26.439432+00:00: dataset_triggered__2026-02-25T09:34:26.439432+00:00, state:running, queued_at: 2026-02-25 09:34:30.880046+00:00. externally triggered: False> successful
2026-02-25 17:36:06,024 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-25 09:34:26.439432+00:00, run_id=dataset_triggered__2026-02-25T09:34:26.439432+00:00, run_start_date=2026-02-25 09:34:30.891967+00:00, run_end_date=2026-02-25 09:36:06.024620+00:00, run_duration=95.132653, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:34:19.119387+00:00, data_interval_end=2026-02-25 09:34:19.119387+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-25 17:36:06,031 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-25 09:34:26.440909+00:00: dataset_triggered__2026-02-25T09:34:26.440909+00:00, state:running, queued_at: 2026-02-25 09:34:30.870486+00:00. externally triggered: False> successful
2026-02-25 17:36:06,032 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-25 09:34:26.440909+00:00, run_id=dataset_triggered__2026-02-25T09:34:26.440909+00:00, run_start_date=2026-02-25 09:34:30.892070+00:00, run_end_date=2026-02-25 09:36:06.032485+00:00, run_duration=95.140415, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-25 09:34:19.119387+00:00, data_interval_end=2026-02-25 09:34:19.119387+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-25 17:39:07,583 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:47:14,630 INFO - Heartbeat recovered after 206.63 seconds
2026-02-25 17:47:22,897 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:50:31,812 INFO - Heartbeat recovered after 52.42 seconds
2026-02-25 17:53:24,854 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 17:58:26,731 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 18:03:27,594 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-25 18:05:15,074 INFO - Exiting gracefully upon receiving signal 15
2026-02-25 18:05:15,915 INFO - Sending Signals.SIGTERM to group 20023. PIDs of all processes in the group: []
2026-02-25 18:05:15,916 INFO - Sending the signal Signals.SIGTERM to group 20023
2026-02-25 18:05:15,917 INFO - Sending the signal Signals.SIGTERM to process 20023 as process group is missing.
2026-02-25 18:05:15,927 INFO - Sending Signals.SIGTERM to group 20023. PIDs of all processes in the group: []
2026-02-25 18:05:15,928 INFO - Sending the signal Signals.SIGTERM to group 20023
2026-02-25 18:05:15,929 INFO - Sending the signal Signals.SIGTERM to process 20023 as process group is missing.
2026-02-25 18:05:15,931 INFO - Exited execute loop
2026-02-26 08:51:58,426 INFO - Loaded executor: SequentialExecutor
2026-02-26 08:51:58,974 INFO - Starting the scheduler
2026-02-26 08:51:58,975 INFO - Processing each file at most -1 times
2026-02-26 08:51:58,980 INFO - Launched DagFileProcessorManager with pid: 1035
2026-02-26 08:51:58,985 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 08:57:02,162 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:02:07,037 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:07:07,305 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:12:09,710 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:17:12,354 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:22:14,177 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:27:15,735 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:32:16,001 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:37:16,029 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:42:18,518 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:47:20,952 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:52:23,964 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 09:57:25,857 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:02:27,008 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:07:27,262 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:12:28,501 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:17:31,006 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:22:31,194 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:27:34,372 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:32:35,266 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:37:36,274 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:42:38,609 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:47:41,166 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:52:41,732 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 10:57:43,182 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:02:45,831 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:07:47,550 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:12:49,463 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:17:49,780 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:22:53,695 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:27:53,935 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:32:56,540 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:38:00,463 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:43:02,492 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:48:02,499 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:53:05,036 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 11:58:05,979 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:03:08,017 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:08:10,291 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:13:10,667 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:18:13,872 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:23:15,170 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:28:16,750 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:33:20,003 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:38:23,222 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:43:24,953 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:52:29,479 INFO - Heartbeat recovered after 343.81 seconds
2026-02-26 12:53:59,844 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 12:59:00,515 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:04:02,014 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:09:04,305 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:14:04,689 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:19:05,278 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:24:07,581 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:25:05,425 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T05:25:00.970965+00:00 [scheduled]>
2026-02-26 13:25:05,426 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 13:25:05,427 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T05:25:00.970965+00:00 [scheduled]>
2026-02-26 13:25:05,430 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T05:25:00.970965+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:25:05,432 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T05:25:00.970965+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:25:05,433 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T05:25:00.970965+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:25:05,435 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T05:25:00.970965+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:25:10,539 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T05:25:00.970965+00:00', try_number=1, map_index=-1)
2026-02-26 13:25:10,556 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T05:25:00.970965+00:00, map_index=-1, run_start_date=2026-02-26 05:25:09.595016+00:00, run_end_date=2026-02-26 05:25:09.815464+00:00, run_duration=0.220448, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=407, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:25:05.429014+00:00, queued_by_job_id=406, pid=12673
2026-02-26 13:25:13,135 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 05:25:00.970965+00:00: manual__2026-02-26T05:25:00.970965+00:00, state:running, queued_at: 2026-02-26 05:25:00.995659+00:00. externally triggered: True> successful
2026-02-26 13:25:13,137 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 05:25:00.970965+00:00, run_id=manual__2026-02-26T05:25:00.970965+00:00, run_start_date=2026-02-26 05:25:05.380352+00:00, run_end_date=2026-02-26 05:25:13.137691+00:00, run_duration=7.757339, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 05:25:00.970965+00:00, data_interval_end=2026-02-26 05:25:00.970965+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 13:25:13,148 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T05:25:09.835017+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T05:25:09.836601+00:00 [scheduled]>
2026-02-26 13:25:13,149 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-26 13:25:13,150 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-26 13:25:13,151 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T05:25:09.835017+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T05:25:09.836601+00:00 [scheduled]>
2026-02-26 13:25:13,154 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T05:25:09.835017+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T05:25:09.836601+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:25:13,156 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T05:25:09.835017+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:25:13,157 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T05:25:09.835017+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:25:13,158 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T05:25:09.836601+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:25:13,158 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T05:25:09.836601+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:25:13,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T05:25:09.835017+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:25:34,682 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T05:25:09.836601+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:25:46,225 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T05:25:09.835017+00:00', try_number=1, map_index=-1)
2026-02-26 13:25:46,227 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T05:25:09.836601+00:00', try_number=1, map_index=-1)
2026-02-26 13:25:46,239 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T05:25:09.835017+00:00, map_index=-1, run_start_date=2026-02-26 05:25:17.161401+00:00, run_end_date=2026-02-26 05:25:33.962480+00:00, run_duration=16.801079, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=408, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:25:13.152253+00:00, queued_by_job_id=406, pid=12678
2026-02-26 13:25:46,241 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T05:25:09.836601+00:00, map_index=-1, run_start_date=2026-02-26 05:25:39.780681+00:00, run_end_date=2026-02-26 05:25:45.540964+00:00, run_duration=5.760283, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=409, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:25:13.152253+00:00, queued_by_job_id=406, pid=12700
2026-02-26 13:25:46,259 INFO - Heartbeat recovered after 35.68 seconds
2026-02-26 13:25:50,608 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 05:25:09.835017+00:00: dataset_triggered__2026-02-26T05:25:09.835017+00:00, state:running, queued_at: 2026-02-26 05:25:13.018440+00:00. externally triggered: False> successful
2026-02-26 13:25:50,609 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 05:25:09.835017+00:00, run_id=dataset_triggered__2026-02-26T05:25:09.835017+00:00, run_start_date=2026-02-26 05:25:13.109620+00:00, run_end_date=2026-02-26 05:25:50.609707+00:00, run_duration=37.500087, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 05:25:00.970965+00:00, data_interval_end=2026-02-26 05:25:00.970965+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-26 13:25:50,615 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 05:25:09.836601+00:00: dataset_triggered__2026-02-26T05:25:09.836601+00:00, state:running, queued_at: 2026-02-26 05:25:13.035918+00:00. externally triggered: False> successful
2026-02-26 13:25:50,616 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 05:25:09.836601+00:00, run_id=dataset_triggered__2026-02-26T05:25:09.836601+00:00, run_start_date=2026-02-26 05:25:13.109741+00:00, run_end_date=2026-02-26 05:25:50.615972+00:00, run_duration=37.506231, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 05:25:00.970965+00:00, data_interval_end=2026-02-26 05:25:00.970965+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-26 13:29:10,291 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:34:12,789 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:39:15,965 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:39:40,621 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T05:39:36.763433+00:00 [scheduled]>
2026-02-26 13:39:40,622 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 13:39:40,623 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T05:39:36.763433+00:00 [scheduled]>
2026-02-26 13:39:40,625 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T05:39:36.763433+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:39:40,626 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T05:39:36.763433+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:39:40,627 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T05:39:36.763433+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:39:40,629 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T05:39:36.763433+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:39:45,767 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T05:39:36.763433+00:00', try_number=1, map_index=-1)
2026-02-26 13:39:45,777 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T05:39:36.763433+00:00, map_index=-1, run_start_date=2026-02-26 05:39:44.811313+00:00, run_end_date=2026-02-26 05:39:45.055162+00:00, run_duration=0.243849, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=410, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:39:40.624169+00:00, queued_by_job_id=406, pid=13206
2026-02-26 13:39:48,280 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 05:39:36.763433+00:00: manual__2026-02-26T05:39:36.763433+00:00, state:running, queued_at: 2026-02-26 05:39:36.784636+00:00. externally triggered: True> successful
2026-02-26 13:39:48,281 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 05:39:36.763433+00:00, run_id=manual__2026-02-26T05:39:36.763433+00:00, run_start_date=2026-02-26 05:39:40.598446+00:00, run_end_date=2026-02-26 05:39:48.281825+00:00, run_duration=7.683379, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 05:39:36.763433+00:00, data_interval_end=2026-02-26 05:39:36.763433+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 13:39:48,292 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T05:39:45.076615+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T05:39:45.078137+00:00 [scheduled]>
2026-02-26 13:39:48,293 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-26 13:39:48,294 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-26 13:39:48,295 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T05:39:45.076615+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T05:39:45.078137+00:00 [scheduled]>
2026-02-26 13:39:48,298 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T05:39:45.076615+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T05:39:45.078137+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:39:48,299 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T05:39:45.076615+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:39:48,300 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T05:39:45.076615+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:39:48,301 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T05:39:45.078137+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:39:48,302 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T05:39:45.078137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:39:48,304 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T05:39:45.076615+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:40:03,185 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T05:39:45.078137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:40:15,068 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T05:39:45.076615+00:00', try_number=1, map_index=-1)
2026-02-26 13:40:15,071 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T05:39:45.078137+00:00', try_number=1, map_index=-1)
2026-02-26 13:40:15,079 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T05:39:45.076615+00:00, map_index=-1, run_start_date=2026-02-26 05:39:52.405110+00:00, run_end_date=2026-02-26 05:40:02.276920+00:00, run_duration=9.87181, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=411, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:39:48.296683+00:00, queued_by_job_id=406, pid=13209
2026-02-26 13:40:15,081 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T05:39:45.078137+00:00, map_index=-1, run_start_date=2026-02-26 05:40:08.121214+00:00, run_end_date=2026-02-26 05:40:14.286759+00:00, run_duration=6.165545, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=412, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:39:48.296683+00:00, queued_by_job_id=406, pid=13237
2026-02-26 13:40:19,306 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 05:39:45.076615+00:00: dataset_triggered__2026-02-26T05:39:45.076615+00:00, state:running, queued_at: 2026-02-26 05:39:48.248549+00:00. externally triggered: False> successful
2026-02-26 13:40:19,307 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 05:39:45.076615+00:00, run_id=dataset_triggered__2026-02-26T05:39:45.076615+00:00, run_start_date=2026-02-26 05:39:48.263193+00:00, run_end_date=2026-02-26 05:40:19.307659+00:00, run_duration=31.044466, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 05:39:36.763433+00:00, data_interval_end=2026-02-26 05:39:36.763433+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-26 13:40:19,313 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 05:39:45.078137+00:00: dataset_triggered__2026-02-26T05:39:45.078137+00:00, state:running, queued_at: 2026-02-26 05:39:48.236253+00:00. externally triggered: False> successful
2026-02-26 13:40:19,314 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 05:39:45.078137+00:00, run_id=dataset_triggered__2026-02-26T05:39:45.078137+00:00, run_start_date=2026-02-26 05:39:48.263303+00:00, run_end_date=2026-02-26 05:40:19.314152+00:00, run_duration=31.050849, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 05:39:36.763433+00:00, data_interval_end=2026-02-26 05:39:36.763433+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-26 13:41:14,563 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
2026-02-26 13:41:14,564 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 13:41:14,565 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
2026-02-26 13:41:14,572 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:41:14,575 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 13:41:14,577 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:14,581 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:19,611 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1)
2026-02-26 13:41:19,621 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T05:41:13.610728+00:00, map_index=-1, run_start_date=2026-02-26 05:41:18.725817+00:00, run_end_date=2026-02-26 05:41:18.924439+00:00, run_duration=0.198622, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=413, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 05:41:14.568985+00:00, queued_by_job_id=406, pid=13296
2026-02-26 13:41:23,332 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
2026-02-26 13:41:23,334 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 13:41:23,335 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 13:41:23,336 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
2026-02-26 13:41:23,338 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:41:23,339 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 13:41:23,340 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:23,341 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 13:41:23,341 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:23,344 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:37,464 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:48,051 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1)
2026-02-26 13:41:48,053 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1)
2026-02-26 13:41:48,062 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T05:41:13.610728+00:00, map_index=-1, run_start_date=2026-02-26 05:41:27.367153+00:00, run_end_date=2026-02-26 05:41:36.740473+00:00, run_duration=9.37332, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=414, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 05:41:23.337161+00:00, queued_by_job_id=406, pid=13299
2026-02-26 13:41:48,063 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T05:41:13.610728+00:00, map_index=-1, run_start_date=2026-02-26 05:41:41.618479+00:00, run_end_date=2026-02-26 05:41:47.368945+00:00, run_duration=5.750466, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=415, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 05:41:23.337161+00:00, queued_by_job_id=406, pid=13322
2026-02-26 13:41:51,516 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
2026-02-26 13:41:51,518 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 13:41:51,519 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>
2026-02-26 13:41:51,523 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T05:41:13.610728+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:41:51,524 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:41:51,525 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:51,527 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T05:41:13.610728+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:41:56,655 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T05:41:13.610728+00:00', try_number=1, map_index=-1)
2026-02-26 13:41:56,665 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=cleanup_task, run_id=manual__2026-02-26T05:41:13.610728+00:00, map_index=-1, run_start_date=2026-02-26 05:41:55.761200+00:00, run_end_date=2026-02-26 05:41:55.952430+00:00, run_duration=0.19123, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=416, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:41:51.520937+00:00, queued_by_job_id=406, pid=13344
2026-02-26 13:42:00,394 ERROR - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 05:41:13.610728+00:00: manual__2026-02-26T05:41:13.610728+00:00, state:running, queued_at: 2026-02-26 05:41:13.636327+00:00. externally triggered: True> failed
2026-02-26 13:42:00,395 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 05:41:13.610728+00:00, run_id=manual__2026-02-26T05:41:13.610728+00:00, run_start_date=2026-02-26 05:41:14.527176+00:00, run_end_date=2026-02-26 05:42:00.395354+00:00, run_duration=45.868178, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 05:41:13.610728+00:00, data_interval_end=2026-02-26 05:41:13.610728+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 13:43:16,162 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
2026-02-26 13:43:16,164 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 13:43:16,164 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
2026-02-26 13:43:16,167 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:43:16,168 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 13:43:16,168 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:16,171 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:21,183 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1)
2026-02-26 13:43:21,193 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T05:43:12.804910+00:00, map_index=-1, run_start_date=2026-02-26 05:43:20.158687+00:00, run_end_date=2026-02-26 05:43:20.448842+00:00, run_duration=0.290155, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=417, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 05:43:16.165923+00:00, queued_by_job_id=406, pid=13406
2026-02-26 13:43:24,090 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
2026-02-26 13:43:24,090 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 13:43:24,091 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 13:43:24,092 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
2026-02-26 13:43:24,094 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:43:24,096 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 13:43:24,097 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:24,098 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 13:43:24,099 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:24,102 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:36,717 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:48,622 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1)
2026-02-26 13:43:48,624 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1)
2026-02-26 13:43:48,632 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T05:43:12.804910+00:00, map_index=-1, run_start_date=2026-02-26 05:43:28.408522+00:00, run_end_date=2026-02-26 05:43:35.973078+00:00, run_duration=7.564556, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=418, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 05:43:24.093555+00:00, queued_by_job_id=406, pid=13412
2026-02-26 13:43:48,633 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T05:43:12.804910+00:00, map_index=-1, run_start_date=2026-02-26 05:43:41.935901+00:00, run_end_date=2026-02-26 05:43:47.920301+00:00, run_duration=5.9844, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=419, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 05:43:24.093555+00:00, queued_by_job_id=406, pid=13441
2026-02-26 13:43:51,539 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
2026-02-26 13:43:51,540 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 13:43:51,541 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>
2026-02-26 13:43:51,543 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T05:43:12.804910+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 13:43:51,544 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 13:43:51,546 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:51,548 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T05:43:12.804910+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 13:43:56,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T05:43:12.804910+00:00', try_number=1, map_index=-1)
2026-02-26 13:43:56,556 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=cleanup_task, run_id=manual__2026-02-26T05:43:12.804910+00:00, map_index=-1, run_start_date=2026-02-26 05:43:55.523182+00:00, run_end_date=2026-02-26 05:43:55.837012+00:00, run_duration=0.31383, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=420, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 05:43:51.542634+00:00, queued_by_job_id=406, pid=13465
2026-02-26 13:43:59,629 INFO - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 05:43:12.804910+00:00: manual__2026-02-26T05:43:12.804910+00:00, state:running, queued_at: 2026-02-26 05:43:12.824807+00:00. externally triggered: True> successful
2026-02-26 13:43:59,630 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 05:43:12.804910+00:00, run_id=manual__2026-02-26T05:43:12.804910+00:00, run_start_date=2026-02-26 05:43:16.138234+00:00, run_end_date=2026-02-26 05:43:59.630242+00:00, run_duration=43.492008, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 05:43:12.804910+00:00, data_interval_end=2026-02-26 05:43:12.804910+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 13:44:17,981 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:49:19,975 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:54:21,873 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 13:59:25,712 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:04:26,540 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:09:29,367 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:14:31,474 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:19:33,980 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:24:36,545 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:29:36,899 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:34:37,890 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:39:41,825 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:44:42,384 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:49:44,996 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:54:47,209 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 14:59:49,852 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:04:49,875 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:09:50,298 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:14:50,695 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:19:51,605 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:24:54,164 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:29:54,555 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:34:57,434 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 15:40:00,759 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:12:16,735 INFO - Heartbeat recovered after 1694.54 seconds
2026-02-26 16:13:10,514 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:18:12,034 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:23:13,555 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:28:15,209 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:31:17,654 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
2026-02-26 16:31:17,655 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:31:17,656 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
2026-02-26 16:31:17,658 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:31:17,660 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 16:31:17,661 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:17,664 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:23,285 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1)
2026-02-26 16:31:23,294 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T08:31:14.540847+00:00, map_index=-1, run_start_date=2026-02-26 08:31:22.342248+00:00, run_end_date=2026-02-26 08:31:22.559945+00:00, run_duration=0.217697, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=421, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 08:31:17.657702+00:00, queued_by_job_id=406, pid=17849
2026-02-26 16:31:26,894 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
2026-02-26 16:31:26,895 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:31:26,896 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 16:31:26,897 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
2026-02-26 16:31:26,900 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:31:26,901 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:31:26,901 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:26,902 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:31:26,903 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:26,906 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:41,494 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:51,641 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1)
2026-02-26 16:31:51,644 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1)
2026-02-26 16:31:51,652 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T08:31:14.540847+00:00, map_index=-1, run_start_date=2026-02-26 08:31:30.755670+00:00, run_end_date=2026-02-26 08:31:40.783204+00:00, run_duration=10.027534, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=422, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:31:26.898684+00:00, queued_by_job_id=406, pid=17853
2026-02-26 16:31:51,654 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T08:31:14.540847+00:00, map_index=-1, run_start_date=2026-02-26 08:31:45.328860+00:00, run_end_date=2026-02-26 08:31:50.998357+00:00, run_duration=5.669497, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=423, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:31:26.898684+00:00, queued_by_job_id=406, pid=17879
2026-02-26 16:31:54,547 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
2026-02-26 16:31:54,548 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:31:54,549 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>
2026-02-26 16:31:54,551 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:31:14.540847+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:31:54,552 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 16:31:54,552 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:54,555 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T08:31:14.540847+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:31:59,315 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T08:31:14.540847+00:00', try_number=1, map_index=-1)
2026-02-26 16:31:59,326 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=cleanup_task, run_id=manual__2026-02-26T08:31:14.540847+00:00, map_index=-1, run_start_date=2026-02-26 08:31:58.365641+00:00, run_end_date=2026-02-26 08:31:58.668470+00:00, run_duration=0.302829, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=424, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 08:31:54.550070+00:00, queued_by_job_id=406, pid=17904
2026-02-26 16:32:01,945 INFO - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 08:31:14.540847+00:00: manual__2026-02-26T08:31:14.540847+00:00, state:running, queued_at: 2026-02-26 08:31:14.568124+00:00. externally triggered: True> successful
2026-02-26 16:32:01,946 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 08:31:14.540847+00:00, run_id=manual__2026-02-26T08:31:14.540847+00:00, run_start_date=2026-02-26 08:31:17.626198+00:00, run_end_date=2026-02-26 08:32:01.946179+00:00, run_duration=44.319981, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 08:31:14.540847+00:00, data_interval_end=2026-02-26 08:31:14.540847+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 16:33:16,495 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:38:16,795 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:43:17,042 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:47:01,462 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
2026-02-26 16:47:01,463 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:47:01,464 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
2026-02-26 16:47:01,466 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:47:01,467 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 16:47:01,468 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:01,470 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:06,583 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1)
2026-02-26 16:47:06,593 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T08:46:58.796298+00:00, map_index=-1, run_start_date=2026-02-26 08:47:05.614179+00:00, run_end_date=2026-02-26 08:47:05.830521+00:00, run_duration=0.216342, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=425, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 08:47:01.465573+00:00, queued_by_job_id=406, pid=18402
2026-02-26 16:47:09,169 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
2026-02-26 16:47:09,170 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:47:09,170 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 16:47:09,171 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
2026-02-26 16:47:09,173 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:47:09,174 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:47:09,175 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:09,176 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:47:09,177 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:09,179 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:23,398 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:33,824 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1)
2026-02-26 16:47:33,830 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1)
2026-02-26 16:47:33,841 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T08:46:58.796298+00:00, map_index=-1, run_start_date=2026-02-26 08:47:13.276718+00:00, run_end_date=2026-02-26 08:47:22.657300+00:00, run_duration=9.380582, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=426, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:47:09.172491+00:00, queued_by_job_id=406, pid=18415
2026-02-26 16:47:33,846 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T08:46:58.796298+00:00, map_index=-1, run_start_date=2026-02-26 08:47:27.486654+00:00, run_end_date=2026-02-26 08:47:33.132877+00:00, run_duration=5.646223, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=427, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:47:09.172491+00:00, queued_by_job_id=406, pid=18449
2026-02-26 16:47:36,852 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
2026-02-26 16:47:36,853 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:47:36,854 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>
2026-02-26 16:47:36,856 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:46:58.796298+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:47:36,857 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 16:47:36,857 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:36,860 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T08:46:58.796298+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:47:41,724 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T08:46:58.796298+00:00', try_number=1, map_index=-1)
2026-02-26 16:47:41,733 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=cleanup_task, run_id=manual__2026-02-26T08:46:58.796298+00:00, map_index=-1, run_start_date=2026-02-26 08:47:40.697176+00:00, run_end_date=2026-02-26 08:47:41.019128+00:00, run_duration=0.321952, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=428, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 08:47:36.855260+00:00, queued_by_job_id=406, pid=18476
2026-02-26 16:47:44,577 INFO - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 08:46:58.796298+00:00: manual__2026-02-26T08:46:58.796298+00:00, state:running, queued_at: 2026-02-26 08:46:58.820718+00:00. externally triggered: True> successful
2026-02-26 16:47:44,578 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 08:46:58.796298+00:00, run_id=manual__2026-02-26T08:46:58.796298+00:00, run_start_date=2026-02-26 08:47:01.439903+00:00, run_end_date=2026-02-26 08:47:44.577981+00:00, run_duration=43.138078, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 08:46:58.796298+00:00, data_interval_end=2026-02-26 08:46:58.796298+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 16:48:18,404 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:49:42,071 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
2026-02-26 16:49:42,072 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:49:42,073 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
2026-02-26 16:49:42,075 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:49:42,076 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 16:49:42,077 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:49:42,080 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:49:47,345 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1)
2026-02-26 16:49:47,354 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T08:49:39.982009+00:00, map_index=-1, run_start_date=2026-02-26 08:49:46.317392+00:00, run_end_date=2026-02-26 08:49:46.564634+00:00, run_duration=0.247242, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=429, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 08:49:42.074580+00:00, queued_by_job_id=406, pid=18558
2026-02-26 16:49:50,166 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
2026-02-26 16:49:50,167 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:49:50,167 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 16:49:50,168 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
2026-02-26 16:49:50,171 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:49:50,172 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:49:50,173 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:49:50,174 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:49:50,175 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:49:50,177 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:50:03,136 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:50:14,338 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1)
2026-02-26 16:50:14,340 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1)
2026-02-26 16:50:14,348 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T08:49:39.982009+00:00, map_index=-1, run_start_date=2026-02-26 08:49:54.448372+00:00, run_end_date=2026-02-26 08:50:02.432718+00:00, run_duration=7.984346, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=430, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:49:50.169707+00:00, queued_by_job_id=406, pid=18567
2026-02-26 16:50:14,350 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T08:49:39.982009+00:00, map_index=-1, run_start_date=2026-02-26 08:50:07.275500+00:00, run_end_date=2026-02-26 08:50:13.640755+00:00, run_duration=6.365255, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=431, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:49:50.169707+00:00, queued_by_job_id=406, pid=18592
2026-02-26 16:50:17,193 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
2026-02-26 16:50:17,193 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:50:17,194 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>
2026-02-26 16:50:17,197 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.cleanup_task manual__2026-02-26T08:49:39.982009+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:50:17,198 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 16:50:17,198 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:50:17,201 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'cleanup_task', 'manual__2026-02-26T08:49:39.982009+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:50:21,943 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='cleanup_task', run_id='manual__2026-02-26T08:49:39.982009+00:00', try_number=1, map_index=-1)
2026-02-26 16:50:21,954 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=cleanup_task, run_id=manual__2026-02-26T08:49:39.982009+00:00, map_index=-1, run_start_date=2026-02-26 08:50:21.003019+00:00, run_end_date=2026-02-26 08:50:21.297638+00:00, run_duration=0.294619, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=432, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 08:50:17.195782+00:00, queued_by_job_id=406, pid=18619
2026-02-26 16:50:24,725 INFO - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 08:49:39.982009+00:00: manual__2026-02-26T08:49:39.982009+00:00, state:running, queued_at: 2026-02-26 08:49:39.996280+00:00. externally triggered: True> successful
2026-02-26 16:50:24,726 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 08:49:39.982009+00:00, run_id=manual__2026-02-26T08:49:39.982009+00:00, run_start_date=2026-02-26 08:49:42.049308+00:00, run_end_date=2026-02-26 08:50:24.726492+00:00, run_duration=42.677184, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 08:49:39.982009+00:00, data_interval_end=2026-02-26 08:49:39.982009+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 16:53:20,009 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:55:35,046 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>
2026-02-26 16:55:35,047 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:55:35,048 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>
2026-02-26 16:55:35,051 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:55:35,052 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:55:33.385268+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 16:55:35,053 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:55:33.385268+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:55:35,055 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:55:33.385268+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:55:40,084 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:55:33.385268+00:00', try_number=1, map_index=-1)
2026-02-26 16:55:40,095 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T08:55:33.385268+00:00, map_index=-1, run_start_date=2026-02-26 08:55:39.103759+00:00, run_end_date=2026-02-26 08:55:39.317911+00:00, run_duration=0.214152, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=407, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 08:55:35.049729+00:00, queued_by_job_id=406, pid=18833
2026-02-26 16:55:43,862 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>
2026-02-26 16:55:43,863 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:55:43,864 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 16:55:43,865 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>
2026-02-26 16:55:43,867 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:55:33.385268+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:55:43,868 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:55:33.385268+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:55:43,868 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:55:33.385268+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:55:43,869 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:55:33.385268+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:55:43,870 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:55:33.385268+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:55:43,873 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:55:33.385268+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:55:49,028 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:55:33.385268+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:55:53,739 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:55:33.385268+00:00', try_number=1, map_index=-1)
2026-02-26 16:55:53,741 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:55:33.385268+00:00', try_number=1, map_index=-1)
2026-02-26 16:55:53,749 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T08:55:33.385268+00:00, map_index=-1, run_start_date=2026-02-26 08:55:48.089653+00:00, run_end_date=2026-02-26 08:55:48.292367+00:00, run_duration=0.202714, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=408, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:55:43.865985+00:00, queued_by_job_id=406, pid=18839
2026-02-26 16:55:53,751 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T08:55:33.385268+00:00, map_index=-1, run_start_date=2026-02-26 08:55:52.843026+00:00, run_end_date=2026-02-26 08:55:53.039583+00:00, run_duration=0.196557, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=409, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:55:43.865985+00:00, queued_by_job_id=406, pid=18845
2026-02-26 16:55:57,279 ERROR - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 08:55:33.385268+00:00: manual__2026-02-26T08:55:33.385268+00:00, state:running, queued_at: 2026-02-26 08:55:33.411354+00:00. externally triggered: True> failed
2026-02-26 16:55:57,280 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 08:55:33.385268+00:00, run_id=manual__2026-02-26T08:55:33.385268+00:00, run_start_date=2026-02-26 08:55:35.024862+00:00, run_end_date=2026-02-26 08:55:57.280848+00:00, run_duration=22.255986, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 08:55:33.385268+00:00, data_interval_end=2026-02-26 08:55:33.385268+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 16:57:39,338 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>
2026-02-26 16:57:39,339 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:57:39,340 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>
2026-02-26 16:57:39,342 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:57:39,344 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:57:35.035228+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 16:57:39,344 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:57:35.035228+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:57:39,347 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:57:35.035228+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:57:44,633 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:57:35.035228+00:00', try_number=1, map_index=-1)
2026-02-26 16:57:44,641 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T08:57:35.035228+00:00, map_index=-1, run_start_date=2026-02-26 08:57:43.663285+00:00, run_end_date=2026-02-26 08:57:43.872547+00:00, run_duration=0.209262, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=410, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 08:57:39.341615+00:00, queued_by_job_id=406, pid=18913
2026-02-26 16:57:47,982 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>
2026-02-26 16:57:47,983 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:57:47,983 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 16:57:47,984 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>
2026-02-26 16:57:47,986 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:57:35.035228+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:57:47,987 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:57:35.035228+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:57:47,988 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:57:35.035228+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:57:47,989 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:57:35.035228+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:57:47,990 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:57:35.035228+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:57:47,992 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:57:35.035228+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:57:52,894 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:57:35.035228+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:57:57,674 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:57:35.035228+00:00', try_number=1, map_index=-1)
2026-02-26 16:57:57,676 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:57:35.035228+00:00', try_number=1, map_index=-1)
2026-02-26 16:57:57,683 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T08:57:35.035228+00:00, map_index=-1, run_start_date=2026-02-26 08:57:51.940131+00:00, run_end_date=2026-02-26 08:57:52.136694+00:00, run_duration=0.196563, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=411, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:57:47.985666+00:00, queued_by_job_id=406, pid=18917
2026-02-26 16:57:57,685 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T08:57:35.035228+00:00, map_index=-1, run_start_date=2026-02-26 08:57:56.789106+00:00, run_end_date=2026-02-26 08:57:56.974570+00:00, run_duration=0.185464, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=412, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:57:47.985666+00:00, queued_by_job_id=406, pid=18919
2026-02-26 16:58:00,278 ERROR - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 08:57:35.035228+00:00: manual__2026-02-26T08:57:35.035228+00:00, state:running, queued_at: 2026-02-26 08:57:35.048159+00:00. externally triggered: True> failed
2026-02-26 16:58:00,279 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 08:57:35.035228+00:00, run_id=manual__2026-02-26T08:57:35.035228+00:00, run_start_date=2026-02-26 08:57:39.312850+00:00, run_end_date=2026-02-26 08:58:00.279503+00:00, run_duration=20.966653, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 08:57:35.035228+00:00, data_interval_end=2026-02-26 08:57:35.035228+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 16:58:22,323 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 16:58:49,047 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>
2026-02-26 16:58:49,048 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:58:49,049 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>
2026-02-26 16:58:49,051 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:58:49,052 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:58:47.297821+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 16:58:49,053 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:58:47.297821+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:58:49,056 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T08:58:47.297821+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:58:53,754 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T08:58:47.297821+00:00', try_number=1, map_index=-1)
2026-02-26 16:58:53,765 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T08:58:47.297821+00:00, map_index=-1, run_start_date=2026-02-26 08:58:52.821925+00:00, run_end_date=2026-02-26 08:58:53.017436+00:00, run_duration=0.195511, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=413, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 08:58:49.050572+00:00, queued_by_job_id=406, pid=18947
2026-02-26 16:58:56,408 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>
2026-02-26 16:58:56,409 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 16:58:56,410 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 16:58:56,411 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>
2026-02-26 16:58:56,413 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T08:58:47.297821+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 16:58:56,414 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:58:47.297821+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:58:56,415 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:58:47.297821+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:58:56,416 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:58:47.297821+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 16:58:56,417 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:58:47.297821+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:58:56,420 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T08:58:47.297821+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:59:01,189 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T08:58:47.297821+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 16:59:05,765 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T08:58:47.297821+00:00', try_number=1, map_index=-1)
2026-02-26 16:59:05,767 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T08:58:47.297821+00:00', try_number=1, map_index=-1)
2026-02-26 16:59:05,776 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T08:58:47.297821+00:00, map_index=-1, run_start_date=2026-02-26 08:59:00.243963+00:00, run_end_date=2026-02-26 08:59:00.442141+00:00, run_duration=0.198178, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=414, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:58:56.412197+00:00, queued_by_job_id=406, pid=18951
2026-02-26 16:59:05,778 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T08:58:47.297821+00:00, map_index=-1, run_start_date=2026-02-26 08:59:04.945001+00:00, run_end_date=2026-02-26 08:59:05.133718+00:00, run_duration=0.188717, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=415, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 08:58:56.412197+00:00, queued_by_job_id=406, pid=18956
2026-02-26 16:59:08,364 ERROR - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 08:58:47.297821+00:00: manual__2026-02-26T08:58:47.297821+00:00, state:running, queued_at: 2026-02-26 08:58:47.309466+00:00. externally triggered: True> failed
2026-02-26 16:59:08,365 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 08:58:47.297821+00:00, run_id=manual__2026-02-26T08:58:47.297821+00:00, run_start_date=2026-02-26 08:58:49.023928+00:00, run_end_date=2026-02-26 08:59:08.365869+00:00, run_duration=19.341941, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 08:58:47.297821+00:00, data_interval_end=2026-02-26 08:58:47.297821+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 17:02:05,242 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>
2026-02-26 17:02:05,243 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 17:02:05,244 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>
2026-02-26 17:02:05,247 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:02:05,247 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T09:02:01.508280+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 17:02:05,248 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T09:02:01.508280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:02:05,250 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T09:02:01.508280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:02:10,569 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T09:02:01.508280+00:00', try_number=1, map_index=-1)
2026-02-26 17:02:10,579 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T09:02:01.508280+00:00, map_index=-1, run_start_date=2026-02-26 09:02:09.656350+00:00, run_end_date=2026-02-26 09:02:09.870105+00:00, run_duration=0.213755, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=416, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 09:02:05.245649+00:00, queued_by_job_id=406, pid=19057
2026-02-26 17:02:13,098 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>
2026-02-26 17:02:13,099 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 17:02:13,100 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 17:02:13,101 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>
2026-02-26 17:02:13,103 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T09:02:01.508280+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:02:13,104 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T09:02:01.508280+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 17:02:13,105 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T09:02:01.508280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:02:13,106 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T09:02:01.508280+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 17:02:13,107 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T09:02:01.508280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:02:13,110 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T09:02:01.508280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:02:17,961 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T09:02:01.508280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:02:22,810 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T09:02:01.508280+00:00', try_number=1, map_index=-1)
2026-02-26 17:02:22,812 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T09:02:01.508280+00:00', try_number=1, map_index=-1)
2026-02-26 17:02:22,821 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T09:02:01.508280+00:00, map_index=-1, run_start_date=2026-02-26 09:02:17.093321+00:00, run_end_date=2026-02-26 09:02:17.287556+00:00, run_duration=0.194235, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=417, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:02:13.102508+00:00, queued_by_job_id=406, pid=19061
2026-02-26 17:02:22,823 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T09:02:01.508280+00:00, map_index=-1, run_start_date=2026-02-26 09:02:21.903303+00:00, run_end_date=2026-02-26 09:02:22.107914+00:00, run_duration=0.204611, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=418, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:02:13.102508+00:00, queued_by_job_id=406, pid=19065
2026-02-26 17:02:25,358 ERROR - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 09:02:01.508280+00:00: manual__2026-02-26T09:02:01.508280+00:00, state:running, queued_at: 2026-02-26 09:02:01.523105+00:00. externally triggered: True> failed
2026-02-26 17:02:25,360 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 09:02:01.508280+00:00, run_id=manual__2026-02-26T09:02:01.508280+00:00, run_start_date=2026-02-26 09:02:05.221626+00:00, run_end_date=2026-02-26 09:02:25.360277+00:00, run_duration=20.138651, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:02:01.508280+00:00, data_interval_end=2026-02-26 09:02:01.508280+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 17:03:25,537 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:05:29,113 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>
2026-02-26 17:05:29,114 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 17:05:29,115 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>
2026-02-26 17:05:29,117 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.producer_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:05:29,119 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T09:05:27.870352+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 17:05:29,120 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T09:05:27.870352+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:05:29,122 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'producer_task', 'manual__2026-02-26T09:05:27.870352+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:05:34,590 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='producer_task', run_id='manual__2026-02-26T09:05:27.870352+00:00', try_number=1, map_index=-1)
2026-02-26 17:05:34,598 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=producer_task, run_id=manual__2026-02-26T09:05:27.870352+00:00, map_index=-1, run_start_date=2026-02-26 09:05:33.635823+00:00, run_end_date=2026-02-26 09:05:33.837477+00:00, run_duration=0.201654, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=419, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 09:05:29.116462+00:00, queued_by_job_id=406, pid=19189
2026-02-26 17:05:38,119 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>
2026-02-26 17:05:38,120 INFO - DAG integrated_cdrd_workflow has 0/16 running and queued tasks
2026-02-26 17:05:38,120 INFO - DAG integrated_cdrd_workflow has 1/16 running and queued tasks
2026-02-26 17:05:38,121 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>
2026-02-26 17:05:38,124 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_workflow.consumer1_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_workflow.consumer2_task manual__2026-02-26T09:05:27.870352+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:05:38,125 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T09:05:27.870352+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 17:05:38,125 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T09:05:27.870352+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:05:38,126 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T09:05:27.870352+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 17:05:38,127 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T09:05:27.870352+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:05:38,129 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer1_task', 'manual__2026-02-26T09:05:27.870352+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:05:42,955 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_workflow', 'consumer2_task', 'manual__2026-02-26T09:05:27.870352+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:05:47,616 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer1_task', run_id='manual__2026-02-26T09:05:27.870352+00:00', try_number=1, map_index=-1)
2026-02-26 17:05:47,619 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_workflow', task_id='consumer2_task', run_id='manual__2026-02-26T09:05:27.870352+00:00', try_number=1, map_index=-1)
2026-02-26 17:05:47,628 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer1_task, run_id=manual__2026-02-26T09:05:27.870352+00:00, map_index=-1, run_start_date=2026-02-26 09:05:42.023214+00:00, run_end_date=2026-02-26 09:05:42.229890+00:00, run_duration=0.206676, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=420, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:05:38.122673+00:00, queued_by_job_id=406, pid=19192
2026-02-26 17:05:47,629 INFO - TaskInstance Finished: dag_id=integrated_cdrd_workflow, task_id=consumer2_task, run_id=manual__2026-02-26T09:05:27.870352+00:00, map_index=-1, run_start_date=2026-02-26 09:05:46.688748+00:00, run_end_date=2026-02-26 09:05:46.885061+00:00, run_duration=0.196313, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=421, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:05:38.122673+00:00, queued_by_job_id=406, pid=19194
2026-02-26 17:05:51,084 ERROR - Marking run <DagRun integrated_cdrd_workflow @ 2026-02-26 09:05:27.870352+00:00: manual__2026-02-26T09:05:27.870352+00:00, state:running, queued_at: 2026-02-26 09:05:27.877459+00:00. externally triggered: True> failed
2026-02-26 17:05:51,085 INFO - DagRun Finished: dag_id=integrated_cdrd_workflow, execution_date=2026-02-26 09:05:27.870352+00:00, run_id=manual__2026-02-26T09:05:27.870352+00:00, run_start_date=2026-02-26 09:05:29.087225+00:00, run_end_date=2026-02-26 09:05:51.085031+00:00, run_duration=21.997806, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:05:27.870352+00:00, data_interval_end=2026-02-26 09:05:27.870352+00:00, dag_hash=cf687674efda3a6ff2c1579e95df75b5
2026-02-26 17:08:11,646 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:08:09.618194+00:00 [scheduled]>
2026-02-26 17:08:11,647 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 17:08:11,647 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:08:09.618194+00:00 [scheduled]>
2026-02-26 17:08:11,650 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:08:09.618194+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:08:11,650 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:08:09.618194+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:08:11,651 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:08:09.618194+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:08:11,653 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:08:09.618194+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:08:16,654 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:08:09.618194+00:00', try_number=1, map_index=-1)
2026-02-26 17:08:16,663 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T09:08:09.618194+00:00, map_index=-1, run_start_date=2026-02-26 09:08:15.725294+00:00, run_end_date=2026-02-26 09:08:15.928244+00:00, run_duration=0.20295, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=422, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:08:11.648987+00:00, queued_by_job_id=406, pid=19292
2026-02-26 17:08:19,368 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 09:08:09.618194+00:00: manual__2026-02-26T09:08:09.618194+00:00, state:running, queued_at: 2026-02-26 09:08:09.636576+00:00. externally triggered: True> successful
2026-02-26 17:08:19,370 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 09:08:09.618194+00:00, run_id=manual__2026-02-26T09:08:09.618194+00:00, run_start_date=2026-02-26 09:08:11.625590+00:00, run_end_date=2026-02-26 09:08:19.370057+00:00, run_duration=7.744467, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:08:09.618194+00:00, data_interval_end=2026-02-26 09:08:09.618194+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 17:08:27,130 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:09:49,169 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:09:46.060574+00:00 [scheduled]>
2026-02-26 17:09:49,170 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 17:09:49,171 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:09:46.060574+00:00 [scheduled]>
2026-02-26 17:09:49,173 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:09:46.060574+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:09:49,174 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:09:46.060574+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:09:49,174 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:09:46.060574+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:09:49,177 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:09:46.060574+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:09:54,212 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:09:46.060574+00:00', try_number=1, map_index=-1)
2026-02-26 17:09:54,221 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T09:09:46.060574+00:00, map_index=-1, run_start_date=2026-02-26 09:09:53.280751+00:00, run_end_date=2026-02-26 09:09:53.491698+00:00, run_duration=0.210947, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=423, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:09:49.172119+00:00, queued_by_job_id=406, pid=19347
2026-02-26 17:09:56,793 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 09:09:46.060574+00:00: manual__2026-02-26T09:09:46.060574+00:00, state:running, queued_at: 2026-02-26 09:09:46.069240+00:00. externally triggered: True> successful
2026-02-26 17:09:56,794 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 09:09:46.060574+00:00, run_id=manual__2026-02-26T09:09:46.060574+00:00, run_start_date=2026-02-26 09:09:49.147786+00:00, run_end_date=2026-02-26 09:09:56.794568+00:00, run_duration=7.646782, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:09:46.060574+00:00, data_interval_end=2026-02-26 09:09:46.060574+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 17:13:28,174 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:14:44,422 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:14:42.407014+00:00 [scheduled]>
2026-02-26 17:14:44,423 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 17:14:44,424 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:14:42.407014+00:00 [scheduled]>
2026-02-26 17:14:44,426 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:14:42.407014+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:14:44,427 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:14:42.407014+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:14:44,427 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:14:42.407014+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:14:44,430 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:14:42.407014+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:14:49,635 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:14:42.407014+00:00', try_number=1, map_index=-1)
2026-02-26 17:14:49,645 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T09:14:42.407014+00:00, map_index=-1, run_start_date=2026-02-26 09:14:48.717059+00:00, run_end_date=2026-02-26 09:14:48.948805+00:00, run_duration=0.231746, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=424, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:14:44.424977+00:00, queued_by_job_id=406, pid=19560
2026-02-26 17:14:52,504 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 09:14:42.407014+00:00: manual__2026-02-26T09:14:42.407014+00:00, state:running, queued_at: 2026-02-26 09:14:42.428662+00:00. externally triggered: True> successful
2026-02-26 17:14:52,506 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 09:14:42.407014+00:00, run_id=manual__2026-02-26T09:14:42.407014+00:00, run_start_date=2026-02-26 09:14:44.401124+00:00, run_end_date=2026-02-26 09:14:52.506015+00:00, run_duration=8.104891, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:14:42.407014+00:00, data_interval_end=2026-02-26 09:14:42.407014+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 17:15:28,852 INFO - Exiting gracefully upon receiving signal 15
2026-02-26 17:15:29,881 INFO - Sending Signals.SIGTERM to group 1035. PIDs of all processes in the group: [1035]
2026-02-26 17:15:29,883 INFO - Sending the signal Signals.SIGTERM to group 1035
2026-02-26 17:15:29,912 INFO - Process psutil.Process(pid=1035, status='terminated', exitcode=<Negsignal.SIGTERM: -15>, started='08:51:58') (1035) terminated with exit code Negsignal.SIGTERM
2026-02-26 17:15:29,935 INFO - Sending Signals.SIGTERM to group 1035. PIDs of all processes in the group: []
2026-02-26 17:15:29,936 INFO - Sending the signal Signals.SIGTERM to group 1035
2026-02-26 17:15:29,939 INFO - Sending the signal Signals.SIGTERM to process 1035 as process group is missing.
2026-02-26 17:15:29,940 INFO - Exited execute loop
2026-02-26 17:15:32,024 INFO - Loaded executor: SequentialExecutor
2026-02-26 17:15:32,716 INFO - Starting the scheduler
2026-02-26 17:15:32,718 INFO - Processing each file at most -1 times
2026-02-26 17:15:32,726 INFO - Launched DagFileProcessorManager with pid: 19721
2026-02-26 17:15:32,734 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:15:53,912 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:15:49.701114+00:00 [scheduled]>
2026-02-26 17:15:53,914 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 17:15:53,915 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:15:49.701114+00:00 [scheduled]>
2026-02-26 17:15:53,918 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:15:49.701114+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:15:53,919 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:15:49.701114+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:15:53,920 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:15:49.701114+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:15:53,923 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:15:49.701114+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:15:59,045 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:15:49.701114+00:00', try_number=1, map_index=-1)
2026-02-26 17:15:59,060 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T09:15:49.701114+00:00, map_index=-1, run_start_date=2026-02-26 09:15:58.101655+00:00, run_end_date=2026-02-26 09:15:58.321599+00:00, run_duration=0.219944, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=426, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:15:53.916592+00:00, queued_by_job_id=425, pid=19749
2026-02-26 17:16:02,452 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 09:15:49.701114+00:00: manual__2026-02-26T09:15:49.701114+00:00, state:running, queued_at: 2026-02-26 09:15:49.728261+00:00. externally triggered: True> successful
2026-02-26 17:16:02,454 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 09:15:49.701114+00:00, run_id=manual__2026-02-26T09:15:49.701114+00:00, run_start_date=2026-02-26 09:15:53.741547+00:00, run_end_date=2026-02-26 09:16:02.454714+00:00, run_duration=8.713167, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:15:49.701114+00:00, data_interval_end=2026-02-26 09:15:49.701114+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 17:19:05,896 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:19:02.861621+00:00 [scheduled]>
2026-02-26 17:19:05,897 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 17:19:05,899 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:19:02.861621+00:00 [scheduled]>
2026-02-26 17:19:05,901 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T09:19:02.861621+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:19:05,902 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:19:02.861621+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:19:05,903 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:19:02.861621+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:19:05,906 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T09:19:02.861621+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:19:11,774 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T09:19:02.861621+00:00', try_number=1, map_index=-1)
2026-02-26 17:19:11,787 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T09:19:02.861621+00:00, map_index=-1, run_start_date=2026-02-26 09:19:10.848597+00:00, run_end_date=2026-02-26 09:19:11.068214+00:00, run_duration=0.219617, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=427, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:19:05.900332+00:00, queued_by_job_id=425, pid=19878
2026-02-26 17:19:14,589 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 09:19:02.861621+00:00: manual__2026-02-26T09:19:02.861621+00:00, state:running, queued_at: 2026-02-26 09:19:02.876395+00:00. externally triggered: True> successful
2026-02-26 17:19:14,590 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 09:19:02.861621+00:00, run_id=manual__2026-02-26T09:19:02.861621+00:00, run_start_date=2026-02-26 09:19:05.876084+00:00, run_end_date=2026-02-26 09:19:14.590502+00:00, run_duration=8.714418, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:19:02.861621+00:00, data_interval_end=2026-02-26 09:19:02.861621+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 17:20:33,776 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:23:21,555 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:23:19.712615+00:00 [scheduled]>
2026-02-26 17:23:21,557 INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
2026-02-26 17:23:21,557 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:23:19.712615+00:00 [scheduled]>
2026-02-26 17:23:21,560 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:23:19.712615+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:23:21,561 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:23:19.712615+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:23:21,562 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:23:19.712615+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:23:21,565 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:23:19.712615+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:23:37,228 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:23:19.712615+00:00', try_number=1, map_index=-1)
2026-02-26 17:23:37,255 INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:23:19.712615+00:00, map_index=-1, run_start_date=2026-02-26 09:23:26.386628+00:00, run_end_date=2026-02-26 09:23:36.466096+00:00, run_duration=10.079468, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=428, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:23:21.559090+00:00, queued_by_job_id=425, pid=20063
2026-02-26 17:23:40,627 INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:23:19.712615+00:00: manual__2026-02-26T09:23:19.712615+00:00, state:running, queued_at: 2026-02-26 09:23:19.740643+00:00. externally triggered: True> successful
2026-02-26 17:23:40,628 INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:23:19.712615+00:00, run_id=manual__2026-02-26T09:23:19.712615+00:00, run_start_date=2026-02-26 09:23:21.534936+00:00, run_end_date=2026-02-26 09:23:40.628438+00:00, run_duration=19.093502, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:23:19.712615+00:00, data_interval_end=2026-02-26 09:23:19.712615+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
2026-02-26 17:25:37,520 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:25:53,430 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:25:52.125609+00:00 [scheduled]>
2026-02-26 17:25:53,431 INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
2026-02-26 17:25:53,432 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:25:52.125609+00:00 [scheduled]>
2026-02-26 17:25:53,435 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:25:52.125609+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:25:53,437 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:25:52.125609+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:25:53,438 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:25:52.125609+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:25:53,440 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:25:52.125609+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:26:13,118 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:25:52.125609+00:00', try_number=1, map_index=-1)
2026-02-26 17:26:13,130 INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:25:52.125609+00:00, map_index=-1, run_start_date=2026-02-26 09:25:57.723608+00:00, run_end_date=2026-02-26 09:26:12.391805+00:00, run_duration=14.668197, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=429, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:25:53.434696+00:00, queued_by_job_id=425, pid=20462
2026-02-26 17:26:15,814 INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:25:52.125609+00:00: manual__2026-02-26T09:25:52.125609+00:00, state:running, queued_at: 2026-02-26 09:25:52.140079+00:00. externally triggered: True> successful
2026-02-26 17:26:15,815 INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:25:52.125609+00:00, run_id=manual__2026-02-26T09:25:52.125609+00:00, run_start_date=2026-02-26 09:25:53.408264+00:00, run_end_date=2026-02-26 09:26:15.815120+00:00, run_duration=22.406856, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:25:52.125609+00:00, data_interval_end=2026-02-26 09:25:52.125609+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
2026-02-26 17:29:01,414 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:28:58.825370+00:00 [scheduled]>
2026-02-26 17:29:01,415 INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
2026-02-26 17:29:01,416 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:28:58.825370+00:00 [scheduled]>
2026-02-26 17:29:01,418 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:28:58.825370+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:29:01,419 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:28:58.825370+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:29:01,420 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:28:58.825370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:29:01,423 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:28:58.825370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:29:15,045 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:28:58.825370+00:00', try_number=1, map_index=-1)
2026-02-26 17:29:15,055 INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:28:58.825370+00:00, map_index=-1, run_start_date=2026-02-26 09:29:05.658175+00:00, run_end_date=2026-02-26 09:29:14.322106+00:00, run_duration=8.663931, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=430, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:29:01.417118+00:00, queued_by_job_id=425, pid=20605
2026-02-26 17:29:17,849 INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:28:58.825370+00:00: manual__2026-02-26T09:28:58.825370+00:00, state:running, queued_at: 2026-02-26 09:28:58.839186+00:00. externally triggered: True> successful
2026-02-26 17:29:17,850 INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:28:58.825370+00:00, run_id=manual__2026-02-26T09:28:58.825370+00:00, run_start_date=2026-02-26 09:29:01.395196+00:00, run_end_date=2026-02-26 09:29:17.849952+00:00, run_duration=16.454756, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:28:58.825370+00:00, data_interval_end=2026-02-26 09:28:58.825370+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
2026-02-26 17:30:38,892 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:30:51,531 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:30:48.672992+00:00 [scheduled]>
2026-02-26 17:30:51,532 INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
2026-02-26 17:30:51,533 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:30:48.672992+00:00 [scheduled]>
2026-02-26 17:30:51,535 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:30:48.672992+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:30:51,536 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:30:48.672992+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:30:51,537 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:30:48.672992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:30:51,539 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:30:48.672992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:31:04,638 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:30:48.672992+00:00', try_number=1, map_index=-1)
2026-02-26 17:31:04,647 INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:30:48.672992+00:00, map_index=-1, run_start_date=2026-02-26 09:30:55.601671+00:00, run_end_date=2026-02-26 09:31:03.939295+00:00, run_duration=8.337624, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=431, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:30:51.534240+00:00, queued_by_job_id=425, pid=20688
2026-02-26 17:31:08,214 INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:30:48.672992+00:00: manual__2026-02-26T09:30:48.672992+00:00, state:running, queued_at: 2026-02-26 09:30:48.686616+00:00. externally triggered: True> successful
2026-02-26 17:31:08,215 INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:30:48.672992+00:00, run_id=manual__2026-02-26T09:30:48.672992+00:00, run_start_date=2026-02-26 09:30:51.509922+00:00, run_end_date=2026-02-26 09:31:08.215109+00:00, run_duration=16.705187, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:30:48.672992+00:00, data_interval_end=2026-02-26 09:30:48.672992+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
2026-02-26 17:33:09,582 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:33:06.057914+00:00 [scheduled]>
2026-02-26 17:33:09,583 INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
2026-02-26 17:33:09,584 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:33:06.057914+00:00 [scheduled]>
2026-02-26 17:33:09,587 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:33:06.057914+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:33:09,588 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:33:06.057914+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:33:09,589 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:33:06.057914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:33:09,591 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:33:06.057914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:33:23,542 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:33:06.057914+00:00', try_number=1, map_index=-1)
2026-02-26 17:33:23,552 INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:33:06.057914+00:00, map_index=-1, run_start_date=2026-02-26 09:33:14.264776+00:00, run_end_date=2026-02-26 09:33:22.824913+00:00, run_duration=8.560137, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=432, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:33:09.585822+00:00, queued_by_job_id=425, pid=20803
2026-02-26 17:33:26,778 INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:33:06.057914+00:00: manual__2026-02-26T09:33:06.057914+00:00, state:running, queued_at: 2026-02-26 09:33:06.070241+00:00. externally triggered: True> successful
2026-02-26 17:33:26,779 INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:33:06.057914+00:00, run_id=manual__2026-02-26T09:33:06.057914+00:00, run_start_date=2026-02-26 09:33:09.557101+00:00, run_end_date=2026-02-26 09:33:26.779389+00:00, run_duration=17.222288, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:33:06.057914+00:00, data_interval_end=2026-02-26 09:33:06.057914+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
2026-02-26 17:35:42,833 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:36:55,396 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:36:52.351602+00:00 [scheduled]>
2026-02-26 17:36:55,397 INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
2026-02-26 17:36:55,398 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:36:52.351602+00:00 [scheduled]>
2026-02-26 17:36:55,400 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:36:52.351602+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:36:55,401 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:36:52.351602+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:36:55,402 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:36:52.351602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:36:55,404 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:36:52.351602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:37:14,627 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:36:52.351602+00:00', try_number=1, map_index=-1)
2026-02-26 17:37:14,638 INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:36:52.351602+00:00, map_index=-1, run_start_date=2026-02-26 09:36:59.767870+00:00, run_end_date=2026-02-26 09:37:13.936056+00:00, run_duration=14.168186, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=433, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:36:55.399337+00:00, queued_by_job_id=425, pid=21024
2026-02-26 17:37:17,858 INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:36:52.351602+00:00: manual__2026-02-26T09:36:52.351602+00:00, state:running, queued_at: 2026-02-26 09:36:52.363527+00:00. externally triggered: True> successful
2026-02-26 17:37:17,860 INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:36:52.351602+00:00, run_id=manual__2026-02-26T09:36:52.351602+00:00, run_start_date=2026-02-26 09:36:55.378814+00:00, run_end_date=2026-02-26 09:37:17.859894+00:00, run_duration=22.48108, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:36:52.351602+00:00, data_interval_end=2026-02-26 09:36:52.351602+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
2026-02-26 17:40:44,320 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:45:46,546 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:50:50,130 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:55:34,539 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:55:30.426904+00:00 [scheduled]>
2026-02-26 17:55:34,541 INFO - DAG integrated_cdrd_complete has 0/16 running and queued tasks
2026-02-26 17:55:34,542 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:55:30.426904+00:00 [scheduled]>
2026-02-26 17:55:34,545 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_complete.integrated_complete_workflow manual__2026-02-26T09:55:30.426904+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:55:34,547 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:55:30.426904+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:55:34,547 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:55:30.426904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:55:34,550 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_complete', 'integrated_complete_workflow', 'manual__2026-02-26T09:55:30.426904+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:55:55,637 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_complete', task_id='integrated_complete_workflow', run_id='manual__2026-02-26T09:55:30.426904+00:00', try_number=1, map_index=-1)
2026-02-26 17:55:55,648 INFO - TaskInstance Finished: dag_id=integrated_cdrd_complete, task_id=integrated_complete_workflow, run_id=manual__2026-02-26T09:55:30.426904+00:00, map_index=-1, run_start_date=2026-02-26 09:55:39.189077+00:00, run_end_date=2026-02-26 09:55:54.904749+00:00, run_duration=15.715672, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=434, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:55:34.543771+00:00, queued_by_job_id=425, pid=21878
2026-02-26 17:55:55,679 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 17:55:59,739 INFO - Marking run <DagRun integrated_cdrd_complete @ 2026-02-26 09:55:30.426904+00:00: manual__2026-02-26T09:55:30.426904+00:00, state:running, queued_at: 2026-02-26 09:55:30.447279+00:00. externally triggered: True> successful
2026-02-26 17:55:59,740 INFO - DagRun Finished: dag_id=integrated_cdrd_complete, execution_date=2026-02-26 09:55:30.426904+00:00, run_id=manual__2026-02-26T09:55:30.426904+00:00, run_start_date=2026-02-26 09:55:34.513486+00:00, run_end_date=2026-02-26 09:55:59.740075+00:00, run_duration=25.226589, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:55:30.426904+00:00, data_interval_end=2026-02-26 09:55:30.426904+00:00, dag_hash=633d80be9cd006931b1d97b5afa227eb
2026-02-26 17:58:29,473 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_with_independent_runs.producer_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
2026-02-26 17:58:29,474 INFO - DAG integrated_cdrd_with_independent_runs has 0/16 running and queued tasks
2026-02-26 17:58:29,475 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_with_independent_runs.producer_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
2026-02-26 17:58:29,478 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_with_independent_runs.producer_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:58:29,479 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='producer_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 17:58:29,480 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'producer_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:58:29,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'producer_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:58:35,727 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='producer_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
2026-02-26 17:58:35,737 INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=producer_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:58:34.747751+00:00, run_end_date=2026-02-26 09:58:34.980187+00:00, run_duration=0.232436, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=435, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 09:58:29.476925+00:00, queued_by_job_id=425, pid=22075
2026-02-26 17:58:38,492 INFO - 2 tasks up for execution:
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer1_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer2_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
2026-02-26 17:58:38,493 INFO - DAG integrated_cdrd_with_independent_runs has 0/16 running and queued tasks
2026-02-26 17:58:38,494 INFO - DAG integrated_cdrd_with_independent_runs has 1/16 running and queued tasks
2026-02-26 17:58:38,495 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer1_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
	<TaskInstance: integrated_cdrd_with_independent_runs.consumer2_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
2026-02-26 17:58:38,497 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_with_independent_runs.consumer1_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>, <TaskInstance: integrated_cdrd_with_independent_runs.consumer2_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:58:38,499 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer1_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 17:58:38,500 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer1_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:58:38,500 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer2_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 17:58:38,501 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer2_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:58:38,504 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer1_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:58:53,120 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'consumer2_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:59:03,601 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer1_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
2026-02-26 17:59:03,603 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='consumer2_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
2026-02-26 17:59:03,613 INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=consumer1_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:58:42.994832+00:00, run_end_date=2026-02-26 09:58:52.367581+00:00, run_duration=9.372749, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=436, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:58:38.496230+00:00, queued_by_job_id=425, pid=22082
2026-02-26 17:59:03,615 INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=consumer2_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:58:57.319721+00:00, run_end_date=2026-02-26 09:59:02.919434+00:00, run_duration=5.599713, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=437, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 09:58:38.496230+00:00, queued_by_job_id=425, pid=22117
2026-02-26 17:59:07,907 INFO - 1 tasks up for execution:
	<TaskInstance: integrated_cdrd_with_independent_runs.cleanup_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
2026-02-26 17:59:07,908 INFO - DAG integrated_cdrd_with_independent_runs has 0/16 running and queued tasks
2026-02-26 17:59:07,909 INFO - Setting the following tasks to queued state:
	<TaskInstance: integrated_cdrd_with_independent_runs.cleanup_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>
2026-02-26 17:59:07,911 INFO - Trying to enqueue tasks: [<TaskInstance: integrated_cdrd_with_independent_runs.cleanup_task manual__2026-02-26T09:58:26.764299+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 17:59:07,912 INFO - Sending TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='cleanup_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 17:59:07,913 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'cleanup_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:59:07,915 INFO - Executing command: ['airflow', 'tasks', 'run', 'integrated_cdrd_with_independent_runs', 'cleanup_task', 'manual__2026-02-26T09:58:26.764299+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 17:59:12,824 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='integrated_cdrd_with_independent_runs', task_id='cleanup_task', run_id='manual__2026-02-26T09:58:26.764299+00:00', try_number=1, map_index=-1)
2026-02-26 17:59:12,832 INFO - TaskInstance Finished: dag_id=integrated_cdrd_with_independent_runs, task_id=cleanup_task, run_id=manual__2026-02-26T09:58:26.764299+00:00, map_index=-1, run_start_date=2026-02-26 09:59:11.781586+00:00, run_end_date=2026-02-26 09:59:12.105461+00:00, run_duration=0.323875, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=438, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 09:59:07.910367+00:00, queued_by_job_id=425, pid=22141
2026-02-26 17:59:15,243 INFO - Marking run <DagRun integrated_cdrd_with_independent_runs @ 2026-02-26 09:58:26.764299+00:00: manual__2026-02-26T09:58:26.764299+00:00, state:running, queued_at: 2026-02-26 09:58:26.800040+00:00. externally triggered: True> successful
2026-02-26 17:59:15,244 INFO - DagRun Finished: dag_id=integrated_cdrd_with_independent_runs, execution_date=2026-02-26 09:58:26.764299+00:00, run_id=manual__2026-02-26T09:58:26.764299+00:00, run_start_date=2026-02-26 09:58:29.444523+00:00, run_end_date=2026-02-26 09:59:15.244322+00:00, run_duration=45.799799, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 09:58:26.764299+00:00, data_interval_end=2026-02-26 09:58:26.764299+00:00, dag_hash=1e5bdc01ec591dca6a1f6624a26306df
2026-02-26 18:00:56,129 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 18:02:41,710 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.producer_task manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
2026-02-26 18:02:41,711 INFO - DAG cdrd_test_workflow_with_independent_tasks has 0/16 running and queued tasks
2026-02-26 18:02:41,712 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.producer_task manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
2026-02-26 18:02:41,714 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_workflow_with_independent_tasks.producer_task manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:02:41,715 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='producer_task', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-26 18:02:41,716 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'producer_task', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:02:41,719 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'producer_task', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:02:46,869 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='producer_task', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
2026-02-26 18:02:46,882 INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=producer_task, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:02:45.821678+00:00, run_end_date=2026-02-26 10:02:46.043749+00:00, run_duration=0.222071, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=439, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-26 10:02:41.713828+00:00, queued_by_job_id=425, pid=22275
2026-02-26 18:02:51,462 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_user_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_role_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
2026-02-26 18:02:51,463 INFO - DAG cdrd_test_workflow_with_independent_tasks has 0/16 running and queued tasks
2026-02-26 18:02:51,464 INFO - DAG cdrd_test_workflow_with_independent_tasks has 1/16 running and queued tasks
2026-02-26 18:02:51,465 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_user_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_role_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
2026-02-26 18:02:51,467 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_user_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>, <TaskInstance: cdrd_test_workflow_with_independent_tasks.consumer_role_management manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:02:51,468 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_user_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 18:02:51,469 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_user_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:02:51,470 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_role_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-26 18:02:51,471 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_role_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:02:51,473 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_user_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:03:03,643 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'consumer_role_management', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:03:14,915 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_user_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
2026-02-26 18:03:14,917 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='consumer_role_management', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
2026-02-26 18:03:14,925 INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=consumer_role_management, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:03:07.534513+00:00, run_end_date=2026-02-26 10:03:14.076970+00:00, run_duration=6.542457, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=441, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 10:02:51.466396+00:00, queued_by_job_id=425, pid=22314
2026-02-26 18:03:14,927 INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=consumer_user_management, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:02:55.328205+00:00, run_end_date=2026-02-26 10:03:02.908759+00:00, run_duration=7.580554, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=440, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-26 10:02:51.466396+00:00, queued_by_job_id=425, pid=22278
2026-02-26 18:03:18,251 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.final_cleanup manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
2026-02-26 18:03:18,253 INFO - DAG cdrd_test_workflow_with_independent_tasks has 0/16 running and queued tasks
2026-02-26 18:03:18,253 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_workflow_with_independent_tasks.final_cleanup manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>
2026-02-26 18:03:18,256 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_workflow_with_independent_tasks.final_cleanup manual__2026-02-26T10:02:37.803650+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:03:18,257 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='final_cleanup', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:03:18,258 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'final_cleanup', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:03:18,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_workflow_with_independent_tasks', 'final_cleanup', 'manual__2026-02-26T10:02:37.803650+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:03:24,914 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_workflow_with_independent_tasks', task_id='final_cleanup', run_id='manual__2026-02-26T10:02:37.803650+00:00', try_number=1, map_index=-1)
2026-02-26 18:03:24,924 INFO - TaskInstance Finished: dag_id=cdrd_test_workflow_with_independent_tasks, task_id=final_cleanup, run_id=manual__2026-02-26T10:02:37.803650+00:00, map_index=-1, run_start_date=2026-02-26 10:03:23.580842+00:00, run_end_date=2026-02-26 10:03:24.171679+00:00, run_duration=0.590837, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=442, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:03:18.255347+00:00, queued_by_job_id=425, pid=22348
2026-02-26 18:03:28,335 INFO - Marking run <DagRun cdrd_test_workflow_with_independent_tasks @ 2026-02-26 10:02:37.803650+00:00: manual__2026-02-26T10:02:37.803650+00:00, state:running, queued_at: 2026-02-26 10:02:37.831036+00:00. externally triggered: True> successful
2026-02-26 18:03:28,336 INFO - DagRun Finished: dag_id=cdrd_test_workflow_with_independent_tasks, execution_date=2026-02-26 10:02:37.803650+00:00, run_id=manual__2026-02-26T10:02:37.803650+00:00, run_start_date=2026-02-26 10:02:41.685169+00:00, run_end_date=2026-02-26 10:03:28.336284+00:00, run_duration=46.651115, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:02:37.803650+00:00, data_interval_end=2026-02-26 10:02:37.803650+00:00, dag_hash=1bb173a514cce065a7a973b3d6c02328
2026-02-26 18:05:59,527 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 18:11:01,105 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 18:11:38,087 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:11:35.192872+00:00 [scheduled]>
2026-02-26 18:11:38,088 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 18:11:38,089 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:11:35.192872+00:00 [scheduled]>
2026-02-26 18:11:38,091 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:11:35.192872+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:11:38,092 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:11:35.192872+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:11:38,093 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:11:35.192872+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:11:38,095 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:11:35.192872+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:11:43,385 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:11:35.192872+00:00', try_number=1, map_index=-1)
2026-02-26 18:11:43,395 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T10:11:35.192872+00:00, map_index=-1, run_start_date=2026-02-26 10:11:42.449152+00:00, run_end_date=2026-02-26 10:11:42.667490+00:00, run_duration=0.218338, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=443, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:11:38.090361+00:00, queued_by_job_id=425, pid=22671
2026-02-26 18:11:46,100 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 10:11:35.192872+00:00: manual__2026-02-26T10:11:35.192872+00:00, state:running, queued_at: 2026-02-26 10:11:35.206413+00:00. externally triggered: True> successful
2026-02-26 18:11:46,101 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 10:11:35.192872+00:00, run_id=manual__2026-02-26T10:11:35.192872+00:00, run_start_date=2026-02-26 10:11:38.064783+00:00, run_end_date=2026-02-26 10:11:46.101176+00:00, run_duration=8.036393, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:11:35.192872+00:00, data_interval_end=2026-02-26 10:11:35.192872+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 18:11:46,112 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:11:42.687993+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:11:42.689631+00:00 [scheduled]>
2026-02-26 18:11:46,112 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-26 18:11:46,113 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-26 18:11:46,114 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:11:42.687993+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:11:42.689631+00:00 [scheduled]>
2026-02-26 18:11:46,118 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:11:42.687993+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:11:42.689631+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:11:46,119 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:11:42.687993+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:11:46,119 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:11:42.687993+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:11:46,120 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:11:42.689631+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:11:46,121 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:11:42.689631+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:11:46,123 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:11:42.687993+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:11:59,723 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:11:42.689631+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:12:10,300 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:11:42.687993+00:00', try_number=1, map_index=-1)
2026-02-26 18:12:10,302 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:11:42.689631+00:00', try_number=1, map_index=-1)
2026-02-26 18:12:10,315 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T10:11:42.687993+00:00, map_index=-1, run_start_date=2026-02-26 10:11:50.111229+00:00, run_end_date=2026-02-26 10:11:58.961118+00:00, run_duration=8.849889, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=444, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:11:46.115954+00:00, queued_by_job_id=425, pid=22674
2026-02-26 18:12:10,316 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T10:11:42.689631+00:00, map_index=-1, run_start_date=2026-02-26 10:12:03.986567+00:00, run_end_date=2026-02-26 10:12:09.559449+00:00, run_duration=5.572882, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=445, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:11:46.115954+00:00, queued_by_job_id=425, pid=22707
2026-02-26 18:12:13,355 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 10:11:42.687993+00:00: dataset_triggered__2026-02-26T10:11:42.687993+00:00, state:running, queued_at: 2026-02-26 10:11:46.061430+00:00. externally triggered: False> successful
2026-02-26 18:12:13,357 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 10:11:42.687993+00:00, run_id=dataset_triggered__2026-02-26T10:11:42.687993+00:00, run_start_date=2026-02-26 10:11:46.081481+00:00, run_end_date=2026-02-26 10:12:13.356796+00:00, run_duration=27.275315, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:27:07.816788+00:00, data_interval_end=2026-02-26 10:11:35.192872+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-26 18:12:13,362 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 10:11:42.689631+00:00: dataset_triggered__2026-02-26T10:11:42.689631+00:00, state:running, queued_at: 2026-02-26 10:11:46.043180+00:00. externally triggered: False> successful
2026-02-26 18:12:13,363 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 10:11:42.689631+00:00, run_id=dataset_triggered__2026-02-26T10:11:42.689631+00:00, run_start_date=2026-02-26 10:11:46.081582+00:00, run_end_date=2026-02-26 10:12:13.363559+00:00, run_duration=27.281977, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-24 07:27:07.816788+00:00, data_interval_end=2026-02-26 10:11:35.192872+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-26 18:13:47,203 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:13:46.477363+00:00 [scheduled]>
2026-02-26 18:13:47,204 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 18:13:47,205 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:13:46.477363+00:00 [scheduled]>
2026-02-26 18:13:47,207 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:13:46.477363+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:13:47,208 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:13:46.477363+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:13:47,209 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:13:46.477363+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:13:47,212 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:13:46.477363+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:13:52,254 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:13:46.477363+00:00', try_number=1, map_index=-1)
2026-02-26 18:13:52,263 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T10:13:46.477363+00:00, map_index=-1, run_start_date=2026-02-26 10:13:51.285716+00:00, run_end_date=2026-02-26 10:13:51.494609+00:00, run_duration=0.208893, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=446, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:13:47.206495+00:00, queued_by_job_id=425, pid=22788
2026-02-26 18:13:55,035 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 10:13:46.477363+00:00: manual__2026-02-26T10:13:46.477363+00:00, state:running, queued_at: 2026-02-26 10:13:46.491611+00:00. externally triggered: True> successful
2026-02-26 18:13:55,036 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 10:13:46.477363+00:00, run_id=manual__2026-02-26T10:13:46.477363+00:00, run_start_date=2026-02-26 10:13:47.182933+00:00, run_end_date=2026-02-26 10:13:55.036148+00:00, run_duration=7.853215, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:13:46.477363+00:00, data_interval_end=2026-02-26 10:13:46.477363+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 18:13:55,046 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:13:51.514442+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:13:51.515976+00:00 [scheduled]>
2026-02-26 18:13:55,047 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-26 18:13:55,048 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-26 18:13:55,049 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:13:51.514442+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:13:51.515976+00:00 [scheduled]>
2026-02-26 18:13:55,052 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:13:51.514442+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:13:51.515976+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:13:55,053 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:13:51.514442+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:13:55,054 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:13:51.514442+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:13:55,054 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:13:51.515976+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:13:55,055 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:13:51.515976+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:13:55,058 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:13:51.514442+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:14:06,960 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:13:51.515976+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:14:17,371 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:13:51.514442+00:00', try_number=1, map_index=-1)
2026-02-26 18:14:17,374 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:13:51.515976+00:00', try_number=1, map_index=-1)
2026-02-26 18:14:17,382 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T10:13:51.514442+00:00, map_index=-1, run_start_date=2026-02-26 10:13:58.903337+00:00, run_end_date=2026-02-26 10:14:06.181138+00:00, run_duration=7.277801, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=447, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:13:55.050809+00:00, queued_by_job_id=425, pid=22791
2026-02-26 18:14:17,384 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T10:13:51.515976+00:00, map_index=-1, run_start_date=2026-02-26 10:14:10.982615+00:00, run_end_date=2026-02-26 10:14:16.638278+00:00, run_duration=5.655663, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=448, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:13:55.050809+00:00, queued_by_job_id=425, pid=22823
2026-02-26 18:14:20,984 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 10:13:51.514442+00:00: dataset_triggered__2026-02-26T10:13:51.514442+00:00, state:running, queued_at: 2026-02-26 10:13:54.992674+00:00. externally triggered: False> successful
2026-02-26 18:14:20,985 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 10:13:51.514442+00:00, run_id=dataset_triggered__2026-02-26T10:13:51.514442+00:00, run_start_date=2026-02-26 10:13:55.017108+00:00, run_end_date=2026-02-26 10:14:20.985241+00:00, run_duration=25.968133, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:13:46.477363+00:00, data_interval_end=2026-02-26 10:13:46.477363+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-26 18:14:20,990 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 10:13:51.515976+00:00: dataset_triggered__2026-02-26T10:13:51.515976+00:00, state:running, queued_at: 2026-02-26 10:13:55.001387+00:00. externally triggered: False> successful
2026-02-26 18:14:20,991 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 10:13:51.515976+00:00, run_id=dataset_triggered__2026-02-26T10:13:51.515976+00:00, run_start_date=2026-02-26 10:13:55.017241+00:00, run_end_date=2026-02-26 10:14:20.991236+00:00, run_duration=25.973995, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:13:46.477363+00:00, data_interval_end=2026-02-26 10:13:46.477363+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-26 18:15:01,152 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:14:58.421790+00:00 [scheduled]>
2026-02-26 18:15:01,153 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-26 18:15:01,153 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:14:58.421790+00:00 [scheduled]>
2026-02-26 18:15:01,156 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-26T10:14:58.421790+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:15:01,157 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:14:58.421790+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:15:01,158 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:14:58.421790+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:15:01,160 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-26T10:14:58.421790+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:15:05,888 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-26T10:14:58.421790+00:00', try_number=1, map_index=-1)
2026-02-26 18:15:05,898 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-26T10:14:58.421790+00:00, map_index=-1, run_start_date=2026-02-26 10:15:04.963941+00:00, run_end_date=2026-02-26 10:15:05.177699+00:00, run_duration=0.213758, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=449, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:15:01.155020+00:00, queued_by_job_id=425, pid=22876
2026-02-26 18:15:08,465 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-26 10:14:58.421790+00:00: manual__2026-02-26T10:14:58.421790+00:00, state:running, queued_at: 2026-02-26 10:14:58.434417+00:00. externally triggered: True> successful
2026-02-26 18:15:08,466 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-26 10:14:58.421790+00:00, run_id=manual__2026-02-26T10:14:58.421790+00:00, run_start_date=2026-02-26 10:15:01.132725+00:00, run_end_date=2026-02-26 10:15:08.466053+00:00, run_duration=7.333328, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-26 10:14:58.421790+00:00, data_interval_end=2026-02-26 10:14:58.421790+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-26 18:15:08,476 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:15:05.197117+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:15:05.199047+00:00 [scheduled]>
2026-02-26 18:15:08,477 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-26 18:15:08,478 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-26 18:15:08,479 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:15:05.197117+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:15:05.199047+00:00 [scheduled]>
2026-02-26 18:15:08,482 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-26T10:15:05.197117+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-26T10:15:05.199047+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-26 18:15:08,483 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:15:05.197117+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:15:08,484 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:15:05.197117+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:15:08,484 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:15:05.199047+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-26 18:15:08,485 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:15:05.199047+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:15:08,488 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-26T10:15:05.197117+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:15:18,715 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-26T10:15:05.199047+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-26 18:15:30,453 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-26T10:15:05.197117+00:00', try_number=1, map_index=-1)
2026-02-26 18:15:30,457 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-26T10:15:05.199047+00:00', try_number=1, map_index=-1)
2026-02-26 18:15:30,466 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-26T10:15:05.199047+00:00, map_index=-1, run_start_date=2026-02-26 10:15:22.675918+00:00, run_end_date=2026-02-26 10:15:29.724573+00:00, run_duration=7.048655, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=451, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:15:08.480731+00:00, queued_by_job_id=425, pid=22918
2026-02-26 18:15:30,468 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-26T10:15:05.197117+00:00, map_index=-1, run_start_date=2026-02-26 10:15:12.386991+00:00, run_end_date=2026-02-26 10:15:17.997438+00:00, run_duration=5.610447, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=450, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-26 10:15:08.480731+00:00, queued_by_job_id=425, pid=22879
2026-02-26 18:15:34,562 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-26 10:15:05.197117+00:00: dataset_triggered__2026-02-26T10:15:05.197117+00:00, state:running, queued_at: 2026-02-26 10:15:08.426699+00:00. externally triggered: False> successful
2026-02-26 18:15:34,563 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-26 10:15:05.197117+00:00, run_id=dataset_triggered__2026-02-26T10:15:05.197117+00:00, run_start_date=2026-02-26 10:15:08.447841+00:00, run_end_date=2026-02-26 10:15:34.563610+00:00, run_duration=26.115769, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:14:58.421790+00:00, data_interval_end=2026-02-26 10:14:58.421790+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-26 18:15:34,570 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-26 10:15:05.199047+00:00: dataset_triggered__2026-02-26T10:15:05.199047+00:00, state:running, queued_at: 2026-02-26 10:15:08.435296+00:00. externally triggered: False> successful
2026-02-26 18:15:34,571 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-26 10:15:05.199047+00:00, run_id=dataset_triggered__2026-02-26T10:15:05.199047+00:00, run_start_date=2026-02-26 10:15:08.447961+00:00, run_end_date=2026-02-26 10:15:34.571336+00:00, run_duration=26.123375, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-26 10:14:58.421790+00:00, data_interval_end=2026-02-26 10:14:58.421790+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-26 18:16:01,321 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-26 18:17:57,396 INFO - Exiting gracefully upon receiving signal 15
2026-02-26 18:17:58,237 INFO - Sending Signals.SIGTERM to group 19721. PIDs of all processes in the group: []
2026-02-26 18:17:58,239 INFO - Sending the signal Signals.SIGTERM to group 19721
2026-02-26 18:17:58,239 INFO - Sending the signal Signals.SIGTERM to process 19721 as process group is missing.
2026-02-26 18:17:58,249 INFO - Sending Signals.SIGTERM to group 19721. PIDs of all processes in the group: []
2026-02-26 18:17:58,250 INFO - Sending the signal Signals.SIGTERM to group 19721
2026-02-26 18:17:58,251 INFO - Sending the signal Signals.SIGTERM to process 19721 as process group is missing.
2026-02-26 18:17:58,251 INFO - Exited execute loop
2026-02-27 08:41:30,020 INFO - Loaded executor: SequentialExecutor
2026-02-27 08:41:31,386 INFO - Starting the scheduler
2026-02-27 08:41:31,388 INFO - Processing each file at most -1 times
2026-02-27 08:41:31,411 INFO - Launched DagFileProcessorManager with pid: 987
2026-02-27 08:41:31,420 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 08:42:20,955 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:42:14.713369+00:00 [scheduled]>
2026-02-27 08:42:20,957 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-27 08:42:20,958 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:42:14.713369+00:00 [scheduled]>
2026-02-27 08:42:21,176 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:42:14.713369+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 08:42:21,178 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-27T00:42:14.713369+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:42:21,179 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-27T00:42:14.713369+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:42:21,182 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-27T00:42:14.713369+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:42:32,346 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-27T00:42:14.713369+00:00', try_number=1, map_index=-1)
2026-02-27 08:42:32,366 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-27T00:42:14.713369+00:00, map_index=-1, run_start_date=2026-02-27 00:42:31.350452+00:00, run_end_date=2026-02-27 00:42:31.558278+00:00, run_duration=0.207826, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=453, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:42:20.960852+00:00, queued_by_job_id=452, pid=1266
2026-02-27 08:42:32,390 INFO - Heartbeat recovered after 62.38 seconds
2026-02-27 08:42:35,267 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-27 00:42:14.713369+00:00: manual__2026-02-27T00:42:14.713369+00:00, state:running, queued_at: 2026-02-27 00:42:14.793795+00:00. externally triggered: True> successful
2026-02-27 08:42:35,268 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-27 00:42:14.713369+00:00, run_id=manual__2026-02-27T00:42:14.713369+00:00, run_start_date=2026-02-27 00:42:20.880105+00:00, run_end_date=2026-02-27 00:42:35.268832+00:00, run_duration=14.388727, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 00:42:14.713369+00:00, data_interval_end=2026-02-27 00:42:14.713369+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-27 08:43:55,369 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:42:31.581218+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:42:31.583419+00:00 [scheduled]>
2026-02-27 08:43:55,370 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-27 08:43:55,371 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-27 08:43:55,371 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:42:31.581218+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:42:31.583419+00:00 [scheduled]>
2026-02-27 08:43:55,375 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:42:31.581218+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:42:31.583419+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 08:43:55,376 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-27T00:42:31.581218+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:43:55,376 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-27T00:42:31.581218+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:43:55,377 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-27T00:42:31.583419+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:43:55,378 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-27T00:42:31.583419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:43:55,380 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-27T00:42:31.581218+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:44:15,446 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-27T00:42:31.583419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:44:27,730 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-27T00:42:31.581218+00:00', try_number=1, map_index=-1)
2026-02-27 08:44:27,733 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-27T00:42:31.583419+00:00', try_number=1, map_index=-1)
2026-02-27 08:44:27,747 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-27T00:42:31.583419+00:00, map_index=-1, run_start_date=2026-02-27 00:44:20.021525+00:00, run_end_date=2026-02-27 00:44:27.044784+00:00, run_duration=7.023259, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=455, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:43:55.373354+00:00, queued_by_job_id=452, pid=1483
2026-02-27 08:44:27,748 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-27T00:42:31.581218+00:00, map_index=-1, run_start_date=2026-02-27 00:43:59.609418+00:00, run_end_date=2026-02-27 00:44:14.750576+00:00, run_duration=15.141158, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=454, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:43:55.373354+00:00, queued_by_job_id=452, pid=1416
2026-02-27 08:44:27,770 INFO - Heartbeat recovered after 37.98 seconds
2026-02-27 08:44:30,055 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-27 00:42:31.581218+00:00: dataset_triggered__2026-02-27T00:42:31.581218+00:00, state:running, queued_at: 2026-02-27 00:43:55.328948+00:00. externally triggered: False> successful
2026-02-27 08:44:30,056 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-27 00:42:31.581218+00:00, run_id=dataset_triggered__2026-02-27T00:42:31.581218+00:00, run_start_date=2026-02-27 00:43:55.342854+00:00, run_end_date=2026-02-27 00:44:30.056403+00:00, run_duration=34.713549, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-27 00:42:14.713369+00:00, data_interval_end=2026-02-27 00:42:14.713369+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-27 08:44:30,061 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-27 00:42:31.583419+00:00: dataset_triggered__2026-02-27T00:42:31.583419+00:00, state:running, queued_at: 2026-02-27 00:43:55.315007+00:00. externally triggered: False> successful
2026-02-27 08:44:30,063 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-27 00:42:31.583419+00:00, run_id=dataset_triggered__2026-02-27T00:42:31.583419+00:00, run_start_date=2026-02-27 00:43:55.342988+00:00, run_end_date=2026-02-27 00:44:30.063094+00:00, run_duration=34.720106, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-27 00:42:14.713369+00:00, data_interval_end=2026-02-27 00:42:14.713369+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-27 08:45:02,157 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:44:59.124689+00:00 [scheduled]>
2026-02-27 08:45:02,158 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-27 08:45:02,159 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:44:59.124689+00:00 [scheduled]>
2026-02-27 08:45:02,161 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:44:59.124689+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 08:45:02,162 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-27T00:44:59.124689+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:45:02,162 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-27T00:44:59.124689+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:45:02,165 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-27T00:44:59.124689+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:45:06,867 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-27T00:44:59.124689+00:00', try_number=1, map_index=-1)
2026-02-27 08:45:06,879 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-27T00:44:59.124689+00:00, map_index=-1, run_start_date=2026-02-27 00:45:05.962116+00:00, run_end_date=2026-02-27 00:45:06.177266+00:00, run_duration=0.21515, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=456, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:45:02.159932+00:00, queued_by_job_id=452, pid=1588
2026-02-27 08:45:09,560 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-27 00:44:59.124689+00:00: manual__2026-02-27T00:44:59.124689+00:00, state:running, queued_at: 2026-02-27 00:44:59.139511+00:00. externally triggered: True> successful
2026-02-27 08:45:09,568 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-27 00:44:59.124689+00:00, run_id=manual__2026-02-27T00:44:59.124689+00:00, run_start_date=2026-02-27 00:45:02.138621+00:00, run_end_date=2026-02-27 00:45:09.567672+00:00, run_duration=7.429051, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 00:44:59.124689+00:00, data_interval_end=2026-02-27 00:44:59.124689+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-27 08:45:09,590 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:45:06.196737+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:45:06.198341+00:00 [scheduled]>
2026-02-27 08:45:09,591 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-27 08:45:09,592 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-27 08:45:09,593 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:45:06.196737+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:45:06.198341+00:00 [scheduled]>
2026-02-27 08:45:09,596 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:45:06.196737+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:45:06.198341+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 08:45:09,597 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-27T00:45:06.196737+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:45:09,597 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-27T00:45:06.196737+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:45:09,598 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-27T00:45:06.198341+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:45:09,599 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-27T00:45:06.198341+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:45:09,601 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-27T00:45:06.196737+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:45:20,870 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-27T00:45:06.198341+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:45:30,528 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-27T00:45:06.196737+00:00', try_number=1, map_index=-1)
2026-02-27 08:45:30,531 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-27T00:45:06.198341+00:00', try_number=1, map_index=-1)
2026-02-27 08:45:30,540 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-27T00:45:06.196737+00:00, map_index=-1, run_start_date=2026-02-27 00:45:13.370969+00:00, run_end_date=2026-02-27 00:45:20.141377+00:00, run_duration=6.770408, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=457, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:45:09.594632+00:00, queued_by_job_id=452, pid=1593
2026-02-27 08:45:30,542 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-27T00:45:06.198341+00:00, map_index=-1, run_start_date=2026-02-27 00:45:24.683707+00:00, run_end_date=2026-02-27 00:45:29.860493+00:00, run_duration=5.176786, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=458, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:45:09.594632+00:00, queued_by_job_id=452, pid=1613
2026-02-27 08:45:33,066 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-27 00:45:06.196737+00:00: dataset_triggered__2026-02-27T00:45:06.196737+00:00, state:running, queued_at: 2026-02-27 00:45:09.524380+00:00. externally triggered: False> successful
2026-02-27 08:45:33,067 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-27 00:45:06.196737+00:00, run_id=dataset_triggered__2026-02-27T00:45:06.196737+00:00, run_start_date=2026-02-27 00:45:09.536887+00:00, run_end_date=2026-02-27 00:45:33.067302+00:00, run_duration=23.530415, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-27 00:44:59.124689+00:00, data_interval_end=2026-02-27 00:44:59.124689+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-27 08:45:33,072 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-27 00:45:06.198341+00:00: dataset_triggered__2026-02-27T00:45:06.198341+00:00, state:running, queued_at: 2026-02-27 00:45:09.516710+00:00. externally triggered: False> successful
2026-02-27 08:45:33,072 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-27 00:45:06.198341+00:00, run_id=dataset_triggered__2026-02-27T00:45:06.198341+00:00, run_start_date=2026-02-27 00:45:09.537464+00:00, run_end_date=2026-02-27 00:45:33.072836+00:00, run_duration=23.535372, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-27 00:44:59.124689+00:00, data_interval_end=2026-02-27 00:44:59.124689+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-27 08:46:32,176 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 08:51:35,299 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 08:55:20,292 INFO - 1 tasks up for execution:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:55:16.247146+00:00 [scheduled]>
2026-02-27 08:55:20,293 INFO - DAG p_cdrd_all has 0/16 running and queued tasks
2026-02-27 08:55:20,295 INFO - Setting the following tasks to queued state:
	<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:55:16.247146+00:00 [scheduled]>
2026-02-27 08:55:20,298 INFO - Trying to enqueue tasks: [<TaskInstance: p_cdrd_all.p_cdrd_TASK manual__2026-02-27T00:55:16.247146+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 08:55:20,300 INFO - Sending TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-27T00:55:16.247146+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:55:20,301 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-27T00:55:16.247146+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:55:20,304 INFO - Executing command: ['airflow', 'tasks', 'run', 'p_cdrd_all', 'p_cdrd_TASK', 'manual__2026-02-27T00:55:16.247146+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:55:25,309 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='p_cdrd_all', task_id='p_cdrd_TASK', run_id='manual__2026-02-27T00:55:16.247146+00:00', try_number=1, map_index=-1)
2026-02-27 08:55:25,320 INFO - TaskInstance Finished: dag_id=p_cdrd_all, task_id=p_cdrd_TASK, run_id=manual__2026-02-27T00:55:16.247146+00:00, map_index=-1, run_start_date=2026-02-27 00:55:24.272669+00:00, run_end_date=2026-02-27 00:55:24.544993+00:00, run_duration=0.272324, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=459, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:55:20.297083+00:00, queued_by_job_id=452, pid=2094
2026-02-27 08:55:29,103 INFO - Marking run <DagRun p_cdrd_all @ 2026-02-27 00:55:16.247146+00:00: manual__2026-02-27T00:55:16.247146+00:00, state:running, queued_at: 2026-02-27 00:55:16.266577+00:00. externally triggered: True> successful
2026-02-27 08:55:29,104 INFO - DagRun Finished: dag_id=p_cdrd_all, execution_date=2026-02-27 00:55:16.247146+00:00, run_id=manual__2026-02-27T00:55:16.247146+00:00, run_start_date=2026-02-27 00:55:20.268175+00:00, run_end_date=2026-02-27 00:55:29.104476+00:00, run_duration=8.836301, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 00:55:16.247146+00:00, data_interval_end=2026-02-27 00:55:16.247146+00:00, dag_hash=31f0b1d27cd6427bd9d93a3a1e5971d5
2026-02-27 08:55:29,114 INFO - 2 tasks up for execution:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:55:24.562708+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:55:24.564056+00:00 [scheduled]>
2026-02-27 08:55:29,116 INFO - DAG c_cdrd_DAG2 has 0/16 running and queued tasks
2026-02-27 08:55:29,117 INFO - DAG c_cdrd_DAG1 has 0/16 running and queued tasks
2026-02-27 08:55:29,117 INFO - Setting the following tasks to queued state:
	<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:55:24.562708+00:00 [scheduled]>
	<TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:55:24.564056+00:00 [scheduled]>
2026-02-27 08:55:29,120 INFO - Trying to enqueue tasks: [<TaskInstance: c_cdrd_DAG2.c_cdrd_TASK2 dataset_triggered__2026-02-27T00:55:24.562708+00:00 [scheduled]>, <TaskInstance: c_cdrd_DAG1.c_cdrd_TASK1 dataset_triggered__2026-02-27T00:55:24.564056+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 08:55:29,121 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-27T00:55:24.562708+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:55:29,122 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-27T00:55:24.562708+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:55:29,123 INFO - Sending TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-27T00:55:24.564056+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 08:55:29,123 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-27T00:55:24.564056+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:55:29,126 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG2', 'c_cdrd_TASK2', 'dataset_triggered__2026-02-27T00:55:24.562708+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:55:40,795 INFO - Executing command: ['airflow', 'tasks', 'run', 'c_cdrd_DAG1', 'c_cdrd_TASK1', 'dataset_triggered__2026-02-27T00:55:24.564056+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 08:55:52,416 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG2', task_id='c_cdrd_TASK2', run_id='dataset_triggered__2026-02-27T00:55:24.562708+00:00', try_number=1, map_index=-1)
2026-02-27 08:55:52,419 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='c_cdrd_DAG1', task_id='c_cdrd_TASK1', run_id='dataset_triggered__2026-02-27T00:55:24.564056+00:00', try_number=1, map_index=-1)
2026-02-27 08:55:52,427 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG1, task_id=c_cdrd_TASK1, run_id=dataset_triggered__2026-02-27T00:55:24.564056+00:00, map_index=-1, run_start_date=2026-02-27 00:55:44.828170+00:00, run_end_date=2026-02-27 00:55:51.707992+00:00, run_duration=6.879822, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=461, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:55:29.119288+00:00, queued_by_job_id=452, pid=2119
2026-02-27 08:55:52,429 INFO - TaskInstance Finished: dag_id=c_cdrd_DAG2, task_id=c_cdrd_TASK2, run_id=dataset_triggered__2026-02-27T00:55:24.562708+00:00, map_index=-1, run_start_date=2026-02-27 00:55:33.169840+00:00, run_end_date=2026-02-27 00:55:40.042132+00:00, run_duration=6.872292, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=460, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 00:55:29.119288+00:00, queued_by_job_id=452, pid=2097
2026-02-27 08:55:54,960 INFO - Marking run <DagRun c_cdrd_DAG2 @ 2026-02-27 00:55:24.562708+00:00: dataset_triggered__2026-02-27T00:55:24.562708+00:00, state:running, queued_at: 2026-02-27 00:55:29.073204+00:00. externally triggered: False> successful
2026-02-27 08:55:54,961 INFO - DagRun Finished: dag_id=c_cdrd_DAG2, execution_date=2026-02-27 00:55:24.562708+00:00, run_id=dataset_triggered__2026-02-27T00:55:24.562708+00:00, run_start_date=2026-02-27 00:55:29.085961+00:00, run_end_date=2026-02-27 00:55:54.961708+00:00, run_duration=25.875747, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-27 00:55:16.247146+00:00, data_interval_end=2026-02-27 00:55:16.247146+00:00, dag_hash=444c5e97aa01ab2bb546ff4efd4e38ce
2026-02-27 08:55:54,967 INFO - Marking run <DagRun c_cdrd_DAG1 @ 2026-02-27 00:55:24.564056+00:00: dataset_triggered__2026-02-27T00:55:24.564056+00:00, state:running, queued_at: 2026-02-27 00:55:29.063135+00:00. externally triggered: False> successful
2026-02-27 08:55:54,968 INFO - DagRun Finished: dag_id=c_cdrd_DAG1, execution_date=2026-02-27 00:55:24.564056+00:00, run_id=dataset_triggered__2026-02-27T00:55:24.564056+00:00, run_start_date=2026-02-27 00:55:29.086092+00:00, run_end_date=2026-02-27 00:55:54.968357+00:00, run_duration=25.882265, state=success, external_trigger=False, run_type=dataset_triggered, data_interval_start=2026-02-27 00:55:16.247146+00:00, data_interval_end=2026-02-27 00:55:16.247146+00:00, dag_hash=af1feaa302aaa0e787b1bb57574d57b5
2026-02-27 08:56:37,729 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:01:40,079 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:06:40,528 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:06:44,248 INFO - 1 tasks up for execution:
	<TaskInstance: main_cdrd_coordinator.trigger_producer manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:06:44,250 INFO - DAG main_cdrd_coordinator has 0/16 running and queued tasks
2026-02-27 09:06:44,251 INFO - Setting the following tasks to queued state:
	<TaskInstance: main_cdrd_coordinator.trigger_producer manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:06:44,253 INFO - Trying to enqueue tasks: [<TaskInstance: main_cdrd_coordinator.trigger_producer manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:06:44,254 INFO - Sending TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_producer', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2026-02-27 09:06:44,255 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_producer', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:06:44,258 INFO - Executing command: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_producer', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:06:49,078 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_producer', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1)
2026-02-27 09:06:49,089 INFO - TaskInstance Finished: dag_id=main_cdrd_coordinator, task_id=trigger_producer, run_id=manual__2026-02-27T01:06:36.749354+00:00, map_index=-1, run_start_date=2026-02-27 01:06:48.160783+00:00, run_end_date=2026-02-27 01:06:48.356003+00:00, run_duration=0.19522, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=462, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2026-02-27 01:06:44.252343+00:00, queued_by_job_id=452, pid=2484
2026-02-27 09:06:51,902 INFO - 1 tasks up for execution:
	<TaskInstance: main_cdrd_coordinator.wait_producer manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:06:51,903 INFO - DAG main_cdrd_coordinator has 0/16 running and queued tasks
2026-02-27 09:06:51,904 INFO - Setting the following tasks to queued state:
	<TaskInstance: main_cdrd_coordinator.wait_producer manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:06:51,907 INFO - Trying to enqueue tasks: [<TaskInstance: main_cdrd_coordinator.wait_producer manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:06:51,908 INFO - Sending TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='wait_producer', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 09:06:51,909 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'wait_producer', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:06:51,911 INFO - Executing command: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'wait_producer', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:06:56,673 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='wait_producer', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1)
2026-02-27 09:06:56,685 INFO - TaskInstance Finished: dag_id=main_cdrd_coordinator, task_id=wait_producer, run_id=manual__2026-02-27T01:06:36.749354+00:00, map_index=-1, run_start_date=2026-02-27 01:06:55.698046+00:00, run_end_date=2026-02-27 01:06:55.896349+00:00, run_duration=0.198303, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=463, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 01:06:51.905724+00:00, queued_by_job_id=452, pid=2487
2026-02-27 09:06:59,313 INFO - 1 tasks up for execution:
	<TaskInstance: main_cdrd_coordinator.trigger_consumers manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:06:59,314 INFO - DAG main_cdrd_coordinator has 0/16 running and queued tasks
2026-02-27 09:06:59,314 INFO - Setting the following tasks to queued state:
	<TaskInstance: main_cdrd_coordinator.trigger_consumers manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:06:59,317 INFO - Trying to enqueue tasks: [<TaskInstance: main_cdrd_coordinator.trigger_consumers manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:06:59,318 INFO - Sending TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_consumers', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 09:06:59,319 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_consumers', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:06:59,321 INFO - Executing command: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_consumers', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:07:04,041 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_consumers', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1)
2026-02-27 09:07:04,052 INFO - TaskInstance Finished: dag_id=main_cdrd_coordinator, task_id=trigger_consumers, run_id=manual__2026-02-27T01:06:36.749354+00:00, map_index=-1, run_start_date=2026-02-27 01:07:03.084041+00:00, run_end_date=2026-02-27 01:07:03.280671+00:00, run_duration=0.19663, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=464, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 01:06:59.315866+00:00, queued_by_job_id=452, pid=2493
2026-02-27 09:07:06,632 INFO - 1 tasks up for execution:
	<TaskInstance: main_cdrd_coordinator.wait_consumers manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:07:06,633 INFO - DAG main_cdrd_coordinator has 0/16 running and queued tasks
2026-02-27 09:07:06,634 INFO - Setting the following tasks to queued state:
	<TaskInstance: main_cdrd_coordinator.wait_consumers manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:07:06,637 INFO - Trying to enqueue tasks: [<TaskInstance: main_cdrd_coordinator.wait_consumers manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:07:06,638 INFO - Sending TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='wait_consumers', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 09:07:06,639 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'wait_consumers', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:07:06,641 INFO - Executing command: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'wait_consumers', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:07:11,213 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='wait_consumers', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1)
2026-02-27 09:07:11,224 INFO - TaskInstance Finished: dag_id=main_cdrd_coordinator, task_id=wait_consumers, run_id=manual__2026-02-27T01:06:36.749354+00:00, map_index=-1, run_start_date=2026-02-27 01:07:10.362809+00:00, run_end_date=2026-02-27 01:07:10.545071+00:00, run_duration=0.182262, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=465, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 01:07:06.635621+00:00, queued_by_job_id=452, pid=2496
2026-02-27 09:07:15,130 INFO - 1 tasks up for execution:
	<TaskInstance: main_cdrd_coordinator.execute_final_summary manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:07:15,131 INFO - DAG main_cdrd_coordinator has 0/16 running and queued tasks
2026-02-27 09:07:15,131 INFO - Setting the following tasks to queued state:
	<TaskInstance: main_cdrd_coordinator.execute_final_summary manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>
2026-02-27 09:07:15,134 INFO - Trying to enqueue tasks: [<TaskInstance: main_cdrd_coordinator.execute_final_summary manual__2026-02-27T01:06:36.749354+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:07:15,135 INFO - Sending TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='execute_final_summary', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 09:07:15,136 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'execute_final_summary', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:07:15,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'execute_final_summary', 'manual__2026-02-27T01:06:36.749354+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:07:19,564 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='execute_final_summary', run_id='manual__2026-02-27T01:06:36.749354+00:00', try_number=1, map_index=-1)
2026-02-27 09:07:19,575 INFO - TaskInstance Finished: dag_id=main_cdrd_coordinator, task_id=execute_final_summary, run_id=manual__2026-02-27T01:06:36.749354+00:00, map_index=-1, run_start_date=2026-02-27 01:07:18.684088+00:00, run_end_date=2026-02-27 01:07:18.862775+00:00, run_duration=0.178687, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=466, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 01:07:15.133211+00:00, queued_by_job_id=452, pid=2501
2026-02-27 09:07:26,217 INFO - Marking run <DagRun main_cdrd_coordinator @ 2026-02-27 01:06:36.749354+00:00: manual__2026-02-27T01:06:36.749354+00:00, state:running, queued_at: 2026-02-27 01:06:36.770704+00:00. externally triggered: True> successful
2026-02-27 09:07:26,218 INFO - DagRun Finished: dag_id=main_cdrd_coordinator, execution_date=2026-02-27 01:06:36.749354+00:00, run_id=manual__2026-02-27T01:06:36.749354+00:00, run_start_date=2026-02-27 01:06:40.475688+00:00, run_end_date=2026-02-27 01:07:26.218138+00:00, run_duration=45.74245, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 01:06:36.749354+00:00, data_interval_end=2026-02-27 01:06:36.749354+00:00, dag_hash=90ad85560ae817a0b64c54dbccbe33bd
2026-02-27 09:11:43,344 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:12:43,654 INFO - 1 tasks up for execution:
	<TaskInstance: main_cdrd_coordinator.trigger_producer_dag manual__2026-02-27T01:12:37.752955+00:00 [scheduled]>
2026-02-27 09:12:43,655 INFO - DAG main_cdrd_coordinator has 0/16 running and queued tasks
2026-02-27 09:12:43,656 INFO - Setting the following tasks to queued state:
	<TaskInstance: main_cdrd_coordinator.trigger_producer_dag manual__2026-02-27T01:12:37.752955+00:00 [scheduled]>
2026-02-27 09:12:43,658 INFO - Trying to enqueue tasks: [<TaskInstance: main_cdrd_coordinator.trigger_producer_dag manual__2026-02-27T01:12:37.752955+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:12:43,659 INFO - Sending TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_producer_dag', run_id='manual__2026-02-27T01:12:37.752955+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 8 and queue default
2026-02-27 09:12:43,660 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_producer_dag', 'manual__2026-02-27T01:12:37.752955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:12:43,662 INFO - Executing command: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_producer_dag', 'manual__2026-02-27T01:12:37.752955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:17:48,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_producer_dag', run_id='manual__2026-02-27T01:12:37.752955+00:00', try_number=1, map_index=-1)
2026-02-27 09:17:48,804 INFO - TaskInstance Finished: dag_id=main_cdrd_coordinator, task_id=trigger_producer_dag, run_id=manual__2026-02-27T01:12:37.752955+00:00, map_index=-1, run_start_date=2026-02-27 01:12:47.798573+00:00, run_end_date=2026-02-27 01:17:48.082929+00:00, run_duration=300.284356, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=467, pool=default_pool, queue=default, priority_weight=8, operator=TriggerDagRunOperator, queued_dttm=2026-02-27 01:12:43.657436+00:00, queued_by_job_id=452, pid=2691
2026-02-27 09:17:48,817 ERROR - DagFileProcessorManager (PID=987) last sent a heartbeat 305.20 seconds ago! Restarting it
2026-02-27 09:17:48,824 INFO - Sending Signals.SIGTERM to group 987. PIDs of all processes in the group: [987]
2026-02-27 09:17:48,825 INFO - Sending the signal Signals.SIGTERM to group 987
2026-02-27 09:17:49,491 INFO - Process psutil.Process(pid=987, status='terminated', exitcode=0, started='08:41:31') (987) terminated with exit code 0
2026-02-27 09:17:49,497 INFO - Launched DagFileProcessorManager with pid: 2766
2026-02-27 09:17:49,514 INFO - Heartbeat recovered after 314.46 seconds
2026-02-27 09:17:49,535 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:18:20,317 INFO - 1 tasks up for execution:
	<TaskInstance: main_cdrd_coordinator.trigger_producer_dag manual__2026-02-27T01:18:16.981449+00:00 [scheduled]>
2026-02-27 09:18:20,318 INFO - DAG main_cdrd_coordinator has 0/16 running and queued tasks
2026-02-27 09:18:20,319 INFO - Setting the following tasks to queued state:
	<TaskInstance: main_cdrd_coordinator.trigger_producer_dag manual__2026-02-27T01:18:16.981449+00:00 [scheduled]>
2026-02-27 09:18:20,321 INFO - Trying to enqueue tasks: [<TaskInstance: main_cdrd_coordinator.trigger_producer_dag manual__2026-02-27T01:18:16.981449+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:18:20,322 INFO - Sending TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_producer_dag', run_id='manual__2026-02-27T01:18:16.981449+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 8 and queue default
2026-02-27 09:18:20,323 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_producer_dag', 'manual__2026-02-27T01:18:16.981449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:18:20,325 INFO - Executing command: ['airflow', 'tasks', 'run', 'main_cdrd_coordinator', 'trigger_producer_dag', 'manual__2026-02-27T01:18:16.981449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:20:26,343 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='main_cdrd_coordinator', task_id='trigger_producer_dag', run_id='manual__2026-02-27T01:18:16.981449+00:00', try_number=1, map_index=-1)
2026-02-27 09:20:26,369 INFO - TaskInstance Finished: dag_id=main_cdrd_coordinator, task_id=trigger_producer_dag, run_id=manual__2026-02-27T01:18:16.981449+00:00, map_index=-1, run_start_date=2026-02-27 01:18:24.398145+00:00, run_end_date=2026-02-27 01:20:24.678083+00:00, run_duration=120.279938, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=462, pool=default_pool, queue=default, priority_weight=8, operator=TriggerDagRunOperator, queued_dttm=2026-02-27 01:18:20.320224+00:00, queued_by_job_id=452, pid=2779
2026-02-27 09:20:26,385 ERROR - DagFileProcessorManager (PID=2766) last sent a heartbeat 126.11 seconds ago! Restarting it
2026-02-27 09:20:26,405 INFO - Sending Signals.SIGTERM to group 2766. PIDs of all processes in the group: [2766]
2026-02-27 09:20:26,406 INFO - Sending the signal Signals.SIGTERM to group 2766
2026-02-27 09:20:27,851 INFO - Process psutil.Process(pid=2766, status='terminated', exitcode=0, started='09:17:49') (2766) terminated with exit code 0
2026-02-27 09:20:27,864 INFO - Launched DagFileProcessorManager with pid: 2803
2026-02-27 09:20:27,908 INFO - Heartbeat recovered after 135.15 seconds
2026-02-27 09:21:32,099 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_pipeline.producer_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
2026-02-27 09:21:32,100 INFO - DAG cdrd_test_pipeline has 0/16 running and queued tasks
2026-02-27 09:21:32,101 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_pipeline.producer_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
2026-02-27 09:21:32,104 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_pipeline.producer_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:21:32,105 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='producer_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 09:21:32,106 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'producer_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:21:32,109 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'producer_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:21:37,062 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='producer_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1)
2026-02-27 09:21:37,073 INFO - TaskInstance Finished: dag_id=cdrd_test_pipeline, task_id=producer_task, run_id=manual__2026-02-27T01:21:25.314371+00:00, map_index=-1, run_start_date=2026-02-27 01:21:36.144334+00:00, run_end_date=2026-02-27 01:21:36.339228+00:00, run_duration=0.194894, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=462, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 01:21:32.102646+00:00, queued_by_job_id=452, pid=2840
2026-02-27 09:21:40,077 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_test_pipeline.consumer1_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
	<TaskInstance: cdrd_test_pipeline.consumer2_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
2026-02-27 09:21:40,078 INFO - DAG cdrd_test_pipeline has 0/16 running and queued tasks
2026-02-27 09:21:40,078 INFO - DAG cdrd_test_pipeline has 1/16 running and queued tasks
2026-02-27 09:21:40,079 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_pipeline.consumer1_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
	<TaskInstance: cdrd_test_pipeline.consumer2_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
2026-02-27 09:21:40,081 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_pipeline.consumer1_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>, <TaskInstance: cdrd_test_pipeline.consumer2_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:21:40,083 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='consumer1_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 09:21:40,083 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'consumer1_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:21:40,084 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='consumer2_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 09:21:40,085 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'consumer2_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:21:40,087 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'consumer1_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:21:53,087 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'consumer2_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:22:02,966 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='consumer1_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1)
2026-02-27 09:22:02,969 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='consumer2_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1)
2026-02-27 09:22:02,978 INFO - TaskInstance Finished: dag_id=cdrd_test_pipeline, task_id=consumer1_task, run_id=manual__2026-02-27T01:21:25.314371+00:00, map_index=-1, run_start_date=2026-02-27 01:21:43.640660+00:00, run_end_date=2026-02-27 01:21:52.246762+00:00, run_duration=8.606102, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=463, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 01:21:40.080321+00:00, queued_by_job_id=452, pid=2845
2026-02-27 09:22:02,980 INFO - TaskInstance Finished: dag_id=cdrd_test_pipeline, task_id=consumer2_task, run_id=manual__2026-02-27T01:21:25.314371+00:00, map_index=-1, run_start_date=2026-02-27 01:21:56.886911+00:00, run_end_date=2026-02-27 01:22:02.305634+00:00, run_duration=5.418723, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=464, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 01:21:40.080321+00:00, queued_by_job_id=452, pid=2867
2026-02-27 09:22:05,762 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_pipeline.final_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
2026-02-27 09:22:05,763 INFO - DAG cdrd_test_pipeline has 0/16 running and queued tasks
2026-02-27 09:22:05,764 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_pipeline.final_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>
2026-02-27 09:22:05,766 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_pipeline.final_task manual__2026-02-27T01:21:25.314371+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:22:05,767 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='final_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 09:22:05,768 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'final_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:22:05,771 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_pipeline', 'final_task', 'manual__2026-02-27T01:21:25.314371+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:22:10,320 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_pipeline', task_id='final_task', run_id='manual__2026-02-27T01:21:25.314371+00:00', try_number=1, map_index=-1)
2026-02-27 09:22:10,331 INFO - TaskInstance Finished: dag_id=cdrd_test_pipeline, task_id=final_task, run_id=manual__2026-02-27T01:21:25.314371+00:00, map_index=-1, run_start_date=2026-02-27 01:22:09.440157+00:00, run_end_date=2026-02-27 01:22:09.714564+00:00, run_duration=0.274407, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=465, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 01:22:05.765494+00:00, queued_by_job_id=452, pid=2890
2026-02-27 09:22:16,787 INFO - Marking run <DagRun cdrd_test_pipeline @ 2026-02-27 01:21:25.314371+00:00: manual__2026-02-27T01:21:25.314371+00:00, state:running, queued_at: 2026-02-27 01:21:25.326638+00:00. externally triggered: True> successful
2026-02-27 09:22:16,788 INFO - DagRun Finished: dag_id=cdrd_test_pipeline, execution_date=2026-02-27 01:21:25.314371+00:00, run_id=manual__2026-02-27T01:21:25.314371+00:00, run_start_date=2026-02-27 01:21:28.138443+00:00, run_end_date=2026-02-27 01:22:16.788821+00:00, run_duration=48.650378, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 01:21:25.314371+00:00, data_interval_end=2026-02-27 01:21:25.314371+00:00, dag_hash=eedf01062d75f90e4a0f8d0c02124c1f
2026-02-27 09:22:50,809 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:27:51,303 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:32:53,613 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:37:57,593 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:39:44,953 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_.producer_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
2026-02-27 09:39:44,954 INFO - DAG cdrd_test_ has 0/16 running and queued tasks
2026-02-27 09:39:44,955 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_.producer_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
2026-02-27 09:39:44,957 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_.producer_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:39:44,958 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='producer_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 09:39:44,958 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', 'producer_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:39:44,961 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', 'producer_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:39:50,123 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='producer_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1)
2026-02-27 09:39:50,133 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=producer_task, run_id=manual__2026-02-27T01:39:38.949158+00:00, map_index=-1, run_start_date=2026-02-27 01:39:49.173637+00:00, run_end_date=2026-02-27 01:39:49.370057+00:00, run_duration=0.19642, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=466, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 01:39:44.955963+00:00, queued_by_job_id=452, pid=3423
2026-02-27 09:39:53,862 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_test_.consumer1_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
	<TaskInstance: cdrd_test_.consumer2_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
2026-02-27 09:39:53,863 INFO - DAG cdrd_test_ has 0/16 running and queued tasks
2026-02-27 09:39:53,864 INFO - DAG cdrd_test_ has 1/16 running and queued tasks
2026-02-27 09:39:53,864 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_.consumer1_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
	<TaskInstance: cdrd_test_.consumer2_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
2026-02-27 09:39:53,867 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_.consumer1_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>, <TaskInstance: cdrd_test_.consumer2_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:39:53,868 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='consumer1_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 09:39:53,868 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', 'consumer1_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:39:53,869 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='consumer2_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 09:39:53,870 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', 'consumer2_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:39:53,872 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', 'consumer1_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:40:07,213 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', 'consumer2_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:40:17,571 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='consumer1_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1)
2026-02-27 09:40:17,574 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='consumer2_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1)
2026-02-27 09:40:17,582 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=consumer1_task, run_id=manual__2026-02-27T01:39:38.949158+00:00, map_index=-1, run_start_date=2026-02-27 01:39:57.769820+00:00, run_end_date=2026-02-27 01:40:06.510288+00:00, run_duration=8.740468, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=467, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 01:39:53.865805+00:00, queued_by_job_id=452, pid=3426
2026-02-27 09:40:17,584 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=consumer2_task, run_id=manual__2026-02-27T01:39:38.949158+00:00, map_index=-1, run_start_date=2026-02-27 01:40:11.524778+00:00, run_end_date=2026-02-27 01:40:16.873478+00:00, run_duration=5.3487, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=468, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 01:39:53.865805+00:00, queued_by_job_id=452, pid=3452
2026-02-27 09:40:21,223 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_.final_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
2026-02-27 09:40:21,224 INFO - DAG cdrd_test_ has 0/16 running and queued tasks
2026-02-27 09:40:21,224 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_.final_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>
2026-02-27 09:40:21,226 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_.final_task manual__2026-02-27T01:39:38.949158+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:40:21,227 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='final_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 09:40:21,228 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', 'final_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:40:21,230 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', 'final_task', 'manual__2026-02-27T01:39:38.949158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:40:25,916 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='final_task', run_id='manual__2026-02-27T01:39:38.949158+00:00', try_number=1, map_index=-1)
2026-02-27 09:40:25,926 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=final_task, run_id=manual__2026-02-27T01:39:38.949158+00:00, map_index=-1, run_start_date=2026-02-27 01:40:24.987563+00:00, run_end_date=2026-02-27 01:40:25.249862+00:00, run_duration=0.262299, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=469, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 01:40:21.225821+00:00, queued_by_job_id=452, pid=3475
2026-02-27 09:40:32,988 INFO - Marking run <DagRun cdrd_test_ @ 2026-02-27 01:39:38.949158+00:00: manual__2026-02-27T01:39:38.949158+00:00, state:running, queued_at: 2026-02-27 01:39:38.962343+00:00. externally triggered: True> successful
2026-02-27 09:40:32,989 INFO - DagRun Finished: dag_id=cdrd_test_, execution_date=2026-02-27 01:39:38.949158+00:00, run_id=manual__2026-02-27T01:39:38.949158+00:00, run_start_date=2026-02-27 01:39:42.434632+00:00, run_end_date=2026-02-27 01:40:32.989386+00:00, run_duration=50.554754, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 01:39:38.949158+00:00, data_interval_end=2026-02-27 01:39:38.949158+00:00, dag_hash=796065f1eafd058b4d3d2b39602860ed
2026-02-27 09:42:12,684 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_.producer_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
2026-02-27 09:42:12,685 INFO - DAG cdrd_test_ has 0/16 running and queued tasks
2026-02-27 09:42:12,686 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_.producer_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
2026-02-27 09:42:12,688 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_.producer_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:42:12,690 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='producer_task', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 09:42:12,690 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', 'producer_task', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:12,693 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', 'producer_task', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:17,455 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='producer_task', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1)
2026-02-27 09:42:17,464 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=producer_task, run_id=manual__2026-02-27T01:42:04.647826+00:00, map_index=-1, run_start_date=2026-02-27 01:42:16.538061+00:00, run_end_date=2026-02-27 01:42:16.735686+00:00, run_duration=0.197625, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=470, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 01:42:12.687585+00:00, queued_by_job_id=452, pid=3564
2026-02-27 09:42:20,159 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_test_. manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
	<TaskInstance: cdrd_test_.consumer2_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
2026-02-27 09:42:20,160 INFO - DAG cdrd_test_ has 0/16 running and queued tasks
2026-02-27 09:42:20,160 INFO - DAG cdrd_test_ has 1/16 running and queued tasks
2026-02-27 09:42:20,161 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_. manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
	<TaskInstance: cdrd_test_.consumer2_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
2026-02-27 09:42:20,164 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_. manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>, <TaskInstance: cdrd_test_.consumer2_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:42:20,165 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 09:42:20,165 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', '', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:20,166 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='consumer2_task', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 09:42:20,167 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', 'consumer2_task', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:20,170 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', '', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:31,565 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', 'consumer2_task', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:41,282 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1)
2026-02-27 09:42:41,284 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='consumer2_task', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1)
2026-02-27 09:42:41,292 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=consumer2_task, run_id=manual__2026-02-27T01:42:04.647826+00:00, map_index=-1, run_start_date=2026-02-27 01:42:35.292841+00:00, run_end_date=2026-02-27 01:42:40.582527+00:00, run_duration=5.289686, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=472, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 01:42:20.162832+00:00, queued_by_job_id=452, pid=3589
2026-02-27 09:42:41,294 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=, run_id=manual__2026-02-27T01:42:04.647826+00:00, map_index=-1, run_start_date=2026-02-27 01:42:23.821857+00:00, run_end_date=2026-02-27 01:42:30.884806+00:00, run_duration=7.062949, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=471, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 01:42:20.162832+00:00, queued_by_job_id=452, pid=3567
2026-02-27 09:42:44,110 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_test_.final_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
2026-02-27 09:42:44,111 INFO - DAG cdrd_test_ has 0/16 running and queued tasks
2026-02-27 09:42:44,111 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_test_.final_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>
2026-02-27 09:42:44,114 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_test_.final_task manual__2026-02-27T01:42:04.647826+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 09:42:44,114 INFO - Sending TaskInstanceKey(dag_id='cdrd_test_', task_id='final_task', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 09:42:44,115 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_test_', 'final_task', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:44,118 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_test_', 'final_task', 'manual__2026-02-27T01:42:04.647826+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 09:42:48,689 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_test_', task_id='final_task', run_id='manual__2026-02-27T01:42:04.647826+00:00', try_number=1, map_index=-1)
2026-02-27 09:42:48,698 INFO - TaskInstance Finished: dag_id=cdrd_test_, task_id=final_task, run_id=manual__2026-02-27T01:42:04.647826+00:00, map_index=-1, run_start_date=2026-02-27 01:42:47.683904+00:00, run_end_date=2026-02-27 01:42:47.963842+00:00, run_duration=0.279938, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=473, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 01:42:44.112837+00:00, queued_by_job_id=452, pid=3609
2026-02-27 09:42:55,322 INFO - Marking run <DagRun cdrd_test_ @ 2026-02-27 01:42:04.647826+00:00: manual__2026-02-27T01:42:04.647826+00:00, state:running, queued_at: 2026-02-27 01:42:04.663439+00:00. externally triggered: True> successful
2026-02-27 09:42:55,323 INFO - DagRun Finished: dag_id=cdrd_test_, execution_date=2026-02-27 01:42:04.647826+00:00, run_id=manual__2026-02-27T01:42:04.647826+00:00, run_start_date=2026-02-27 01:42:08.638168+00:00, run_end_date=2026-02-27 01:42:55.323451+00:00, run_duration=46.685283, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 01:42:04.647826+00:00, data_interval_end=2026-02-27 01:42:04.647826+00:00, dag_hash=b552032b930b66d2116e8eaee285306a
2026-02-27 09:42:59,454 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:47:59,639 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:53:01,292 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 09:58:02,368 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:03:04,734 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:08:06,808 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:13:09,219 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:18:12,020 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:23:13,998 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:28:14,281 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:33:16,032 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:38:17,419 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:43:17,659 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:48:20,097 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:53:21,660 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 10:58:23,912 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:03:25,892 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:08:28,009 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:09:00,062 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__.producer_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
2026-02-27 11:09:00,063 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 11:09:00,064 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__.producer_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
2026-02-27 11:09:00,066 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__.producer_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 11:09:00,068 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='producer_task', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 11:09:00,069 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', 'producer_task', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:00,071 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', 'producer_task', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:05,528 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='producer_task', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1)
2026-02-27 11:09:05,557 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=producer_task, run_id=manual__2026-02-27T03:08:52.537899+00:00, map_index=-1, run_start_date=2026-02-27 03:09:04.524643+00:00, run_end_date=2026-02-27 03:09:04.831323+00:00, run_duration=0.30668, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=474, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 03:09:00.065321+00:00, queued_by_job_id=452, pid=6106
2026-02-27 11:09:09,124 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
	<TaskInstance: cdrd__.consumer2_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
2026-02-27 11:09:09,125 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 11:09:09,126 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 11:09:09,127 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
	<TaskInstance: cdrd__.consumer2_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
2026-02-27 11:09:09,129 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>, <TaskInstance: cdrd__.consumer2_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 11:09:09,130 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 11:09:09,131 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:09,131 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='consumer2_task', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 11:09:09,132 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', 'consumer2_task', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:09,135 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:22,428 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', 'consumer2_task', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:32,770 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1)
2026-02-27 11:09:32,772 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='consumer2_task', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1)
2026-02-27 11:09:32,780 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=consumer2_task, run_id=manual__2026-02-27T03:08:52.537899+00:00, map_index=-1, run_start_date=2026-02-27 03:09:26.546300+00:00, run_end_date=2026-02-27 03:09:32.090355+00:00, run_duration=5.544055, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=476, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 03:09:09.128213+00:00, queued_by_job_id=452, pid=6133
2026-02-27 11:09:32,781 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T03:08:52.537899+00:00, map_index=-1, run_start_date=2026-02-27 03:09:13.093418+00:00, run_end_date=2026-02-27 03:09:21.741310+00:00, run_duration=8.647892, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=475, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 03:09:09.128213+00:00, queued_by_job_id=452, pid=6109
2026-02-27 11:09:36,333 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__.final_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
2026-02-27 11:09:36,333 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 11:09:36,334 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__.final_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>
2026-02-27 11:09:36,337 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__.final_task manual__2026-02-27T03:08:52.537899+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 11:09:36,338 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='final_task', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 11:09:36,339 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', 'final_task', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:36,342 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', 'final_task', 'manual__2026-02-27T03:08:52.537899+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:09:40,911 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='final_task', run_id='manual__2026-02-27T03:08:52.537899+00:00', try_number=1, map_index=-1)
2026-02-27 11:09:40,919 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=final_task, run_id=manual__2026-02-27T03:08:52.537899+00:00, map_index=-1, run_start_date=2026-02-27 03:09:39.954181+00:00, run_end_date=2026-02-27 03:09:40.211629+00:00, run_duration=0.257448, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=477, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 03:09:36.335521+00:00, queued_by_job_id=452, pid=6153
2026-02-27 11:09:48,145 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 03:08:52.537899+00:00: manual__2026-02-27T03:08:52.537899+00:00, state:running, queued_at: 2026-02-27 03:08:52.560885+00:00. externally triggered: True> successful
2026-02-27 11:09:48,146 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 03:08:52.537899+00:00, run_id=manual__2026-02-27T03:08:52.537899+00:00, run_start_date=2026-02-27 03:08:55.627443+00:00, run_end_date=2026-02-27 03:09:48.146678+00:00, run_duration=52.519235, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 03:08:52.537899+00:00, data_interval_end=2026-02-27 03:08:52.537899+00:00, dag_hash=1f47907ee79b7c4e1ee860e8c0d1cec2
2026-02-27 11:12:24,206 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
2026-02-27 11:12:24,211 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 11:12:24,212 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
2026-02-27 11:12:24,214 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 11:12:24,215 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 11:12:24,216 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:24,229 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:29,084 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1)
2026-02-27 11:12:29,093 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T03:12:18.578524+00:00, map_index=-1, run_start_date=2026-02-27 03:12:28.207795+00:00, run_end_date=2026-02-27 03:12:28.400301+00:00, run_duration=0.192506, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=478, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 03:12:24.213488+00:00, queued_by_job_id=452, pid=6251
2026-02-27 11:12:32,536 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
2026-02-27 11:12:32,537 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 11:12:32,538 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 11:12:32,539 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
2026-02-27 11:12:32,541 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 11:12:32,542 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 11:12:32,543 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:32,544 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 11:12:32,544 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:32,547 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:37,235 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:41,982 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1)
2026-02-27 11:12:41,985 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1)
2026-02-27 11:12:41,993 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T03:12:18.578524+00:00, map_index=-1, run_start_date=2026-02-27 03:12:36.279935+00:00, run_end_date=2026-02-27 03:12:36.478905+00:00, run_duration=0.19897, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=479, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 03:12:32.540194+00:00, queued_by_job_id=452, pid=6254
2026-02-27 11:12:41,995 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T03:12:18.578524+00:00, map_index=-1, run_start_date=2026-02-27 03:12:41.031579+00:00, run_end_date=2026-02-27 03:12:41.231557+00:00, run_duration=0.199978, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=480, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 03:12:32.540194+00:00, queued_by_job_id=452, pid=6256
2026-02-27 11:12:45,076 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
2026-02-27 11:12:45,078 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 11:12:45,079 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>
2026-02-27 11:12:45,082 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T03:12:18.578524+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 11:12:45,083 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 11:12:45,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:45,087 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T03:12:18.578524+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_1p1n2t.py']
2026-02-27 11:12:52,934 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T03:12:18.578524+00:00', try_number=1, map_index=-1)
2026-02-27 11:12:52,948 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T03:12:18.578524+00:00, map_index=-1, run_start_date=2026-02-27 03:12:50.307979+00:00, run_end_date=2026-02-27 03:12:51.417718+00:00, run_duration=1.109739, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=481, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 03:12:45.080866+00:00, queued_by_job_id=452, pid=6279
2026-02-27 11:13:09,112 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 03:12:18.578524+00:00: manual__2026-02-27T03:12:18.578524+00:00, state:running, queued_at: 2026-02-27 03:12:18.593035+00:00. externally triggered: True> successful
2026-02-27 11:13:09,114 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 03:12:18.578524+00:00, run_id=manual__2026-02-27T03:12:18.578524+00:00, run_start_date=2026-02-27 03:12:20.612772+00:00, run_end_date=2026-02-27 03:13:09.114348+00:00, run_duration=48.501576, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 03:12:18.578524+00:00, data_interval_end=2026-02-27 03:12:18.578524+00:00, dag_hash=7a9cb72c23cbf5fb73bb4d067985366a
2026-02-27 11:13:28,147 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:18:29,923 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:23:31,606 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:28:34,182 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:33:35,785 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:38:38,503 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:43:42,100 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:48:43,386 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:53:46,368 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 11:58:48,165 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:03:35,009 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
2026-02-27 12:03:35,010 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:03:35,011 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
2026-02-27 12:03:35,014 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:03:35,019 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 12:03:35,020 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:03:35,025 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:03:40,101 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1)
2026-02-27 12:03:40,112 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:03:27.179808+00:00, map_index=-1, run_start_date=2026-02-27 04:03:39.148476+00:00, run_end_date=2026-02-27 04:03:39.355516+00:00, run_duration=0.20704, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=482, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 04:03:35.012674+00:00, queued_by_job_id=452, pid=8877
2026-02-27 12:03:43,937 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
2026-02-27 12:03:43,939 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:03:43,940 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 12:03:43,941 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
2026-02-27 12:03:43,943 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:03:43,944 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:03:43,945 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:03:43,946 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:03:43,947 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:03:43,949 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:03:48,856 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:03:53,727 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1)
2026-02-27 12:03:53,729 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1)
2026-02-27 12:03:53,739 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:03:27.179808+00:00, map_index=-1, run_start_date=2026-02-27 04:03:47.897273+00:00, run_end_date=2026-02-27 04:03:48.105687+00:00, run_duration=0.208414, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=483, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:03:43.942126+00:00, queued_by_job_id=452, pid=8882
2026-02-27 12:03:53,740 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:03:27.179808+00:00, map_index=-1, run_start_date=2026-02-27 04:03:52.787119+00:00, run_end_date=2026-02-27 04:03:53.001696+00:00, run_duration=0.214577, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=484, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:03:43.942126+00:00, queued_by_job_id=452, pid=8888
2026-02-27 12:03:53,765 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:03:57,360 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
2026-02-27 12:03:57,361 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:03:57,361 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>
2026-02-27 12:03:57,364 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:03:27.179808+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:03:57,365 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:03:57,366 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:03:57,368 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:03:27.179808+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:04:02,208 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:03:27.179808+00:00', try_number=1, map_index=-1)
2026-02-27 12:04:02,218 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:03:27.179808+00:00, map_index=-1, run_start_date=2026-02-27 04:04:01.230714+00:00, run_end_date=2026-02-27 04:04:01.515295+00:00, run_duration=0.284581, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=485, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:03:57.362862+00:00, queued_by_job_id=452, pid=8895
2026-02-27 12:04:08,851 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 04:03:27.179808+00:00: manual__2026-02-27T04:03:27.179808+00:00, state:running, queued_at: 2026-02-27 04:03:27.224969+00:00. externally triggered: True> successful
2026-02-27 12:04:08,855 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 04:03:27.179808+00:00, run_id=manual__2026-02-27T04:03:27.179808+00:00, run_start_date=2026-02-27 04:03:30.531181+00:00, run_end_date=2026-02-27 04:04:08.855356+00:00, run_duration=38.324175, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:03:27.179808+00:00, data_interval_end=2026-02-27 04:03:27.179808+00:00, dag_hash=451304d578ac06293d7ed988098d76d9
2026-02-27 12:08:54,176 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:09:06,666 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:09:00.407560+00:00 [scheduled]>
2026-02-27 12:09:06,667 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:09:06,668 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:09:00.407560+00:00 [scheduled]>
2026-02-27 12:09:06,671 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:09:00.407560+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:09:06,672 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:09:00.407560+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 12:09:06,672 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:09:00.407560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:09:06,675 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:09:00.407560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:09:11,951 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:09:00.407560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']' returned non-zero exit status 1..
2026-02-27 12:09:11,956 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:09:00.407560+00:00', try_number=1, map_index=-1)
2026-02-27 12:09:11,965 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:09:00.407560+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor=SequentialExecutor(parallelism=32), executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 04:09:06.669407+00:00, queued_by_job_id=452, pid=None
2026-02-27 12:09:11,966 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: cdrd__. manual__2026-02-27T04:09:00.407560+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2026-02-27 12:09:11,982 ERROR - Executor SequentialExecutor(parallelism=32) reported that the task instance <TaskInstance: cdrd__. manual__2026-02-27T04:09:00.407560+00:00 [queued]> finished with state failed, but the task instance's state attribute is queued. Learn more: https://airflow.apache.org/docs/apache-airflow/stable/troubleshooting.html#task-state-changed-externally
2026-02-27 12:09:12,016 INFO - Marking task as FAILED. dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:09:00.407560+00:00, execution_date=20260227T040900, start_date=, end_date=20260227T040911
2026-02-27 12:09:26,300 ERROR - Marking run <DagRun cdrd__ @ 2026-02-27 04:09:00.407560+00:00: manual__2026-02-27T04:09:00.407560+00:00, state:running, queued_at: 2026-02-27 04:09:00.430482+00:00. externally triggered: True> failed
2026-02-27 12:09:26,301 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 04:09:00.407560+00:00, run_id=manual__2026-02-27T04:09:00.407560+00:00, run_start_date=2026-02-27 04:09:03.687058+00:00, run_end_date=2026-02-27 04:09:26.301754+00:00, run_duration=22.614696, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:09:00.407560+00:00, data_interval_end=2026-02-27 04:09:00.407560+00:00, dag_hash=451304d578ac06293d7ed988098d76d9
2026-02-27 12:11:05,961 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
2026-02-27 12:11:05,962 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:11:05,963 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
2026-02-27 12:11:05,966 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:11:05,967 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 12:11:05,967 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:05,970 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:11,404 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1)
2026-02-27 12:11:11,414 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:10:57.947250+00:00, map_index=-1, run_start_date=2026-02-27 04:11:10.466049+00:00, run_end_date=2026-02-27 04:11:10.692141+00:00, run_duration=0.226092, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=486, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 04:11:05.964566+00:00, queued_by_job_id=452, pid=9198
2026-02-27 12:11:14,276 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
2026-02-27 12:11:14,277 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:11:14,278 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 12:11:14,278 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
2026-02-27 12:11:14,281 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:11:14,282 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:11:14,283 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:14,283 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:11:14,284 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:14,287 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:19,249 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:24,167 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1)
2026-02-27 12:11:24,169 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1)
2026-02-27 12:11:24,178 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:10:57.947250+00:00, map_index=-1, run_start_date=2026-02-27 04:11:18.264886+00:00, run_end_date=2026-02-27 04:11:18.494708+00:00, run_duration=0.229822, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=487, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:11:14.279940+00:00, queued_by_job_id=452, pid=9203
2026-02-27 12:11:24,180 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:10:57.947250+00:00, map_index=-1, run_start_date=2026-02-27 04:11:23.205738+00:00, run_end_date=2026-02-27 04:11:23.416345+00:00, run_duration=0.210607, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=488, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:11:14.279940+00:00, queued_by_job_id=452, pid=9208
2026-02-27 12:11:27,203 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
2026-02-27 12:11:27,205 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:11:27,206 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>
2026-02-27 12:11:27,208 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:10:57.947250+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:11:27,210 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:11:27,210 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:27,213 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:10:57.947250+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:11:32,132 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:10:57.947250+00:00', try_number=1, map_index=-1)
2026-02-27 12:11:32,142 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:10:57.947250+00:00, map_index=-1, run_start_date=2026-02-27 04:11:31.110223+00:00, run_end_date=2026-02-27 04:11:31.402921+00:00, run_duration=0.292698, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=489, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:11:27.207312+00:00, queued_by_job_id=452, pid=9211
2026-02-27 12:11:38,905 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 04:10:57.947250+00:00: manual__2026-02-27T04:10:57.947250+00:00, state:running, queued_at: 2026-02-27 04:10:57.970572+00:00. externally triggered: True> successful
2026-02-27 12:11:38,907 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 04:10:57.947250+00:00, run_id=manual__2026-02-27T04:10:57.947250+00:00, run_start_date=2026-02-27 04:11:01.406892+00:00, run_end_date=2026-02-27 04:11:38.907139+00:00, run_duration=37.500247, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:10:57.947250+00:00, data_interval_end=2026-02-27 04:10:57.947250+00:00, dag_hash=f423c6d57bd448cfa3ce51a92ed5a07a
2026-02-27 12:12:24,235 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>
2026-02-27 12:12:24,236 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:12:24,237 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>
2026-02-27 12:12:24,240 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:12:24,243 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:12:16.465169+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 12:12:24,244 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:12:16.465169+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:12:24,261 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:12:16.465169+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:12:29,256 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:12:16.465169+00:00', try_number=1, map_index=-1)
2026-02-27 12:12:29,266 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:12:16.465169+00:00, map_index=-1, run_start_date=2026-02-27 04:12:28.336564+00:00, run_end_date=2026-02-27 04:12:28.548657+00:00, run_duration=0.212093, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=490, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 04:12:24.238969+00:00, queued_by_job_id=452, pid=9241
2026-02-27 12:12:32,990 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>
2026-02-27 12:12:32,991 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:12:32,992 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>
2026-02-27 12:12:32,994 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:12:32,997 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:12:16.465169+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:12:32,998 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:12:16.465169+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:12:33,001 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:12:16.465169+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:12:38,152 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:12:16.465169+00:00', try_number=1, map_index=-1)
2026-02-27 12:12:38,162 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:12:16.465169+00:00, map_index=-1, run_start_date=2026-02-27 04:12:37.090689+00:00, run_end_date=2026-02-27 04:12:37.319968+00:00, run_duration=0.229279, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=491, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:12:32.993172+00:00, queued_by_job_id=452, pid=9245
2026-02-27 12:12:43,111 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>
2026-02-27 12:12:43,112 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:12:43,113 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>
2026-02-27 12:12:43,118 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:12:16.465169+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:12:43,119 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:12:16.465169+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:12:43,122 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:12:16.465169+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:12:43,141 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:12:16.465169+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:12:50,182 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:12:16.465169+00:00', try_number=1, map_index=-1)
2026-02-27 12:12:50,197 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:12:16.465169+00:00, map_index=-1, run_start_date=2026-02-27 04:12:49.007009+00:00, run_end_date=2026-02-27 04:12:49.343960+00:00, run_duration=0.336951, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=492, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:12:43.114621+00:00, queued_by_job_id=452, pid=9254
2026-02-27 12:12:58,237 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 04:12:16.465169+00:00: manual__2026-02-27T04:12:16.465169+00:00, state:running, queued_at: 2026-02-27 04:12:16.494333+00:00. externally triggered: True> successful
2026-02-27 12:12:58,238 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 04:12:16.465169+00:00, run_id=manual__2026-02-27T04:12:16.465169+00:00, run_start_date=2026-02-27 04:12:20.313697+00:00, run_end_date=2026-02-27 04:12:58.238609+00:00, run_duration=37.924912, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:12:16.465169+00:00, data_interval_end=2026-02-27 04:12:16.465169+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 12:13:56,470 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:18:14,590 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>
2026-02-27 12:18:14,591 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:18:14,592 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>
2026-02-27 12:18:14,594 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:18:14,595 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:18:08.850854+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 12:18:14,596 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:18:08.850854+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:18:14,599 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:18:08.850854+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:18:19,917 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:18:08.850854+00:00', try_number=1, map_index=-1)
2026-02-27 12:18:19,926 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:18:08.850854+00:00, map_index=-1, run_start_date=2026-02-27 04:18:18.988648+00:00, run_end_date=2026-02-27 04:18:19.204856+00:00, run_duration=0.216208, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=493, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 04:18:14.593574+00:00, queued_by_job_id=452, pid=9487
2026-02-27 12:18:22,668 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>
2026-02-27 12:18:22,669 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:18:22,670 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>
2026-02-27 12:18:22,673 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:18:22,674 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:18:08.850854+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:18:22,674 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:18:08.850854+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:18:22,677 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:18:08.850854+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:18:28,636 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:18:08.850854+00:00', try_number=1, map_index=-1)
2026-02-27 12:18:28,647 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:18:08.850854+00:00, map_index=-1, run_start_date=2026-02-27 04:18:27.742452+00:00, run_end_date=2026-02-27 04:18:27.979832+00:00, run_duration=0.23738, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=494, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:18:22.671649+00:00, queued_by_job_id=452, pid=9506
2026-02-27 12:18:31,554 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>
2026-02-27 12:18:31,556 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:18:31,557 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>
2026-02-27 12:18:31,561 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:18:08.850854+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:18:31,563 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:18:08.850854+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:18:31,564 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:18:08.850854+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:18:31,568 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:18:08.850854+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:18:37,937 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:18:08.850854+00:00', try_number=1, map_index=-1)
2026-02-27 12:18:37,951 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:18:08.850854+00:00, map_index=-1, run_start_date=2026-02-27 04:18:36.907311+00:00, run_end_date=2026-02-27 04:18:37.213161+00:00, run_duration=0.30585, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=495, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:18:31.559163+00:00, queued_by_job_id=452, pid=9510
2026-02-27 12:18:47,848 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 04:18:08.850854+00:00: manual__2026-02-27T04:18:08.850854+00:00, state:running, queued_at: 2026-02-27 04:18:08.866420+00:00. externally triggered: True> successful
2026-02-27 12:18:47,849 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 04:18:08.850854+00:00, run_id=manual__2026-02-27T04:18:08.850854+00:00, run_start_date=2026-02-27 04:18:11.997566+00:00, run_end_date=2026-02-27 04:18:47.849520+00:00, run_duration=35.851954, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:18:08.850854+00:00, data_interval_end=2026-02-27 04:18:08.850854+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 12:18:57,115 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:20:02,770 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>
2026-02-27 12:20:02,772 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:20:02,773 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>
2026-02-27 12:20:02,775 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:20:02,776 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:19:56.105773+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 12:20:02,777 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:19:56.105773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:20:02,780 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:19:56.105773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:20:08,372 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:19:56.105773+00:00', try_number=1, map_index=-1)
2026-02-27 12:20:08,382 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:19:56.105773+00:00, map_index=-1, run_start_date=2026-02-27 04:20:07.404555+00:00, run_end_date=2026-02-27 04:20:07.615147+00:00, run_duration=0.210592, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=496, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 04:20:02.774347+00:00, queued_by_job_id=452, pid=9558
2026-02-27 12:20:11,015 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>
2026-02-27 12:20:11,016 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:20:11,017 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>
2026-02-27 12:20:11,019 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:20:11,021 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:19:56.105773+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:20:11,022 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:19:56.105773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:20:11,025 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:19:56.105773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:20:24,586 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:19:56.105773+00:00', try_number=1, map_index=-1)
2026-02-27 12:20:24,599 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:19:56.105773+00:00, map_index=-1, run_start_date=2026-02-27 04:20:15.434174+00:00, run_end_date=2026-02-27 04:20:23.837603+00:00, run_duration=8.403429, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=497, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:20:11.018397+00:00, queued_by_job_id=452, pid=9561
2026-02-27 12:20:28,908 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>
2026-02-27 12:20:28,909 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:20:28,910 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>
2026-02-27 12:20:28,913 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T04:19:56.105773+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:20:28,914 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:19:56.105773+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:20:28,915 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:19:56.105773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:20:28,917 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:19:56.105773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:20:33,786 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:19:56.105773+00:00', try_number=1, map_index=-1)
2026-02-27 12:20:33,796 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:19:56.105773+00:00, map_index=-1, run_start_date=2026-02-27 04:20:32.771776+00:00, run_end_date=2026-02-27 04:20:33.066851+00:00, run_duration=0.295075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=498, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:20:28.911744+00:00, queued_by_job_id=452, pid=9594
2026-02-27 12:20:42,837 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 04:19:56.105773+00:00: manual__2026-02-27T04:19:56.105773+00:00, state:running, queued_at: 2026-02-27 04:19:56.121913+00:00. externally triggered: True> successful
2026-02-27 12:20:42,838 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 04:19:56.105773+00:00, run_id=manual__2026-02-27T04:19:56.105773+00:00, run_start_date=2026-02-27 04:19:57.953684+00:00, run_end_date=2026-02-27 04:20:42.838571+00:00, run_duration=44.884887, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:19:56.105773+00:00, data_interval_end=2026-02-27 04:19:56.105773+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 12:21:17,468 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
2026-02-27 12:21:17,469 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:21:17,470 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
2026-02-27 12:21:17,472 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:21:17,473 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 12:21:17,474 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:17,478 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:22,446 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1)
2026-02-27 12:21:22,457 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:21:12.029279+00:00, map_index=-1, run_start_date=2026-02-27 04:21:21.491181+00:00, run_end_date=2026-02-27 04:21:21.708450+00:00, run_duration=0.217269, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=499, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 04:21:17.471388+00:00, queued_by_job_id=452, pid=9635
2026-02-27 12:21:26,523 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
2026-02-27 12:21:26,524 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:21:26,525 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 12:21:26,525 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
2026-02-27 12:21:26,529 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:21:26,530 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:21:26,530 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:26,531 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:21:26,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:26,534 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:31,614 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:36,786 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1)
2026-02-27 12:21:36,788 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1)
2026-02-27 12:21:36,798 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:21:12.029279+00:00, map_index=-1, run_start_date=2026-02-27 04:21:30.677194+00:00, run_end_date=2026-02-27 04:21:30.895330+00:00, run_duration=0.218136, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=500, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:21:26.526974+00:00, queued_by_job_id=452, pid=9650
2026-02-27 12:21:36,800 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:21:12.029279+00:00, map_index=-1, run_start_date=2026-02-27 04:21:35.865881+00:00, run_end_date=2026-02-27 04:21:36.079165+00:00, run_duration=0.213284, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=501, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:21:26.526974+00:00, queued_by_job_id=452, pid=9652
2026-02-27 12:21:42,812 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
2026-02-27 12:21:42,813 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:21:42,814 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>
2026-02-27 12:21:42,816 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:21:12.029279+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:21:42,817 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:21:42,818 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:42,820 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:21:12.029279+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:21:48,527 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:21:12.029279+00:00', try_number=1, map_index=-1)
2026-02-27 12:21:48,568 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:21:12.029279+00:00, map_index=-1, run_start_date=2026-02-27 04:21:47.327293+00:00, run_end_date=2026-02-27 04:21:47.638941+00:00, run_duration=0.311648, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=502, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:21:42.815228+00:00, queued_by_job_id=452, pid=9671
2026-02-27 12:21:56,831 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 04:21:12.029279+00:00: manual__2026-02-27T04:21:12.029279+00:00, state:running, queued_at: 2026-02-27 04:21:12.044848+00:00. externally triggered: True> successful
2026-02-27 12:21:56,832 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 04:21:12.029279+00:00, run_id=manual__2026-02-27T04:21:12.029279+00:00, run_start_date=2026-02-27 04:21:13.242513+00:00, run_end_date=2026-02-27 04:21:56.832617+00:00, run_duration=43.590104, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:21:12.029279+00:00, data_interval_end=2026-02-27 04:21:12.029279+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 12:23:22,788 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
2026-02-27 12:23:22,790 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:23:22,791 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
2026-02-27 12:23:22,793 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:23:22,794 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 12:23:22,795 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:23:22,798 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:23:28,183 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1)
2026-02-27 12:23:28,194 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:23:15.768955+00:00, map_index=-1, run_start_date=2026-02-27 04:23:27.224901+00:00, run_end_date=2026-02-27 04:23:27.435516+00:00, run_duration=0.210615, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=503, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 04:23:22.791948+00:00, queued_by_job_id=452, pid=9755
2026-02-27 12:23:31,002 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
2026-02-27 12:23:31,003 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:23:31,004 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 12:23:31,006 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
2026-02-27 12:23:31,010 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:23:31,011 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:23:31,011 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:23:31,012 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:23:31,013 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:23:31,016 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:23:41,977 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:23:52,409 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1)
2026-02-27 12:23:52,411 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1)
2026-02-27 12:23:52,419 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:23:15.768955+00:00, map_index=-1, run_start_date=2026-02-27 04:23:35.517473+00:00, run_end_date=2026-02-27 04:23:41.283887+00:00, run_duration=5.766414, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=504, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:23:31.008281+00:00, queued_by_job_id=452, pid=9760
2026-02-27 12:23:52,421 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:23:15.768955+00:00, map_index=-1, run_start_date=2026-02-27 04:23:45.930993+00:00, run_end_date=2026-02-27 04:23:51.620416+00:00, run_duration=5.689423, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=505, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:23:31.008281+00:00, queued_by_job_id=452, pid=9786
2026-02-27 12:23:55,578 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
2026-02-27 12:23:55,580 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:23:55,580 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>
2026-02-27 12:23:55,583 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:23:15.768955+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:23:55,584 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:23:55,585 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:23:55,588 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:23:15.768955+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:24:00,644 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:23:15.768955+00:00', try_number=1, map_index=-1)
2026-02-27 12:24:00,654 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:23:15.768955+00:00, map_index=-1, run_start_date=2026-02-27 04:23:59.647487+00:00, run_end_date=2026-02-27 04:23:59.947079+00:00, run_duration=0.299592, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=506, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:23:55.581739+00:00, queued_by_job_id=452, pid=9815
2026-02-27 12:24:00,679 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:24:08,670 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 04:23:15.768955+00:00: manual__2026-02-27T04:23:15.768955+00:00, state:running, queued_at: 2026-02-27 04:23:15.782347+00:00. externally triggered: True> successful
2026-02-27 12:24:08,673 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 04:23:15.768955+00:00, run_id=manual__2026-02-27T04:23:15.768955+00:00, run_start_date=2026-02-27 04:23:18.693613+00:00, run_end_date=2026-02-27 04:24:08.672747+00:00, run_duration=49.979134, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:23:15.768955+00:00, data_interval_end=2026-02-27 04:23:15.768955+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 12:28:27,028 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
2026-02-27 12:28:27,031 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:28:27,032 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
2026-02-27 12:28:27,035 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:28:27,036 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 12:28:27,037 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:28:27,040 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:28:32,794 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1)
2026-02-27 12:28:32,804 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:28:21.560806+00:00, map_index=-1, run_start_date=2026-02-27 04:28:31.776559+00:00, run_end_date=2026-02-27 04:28:32.022619+00:00, run_duration=0.24606, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=507, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 04:28:27.033736+00:00, queued_by_job_id=452, pid=10080
2026-02-27 12:28:36,030 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
2026-02-27 12:28:36,031 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:28:36,032 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 12:28:36,033 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
2026-02-27 12:28:36,037 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:28:36,038 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:28:36,039 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:28:36,040 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:28:36,040 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:28:36,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:28:47,506 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:28:58,200 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1)
2026-02-27 12:28:58,203 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1)
2026-02-27 12:28:58,212 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:28:21.560806+00:00, map_index=-1, run_start_date=2026-02-27 04:28:39.961126+00:00, run_end_date=2026-02-27 04:28:46.771830+00:00, run_duration=6.810704, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=508, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:28:36.034760+00:00, queued_by_job_id=452, pid=10083
2026-02-27 12:28:58,214 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:28:21.560806+00:00, map_index=-1, run_start_date=2026-02-27 04:28:51.504916+00:00, run_end_date=2026-02-27 04:28:57.510168+00:00, run_duration=6.005252, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=509, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:28:36.034760+00:00, queued_by_job_id=452, pid=10113
2026-02-27 12:29:01,430 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
2026-02-27 12:29:01,431 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:29:01,432 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>
2026-02-27 12:29:01,434 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:28:21.560806+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:29:01,435 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:29:01,436 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:29:01,438 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:28:21.560806+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:29:06,883 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:28:21.560806+00:00', try_number=1, map_index=-1)
2026-02-27 12:29:06,911 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:28:21.560806+00:00, map_index=-1, run_start_date=2026-02-27 04:29:05.769878+00:00, run_end_date=2026-02-27 04:29:06.089461+00:00, run_duration=0.319583, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=510, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:29:01.433415+00:00, queued_by_job_id=452, pid=10140
2026-02-27 12:29:06,934 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:29:14,565 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 04:28:21.560806+00:00: manual__2026-02-27T04:28:21.560806+00:00, state:running, queued_at: 2026-02-27 04:28:21.574335+00:00. externally triggered: True> successful
2026-02-27 12:29:14,566 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 04:28:21.560806+00:00, run_id=manual__2026-02-27T04:28:21.560806+00:00, run_start_date=2026-02-27 04:28:23.465895+00:00, run_end_date=2026-02-27 04:29:14.566277+00:00, run_duration=51.100382, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:28:21.560806+00:00, data_interval_end=2026-02-27 04:28:21.560806+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 12:29:44,844 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>
2026-02-27 12:29:44,845 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:29:44,846 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:29:44,847 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>
2026-02-27 12:29:44,850 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:29:44,851 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 12:29:44,852 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:29:44,853 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:29:38.197137+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 12:29:44,854 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:29:38.197137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:29:44,857 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:29:49,757 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:29:38.197137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:29:54,780 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1)
2026-02-27 12:29:54,782 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:29:38.197137+00:00', try_number=1, map_index=-1)
2026-02-27 12:29:54,795 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:29:36.991328+00:00, map_index=-1, run_start_date=2026-02-27 04:29:48.787984+00:00, run_end_date=2026-02-27 04:29:48.994213+00:00, run_duration=0.206229, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=511, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 04:29:44.848646+00:00, queued_by_job_id=452, pid=10151
2026-02-27 12:29:54,797 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:29:38.197137+00:00, map_index=-1, run_start_date=2026-02-27 04:29:53.806436+00:00, run_end_date=2026-02-27 04:29:54.024462+00:00, run_duration=0.218026, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=512, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 04:29:44.848646+00:00, queued_by_job_id=452, pid=10153
2026-02-27 12:29:58,517 INFO - 3 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>
2026-02-27 12:29:58,519 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:29:58,519 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 12:29:58,520 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:29:58,521 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>
2026-02-27 12:29:58,527 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:29:58,528 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:29:58,529 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:29:58,530 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:29:58,531 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:29:58,531 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:29:38.197137+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 12:29:58,532 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:29:38.197137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:29:58,535 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:30:09,510 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:30:19,931 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:29:38.197137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:30:31,813 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1)
2026-02-27 12:30:31,815 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1)
2026-02-27 12:30:31,816 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:29:38.197137+00:00', try_number=1, map_index=-1)
2026-02-27 12:30:31,831 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:29:36.991328+00:00, map_index=-1, run_start_date=2026-02-27 04:30:02.422559+00:00, run_end_date=2026-02-27 04:30:08.831173+00:00, run_duration=6.408614, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=513, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:29:58.523659+00:00, queued_by_job_id=452, pid=10162
2026-02-27 12:30:31,833 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:29:36.991328+00:00, map_index=-1, run_start_date=2026-02-27 04:30:13.539839+00:00, run_end_date=2026-02-27 04:30:19.178349+00:00, run_duration=5.63851, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=514, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:29:58.523659+00:00, queued_by_job_id=452, pid=10199
2026-02-27 12:30:31,834 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:29:38.197137+00:00, map_index=-1, run_start_date=2026-02-27 04:30:23.883924+00:00, run_end_date=2026-02-27 04:30:31.060121+00:00, run_duration=7.176197, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=515, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 04:29:58.523659+00:00, queued_by_job_id=452, pid=10220
2026-02-27 12:30:31,855 INFO - Heartbeat recovered after 37.04 seconds
2026-02-27 12:30:35,886 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>
2026-02-27 12:30:35,888 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 12:30:35,889 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 12:30:35,889 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>
2026-02-27 12:30:35,892 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T04:29:36.991328+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-27T04:29:38.197137+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 12:30:35,893 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:30:35,894 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:30:35,895 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:29:38.197137+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 12:30:35,896 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:29:38.197137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:30:35,899 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T04:29:36.991328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 12:30:40,923 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T04:29:38.197137+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 12:30:45,724 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T04:29:36.991328+00:00', try_number=1, map_index=-1)
2026-02-27 12:30:45,726 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T04:29:38.197137+00:00', try_number=1, map_index=-1)
2026-02-27 12:30:45,734 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T04:29:36.991328+00:00, map_index=-1, run_start_date=2026-02-27 04:30:39.905239+00:00, run_end_date=2026-02-27 04:30:40.212556+00:00, run_duration=0.307317, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=516, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:30:35.891023+00:00, queued_by_job_id=452, pid=10240
2026-02-27 12:30:45,736 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T04:29:38.197137+00:00, map_index=-1, run_start_date=2026-02-27 04:30:44.764572+00:00, run_end_date=2026-02-27 04:30:45.059937+00:00, run_duration=0.295365, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=517, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 04:30:35.891023+00:00, queued_by_job_id=452, pid=10242
2026-02-27 12:30:53,477 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 04:29:36.991328+00:00: manual__2026-02-27T04:29:36.991328+00:00, state:running, queued_at: 2026-02-27 04:29:37.006827+00:00. externally triggered: True> successful
2026-02-27 12:30:53,479 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 04:29:36.991328+00:00, run_id=manual__2026-02-27T04:29:36.991328+00:00, run_start_date=2026-02-27 04:29:40.249970+00:00, run_end_date=2026-02-27 04:30:53.479058+00:00, run_duration=73.229088, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:29:36.991328+00:00, data_interval_end=2026-02-27 04:29:36.991328+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 12:30:53,484 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 04:29:38.197137+00:00: manual__2026-02-27T04:29:38.197137+00:00, state:running, queued_at: 2026-02-27 04:29:38.212006+00:00. externally triggered: True> successful
2026-02-27 12:30:53,491 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 04:29:38.197137+00:00, run_id=manual__2026-02-27T04:29:38.197137+00:00, run_start_date=2026-02-27 04:29:40.253221+00:00, run_end_date=2026-02-27 04:30:53.491204+00:00, run_duration=73.237983, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 04:29:38.197137+00:00, data_interval_end=2026-02-27 04:29:38.197137+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 12:34:09,934 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:48:35,246 INFO - Heartbeat recovered after 837.08 seconds
2026-02-27 12:52:58,866 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 12:58:01,602 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:03:04,268 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:08:08,776 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:13:10,322 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:17:50,490 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:17:43.785648+00:00 [scheduled]>
2026-02-27 13:17:50,492 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:17:50,493 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:17:43.785648+00:00 [scheduled]>
2026-02-27 13:17:50,496 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:17:43.785648+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:17:50,498 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='trigger_', run_id='manual__2026-02-27T05:17:43.785648+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2026-02-27 13:17:50,499 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'trigger_', 'manual__2026-02-27T05:17:43.785648+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:17:50,503 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'trigger_', 'manual__2026-02-27T05:17:43.785648+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:21:00,907 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='trigger_', run_id='manual__2026-02-27T05:17:43.785648+00:00', try_number=1, map_index=-1)
2026-02-27 13:21:00,954 ERROR - DagFileProcessorManager (PID=2803) last sent a heartbeat 190.55 seconds ago! Restarting it
2026-02-27 13:21:00,967 INFO - Sending Signals.SIGTERM to group 2803. PIDs of all processes in the group: [2803]
2026-02-27 13:21:00,968 INFO - Sending the signal Signals.SIGTERM to group 2803
2026-02-27 13:21:01,793 INFO - Process psutil.Process(pid=2803, status='terminated', exitcode=0, started='09:20:27') (2803) terminated with exit code 0
2026-02-27 13:21:01,806 INFO - Launched DagFileProcessorManager with pid: 11866
2026-02-27 13:21:01,828 INFO - Heartbeat recovered after 200.72 seconds
2026-02-27 13:21:01,846 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:21:13,850 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:17:54.213530+00:00 [scheduled]>
2026-02-27 13:21:13,851 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:21:13,852 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:17:54.213530+00:00 [scheduled]>
2026-02-27 13:21:13,856 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:17:54.213530+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:21:13,857 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:17:54.213530+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 13:21:13,858 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:17:54.213530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:21:13,861 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:17:54.213530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:21:19,504 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:17:54.213530+00:00', try_number=1, map_index=-1)
2026-02-27 13:21:41,976 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:21:41,978 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:21:41,979 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:21:41,982 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:21:41,984 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='trigger_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2026-02-27 13:21:41,985 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'trigger_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:21:41,988 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'trigger_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:21:46,207 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='trigger_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1)
2026-02-27 13:21:46,216 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=trigger_, run_id=manual__2026-02-27T05:21:34.303328+00:00, map_index=-1, run_start_date=2026-02-27 05:21:45.125483+00:00, run_end_date=2026-02-27 05:21:45.542846+00:00, run_duration=0.417363, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=519, pool=default_pool, queue=default, priority_weight=6, operator=TriggerDagRunOperator, queued_dttm=2026-02-27 05:21:41.980687+00:00, queued_by_job_id=452, pid=11898
2026-02-27 13:21:50,035 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:21:50,036 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:21:50,038 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:21:50,041 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:21:50,043 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:21:50,044 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:21:50,047 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:21:53,945 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1)
2026-02-27 13:21:53,956 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=wait_for_, run_id=manual__2026-02-27T05:21:34.303328+00:00, map_index=-1, run_start_date=2026-02-27 05:21:52.971266+00:00, run_end_date=2026-02-27 05:21:53.366406+00:00, run_duration=0.39514, state=up_for_reschedule, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=520, pool=default_pool, queue=default, priority_weight=5, operator=ExternalTaskSensor, queued_dttm=2026-02-27 05:21:50.040251+00:00, queued_by_job_id=452, pid=11901
2026-02-27 13:22:39,463 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:22:39,464 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:22:39,465 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:22:39,468 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:22:39,470 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:22:39,472 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:22:39,475 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:22:44,056 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1)
2026-02-27 13:22:44,066 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=wait_for_, run_id=manual__2026-02-27T05:21:34.303328+00:00, map_index=-1, run_start_date=2026-02-27 05:22:43.065727+00:00, run_end_date=2026-02-27 05:22:43.487860+00:00, run_duration=0.422133, state=up_for_reschedule, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=521, pool=default_pool, queue=default, priority_weight=5, operator=ExternalTaskSensor, queued_dttm=2026-02-27 05:22:39.466127+00:00, queued_by_job_id=452, pid=11920
2026-02-27 13:23:40,467 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:23:40,469 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:23:40,470 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:23:40,473 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:23:40,474 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:23:40,475 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:23:40,478 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:23:44,968 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1)
2026-02-27 13:23:44,980 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=wait_for_, run_id=manual__2026-02-27T05:21:34.303328+00:00, map_index=-1, run_start_date=2026-02-27 05:23:43.975305+00:00, run_end_date=2026-02-27 05:23:44.424614+00:00, run_duration=0.449309, state=up_for_reschedule, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=522, pool=default_pool, queue=default, priority_weight=5, operator=ExternalTaskSensor, queued_dttm=2026-02-27 05:23:40.471698+00:00, queued_by_job_id=452, pid=11964
2026-02-27 13:24:49,720 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:24:49,722 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:24:49,723 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>
2026-02-27 13:24:49,726 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:21:34.303328+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:24:49,727 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:24:49,737 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:24:49,741 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:21:34.303328+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:24:54,441 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:21:34.303328+00:00', try_number=1, map_index=-1)
2026-02-27 13:24:54,454 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=wait_for_, run_id=manual__2026-02-27T05:21:34.303328+00:00, map_index=-1, run_start_date=2026-02-27 05:24:53.505269+00:00, run_end_date=2026-02-27 05:24:53.881612+00:00, run_duration=0.376343, state=up_for_reschedule, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=523, pool=default_pool, queue=default, priority_weight=5, operator=ExternalTaskSensor, queued_dttm=2026-02-27 05:24:49.724932+00:00, queued_by_job_id=452, pid=12012
2026-02-27 13:26:03,437 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:26:53,446 WARNING - Serialized DAG cdrd_ no longer exists
2026-02-27 13:26:53,449 ERROR - Couldn't find DAG cdrd_ in DAG bag or database!
2026-02-27 13:26:53,462 ERROR - DAG 'cdrd_' not found in serialized_dag table
2026-02-27 13:27:40,811 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:27:40,813 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:27:40,814 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:27:40,817 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:27:40,818 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='trigger_', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2026-02-27 13:27:40,818 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'trigger_', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:27:40,821 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'trigger_', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:27:45,178 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='trigger_', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1)
2026-02-27 13:27:45,188 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=trigger_, run_id=manual__2026-02-27T05:27:33.151070+00:00, map_index=-1, run_start_date=2026-02-27 05:27:44.136838+00:00, run_end_date=2026-02-27 05:27:44.560830+00:00, run_duration=0.423992, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=486, pool=default_pool, queue=default, priority_weight=6, operator=TriggerDagRunOperator, queued_dttm=2026-02-27 05:27:40.815733+00:00, queued_by_job_id=452, pid=12112
2026-02-27 13:27:48,014 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:27:48,015 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:27:48,016 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:27:48,019 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:27:48,020 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:27:48,021 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:27:48,024 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:27:51,902 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1)
2026-02-27 13:27:51,913 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=wait_for_, run_id=manual__2026-02-27T05:27:33.151070+00:00, map_index=-1, run_start_date=2026-02-27 05:27:50.928575+00:00, run_end_date=2026-02-27 05:27:51.301300+00:00, run_duration=0.372725, state=up_for_reschedule, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=487, pool=default_pool, queue=default, priority_weight=5, operator=ExternalTaskSensor, queued_dttm=2026-02-27 05:27:48.017738+00:00, queued_by_job_id=452, pid=12115
2026-02-27 13:29:51,479 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:29:51,480 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:29:51,481 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:29:51,483 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:29:51,485 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:29:51,486 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:29:51,489 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'wait_for_', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:29:56,109 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='wait_for_', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1)
2026-02-27 13:29:56,124 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=wait_for_, run_id=manual__2026-02-27T05:27:33.151070+00:00, map_index=-1, run_start_date=2026-02-27 05:29:54.997794+00:00, run_end_date=2026-02-27 05:29:55.404978+00:00, run_duration=0.407184, state=up_for_reschedule, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=2, job_id=488, pool=default_pool, queue=default, priority_weight=5, operator=ExternalTaskSensor, queued_dttm=2026-02-27 05:29:51.482115+00:00, queued_by_job_id=452, pid=12174
2026-02-27 13:31:04,816 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:31:18,717 WARNING - Serialized DAG cdrd_ no longer exists
2026-02-27 13:31:18,721 ERROR - Couldn't find DAG cdrd_ in DAG bag or database!
2026-02-27 13:31:18,727 ERROR - DAG 'cdrd_' not found in serialized_dag table
2026-02-27 13:31:23,188 ERROR - Failed to get task for ti <TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:27:33.151070+00:00 [success]>. Marking it as removed.
2026-02-27 13:31:23,198 ERROR - Failed to get task for ti <TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [up_for_reschedule]>. Marking it as removed.
2026-02-27 13:31:23,200 ERROR - Failed to get task for ti <TaskInstance: cdrd_.trigger_ manual__2026-02-27T05:27:33.151070+00:00 [None]>. Marking it as removed.
2026-02-27 13:31:23,201 ERROR - Failed to get task for ti <TaskInstance: cdrd_.wait_for_ manual__2026-02-27T05:27:33.151070+00:00 [None]>. Marking it as removed.
2026-02-27 13:31:23,222 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:31:23,223 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:31:23,224 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>
2026-02-27 13:31:23,227 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:27:33.151070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:31:23,229 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2026-02-27 13:31:23,231 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:31:23,234 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:27:33.151070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:31:28,400 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:27:33.151070+00:00', try_number=1, map_index=-1)
2026-02-27 13:31:48,126 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>
2026-02-27 13:31:48,127 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:31:48,128 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>
2026-02-27 13:31:48,131 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:31:48,132 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:31:42.617986+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2026-02-27 13:31:48,133 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:31:42.617986+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:31:48,135 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:31:42.617986+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:31:52,404 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:31:42.617986+00:00', try_number=1, map_index=-1)
2026-02-27 13:31:52,414 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:31:42.617986+00:00, map_index=-1, run_start_date=2026-02-27 05:31:51.370978+00:00, run_end_date=2026-02-27 05:31:51.806064+00:00, run_duration=0.435086, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=486, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2026-02-27 05:31:48.129181+00:00, queued_by_job_id=452, pid=12307
2026-02-27 13:31:55,082 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>
2026-02-27 13:31:55,083 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:31:55,084 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>
2026-02-27 13:31:55,087 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:31:55,088 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:31:42.617986+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2026-02-27 13:31:55,089 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:31:42.617986+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:31:55,091 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:31:42.617986+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:31:59,018 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:31:42.617986+00:00', try_number=1, map_index=-1)
2026-02-27 13:31:59,028 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T05:31:42.617986+00:00, map_index=-1, run_start_date=2026-02-27 05:31:58.062108+00:00, run_end_date=2026-02-27 05:31:58.470977+00:00, run_duration=0.408869, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=487, pool=default_pool, queue=default, priority_weight=6, operator=TriggerDagRunOperator, queued_dttm=2026-02-27 05:31:55.085614+00:00, queued_by_job_id=452, pid=12310
2026-02-27 13:32:01,958 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>
2026-02-27 13:32:01,959 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:32:01,960 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>
2026-02-27 13:32:01,963 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T05:31:42.617986+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:32:01,964 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:31:42.617986+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:32:01,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:31:42.617986+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:32:01,968 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:31:42.617986+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:40:35,446 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:31:42.617986+00:00', try_number=1, map_index=-1)
2026-02-27 13:40:35,476 ERROR - DagFileProcessorManager (PID=11866) last sent a heartbeat 513.75 seconds ago! Restarting it
2026-02-27 13:40:35,488 INFO - Sending Signals.SIGTERM to group 11866. PIDs of all processes in the group: [11866]
2026-02-27 13:40:35,489 INFO - Sending the signal Signals.SIGTERM to group 11866
2026-02-27 13:40:36,318 INFO - Process psutil.Process(pid=11866, status='terminated', exitcode=0, started='13:21:01') (11866) terminated with exit code 0
2026-02-27 13:40:36,329 INFO - Launched DagFileProcessorManager with pid: 12498
2026-02-27 13:40:36,344 INFO - Heartbeat recovered after 517.29 seconds
2026-02-27 13:40:36,372 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:40:57,711 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_.DAG manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:40:57,713 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:40:57,714 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_.DAG manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:40:57,717 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_.DAG manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:40:57,719 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='DAG', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 7 and queue default
2026-02-27 13:40:57,720 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'DAG', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:40:57,723 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'DAG', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:01,981 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='DAG', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1)
2026-02-27 13:41:01,992 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=DAG, run_id=manual__2026-02-27T05:40:49.496070+00:00, map_index=-1, run_start_date=2026-02-27 05:41:01.017388+00:00, run_end_date=2026-02-27 05:41:01.401526+00:00, run_duration=0.384138, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=489, pool=default_pool, queue=default, priority_weight=7, operator=PythonOperator, queued_dttm=2026-02-27 05:40:57.715628+00:00, queued_by_job_id=452, pid=12524
2026-02-27 13:41:05,629 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:05,631 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:41:05,632 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:05,634 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:41:05,635 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2026-02-27 13:41:05,636 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:05,639 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:11,594 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1)
2026-02-27 13:41:11,606 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:40:49.496070+00:00, map_index=-1, run_start_date=2026-02-27 05:41:08.588800+00:00, run_end_date=2026-02-27 05:41:11.020404+00:00, run_duration=2.431604, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=490, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2026-02-27 05:41:05.633362+00:00, queued_by_job_id=452, pid=12527
2026-02-27 13:41:15,435 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:15,436 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:41:15,436 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:15,439 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:41:15,441 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:41:15,441 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:15,444 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:19,351 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1)
2026-02-27 13:41:19,378 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T05:40:49.496070+00:00, map_index=-1, run_start_date=2026-02-27 05:41:18.322972+00:00, run_end_date=2026-02-27 05:41:18.735202+00:00, run_duration=0.41223, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=491, pool=default_pool, queue=default, priority_weight=5, operator=TriggerDagRunOperator, queued_dttm=2026-02-27 05:41:15.438227+00:00, queued_by_job_id=452, pid=12534
2026-02-27 13:41:23,115 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:23,116 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:41:23,117 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:23,119 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:41:23,120 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 13:41:23,121 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:23,124 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:37,065 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1)
2026-02-27 13:41:37,076 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:40:49.496070+00:00, map_index=-1, run_start_date=2026-02-27 05:41:26.089413+00:00, run_end_date=2026-02-27 05:41:36.464042+00:00, run_duration=10.374629, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=492, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 05:41:23.118427+00:00, queued_by_job_id=452, pid=12539
2026-02-27 13:41:40,894 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:40,895 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:41:40,896 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:40,899 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:41:40,900 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:41:40,900 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:40,903 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:44,913 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1)
2026-02-27 13:41:44,926 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:40:49.496070+00:00, map_index=-1, run_start_date=2026-02-27 05:41:43.889675+00:00, run_end_date=2026-02-27 05:41:44.280665+00:00, run_duration=0.39099, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=493, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 05:41:40.897839+00:00, queued_by_job_id=452, pid=12547
2026-02-27 13:41:48,166 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:48,167 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:41:48,168 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>
2026-02-27 13:41:48,171 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:40:49.496070+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:41:48,172 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 13:41:48,173 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:48,176 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:40:49.496070+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:41:52,048 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:40:49.496070+00:00', try_number=1, map_index=-1)
2026-02-27 13:41:52,057 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:40:49.496070+00:00, map_index=-1, run_start_date=2026-02-27 05:41:51.125579+00:00, run_end_date=2026-02-27 05:41:51.506357+00:00, run_duration=0.380778, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=494, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 05:41:48.169871+00:00, queued_by_job_id=452, pid=12550
2026-02-27 13:41:58,992 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 05:40:49.496070+00:00: manual__2026-02-27T05:40:49.496070+00:00, state:running, queued_at: 2026-02-27 05:40:49.527964+00:00. externally triggered: True> successful
2026-02-27 13:41:58,994 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 05:40:49.496070+00:00, run_id=manual__2026-02-27T05:40:49.496070+00:00, run_start_date=2026-02-27 05:40:53.929794+00:00, run_end_date=2026-02-27 05:41:58.993990+00:00, run_duration=65.064196, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 05:40:49.496070+00:00, data_interval_end=2026-02-27 05:40:49.496070+00:00, dag_hash=9ec5776a3d28aaf7ed843b458e05dcf0
2026-02-27 13:44:52,294 INFO - 3 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>
	<TaskInstance: cdrd_.API manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>
2026-02-27 13:44:52,296 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:44:52,297 INFO - DAG cdrd_ has 1/16 running and queued tasks
2026-02-27 13:44:52,298 INFO - DAG cdrd_ has 2/16 running and queued tasks
2026-02-27 13:44:52,299 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>
	<TaskInstance: cdrd_.API manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>
2026-02-27 13:44:52,302 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>, <TaskInstance: cdrd_.API manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-27T05:44:44.732980+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:44:52,304 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:44:44.732980+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:44:52,305 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:44:44.732980+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:44:52,306 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='API', run_id='manual__2026-02-27T05:44:44.732980+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:44:52,306 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'API', 'manual__2026-02-27T05:44:44.732980+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:44:52,307 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:44:44.732980+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:44:52,308 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:44:44.732980+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:44:52,311 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:44:44.732980+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:45:00,879 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'API', 'manual__2026-02-27T05:44:44.732980+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:48:46,143 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:44:44.732980+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:48:51,303 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:44:44.732980+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']' returned non-zero exit status 1..
2026-02-27 13:48:51,306 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:44:44.732980+00:00', try_number=1, map_index=-1)
2026-02-27 13:48:51,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='API', run_id='manual__2026-02-27T05:44:44.732980+00:00', try_number=1, map_index=-1)
2026-02-27 13:48:51,307 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:44:44.732980+00:00', try_number=1, map_index=-1)
2026-02-27 13:48:51,328 ERROR - DagFileProcessorManager (PID=12498) last sent a heartbeat 239.09 seconds ago! Restarting it
2026-02-27 13:48:51,336 INFO - Sending Signals.SIGTERM to group 12498. PIDs of all processes in the group: [12498]
2026-02-27 13:48:51,337 INFO - Sending the signal Signals.SIGTERM to group 12498
2026-02-27 13:48:52,205 INFO - Process psutil.Process(pid=12498, status='terminated', exitcode=0, started='13:40:36') (12498) terminated with exit code 0
2026-02-27 13:48:52,213 INFO - Launched DagFileProcessorManager with pid: 12791
2026-02-27 13:48:52,228 INFO - Heartbeat recovered after 243.84 seconds
2026-02-27 13:48:52,239 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:49:03,714 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>
2026-02-27 13:49:03,715 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 13:49:03,716 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:49:03,717 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>
2026-02-27 13:49:03,721 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:49:03,722 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:49:03,723 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:49:03,724 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:47:58.667278+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 13:49:03,725 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:47:58.667278+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:49:03,728 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:49:10,112 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:47:58.667278+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:49:15,165 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1)
2026-02-27 13:49:15,167 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:47:58.667278+00:00', try_number=1, map_index=-1)
2026-02-27 13:49:15,177 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T05:48:51.261592+00:00, map_index=-1, run_start_date=2026-02-27 05:49:09.007837+00:00, run_end_date=2026-02-27 05:49:09.309275+00:00, run_duration=0.301438, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=488, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 05:49:03.719450+00:00, queued_by_job_id=452, pid=12817
2026-02-27 13:49:15,179 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:47:58.667278+00:00, map_index=-1, run_start_date=2026-02-27 05:49:14.109086+00:00, run_end_date=2026-02-27 05:49:14.383715+00:00, run_duration=0.274629, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=489, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 05:49:03.719450+00:00, queued_by_job_id=452, pid=12822
2026-02-27 13:49:19,340 INFO - 3 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
2026-02-27 13:49:19,341 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:49:19,341 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 13:49:19,342 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 13:49:19,344 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
2026-02-27 13:49:19,347 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:49:19,348 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:47:58.667278+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:49:19,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:47:58.667278+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:49:19,350 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:49:19,351 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:49:19,352 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:49:19,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:49:19,355 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:47:58.667278+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:49:35,073 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:49:48,256 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:50:00,691 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:47:58.667278+00:00', try_number=1, map_index=-1)
2026-02-27 13:50:00,693 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1)
2026-02-27 13:50:00,694 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1)
2026-02-27 13:50:00,708 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T05:48:51.261592+00:00, map_index=-1, run_start_date=2026-02-27 05:49:39.999169+00:00, run_end_date=2026-02-27 05:49:46.910271+00:00, run_duration=6.911102, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=491, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 05:49:19.345348+00:00, queued_by_job_id=452, pid=12874
2026-02-27 13:50:00,711 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T05:48:51.261592+00:00, map_index=-1, run_start_date=2026-02-27 05:49:53.186321+00:00, run_end_date=2026-02-27 05:49:59.315076+00:00, run_duration=6.128755, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=492, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 05:49:19.345348+00:00, queued_by_job_id=452, pid=12907
2026-02-27 13:50:00,712 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:47:58.667278+00:00, map_index=-1, run_start_date=2026-02-27 05:49:23.283684+00:00, run_end_date=2026-02-27 05:49:33.343792+00:00, run_duration=10.060108, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=490, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 05:49:19.345348+00:00, queued_by_job_id=452, pid=12826
2026-02-27 13:50:00,736 INFO - Heartbeat recovered after 45.54 seconds
2026-02-27 13:50:04,204 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
2026-02-27 13:50:04,205 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:50:04,206 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 13:50:04,208 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>
2026-02-27 13:50:04,211 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:47:58.667278+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T05:48:51.261592+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:50:04,212 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:47:58.667278+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 13:50:04,213 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:47:58.667278+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:50:04,213 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 13:50:04,214 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:50:04,217 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:47:58.667278+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:50:09,503 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T05:48:51.261592+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 13:50:14,708 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:47:58.667278+00:00', try_number=1, map_index=-1)
2026-02-27 13:50:14,710 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T05:48:51.261592+00:00', try_number=1, map_index=-1)
2026-02-27 13:50:14,719 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T05:48:51.261592+00:00, map_index=-1, run_start_date=2026-02-27 05:50:13.679169+00:00, run_end_date=2026-02-27 05:50:13.972026+00:00, run_duration=0.292857, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=494, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 05:50:04.209534+00:00, queued_by_job_id=452, pid=12951
2026-02-27 13:50:14,721 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:47:58.667278+00:00, map_index=-1, run_start_date=2026-02-27 05:50:08.410367+00:00, run_end_date=2026-02-27 05:50:08.767210+00:00, run_duration=0.356843, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=493, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 05:50:04.209534+00:00, queued_by_job_id=452, pid=12946
2026-02-27 13:50:24,557 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 05:47:58.667278+00:00: manual__2026-02-27T05:47:58.667278+00:00, state:running, queued_at: 2026-02-27 05:47:58.707899+00:00. externally triggered: True> successful
2026-02-27 13:50:24,558 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 05:47:58.667278+00:00, run_id=manual__2026-02-27T05:47:58.667278+00:00, run_start_date=2026-02-27 05:48:57.429948+00:00, run_end_date=2026-02-27 05:50:24.558421+00:00, run_duration=87.128473, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 05:47:58.667278+00:00, data_interval_end=2026-02-27 05:47:58.667278+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 13:50:24,564 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 05:48:51.261592+00:00: manual__2026-02-27T05:48:51.261592+00:00, state:running, queued_at: 2026-02-27 05:48:51.283494+00:00. externally triggered: True> successful
2026-02-27 13:50:24,565 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 05:48:51.261592+00:00, run_id=manual__2026-02-27T05:48:51.261592+00:00, run_start_date=2026-02-27 05:48:57.432526+00:00, run_end_date=2026-02-27 05:50:24.565395+00:00, run_duration=87.132869, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 05:48:51.261592+00:00, data_interval_end=2026-02-27 05:48:51.261592+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 13:50:42,321 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>
2026-02-27 13:50:42,321 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:50:42,323 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>
2026-02-27 13:50:42,326 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:50:42,327 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:50:37+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 13:50:42,327 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:50:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:50:42,330 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:50:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:50:47,146 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:50:37+00:00', try_number=1, map_index=-1)
2026-02-27 13:50:47,156 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:50:37+00:00, map_index=-1, run_start_date=2026-02-27 05:50:46.199430+00:00, run_end_date=2026-02-27 05:50:46.408446+00:00, run_duration=0.209016, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=495, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 05:50:42.324595+00:00, queued_by_job_id=452, pid=12984
2026-02-27 13:50:50,246 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>
2026-02-27 13:50:50,247 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:50:50,248 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>
2026-02-27 13:50:50,250 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:50:50,251 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:50:37+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:50:50,252 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:50:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:50:50,255 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:50:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:51:05,339 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:50:37+00:00', try_number=1, map_index=-1)
2026-02-27 13:51:05,352 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:50:37+00:00, map_index=-1, run_start_date=2026-02-27 05:50:55.894008+00:00, run_end_date=2026-02-27 05:51:04.533188+00:00, run_duration=8.63918, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=496, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 05:50:50.249146+00:00, queued_by_job_id=452, pid=12998
2026-02-27 13:51:09,443 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>
2026-02-27 13:51:09,444 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:51:09,445 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>
2026-02-27 13:51:09,448 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:50:37+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:51:09,449 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:50:37+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 13:51:09,450 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:50:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:51:09,452 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:50:37+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 13:51:16,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:50:37+00:00', try_number=1, map_index=-1)
2026-02-27 13:51:16,253 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:50:37+00:00, map_index=-1, run_start_date=2026-02-27 05:51:14.318919+00:00, run_end_date=2026-02-27 05:51:14.838308+00:00, run_duration=0.519389, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=497, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 05:51:09.446945+00:00, queued_by_job_id=452, pid=13040
2026-02-27 13:51:23,124 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 05:50:37+00:00: manual__2026-02-27T05:50:37+00:00, state:running, queued_at: 2026-02-27 05:50:37.867124+00:00. externally triggered: True> successful
2026-02-27 13:51:23,125 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 05:50:37+00:00, run_id=manual__2026-02-27T05:50:37+00:00, run_start_date=2026-02-27 05:50:38.524602+00:00, run_end_date=2026-02-27 05:51:23.124942+00:00, run_duration=44.60034, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 05:50:37+00:00, data_interval_end=2026-02-27 05:50:37+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 13:52:55,179 INFO - 3 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>
	<TaskInstance: cdrd_.API manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>
2026-02-27 13:52:55,180 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:52:55,181 INFO - DAG cdrd_ has 1/16 running and queued tasks
2026-02-27 13:52:55,182 INFO - DAG cdrd_ has 2/16 running and queued tasks
2026-02-27 13:52:55,183 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>
	<TaskInstance: cdrd_.API manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>
2026-02-27 13:52:55,186 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>, <TaskInstance: cdrd_.API manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-27T05:52:48.748580+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:52:55,187 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:52:48.748580+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:52:55,187 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:52:48.748580+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:52:55,188 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='API', run_id='manual__2026-02-27T05:52:48.748580+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:52:55,189 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', 'API', 'manual__2026-02-27T05:52:48.748580+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:52:55,190 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:52:48.748580+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 13:52:55,191 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:52:48.748580+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:52:55,194 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:52:48.748580+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:53:02,753 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', 'API', 'manual__2026-02-27T05:52:48.748580+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:58:23,459 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:52:48.748580+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:58:27,794 ERROR - Failed to execute task Command '['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:52:48.748580+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']' returned non-zero exit status 1..
2026-02-27 13:58:27,797 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:52:48.748580+00:00', try_number=1, map_index=-1)
2026-02-27 13:58:27,798 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='API', run_id='manual__2026-02-27T05:52:48.748580+00:00', try_number=1, map_index=-1)
2026-02-27 13:58:27,799 INFO - Received executor event with state failed for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:52:48.748580+00:00', try_number=1, map_index=-1)
2026-02-27 13:58:27,832 ERROR - DagFileProcessorManager (PID=12791) last sent a heartbeat 332.70 seconds ago! Restarting it
2026-02-27 13:58:27,845 INFO - Sending Signals.SIGTERM to group 12791. PIDs of all processes in the group: [12791]
2026-02-27 13:58:27,846 INFO - Sending the signal Signals.SIGTERM to group 12791
2026-02-27 13:58:28,511 INFO - Process psutil.Process(pid=12791, status='terminated', exitcode=0, started='13:48:52') (12791) terminated with exit code 0
2026-02-27 13:58:28,523 INFO - Launched DagFileProcessorManager with pid: 13299
2026-02-27 13:58:28,544 INFO - Heartbeat recovered after 341.06 seconds
2026-02-27 13:58:28,572 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 13:58:40,604 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 13:58:40,606 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:58:40,608 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 13:58:40,610 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:58:40,612 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 6 and queue default
2026-02-27 13:58:40,612 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:58:40,615 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:58:48,674 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1)
2026-02-27 13:58:48,688 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T05:57:38.693560+00:00, map_index=-1, run_start_date=2026-02-27 05:58:43.998848+00:00, run_end_date=2026-02-27 05:58:48.060199+00:00, run_duration=4.061351, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=500, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2026-02-27 05:58:40.609530+00:00, queued_by_job_id=452, pid=13304
2026-02-27 13:58:52,990 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 13:58:52,991 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 13:58:52,992 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 13:58:52,994 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 13:58:52,995 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 13:58:52,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 13:58:52,998 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:00:26,933 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1)
2026-02-27 14:00:26,944 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T05:57:38.693560+00:00, map_index=-1, run_start_date=2026-02-27 05:58:55.868023+00:00, run_end_date=2026-02-27 06:00:26.256267+00:00, run_duration=90.388244, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=501, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 05:58:52.993249+00:00, queued_by_job_id=452, pid=13316
2026-02-27 14:00:26,957 ERROR - DagFileProcessorManager (PID=13299) last sent a heartbeat 94.01 seconds ago! Restarting it
2026-02-27 14:00:26,969 INFO - Sending Signals.SIGTERM to group 13299. PIDs of all processes in the group: [13299]
2026-02-27 14:00:26,970 INFO - Sending the signal Signals.SIGTERM to group 13299
2026-02-27 14:00:27,513 INFO - Process psutil.Process(pid=13299, status='terminated', exitcode=0, started='13:58:28') (13299) terminated with exit code 0
2026-02-27 14:00:27,522 INFO - Launched DagFileProcessorManager with pid: 13341
2026-02-27 14:00:27,535 INFO - Heartbeat recovered after 98.83 seconds
2026-02-27 14:00:33,366 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 14:00:33,367 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 14:00:33,368 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 14:00:33,370 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:00:33,372 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 14:00:33,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:00:33,375 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:00:41,666 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1)
2026-02-27 14:00:41,678 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T05:57:38.693560+00:00, map_index=-1, run_start_date=2026-02-27 06:00:36.691305+00:00, run_end_date=2026-02-27 06:00:41.112894+00:00, run_duration=4.421589, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=502, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 06:00:33.369588+00:00, queued_by_job_id=452, pid=13344
2026-02-27 14:00:46,144 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 14:00:46,145 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 14:00:46,146 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 14:00:46,149 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:00:46,150 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 14:00:46,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:00:46,154 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:02:20,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1)
2026-02-27 14:02:20,555 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T05:57:38.693560+00:00, map_index=-1, run_start_date=2026-02-27 06:00:49.427171+00:00, run_end_date=2026-02-27 06:02:19.885216+00:00, run_duration=90.458045, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=503, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 06:00:46.148460+00:00, queued_by_job_id=452, pid=13357
2026-02-27 14:02:20,570 ERROR - DagFileProcessorManager (PID=13341) last sent a heartbeat 94.48 seconds ago! Restarting it
2026-02-27 14:02:20,582 INFO - Sending Signals.SIGTERM to group 13341. PIDs of all processes in the group: [13341]
2026-02-27 14:02:20,583 INFO - Sending the signal Signals.SIGTERM to group 13341
2026-02-27 14:02:21,327 INFO - Process psutil.Process(pid=13341, status='terminated', exitcode=0, started='14:00:27') (13341) terminated with exit code 0
2026-02-27 14:02:21,333 INFO - Launched DagFileProcessorManager with pid: 13431
2026-02-27 14:02:21,351 INFO - Heartbeat recovered after 99.65 seconds
2026-02-27 14:02:27,313 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 14:02:27,315 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 14:02:27,316 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 14:02:27,317 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>
2026-02-27 14:02:27,320 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-27T05:57:38.693560+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:02:27,321 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 14:02:27,322 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:02:27,323 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 14:02:27,325 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:02:27,328 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:02:33,271 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T05:57:38.693560+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:02:37,223 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1)
2026-02-27 14:02:37,226 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T05:57:38.693560+00:00', try_number=1, map_index=-1)
2026-02-27 14:02:37,236 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=triggered_by_main_dag_1772172037, map_index=-1, run_start_date=2026-02-27 06:02:32.254733+00:00, run_end_date=2026-02-27 06:02:32.514890+00:00, run_duration=0.260157, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=504, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 06:02:27.319216+00:00, queued_by_job_id=452, pid=13435
2026-02-27 14:02:37,237 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T05:57:38.693560+00:00, map_index=-1, run_start_date=2026-02-27 06:02:36.206995+00:00, run_end_date=2026-02-27 06:02:36.648149+00:00, run_duration=0.441154, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=1, job_id=505, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 06:02:27.319216+00:00, queued_by_job_id=452, pid=13437
2026-02-27 14:02:41,910 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
2026-02-27 14:02:41,913 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 14:02:41,916 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 14:02:41,919 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
2026-02-27 14:02:41,928 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>, <TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:02:41,932 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 14:02:41,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:02:41,939 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 14:02:41,941 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:02:41,945 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:02:58,070 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:03:10,384 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1)
2026-02-27 14:03:10,386 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1)
2026-02-27 14:03:10,398 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=triggered_by_main_dag_1772172037, map_index=-1, run_start_date=2026-02-27 06:02:47.402567+00:00, run_end_date=2026-02-27 06:02:56.968651+00:00, run_duration=9.566084, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=506, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 06:02:41.923230+00:00, queued_by_job_id=452, pid=13451
2026-02-27 14:03:10,401 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=triggered_by_main_dag_1772172037, map_index=-1, run_start_date=2026-02-27 06:03:03.399106+00:00, run_end_date=2026-02-27 06:03:09.256050+00:00, run_duration=5.856944, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=507, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 06:02:41.923230+00:00, queued_by_job_id=452, pid=13502
2026-02-27 14:03:10,428 INFO - Heartbeat recovered after 33.17 seconds
2026-02-27 14:03:15,244 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 05:57:38.693560+00:00: manual__2026-02-27T05:57:38.693560+00:00, state:running, queued_at: 2026-02-27 05:57:38.730856+00:00. externally triggered: True> successful
2026-02-27 14:03:15,245 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 05:57:38.693560+00:00, run_id=manual__2026-02-27T05:57:38.693560+00:00, run_start_date=2026-02-27 05:58:34.174901+00:00, run_end_date=2026-02-27 06:03:15.245462+00:00, run_duration=281.070561, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 05:57:38.693560+00:00, data_interval_end=2026-02-27 05:57:38.693560+00:00, dag_hash=4b48a92f1136f16d73b59d34d0420ed6
2026-02-27 14:03:15,256 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
2026-02-27 14:03:15,257 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 14:03:15,258 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>
2026-02-27 14:03:15,261 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. triggered_by_main_dag_1772172037 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:03:15,262 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 14:03:15,263 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:03:15,266 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'triggered_by_main_dag_1772172037', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:03:20,725 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='triggered_by_main_dag_1772172037', try_number=1, map_index=-1)
2026-02-27 14:03:20,746 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=triggered_by_main_dag_1772172037, map_index=-1, run_start_date=2026-02-27 06:03:19.617956+00:00, run_end_date=2026-02-27 06:03:19.919046+00:00, run_duration=0.30109, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=508, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 06:03:15.260174+00:00, queued_by_job_id=452, pid=13539
2026-02-27 14:03:28,444 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 06:00:40+00:00: triggered_by_main_dag_1772172037, state:running, queued_at: 2026-02-27 06:00:40.658073+00:00. externally triggered: True> successful
2026-02-27 14:03:28,446 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 06:00:40+00:00, run_id=triggered_by_main_dag_1772172037, run_start_date=2026-02-27 06:00:46.110106+00:00, run_end_date=2026-02-27 06:03:28.445968+00:00, run_duration=162.335862, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 06:00:40+00:00, data_interval_end=2026-02-27 06:00:40+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 14:03:32,313 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:06:26,912 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_._ manual__2026-02-27T06:06:21.730557+00:00 [scheduled]>
	<TaskInstance: cdrd_._ manual__2026-02-27T06:06:21.730557+00:00 [scheduled]>
2026-02-27 14:06:26,913 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 14:06:26,914 INFO - DAG cdrd_ has 1/16 running and queued tasks
2026-02-27 14:06:26,914 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_._ manual__2026-02-27T06:06:21.730557+00:00 [scheduled]>
	<TaskInstance: cdrd_._ manual__2026-02-27T06:06:21.730557+00:00 [scheduled]>
2026-02-27 14:06:26,917 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_._ manual__2026-02-27T06:06:21.730557+00:00 [scheduled]>, <TaskInstance: cdrd_._ manual__2026-02-27T06:06:21.730557+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:06:26,918 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T06:06:21.730557+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 14:06:26,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T06:06:21.730557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:06:26,919 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T06:06:21.730557+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 14:06:26,920 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T06:06:21.730557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:06:26,923 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T06:06:21.730557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:06:34,168 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '_', 'manual__2026-02-27T06:06:21.730557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD/cdrd_.py']
2026-02-27 14:06:41,358 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T06:06:21.730557+00:00', try_number=1, map_index=-1)
2026-02-27 14:06:41,363 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='_', run_id='manual__2026-02-27T06:06:21.730557+00:00', try_number=1, map_index=-1)
2026-02-27 14:06:41,372 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T06:06:21.730557+00:00, map_index=-1, run_start_date=2026-02-27 06:06:29.815044+00:00, run_end_date=2026-02-27 06:06:33.607691+00:00, run_duration=3.792647, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=509, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-27 06:06:26.916059+00:00, queued_by_job_id=452, pid=13658
2026-02-27 14:06:41,374 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=_, run_id=manual__2026-02-27T06:06:21.730557+00:00, map_index=-1, run_start_date=2026-02-27 06:06:37.131588+00:00, run_end_date=2026-02-27 06:06:40.785181+00:00, run_duration=3.653593, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=510, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-27 06:06:26.916059+00:00, queued_by_job_id=452, pid=13663
2026-02-27 14:06:48,226 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 06:06:21.730557+00:00: manual__2026-02-27T06:06:21.730557+00:00, state:running, queued_at: 2026-02-27 06:06:21.750690+00:00. externally triggered: True> successful
2026-02-27 14:06:48,227 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 06:06:21.730557+00:00, run_id=manual__2026-02-27T06:06:21.730557+00:00, run_start_date=2026-02-27 06:06:23.302588+00:00, run_end_date=2026-02-27 06:06:48.227801+00:00, run_duration=24.925213, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 06:06:21.730557+00:00, data_interval_end=2026-02-27 06:06:21.730557+00:00, dag_hash=350ed43b88aef8a39806235db83d1817
2026-02-27 14:06:48,242 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
2026-02-27 14:06:48,243 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 14:06:48,244 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
2026-02-27 14:06:48,246 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:06:48,247 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 14:06:48,248 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:06:48,250 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:06:53,428 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1)
2026-02-27 14:06:53,439 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T06:06:40+00:00, map_index=-1, run_start_date=2026-02-27 06:06:52.498537+00:00, run_end_date=2026-02-27 06:06:52.728104+00:00, run_duration=0.229567, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=511, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 06:06:48.245188+00:00, queued_by_job_id=452, pid=13669
2026-02-27 14:06:56,402 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
2026-02-27 14:06:56,404 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 14:06:56,405 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 14:06:56,406 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
2026-02-27 14:06:56,408 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:06:56,409 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 14:06:56,410 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:06:56,410 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 14:06:56,411 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:06:56,414 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:07:09,189 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:07:20,483 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1)
2026-02-27 14:07:20,485 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1)
2026-02-27 14:07:20,493 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T06:06:40+00:00, map_index=-1, run_start_date=2026-02-27 06:07:00.374827+00:00, run_end_date=2026-02-27 06:07:08.517460+00:00, run_duration=8.142633, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=512, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 06:06:56.406988+00:00, queued_by_job_id=452, pid=13672
2026-02-27 14:07:20,495 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T06:06:40+00:00, map_index=-1, run_start_date=2026-02-27 06:07:13.571967+00:00, run_end_date=2026-02-27 06:07:19.724457+00:00, run_duration=6.15249, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=513, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 06:06:56.406988+00:00, queued_by_job_id=452, pid=13715
2026-02-27 14:07:23,797 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
2026-02-27 14:07:23,798 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 14:07:23,798 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>
2026-02-27 14:07:23,801 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T06:06:40+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:07:23,803 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 14:07:23,803 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:07:23,806 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T06:06:40+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 14:07:28,733 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T06:06:40+00:00', try_number=1, map_index=-1)
2026-02-27 14:07:28,744 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T06:06:40+00:00, map_index=-1, run_start_date=2026-02-27 06:07:27.745313+00:00, run_end_date=2026-02-27 06:07:28.027769+00:00, run_duration=0.282456, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=514, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 06:07:23.799857+00:00, queued_by_job_id=452, pid=13737
2026-02-27 14:07:35,395 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 06:06:40+00:00: manual__2026-02-27T06:06:40+00:00, state:running, queued_at: 2026-02-27 06:06:40.349238+00:00. externally triggered: True> successful
2026-02-27 14:07:35,396 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 06:06:40+00:00, run_id=manual__2026-02-27T06:06:40+00:00, run_start_date=2026-02-27 06:06:44.083681+00:00, run_end_date=2026-02-27 06:07:35.396014+00:00, run_duration=51.312333, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 06:06:40+00:00, data_interval_end=2026-02-27 06:06:40+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 14:07:52,730 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>
2026-02-27 14:07:52,733 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 14:07:52,736 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>
2026-02-27 14:07:52,742 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:07:52,744 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T06:06:33+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 14:07:52,746 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T06:06:33+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 14:07:52,752 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T06:06:33+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 14:07:58,188 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T06:06:33+00:00', try_number=1, map_index=-1)
2026-02-27 14:07:58,197 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T06:06:33+00:00, map_index=-1, run_start_date=2026-02-27 06:07:57.216131+00:00, run_end_date=2026-02-27 06:07:57.438767+00:00, run_duration=0.222636, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=515, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 06:07:52.738370+00:00, queued_by_job_id=452, pid=13753
2026-02-27 14:08:01,999 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>
2026-02-27 14:08:02,000 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 14:08:02,003 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>
2026-02-27 14:08:02,006 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:08:02,007 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T06:06:33+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 14:08:02,007 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T06:06:33+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 14:08:02,011 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T06:06:33+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 14:08:15,711 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T06:06:33+00:00', try_number=1, map_index=-1)
2026-02-27 14:08:15,721 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T06:06:33+00:00, map_index=-1, run_start_date=2026-02-27 06:08:06.471208+00:00, run_end_date=2026-02-27 06:08:15.017707+00:00, run_duration=8.546499, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=516, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 06:08:02.004680+00:00, queued_by_job_id=452, pid=13759
2026-02-27 14:08:21,133 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>
2026-02-27 14:08:21,134 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 14:08:21,136 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>
2026-02-27 14:08:21,140 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T06:06:33+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 14:08:21,141 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T06:06:33+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 14:08:21,142 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T06:06:33+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 14:08:21,146 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T06:06:33+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 14:08:26,649 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T06:06:33+00:00', try_number=1, map_index=-1)
2026-02-27 14:08:26,659 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T06:06:33+00:00, map_index=-1, run_start_date=2026-02-27 06:08:25.419666+00:00, run_end_date=2026-02-27 06:08:25.938348+00:00, run_duration=0.518682, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=517, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 06:08:21.137827+00:00, queued_by_job_id=452, pid=13801
2026-02-27 14:08:36,263 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 06:06:33+00:00: manual__2026-02-27T06:06:33+00:00, state:running, queued_at: 2026-02-27 06:06:33.129373+00:00. externally triggered: True> successful
2026-02-27 14:08:36,265 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 06:06:33+00:00, run_id=manual__2026-02-27T06:06:33+00:00, run_start_date=2026-02-27 06:07:48.903612+00:00, run_end_date=2026-02-27 06:08:36.265175+00:00, run_duration=47.361563, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 06:06:33+00:00, data_interval_end=2026-02-27 06:06:33+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 14:08:36,296 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:13:37,369 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:18:37,619 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:23:40,654 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:28:41,419 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:33:42,631 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:38:43,126 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:43:45,157 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:48:45,793 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:53:46,121 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 14:58:48,853 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:03:51,895 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:08:53,903 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:13:55,525 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:16:55,956 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>
2026-02-27 15:16:55,958 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:16:55,958 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>
2026-02-27 15:16:55,961 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:16:55,965 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:16:49.714180+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 15:16:55,966 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:16:49.714180+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:16:55,969 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:16:49.714180+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:17:01,641 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:16:49.714180+00:00', try_number=1, map_index=-1)
2026-02-27 15:17:01,651 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:16:49.714180+00:00, map_index=-1, run_start_date=2026-02-27 07:17:00.689263+00:00, run_end_date=2026-02-27 07:17:00.916213+00:00, run_duration=0.22695, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=518, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 07:16:55.959958+00:00, queued_by_job_id=452, pid=16462
2026-02-27 15:17:04,710 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>
2026-02-27 15:17:04,712 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:17:04,712 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>
2026-02-27 15:17:04,716 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:17:04,717 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:16:49.714180+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:17:04,718 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:16:49.714180+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:17:04,720 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:16:49.714180+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:17:19,736 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:16:49.714180+00:00', try_number=1, map_index=-1)
2026-02-27 15:17:19,747 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:16:49.714180+00:00, map_index=-1, run_start_date=2026-02-27 07:17:08.999636+00:00, run_end_date=2026-02-27 07:17:18.848973+00:00, run_duration=9.849337, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=519, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:17:04.713875+00:00, queued_by_job_id=452, pid=16470
2026-02-27 15:17:23,158 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>
2026-02-27 15:17:23,159 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:17:23,160 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>
2026-02-27 15:17:23,163 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:16:49.714180+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:17:23,164 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:16:49.714180+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:17:23,165 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:16:49.714180+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:17:23,167 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:16:49.714180+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:17:28,245 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:16:49.714180+00:00', try_number=1, map_index=-1)
2026-02-27 15:17:28,254 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:16:49.714180+00:00, map_index=-1, run_start_date=2026-02-27 07:17:27.203382+00:00, run_end_date=2026-02-27 07:17:27.521736+00:00, run_duration=0.318354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=520, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:17:23.161711+00:00, queued_by_job_id=452, pid=16517
2026-02-27 15:17:35,268 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 07:16:49.714180+00:00: manual__2026-02-27T07:16:49.714180+00:00, state:running, queued_at: 2026-02-27 07:16:49.742174+00:00. externally triggered: True> successful
2026-02-27 15:17:35,269 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 07:16:49.714180+00:00, run_id=manual__2026-02-27T07:16:49.714180+00:00, run_start_date=2026-02-27 07:16:52.084718+00:00, run_end_date=2026-02-27 07:17:35.269774+00:00, run_duration=43.185056, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:16:49.714180+00:00, data_interval_end=2026-02-27 07:16:49.714180+00:00, dag_hash=98a67ac16d9eb12345f0f141bee51793
2026-02-27 15:18:58,660 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:23:04,463 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>
2026-02-27 15:23:04,464 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:23:04,465 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>
2026-02-27 15:23:04,468 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:23:04,469 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:22:56.996721+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 15:23:04,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:22:56.996721+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:23:04,473 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:22:56.996721+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:23:09,809 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:22:56.996721+00:00', try_number=1, map_index=-1)
2026-02-27 15:23:09,821 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:22:56.996721+00:00, map_index=-1, run_start_date=2026-02-27 07:23:08.854782+00:00, run_end_date=2026-02-27 07:23:09.084395+00:00, run_duration=0.229613, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=521, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 07:23:04.466909+00:00, queued_by_job_id=452, pid=16728
2026-02-27 15:23:13,472 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>
2026-02-27 15:23:13,473 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:23:13,473 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>
2026-02-27 15:23:13,476 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:23:13,478 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:22:56.996721+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:23:13,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:22:56.996721+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:23:13,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:22:56.996721+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:23:59,788 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:22:56.996721+00:00', try_number=1, map_index=-1)
2026-02-27 15:23:59,801 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:22:56.996721+00:00, map_index=-1, run_start_date=2026-02-27 07:23:17.762131+00:00, run_end_date=2026-02-27 07:23:58.842961+00:00, run_duration=41.08083, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=522, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:23:13.475002+00:00, queued_by_job_id=452, pid=16731
2026-02-27 15:23:59,882 INFO - Heartbeat recovered after 50.04 seconds
2026-02-27 15:23:59,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:24:03,618 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>
2026-02-27 15:24:03,619 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:24:03,619 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>
2026-02-27 15:24:03,622 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:22:56.996721+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:24:03,623 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:22:56.996721+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:24:03,624 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:22:56.996721+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:24:03,628 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:22:56.996721+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:24:08,935 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:22:56.996721+00:00', try_number=1, map_index=-1)
2026-02-27 15:24:08,946 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:22:56.996721+00:00, map_index=-1, run_start_date=2026-02-27 07:24:07.879137+00:00, run_end_date=2026-02-27 07:24:08.181386+00:00, run_duration=0.302249, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=523, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:24:03.620917+00:00, queued_by_job_id=452, pid=16786
2026-02-27 15:24:17,222 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 07:22:56.996721+00:00: manual__2026-02-27T07:22:56.996721+00:00, state:running, queued_at: 2026-02-27 07:22:57.020688+00:00. externally triggered: True> successful
2026-02-27 15:24:17,224 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 07:22:56.996721+00:00, run_id=manual__2026-02-27T07:22:56.996721+00:00, run_start_date=2026-02-27 07:22:59.823788+00:00, run_end_date=2026-02-27 07:24:17.223978+00:00, run_duration=77.40019, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:22:56.996721+00:00, data_interval_end=2026-02-27 07:22:56.996721+00:00, dag_hash=98a67ac16d9eb12345f0f141bee51793
2026-02-27 15:25:50,158 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>
2026-02-27 15:25:50,160 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:25:50,161 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>
2026-02-27 15:25:50,168 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:25:50,170 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:25:42.666628+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 15:25:50,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:25:42.666628+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:25:50,186 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:25:42.666628+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:25:56,679 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:25:42.666628+00:00', try_number=1, map_index=-1)
2026-02-27 15:25:56,692 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:25:42.666628+00:00, map_index=-1, run_start_date=2026-02-27 07:25:55.650346+00:00, run_end_date=2026-02-27 07:25:55.934510+00:00, run_duration=0.284164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=524, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 07:25:50.163724+00:00, queued_by_job_id=452, pid=16879
2026-02-27 15:25:59,672 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>
2026-02-27 15:25:59,673 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:25:59,673 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>
2026-02-27 15:25:59,676 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:25:59,677 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:25:42.666628+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:25:59,678 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:25:42.666628+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:25:59,681 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:25:42.666628+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:26:20,401 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:25:42.666628+00:00', try_number=1, map_index=-1)
2026-02-27 15:26:20,414 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:25:42.666628+00:00, map_index=-1, run_start_date=2026-02-27 07:26:04.067574+00:00, run_end_date=2026-02-27 07:26:19.613657+00:00, run_duration=15.546083, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=525, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:25:59.675034+00:00, queued_by_job_id=452, pid=16885
2026-02-27 15:26:24,283 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>
2026-02-27 15:26:24,284 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:26:24,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>
2026-02-27 15:26:24,288 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:25:42.666628+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:26:24,289 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:25:42.666628+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:26:24,290 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:25:42.666628+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:26:24,293 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:25:42.666628+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:26:29,785 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:25:42.666628+00:00', try_number=1, map_index=-1)
2026-02-27 15:26:29,796 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:25:42.666628+00:00, map_index=-1, run_start_date=2026-02-27 07:26:28.733822+00:00, run_end_date=2026-02-27 07:26:29.042954+00:00, run_duration=0.309132, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=526, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:26:24.285846+00:00, queued_by_job_id=452, pid=16932
2026-02-27 15:26:37,215 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 07:25:42.666628+00:00: manual__2026-02-27T07:25:42.666628+00:00, state:running, queued_at: 2026-02-27 07:25:42.692594+00:00. externally triggered: True> successful
2026-02-27 15:26:37,216 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 07:25:42.666628+00:00, run_id=manual__2026-02-27T07:25:42.666628+00:00, run_start_date=2026-02-27 07:25:45.225956+00:00, run_end_date=2026-02-27 07:26:37.216072+00:00, run_duration=51.990116, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:25:42.666628+00:00, data_interval_end=2026-02-27 07:25:42.666628+00:00, dag_hash=98a67ac16d9eb12345f0f141bee51793
2026-02-27 15:28:23,141 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>
2026-02-27 15:28:23,142 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:28:23,143 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>
2026-02-27 15:28:23,146 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:28:23,147 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:28:17.634534+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 15:28:23,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:28:17.634534+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:28:23,151 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:28:17.634534+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:28:28,815 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:28:17.634534+00:00', try_number=1, map_index=-1)
2026-02-27 15:28:28,825 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:28:17.634534+00:00, map_index=-1, run_start_date=2026-02-27 07:28:27.860478+00:00, run_end_date=2026-02-27 07:28:28.088540+00:00, run_duration=0.228062, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=527, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 07:28:23.144544+00:00, queued_by_job_id=452, pid=17020
2026-02-27 15:28:33,012 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>
2026-02-27 15:28:33,013 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:28:33,014 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>
2026-02-27 15:28:33,017 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:28:33,019 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:28:17.634534+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:28:33,020 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:28:17.634534+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:28:33,023 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:28:17.634534+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:28:53,195 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:28:17.634534+00:00', try_number=1, map_index=-1)
2026-02-27 15:28:53,210 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:28:17.634534+00:00, map_index=-1, run_start_date=2026-02-27 07:28:37.308542+00:00, run_end_date=2026-02-27 07:28:52.386147+00:00, run_duration=15.077605, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=528, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:28:33.016136+00:00, queued_by_job_id=452, pid=17023
2026-02-27 15:28:56,460 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>
2026-02-27 15:28:56,461 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:28:56,462 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>
2026-02-27 15:28:56,466 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:28:17.634534+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:28:56,468 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:28:17.634534+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:28:56,470 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:28:17.634534+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:28:56,472 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:28:17.634534+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-27 15:29:01,878 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:28:17.634534+00:00', try_number=1, map_index=-1)
2026-02-27 15:29:01,888 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:28:17.634534+00:00, map_index=-1, run_start_date=2026-02-27 07:29:00.850701+00:00, run_end_date=2026-02-27 07:29:01.170698+00:00, run_duration=0.319997, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=529, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:28:56.464936+00:00, queued_by_job_id=452, pid=17072
2026-02-27 15:29:01,915 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:29:11,070 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 07:28:17.634534+00:00: manual__2026-02-27T07:28:17.634534+00:00, state:running, queued_at: 2026-02-27 07:28:17.659925+00:00. externally triggered: True> successful
2026-02-27 15:29:11,071 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 07:28:17.634534+00:00, run_id=manual__2026-02-27T07:28:17.634534+00:00, run_start_date=2026-02-27 07:28:19.375091+00:00, run_end_date=2026-02-27 07:29:11.071441+00:00, run_duration=51.69635, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:28:17.634534+00:00, data_interval_end=2026-02-27 07:28:17.634534+00:00, dag_hash=98a67ac16d9eb12345f0f141bee51793
2026-02-27 15:29:15,929 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>
2026-02-27 15:29:15,930 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:29:15,931 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>
2026-02-27 15:29:15,934 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:29:15,935 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:29:08.391994+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 15:29:15,936 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:29:08.391994+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:29:15,939 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:29:08.391994+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:29:21,318 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:29:08.391994+00:00', try_number=1, map_index=-1)
2026-02-27 15:29:21,328 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:29:08.391994+00:00, map_index=-1, run_start_date=2026-02-27 07:29:20.390836+00:00, run_end_date=2026-02-27 07:29:20.606291+00:00, run_duration=0.215455, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=530, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 07:29:15.932767+00:00, queued_by_job_id=452, pid=17079
2026-02-27 15:29:25,305 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>
2026-02-27 15:29:25,306 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:29:25,306 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>
2026-02-27 15:29:25,309 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:29:25,310 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:29:08.391994+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:29:25,311 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:29:08.391994+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:29:25,314 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:29:08.391994+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:29:38,504 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:29:08.391994+00:00', try_number=1, map_index=-1)
2026-02-27 15:29:38,517 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:29:08.391994+00:00, map_index=-1, run_start_date=2026-02-27 07:29:30.073974+00:00, run_end_date=2026-02-27 07:29:37.679336+00:00, run_duration=7.605362, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=531, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:29:25.307961+00:00, queued_by_job_id=452, pid=17088
2026-02-27 15:29:42,552 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>
2026-02-27 15:29:42,559 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:29:42,561 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>
2026-02-27 15:29:42,569 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:29:08.391994+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:29:42,573 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:29:08.391994+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:29:42,575 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:29:08.391994+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:29:42,582 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:29:08.391994+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:29:49,634 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:29:08.391994+00:00', try_number=1, map_index=-1)
2026-02-27 15:29:49,655 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:29:08.391994+00:00, map_index=-1, run_start_date=2026-02-27 07:29:48.436635+00:00, run_end_date=2026-02-27 07:29:48.762285+00:00, run_duration=0.32565, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=532, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:29:42.565510+00:00, queued_by_job_id=452, pid=17119
2026-02-27 15:29:57,665 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 07:29:08.391994+00:00: manual__2026-02-27T07:29:08.391994+00:00, state:running, queued_at: 2026-02-27 07:29:08.417553+00:00. externally triggered: True> successful
2026-02-27 15:29:57,666 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 07:29:08.391994+00:00, run_id=manual__2026-02-27T07:29:08.391994+00:00, run_start_date=2026-02-27 07:29:11.049562+00:00, run_end_date=2026-02-27 07:29:57.666611+00:00, run_duration=46.617049, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:29:08.391994+00:00, data_interval_end=2026-02-27 07:29:08.391994+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 15:34:02,151 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:39:03,827 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:44:09,748 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:49:10,332 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:50:21,062 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
2026-02-27 15:50:21,063 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:50:21,065 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
2026-02-27 15:50:21,068 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:50:21,071 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 5 and queue default
2026-02-27 15:50:21,072 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:21,074 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:26,993 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1)
2026-02-27 15:50:27,004 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:50:16.304898+00:00, map_index=-1, run_start_date=2026-02-27 07:50:26.017495+00:00, run_end_date=2026-02-27 07:50:26.250266+00:00, run_duration=0.232771, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=533, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2026-02-27 07:50:21.066780+00:00, queued_by_job_id=452, pid=18150
2026-02-27 15:50:29,942 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
2026-02-27 15:50:29,943 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:50:29,944 INFO - DAG cdrd__ has 1/16 running and queued tasks
2026-02-27 15:50:29,944 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
2026-02-27 15:50:29,948 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>, <TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:50:29,949 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:50:29,950 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:29,951 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:50:29,952 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:29,955 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:34,989 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:40,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1)
2026-02-27 15:50:40,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1)
2026-02-27 15:50:40,317 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:50:16.304898+00:00, map_index=-1, run_start_date=2026-02-27 07:50:34.012303+00:00, run_end_date=2026-02-27 07:50:34.233487+00:00, run_duration=0.221184, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=534, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:50:29.945829+00:00, queued_by_job_id=452, pid=18157
2026-02-27 15:50:40,320 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:50:16.304898+00:00, map_index=-1, run_start_date=2026-02-27 07:50:39.298962+00:00, run_end_date=2026-02-27 07:50:39.520680+00:00, run_duration=0.221718, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=535, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:50:29.945829+00:00, queued_by_job_id=452, pid=18159
2026-02-27 15:50:43,418 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
2026-02-27 15:50:43,419 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-27 15:50:43,420 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>
2026-02-27 15:50:43,423 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-27T07:50:16.304898+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:50:43,424 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:50:43,424 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:43,427 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-27T07:50:16.304898+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-27 15:50:48,541 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-27T07:50:16.304898+00:00', try_number=1, map_index=-1)
2026-02-27 15:50:48,551 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-27T07:50:16.304898+00:00, map_index=-1, run_start_date=2026-02-27 07:50:47.491508+00:00, run_end_date=2026-02-27 07:50:47.809323+00:00, run_duration=0.317815, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=536, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:50:43.421418+00:00, queued_by_job_id=452, pid=18162
2026-02-27 15:50:56,570 INFO - Marking run <DagRun cdrd__ @ 2026-02-27 07:50:16.304898+00:00: manual__2026-02-27T07:50:16.304898+00:00, state:running, queued_at: 2026-02-27 07:50:16.336542+00:00. externally triggered: True> successful
2026-02-27 15:50:56,571 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-27 07:50:16.304898+00:00, run_id=manual__2026-02-27T07:50:16.304898+00:00, run_start_date=2026-02-27 07:50:17.315756+00:00, run_end_date=2026-02-27 07:50:56.571525+00:00, run_duration=39.255769, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:50:16.304898+00:00, data_interval_end=2026-02-27 07:50:16.304898+00:00, dag_hash=56a1c591ff99dfa71607fea0fd19b3e2
2026-02-27 15:52:10,938 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>
2026-02-27 15:52:10,940 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:52:10,941 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>
2026-02-27 15:52:10,944 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:52:10,945 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:52:03.742918+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 15:52:10,946 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:52:03.742918+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:52:10,948 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:52:03.742918+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:52:16,895 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:52:03.742918+00:00', try_number=1, map_index=-1)
2026-02-27 15:52:16,905 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:52:03.742918+00:00, map_index=-1, run_start_date=2026-02-27 07:52:15.907873+00:00, run_end_date=2026-02-27 07:52:16.186001+00:00, run_duration=0.278128, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=537, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 07:52:10.942720+00:00, queued_by_job_id=452, pid=18246
2026-02-27 15:52:19,908 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>
2026-02-27 15:52:19,909 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:52:19,910 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>
2026-02-27 15:52:19,914 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:52:19,915 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:52:03.742918+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:52:19,916 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:52:03.742918+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:52:19,919 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:52:03.742918+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:52:25,123 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:52:03.742918+00:00', try_number=1, map_index=-1)
2026-02-27 15:52:25,134 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:52:03.742918+00:00, map_index=-1, run_start_date=2026-02-27 07:52:24.146221+00:00, run_end_date=2026-02-27 07:52:24.367959+00:00, run_duration=0.221738, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=538, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:52:19.912405+00:00, queued_by_job_id=452, pid=18249
2026-02-27 15:52:28,297 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>
2026-02-27 15:52:28,298 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:52:28,299 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>
2026-02-27 15:52:28,302 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:52:03.742918+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:52:28,303 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:52:03.742918+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:52:28,304 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:52:03.742918+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:52:28,307 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:52:03.742918+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:52:33,563 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:52:03.742918+00:00', try_number=1, map_index=-1)
2026-02-27 15:52:33,573 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:52:03.742918+00:00, map_index=-1, run_start_date=2026-02-27 07:52:32.511733+00:00, run_end_date=2026-02-27 07:52:32.814975+00:00, run_duration=0.303242, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=539, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:52:28.301066+00:00, queued_by_job_id=452, pid=18252
2026-02-27 15:52:42,023 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 07:52:03.742918+00:00: manual__2026-02-27T07:52:03.742918+00:00, state:running, queued_at: 2026-02-27 07:52:03.759024+00:00. externally triggered: True> successful
2026-02-27 15:52:42,026 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 07:52:03.742918+00:00, run_id=manual__2026-02-27T07:52:03.742918+00:00, run_start_date=2026-02-27 07:52:06.946284+00:00, run_end_date=2026-02-27 07:52:42.026492+00:00, run_duration=35.080208, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:52:03.742918+00:00, data_interval_end=2026-02-27 07:52:03.742918+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 15:54:12,347 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 15:54:26,168 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>
2026-02-27 15:54:26,169 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:54:26,171 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>
2026-02-27 15:54:26,173 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:54:26,174 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:54:17.738738+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-27 15:54:26,175 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:54:17.738738+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:54:26,178 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:54:17.738738+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:54:31,559 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:54:17.738738+00:00', try_number=1, map_index=-1)
2026-02-27 15:54:31,570 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:54:17.738738+00:00, map_index=-1, run_start_date=2026-02-27 07:54:30.534581+00:00, run_end_date=2026-02-27 07:54:30.789832+00:00, run_duration=0.255251, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=540, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-27 07:54:26.172405+00:00, queued_by_job_id=452, pid=18336
2026-02-27 15:54:35,275 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>
2026-02-27 15:54:35,275 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:54:35,276 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>
2026-02-27 15:54:35,279 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:54:35,280 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:54:17.738738+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 15:54:35,280 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:54:17.738738+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:54:35,283 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:54:17.738738+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:54:40,780 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:54:17.738738+00:00', try_number=1, map_index=-1)
2026-02-27 15:54:40,790 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:54:17.738738+00:00, map_index=-1, run_start_date=2026-02-27 07:54:39.811089+00:00, run_end_date=2026-02-27 07:54:40.085762+00:00, run_duration=0.274673, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=541, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 07:54:35.277518+00:00, queued_by_job_id=452, pid=18347
2026-02-27 15:54:44,852 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>
2026-02-27 15:54:44,853 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 15:54:44,854 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>
2026-02-27 15:54:44,857 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T07:54:17.738738+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 15:54:44,858 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:54:17.738738+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 15:54:44,859 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:54:17.738738+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:54:44,863 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T07:54:17.738738+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 15:54:50,170 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T07:54:17.738738+00:00', try_number=1, map_index=-1)
2026-02-27 15:54:50,180 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T07:54:17.738738+00:00, map_index=-1, run_start_date=2026-02-27 07:54:49.128541+00:00, run_end_date=2026-02-27 07:54:49.456106+00:00, run_duration=0.327565, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=542, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 07:54:44.855982+00:00, queued_by_job_id=452, pid=18352
2026-02-27 15:54:58,814 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 07:54:17.738738+00:00: manual__2026-02-27T07:54:17.738738+00:00, state:running, queued_at: 2026-02-27 07:54:17.748808+00:00. externally triggered: True> successful
2026-02-27 15:54:58,815 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 07:54:17.738738+00:00, run_id=manual__2026-02-27T07:54:17.738738+00:00, run_start_date=2026-02-27 07:54:22.753294+00:00, run_end_date=2026-02-27 07:54:58.815321+00:00, run_duration=36.062027, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 07:54:17.738738+00:00, data_interval_end=2026-02-27 07:54:17.738738+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-27 15:59:16,282 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:04:18,516 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:09:18,741 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:14:20,957 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:19:24,688 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:24:25,151 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:29:27,697 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:34:30,738 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:39:33,358 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:44:35,945 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:49:38,362 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:54:39,977 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 16:59:44,106 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:04:44,148 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:09:45,314 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:14:48,003 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:19:44,039 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>
2026-02-27 17:19:44,040 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:19:44,041 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>
2026-02-27 17:19:44,044 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:19:44,049 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:19:41.380863+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:19:44,050 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:19:41.380863+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:19:44,053 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:19:41.380863+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:19:49,390 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:19:41.380863+00:00', try_number=1, map_index=-1)
2026-02-27 17:19:49,401 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:19:41.380863+00:00, map_index=-1, run_start_date=2026-02-27 09:19:48.366774+00:00, run_end_date=2026-02-27 09:19:48.686134+00:00, run_duration=0.31936, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=543, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:19:44.042920+00:00, queued_by_job_id=452, pid=21188
2026-02-27 17:19:49,433 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:19:52,606 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>
2026-02-27 17:19:52,607 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:19:52,609 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>
2026-02-27 17:19:52,611 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:19:52,614 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:19:41.380863+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:19:52,615 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:19:41.380863+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:19:52,617 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:19:41.380863+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:19:58,148 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:19:41.380863+00:00', try_number=1, map_index=-1)
2026-02-27 17:19:58,158 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:19:41.380863+00:00, map_index=-1, run_start_date=2026-02-27 09:19:57.085474+00:00, run_end_date=2026-02-27 09:19:57.366502+00:00, run_duration=0.281028, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=544, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:19:52.610176+00:00, queued_by_job_id=452, pid=21192
2026-02-27 17:20:01,346 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>
2026-02-27 17:20:01,347 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:20:01,347 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>
2026-02-27 17:20:01,350 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:19:41.380863+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:20:01,351 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:19:41.380863+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:20:01,352 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:19:41.380863+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:20:01,354 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:19:41.380863+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:20:06,545 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:19:41.380863+00:00', try_number=1, map_index=-1)
2026-02-27 17:20:06,556 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:19:41.380863+00:00, map_index=-1, run_start_date=2026-02-27 09:20:05.558484+00:00, run_end_date=2026-02-27 09:20:05.770994+00:00, run_duration=0.21251, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=545, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:20:01.349122+00:00, queued_by_job_id=452, pid=21200
2026-02-27 17:20:09,746 ERROR - Marking run <DagRun cdrd_ @ 2026-02-27 09:19:41.380863+00:00: manual__2026-02-27T09:19:41.380863+00:00, state:running, queued_at: 2026-02-27 09:19:41.421688+00:00. externally triggered: True> failed
2026-02-27 17:20:09,747 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:19:41.380863+00:00, run_id=manual__2026-02-27T09:19:41.380863+00:00, run_start_date=2026-02-27 09:19:44.004228+00:00, run_end_date=2026-02-27 09:20:09.746997+00:00, run_duration=25.742769, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:19:41.380863+00:00, data_interval_end=2026-02-27 09:19:41.380863+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:21:34,901 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>
2026-02-27 17:21:34,902 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:21:34,902 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>
2026-02-27 17:21:34,905 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:21:34,906 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:21:33.123046+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:21:34,907 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:21:33.123046+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:21:34,910 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:21:33.123046+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:21:40,557 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:21:33.123046+00:00', try_number=1, map_index=-1)
2026-02-27 17:21:40,567 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:21:33.123046+00:00, map_index=-1, run_start_date=2026-02-27 09:21:39.455362+00:00, run_end_date=2026-02-27 09:21:39.792031+00:00, run_duration=0.336669, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=546, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:21:34.903789+00:00, queued_by_job_id=452, pid=21261
2026-02-27 17:21:43,296 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>
2026-02-27 17:21:43,297 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:21:43,298 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>
2026-02-27 17:21:43,301 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:21:43,302 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:21:33.123046+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:21:43,302 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:21:33.123046+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:21:43,305 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:21:33.123046+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:21:49,551 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:21:33.123046+00:00', try_number=1, map_index=-1)
2026-02-27 17:21:49,563 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:21:33.123046+00:00, map_index=-1, run_start_date=2026-02-27 09:21:48.568465+00:00, run_end_date=2026-02-27 09:21:48.785598+00:00, run_duration=0.217133, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=547, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:21:43.299808+00:00, queued_by_job_id=452, pid=21266
2026-02-27 17:21:52,474 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>
2026-02-27 17:21:52,474 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:21:52,475 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>
2026-02-27 17:21:52,478 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:21:33.123046+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:21:52,479 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:21:33.123046+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:21:52,481 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:21:33.123046+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:21:52,483 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:21:33.123046+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:21:57,650 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:21:33.123046+00:00', try_number=1, map_index=-1)
2026-02-27 17:21:57,661 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:21:33.123046+00:00, map_index=-1, run_start_date=2026-02-27 09:21:56.670180+00:00, run_end_date=2026-02-27 09:21:56.878798+00:00, run_duration=0.208618, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=548, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:21:52.477027+00:00, queued_by_job_id=452, pid=21269
2026-02-27 17:22:01,013 ERROR - Marking run <DagRun cdrd_ @ 2026-02-27 09:21:33.123046+00:00: manual__2026-02-27T09:21:33.123046+00:00, state:running, queued_at: 2026-02-27 09:21:33.134575+00:00. externally triggered: True> failed
2026-02-27 17:22:01,014 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:21:33.123046+00:00, run_id=manual__2026-02-27T09:21:33.123046+00:00, run_start_date=2026-02-27 09:21:34.877091+00:00, run_end_date=2026-02-27 09:22:01.014240+00:00, run_duration=26.137149, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:21:33.123046+00:00, data_interval_end=2026-02-27 09:21:33.123046+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:24:51,954 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:26:26,546 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>
2026-02-27 17:26:26,548 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:26:26,550 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>
2026-02-27 17:26:26,554 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:26:26,555 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:26:25.613914+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:26:26,557 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:26:25.613914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:26:26,559 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:26:25.613914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:26:32,062 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:26:25.613914+00:00', try_number=1, map_index=-1)
2026-02-27 17:26:32,077 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:26:25.613914+00:00, map_index=-1, run_start_date=2026-02-27 09:26:30.956148+00:00, run_end_date=2026-02-27 09:26:31.283140+00:00, run_duration=0.326992, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=549, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:26:26.552768+00:00, queued_by_job_id=452, pid=21478
2026-02-27 17:26:34,908 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>
2026-02-27 17:26:34,909 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:26:34,909 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>
2026-02-27 17:26:34,912 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:26:34,913 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:26:25.613914+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:26:34,913 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:26:25.613914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:26:34,917 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:26:25.613914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:26:40,244 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:26:25.613914+00:00', try_number=1, map_index=-1)
2026-02-27 17:26:40,255 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:26:25.613914+00:00, map_index=-1, run_start_date=2026-02-27 09:26:39.277848+00:00, run_end_date=2026-02-27 09:26:39.497469+00:00, run_duration=0.219621, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=550, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:26:34.910908+00:00, queued_by_job_id=452, pid=21482
2026-02-27 17:26:43,198 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>
2026-02-27 17:26:43,199 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:26:43,200 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>
2026-02-27 17:26:43,203 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:26:25.613914+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:26:43,204 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:26:25.613914+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:26:43,204 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:26:25.613914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:26:43,207 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:26:25.613914+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:26:48,544 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:26:25.613914+00:00', try_number=1, map_index=-1)
2026-02-27 17:26:48,555 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:26:25.613914+00:00, map_index=-1, run_start_date=2026-02-27 09:26:47.574966+00:00, run_end_date=2026-02-27 09:26:47.801589+00:00, run_duration=0.226623, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=551, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:26:43.201823+00:00, queued_by_job_id=452, pid=21485
2026-02-27 17:26:52,705 ERROR - Marking run <DagRun cdrd_ @ 2026-02-27 09:26:25.613914+00:00: manual__2026-02-27T09:26:25.613914+00:00, state:running, queued_at: 2026-02-27 09:26:25.640158+00:00. externally triggered: True> failed
2026-02-27 17:26:52,706 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:26:25.613914+00:00, run_id=manual__2026-02-27T09:26:25.613914+00:00, run_start_date=2026-02-27 09:26:26.505859+00:00, run_end_date=2026-02-27 09:26:52.706234+00:00, run_duration=26.200375, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:26:25.613914+00:00, data_interval_end=2026-02-27 09:26:25.613914+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:28:34,747 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>
2026-02-27 17:28:34,749 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:28:34,750 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>
2026-02-27 17:28:34,752 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:28:34,754 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:28:32.132734+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:28:34,754 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:28:32.132734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:28:34,757 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:28:32.132734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:28:40,799 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:28:32.132734+00:00', try_number=1, map_index=-1)
2026-02-27 17:28:40,810 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:28:32.132734+00:00, map_index=-1, run_start_date=2026-02-27 09:28:39.728188+00:00, run_end_date=2026-02-27 09:28:40.052659+00:00, run_duration=0.324471, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=552, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:28:34.751768+00:00, queued_by_job_id=452, pid=21553
2026-02-27 17:28:43,657 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>
2026-02-27 17:28:43,658 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:28:43,659 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>
2026-02-27 17:28:43,661 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:28:43,663 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:28:32.132734+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:28:43,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:28:32.132734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:28:43,666 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:28:32.132734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:28:49,190 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:28:32.132734+00:00', try_number=1, map_index=-1)
2026-02-27 17:28:49,201 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:28:32.132734+00:00, map_index=-1, run_start_date=2026-02-27 09:28:48.135642+00:00, run_end_date=2026-02-27 09:28:48.345096+00:00, run_duration=0.209454, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=553, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:28:43.660280+00:00, queued_by_job_id=452, pid=21559
2026-02-27 17:28:52,164 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>
2026-02-27 17:28:52,165 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:28:52,166 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>
2026-02-27 17:28:52,168 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:28:32.132734+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:28:52,169 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:28:32.132734+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:28:52,170 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:28:32.132734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:28:52,173 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:28:32.132734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:28:57,259 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:28:32.132734+00:00', try_number=1, map_index=-1)
2026-02-27 17:28:57,271 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:28:32.132734+00:00, map_index=-1, run_start_date=2026-02-27 09:28:56.305447+00:00, run_end_date=2026-02-27 09:28:56.516117+00:00, run_duration=0.21067, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=554, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:28:52.167308+00:00, queued_by_job_id=452, pid=21562
2026-02-27 17:29:04,792 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:28:32.132734+00:00: manual__2026-02-27T09:28:32.132734+00:00, state:running, queued_at: 2026-02-27 09:28:32.148083+00:00. externally triggered: True> successful
2026-02-27 17:29:04,793 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:28:32.132734+00:00, run_id=manual__2026-02-27T09:28:32.132734+00:00, run_start_date=2026-02-27 09:28:34.706866+00:00, run_end_date=2026-02-27 09:29:04.793338+00:00, run_duration=30.086472, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:28:32.132734+00:00, data_interval_end=2026-02-27 09:28:32.132734+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:29:53,195 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:31:30,431 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>
2026-02-27 17:31:30,432 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:31:30,433 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>
2026-02-27 17:31:30,435 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:31:30,436 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:31:27.008999+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:31:30,437 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:31:27.008999+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:31:30,439 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:31:27.008999+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:31:36,044 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:31:27.008999+00:00', try_number=1, map_index=-1)
2026-02-27 17:31:36,053 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:31:27.008999+00:00, map_index=-1, run_start_date=2026-02-27 09:31:35.035003+00:00, run_end_date=2026-02-27 09:31:35.342465+00:00, run_duration=0.307462, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=555, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:31:30.434354+00:00, queued_by_job_id=452, pid=21671
2026-02-27 17:31:38,798 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>
2026-02-27 17:31:38,799 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:31:38,800 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>
2026-02-27 17:31:38,803 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:31:38,804 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:31:27.008999+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:31:38,804 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:31:27.008999+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:31:38,807 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:31:27.008999+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:31:43,894 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:31:27.008999+00:00', try_number=1, map_index=-1)
2026-02-27 17:31:43,904 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:31:27.008999+00:00, map_index=-1, run_start_date=2026-02-27 09:31:42.907231+00:00, run_end_date=2026-02-27 09:31:43.122048+00:00, run_duration=0.214817, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=556, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:31:38.801862+00:00, queued_by_job_id=452, pid=21675
2026-02-27 17:31:46,705 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>
2026-02-27 17:31:46,706 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:31:46,708 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>
2026-02-27 17:31:46,711 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:31:27.008999+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:31:46,712 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:31:27.008999+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:31:46,712 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:31:27.008999+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:31:46,715 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:31:27.008999+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:32:00,261 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:31:27.008999+00:00', try_number=1, map_index=-1)
2026-02-27 17:32:00,274 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:31:27.008999+00:00, map_index=-1, run_start_date=2026-02-27 09:31:50.725536+00:00, run_end_date=2026-02-27 09:31:59.557076+00:00, run_duration=8.83154, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=557, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:31:46.709745+00:00, queued_by_job_id=452, pid=21685
2026-02-27 17:32:07,363 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:31:27.008999+00:00: manual__2026-02-27T09:31:27.008999+00:00, state:running, queued_at: 2026-02-27 09:31:27.023100+00:00. externally triggered: True> successful
2026-02-27 17:32:07,364 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:31:27.008999+00:00, run_id=manual__2026-02-27T09:31:27.008999+00:00, run_start_date=2026-02-27 09:31:30.404908+00:00, run_end_date=2026-02-27 09:32:07.364628+00:00, run_duration=36.95972, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:31:27.008999+00:00, data_interval_end=2026-02-27 09:31:27.008999+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:33:50,265 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>
2026-02-27 17:33:50,266 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:33:50,267 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>
2026-02-27 17:33:50,269 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:33:50,271 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:33:47.037310+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:33:50,272 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:33:47.037310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:33:50,274 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:33:47.037310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:33:55,681 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:33:47.037310+00:00', try_number=1, map_index=-1)
2026-02-27 17:33:55,691 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:33:47.037310+00:00, map_index=-1, run_start_date=2026-02-27 09:33:54.606513+00:00, run_end_date=2026-02-27 09:33:54.941347+00:00, run_duration=0.334834, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=558, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:33:50.268586+00:00, queued_by_job_id=452, pid=21868
2026-02-27 17:33:59,629 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>
2026-02-27 17:33:59,630 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:33:59,631 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>
2026-02-27 17:33:59,633 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:33:59,634 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:33:47.037310+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:33:59,635 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:33:47.037310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:33:59,638 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:33:47.037310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:34:05,157 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:33:47.037310+00:00', try_number=1, map_index=-1)
2026-02-27 17:34:05,168 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:33:47.037310+00:00, map_index=-1, run_start_date=2026-02-27 09:34:04.221484+00:00, run_end_date=2026-02-27 09:34:04.431219+00:00, run_duration=0.209735, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=559, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:33:59.632142+00:00, queued_by_job_id=452, pid=21875
2026-02-27 17:34:09,282 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>
2026-02-27 17:34:09,283 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:34:09,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>
2026-02-27 17:34:09,287 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:33:47.037310+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:34:09,288 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:33:47.037310+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:34:09,288 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:33:47.037310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:34:09,291 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:33:47.037310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:34:20,653 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:33:47.037310+00:00', try_number=1, map_index=-1)
2026-02-27 17:34:20,664 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:33:47.037310+00:00, map_index=-1, run_start_date=2026-02-27 09:34:13.448608+00:00, run_end_date=2026-02-27 09:34:19.948939+00:00, run_duration=6.500331, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=560, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:34:09.285345+00:00, queued_by_job_id=452, pid=21878
2026-02-27 17:34:27,010 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:33:47.037310+00:00: manual__2026-02-27T09:33:47.037310+00:00, state:running, queued_at: 2026-02-27 09:33:47.051605+00:00. externally triggered: True> successful
2026-02-27 17:34:27,012 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:33:47.037310+00:00, run_id=manual__2026-02-27T09:33:47.037310+00:00, run_start_date=2026-02-27 09:33:50.240095+00:00, run_end_date=2026-02-27 09:34:27.011913+00:00, run_duration=36.771818, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:33:47.037310+00:00, data_interval_end=2026-02-27 09:33:47.037310+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:34:54,843 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:35:46,756 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>
2026-02-27 17:35:46,757 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:35:46,758 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>
2026-02-27 17:35:46,761 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:35:46,762 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:35:43.951530+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:35:46,762 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:35:43.951530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:35:46,765 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:35:43.951530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:35:52,160 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:35:43.951530+00:00', try_number=1, map_index=-1)
2026-02-27 17:35:52,172 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:35:43.951530+00:00, map_index=-1, run_start_date=2026-02-27 09:35:51.127771+00:00, run_end_date=2026-02-27 09:35:51.432039+00:00, run_duration=0.304268, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=561, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:35:46.759427+00:00, queued_by_job_id=452, pid=21973
2026-02-27 17:35:54,853 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>
2026-02-27 17:35:54,854 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:35:54,855 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>
2026-02-27 17:35:54,858 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:35:54,859 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:35:43.951530+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:35:54,860 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:35:43.951530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:35:54,862 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:35:43.951530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:36:00,012 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:35:43.951530+00:00', try_number=1, map_index=-1)
2026-02-27 17:36:00,023 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:35:43.951530+00:00, map_index=-1, run_start_date=2026-02-27 09:35:59.024674+00:00, run_end_date=2026-02-27 09:35:59.238753+00:00, run_duration=0.214079, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=562, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:35:54.856768+00:00, queued_by_job_id=452, pid=21977
2026-02-27 17:36:03,602 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>
2026-02-27 17:36:03,603 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:36:03,604 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>
2026-02-27 17:36:03,607 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:35:43.951530+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:36:03,608 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:35:43.951530+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:36:03,609 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:35:43.951530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:36:03,611 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:35:43.951530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:36:08,610 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:35:43.951530+00:00', try_number=1, map_index=-1)
2026-02-27 17:36:08,624 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:35:43.951530+00:00, map_index=-1, run_start_date=2026-02-27 09:36:07.647807+00:00, run_end_date=2026-02-27 09:36:07.858817+00:00, run_duration=0.21101, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=563, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:36:03.605742+00:00, queued_by_job_id=452, pid=21983
2026-02-27 17:36:17,284 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:35:43.951530+00:00: manual__2026-02-27T09:35:43.951530+00:00, state:running, queued_at: 2026-02-27 09:35:43.967006+00:00. externally triggered: True> successful
2026-02-27 17:36:17,285 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:35:43.951530+00:00, run_id=manual__2026-02-27T09:35:43.951530+00:00, run_start_date=2026-02-27 09:35:46.731365+00:00, run_end_date=2026-02-27 09:36:17.285780+00:00, run_duration=30.554415, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:35:43.951530+00:00, data_interval_end=2026-02-27 09:35:43.951530+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:37:16,946 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>
2026-02-27 17:37:16,947 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:37:16,948 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>
2026-02-27 17:37:16,951 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:37:16,952 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:37:13.696782+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:37:16,953 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:37:13.696782+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:37:16,956 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:37:13.696782+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:37:22,126 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:37:13.696782+00:00', try_number=1, map_index=-1)
2026-02-27 17:37:22,136 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:37:13.696782+00:00, map_index=-1, run_start_date=2026-02-27 09:37:21.124527+00:00, run_end_date=2026-02-27 09:37:21.435342+00:00, run_duration=0.310815, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=564, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:37:16.950484+00:00, queued_by_job_id=452, pid=22021
2026-02-27 17:37:25,825 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>
2026-02-27 17:37:25,826 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:37:25,827 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>
2026-02-27 17:37:25,829 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:37:25,830 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:37:13.696782+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:37:25,831 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:37:13.696782+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:37:25,834 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:37:13.696782+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:37:30,920 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:37:13.696782+00:00', try_number=1, map_index=-1)
2026-02-27 17:37:30,930 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:37:13.696782+00:00, map_index=-1, run_start_date=2026-02-27 09:37:29.945131+00:00, run_end_date=2026-02-27 09:37:30.165819+00:00, run_duration=0.220688, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=565, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:37:25.828519+00:00, queued_by_job_id=452, pid=22024
2026-02-27 17:37:34,867 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>
2026-02-27 17:37:34,868 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:37:34,868 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>
2026-02-27 17:37:34,871 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:37:13.696782+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:37:34,872 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:37:13.696782+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:37:34,873 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:37:13.696782+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:37:34,875 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:37:13.696782+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:37:40,271 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:37:13.696782+00:00', try_number=1, map_index=-1)
2026-02-27 17:37:40,281 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:37:13.696782+00:00, map_index=-1, run_start_date=2026-02-27 09:37:39.083248+00:00, run_end_date=2026-02-27 09:37:39.544479+00:00, run_duration=0.461231, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=566, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:37:34.870147+00:00, queued_by_job_id=452, pid=22027
2026-02-27 17:37:48,195 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:37:13.696782+00:00: manual__2026-02-27T09:37:13.696782+00:00, state:running, queued_at: 2026-02-27 09:37:13.705760+00:00. externally triggered: True> successful
2026-02-27 17:37:48,196 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:37:13.696782+00:00, run_id=manual__2026-02-27T09:37:13.696782+00:00, run_start_date=2026-02-27 09:37:16.920657+00:00, run_end_date=2026-02-27 09:37:48.196528+00:00, run_duration=31.275871, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:37:13.696782+00:00, data_interval_end=2026-02-27 09:37:13.696782+00:00, dag_hash=8e3fdff7ec26eff2752d82f898ca58e5
2026-02-27 17:39:58,238 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:40:35,366 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>
2026-02-27 17:40:35,367 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:40:35,367 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>
2026-02-27 17:40:35,370 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:40:35,371 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:40:31.860873+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:40:35,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:40:31.860873+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:40:35,374 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:40:31.860873+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:40:40,728 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:40:31.860873+00:00', try_number=1, map_index=-1)
2026-02-27 17:40:40,737 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:40:31.860873+00:00, map_index=-1, run_start_date=2026-02-27 09:40:39.667375+00:00, run_end_date=2026-02-27 09:40:39.978465+00:00, run_duration=0.31109, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=567, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:40:35.369093+00:00, queued_by_job_id=452, pid=22146
2026-02-27 17:40:43,553 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>
2026-02-27 17:40:43,554 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:40:43,555 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>
2026-02-27 17:40:43,558 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:40:43,559 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:40:31.860873+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:40:43,560 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:40:31.860873+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:40:43,562 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:40:31.860873+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:40:48,604 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:40:31.860873+00:00', try_number=1, map_index=-1)
2026-02-27 17:40:48,614 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:40:31.860873+00:00, map_index=-1, run_start_date=2026-02-27 09:40:47.621360+00:00, run_end_date=2026-02-27 09:40:47.829974+00:00, run_duration=0.208614, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=568, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:40:43.556848+00:00, queued_by_job_id=452, pid=22150
2026-02-27 17:40:52,583 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>
2026-02-27 17:40:52,584 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:40:52,585 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>
2026-02-27 17:40:52,587 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:40:31.860873+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:40:52,589 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:40:31.860873+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:40:52,589 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:40:31.860873+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:40:52,593 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:40:31.860873+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:41:03,843 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:40:31.860873+00:00', try_number=1, map_index=-1)
2026-02-27 17:41:03,856 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:40:31.860873+00:00, map_index=-1, run_start_date=2026-02-27 09:40:56.798927+00:00, run_end_date=2026-02-27 09:41:03.133718+00:00, run_duration=6.334791, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=569, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:40:52.586642+00:00, queued_by_job_id=452, pid=22153
2026-02-27 17:41:12,998 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:40:31.860873+00:00: manual__2026-02-27T09:40:31.860873+00:00, state:running, queued_at: 2026-02-27 09:40:31.873948+00:00. externally triggered: True> successful
2026-02-27 17:41:12,999 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:40:31.860873+00:00, run_id=manual__2026-02-27T09:40:31.860873+00:00, run_start_date=2026-02-27 09:40:35.336231+00:00, run_end_date=2026-02-27 09:41:12.999686+00:00, run_duration=37.663455, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:40:31.860873+00:00, data_interval_end=2026-02-27 09:40:31.860873+00:00, dag_hash=c38e4d01d8794edab9c26738273f0d92
2026-02-27 17:45:00,726 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:46:06,697 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>
2026-02-27 17:46:06,698 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:46:06,698 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>
2026-02-27 17:46:06,701 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:46:06,702 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:46:03.086992+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:46:06,703 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:46:03.086992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:46:06,705 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:46:03.086992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:46:11,811 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:46:03.086992+00:00', try_number=1, map_index=-1)
2026-02-27 17:46:11,822 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:46:03.086992+00:00, map_index=-1, run_start_date=2026-02-27 09:46:10.683765+00:00, run_end_date=2026-02-27 09:46:11.005658+00:00, run_duration=0.321893, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=570, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:46:06.700141+00:00, queued_by_job_id=452, pid=22349
2026-02-27 17:46:14,367 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>
2026-02-27 17:46:14,368 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:46:14,369 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>
2026-02-27 17:46:14,371 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:46:14,372 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:46:03.086992+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:46:14,373 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:46:03.086992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:46:14,375 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:46:03.086992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:46:19,260 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:46:03.086992+00:00', try_number=1, map_index=-1)
2026-02-27 17:46:19,270 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:46:03.086992+00:00, map_index=-1, run_start_date=2026-02-27 09:46:18.369588+00:00, run_end_date=2026-02-27 09:46:18.577967+00:00, run_duration=0.208379, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=571, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:46:14.370509+00:00, queued_by_job_id=452, pid=22353
2026-02-27 17:46:21,807 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>
2026-02-27 17:46:21,808 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:46:21,809 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>
2026-02-27 17:46:21,811 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:46:03.086992+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:46:21,812 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:46:03.086992+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:46:21,813 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:46:03.086992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:46:21,815 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:46:03.086992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:46:32,630 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:46:03.086992+00:00', try_number=1, map_index=-1)
2026-02-27 17:46:32,642 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:46:03.086992+00:00, map_index=-1, run_start_date=2026-02-27 09:46:25.734533+00:00, run_end_date=2026-02-27 09:46:31.923324+00:00, run_duration=6.188791, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=572, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:46:21.810559+00:00, queued_by_job_id=452, pid=22356
2026-02-27 17:46:42,383 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:46:03.086992+00:00: manual__2026-02-27T09:46:03.086992+00:00, state:running, queued_at: 2026-02-27 09:46:03.101871+00:00. externally triggered: True> successful
2026-02-27 17:46:42,384 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:46:03.086992+00:00, run_id=manual__2026-02-27T09:46:03.086992+00:00, run_start_date=2026-02-27 09:46:06.670049+00:00, run_end_date=2026-02-27 09:46:42.384655+00:00, run_duration=35.714606, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:46:03.086992+00:00, data_interval_end=2026-02-27 09:46:03.086992+00:00, dag_hash=c38e4d01d8794edab9c26738273f0d92
2026-02-27 17:48:08,622 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>
2026-02-27 17:48:08,628 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:48:08,629 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>
2026-02-27 17:48:08,631 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:48:08,633 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:48:05.416000+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-27 17:48:08,634 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:48:05.416000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:48:08,645 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:48:05.416000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:48:14,231 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:48:05.416000+00:00', try_number=1, map_index=-1)
2026-02-27 17:48:14,242 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:48:05.416000+00:00, map_index=-1, run_start_date=2026-02-27 09:48:13.104200+00:00, run_end_date=2026-02-27 09:48:13.440946+00:00, run_duration=0.336746, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=573, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-27 09:48:08.630568+00:00, queued_by_job_id=452, pid=22456
2026-02-27 17:48:17,986 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>
2026-02-27 17:48:17,987 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:48:17,988 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>
2026-02-27 17:48:17,991 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:48:17,993 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:48:05.416000+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-27 17:48:17,994 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:48:05.416000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:48:17,997 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:48:05.416000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:48:24,947 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:48:05.416000+00:00', try_number=1, map_index=-1)
2026-02-27 17:48:24,987 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:48:05.416000+00:00, map_index=-1, run_start_date=2026-02-27 09:48:23.907478+00:00, run_end_date=2026-02-27 09:48:24.141738+00:00, run_duration=0.23426, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=574, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-27 09:48:17.990158+00:00, queued_by_job_id=452, pid=22484
2026-02-27 17:48:28,944 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>
2026-02-27 17:48:28,945 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-27 17:48:28,946 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>
2026-02-27 17:48:28,949 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-27T09:48:05.416000+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-27 17:48:28,951 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:48:05.416000+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-27 17:48:28,952 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:48:05.416000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:48:28,956 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-27T09:48:05.416000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-27 17:49:04,397 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-27T09:48:05.416000+00:00', try_number=1, map_index=-1)
2026-02-27 17:49:04,457 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-27T09:48:05.416000+00:00, map_index=-1, run_start_date=2026-02-27 09:48:37.818737+00:00, run_end_date=2026-02-27 09:49:02.746400+00:00, run_duration=24.927663, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=575, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-27 09:48:28.948459+00:00, queued_by_job_id=452, pid=22524
2026-02-27 17:49:04,496 INFO - Heartbeat recovered after 39.49 seconds
2026-02-27 17:49:13,806 INFO - Marking run <DagRun cdrd_ @ 2026-02-27 09:48:05.416000+00:00: manual__2026-02-27T09:48:05.416000+00:00, state:running, queued_at: 2026-02-27 09:48:05.429538+00:00. externally triggered: True> successful
2026-02-27 17:49:13,808 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-27 09:48:05.416000+00:00, run_id=manual__2026-02-27T09:48:05.416000+00:00, run_start_date=2026-02-27 09:48:08.579377+00:00, run_end_date=2026-02-27 09:49:13.807910+00:00, run_duration=65.228533, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-27 09:48:05.416000+00:00, data_interval_end=2026-02-27 09:48:05.416000+00:00, dag_hash=c38e4d01d8794edab9c26738273f0d92
2026-02-27 17:50:02,681 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 17:55:06,101 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 18:00:07,072 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-27 18:04:27,502 INFO - Exiting gracefully upon receiving signal 15
2026-02-27 18:04:28,407 INFO - Sending Signals.SIGTERM to group 13431. PIDs of all processes in the group: []
2026-02-27 18:04:28,409 INFO - Sending the signal Signals.SIGTERM to group 13431
2026-02-27 18:04:28,410 INFO - Sending the signal Signals.SIGTERM to process 13431 as process group is missing.
2026-02-27 18:04:28,419 INFO - Sending Signals.SIGTERM to group 13431. PIDs of all processes in the group: []
2026-02-27 18:04:28,420 INFO - Sending the signal Signals.SIGTERM to group 13431
2026-02-27 18:04:28,421 INFO - Sending the signal Signals.SIGTERM to process 13431 as process group is missing.
2026-02-27 18:04:28,422 INFO - Exited execute loop
2026-02-28 08:36:24,202 INFO - Loaded executor: SequentialExecutor
2026-02-28 08:36:24,895 INFO - Starting the scheduler
2026-02-28 08:36:24,896 INFO - Processing each file at most -1 times
2026-02-28 08:36:24,902 INFO - Launched DagFileProcessorManager with pid: 861
2026-02-28 08:36:24,905 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 08:41:28,195 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 08:46:28,493 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 08:51:29,741 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 08:56:32,799 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:01:33,450 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:05:20,821 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>
2026-02-28 09:05:20,822 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:05:20,823 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>
2026-02-28 09:05:20,826 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:05:20,827 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:05:15.214093+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 09:05:20,828 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:05:15.214093+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:05:20,831 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:05:15.214093+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:05:26,047 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:05:15.214093+00:00', try_number=1, map_index=-1)
2026-02-28 09:05:26,060 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:05:15.214093+00:00, map_index=-1, run_start_date=2026-02-28 01:05:25.075936+00:00, run_end_date=2026-02-28 01:05:25.294348+00:00, run_duration=0.218412, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=577, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 01:05:20.824579+00:00, queued_by_job_id=576, pid=2824
2026-02-28 09:05:29,823 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>
2026-02-28 09:05:29,824 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:05:29,825 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>
2026-02-28 09:05:29,827 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:05:29,828 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:05:15.214093+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 09:05:29,829 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:05:15.214093+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:05:29,831 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:05:15.214093+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:05:45,774 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:05:15.214093+00:00', try_number=1, map_index=-1)
2026-02-28 09:05:45,784 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:05:15.214093+00:00, map_index=-1, run_start_date=2026-02-28 01:05:33.682332+00:00, run_end_date=2026-02-28 01:05:44.967021+00:00, run_duration=11.284689, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=578, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 01:05:29.826351+00:00, queued_by_job_id=576, pid=2828
2026-02-28 09:05:49,474 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>
2026-02-28 09:05:49,475 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:05:49,475 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>
2026-02-28 09:05:49,478 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:05:15.214093+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:05:49,479 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:05:15.214093+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 09:05:49,479 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:05:15.214093+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:05:49,482 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:05:15.214093+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:05:54,598 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:05:15.214093+00:00', try_number=1, map_index=-1)
2026-02-28 09:05:54,607 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:05:15.214093+00:00, map_index=-1, run_start_date=2026-02-28 01:05:53.657618+00:00, run_end_date=2026-02-28 01:05:53.932620+00:00, run_duration=0.275002, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=579, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 01:05:49.476892+00:00, queued_by_job_id=576, pid=2863
2026-02-28 09:06:01,358 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 01:05:15.214093+00:00: manual__2026-02-28T01:05:15.214093+00:00, state:running, queued_at: 2026-02-28 01:05:15.236519+00:00. externally triggered: True> successful
2026-02-28 09:06:01,359 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 01:05:15.214093+00:00, run_id=manual__2026-02-28T01:05:15.214093+00:00, run_start_date=2026-02-28 01:05:16.249206+00:00, run_end_date=2026-02-28 01:06:01.359671+00:00, run_duration=45.110465, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 01:05:15.214093+00:00, data_interval_end=2026-02-28 01:05:15.214093+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 09:06:33,720 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:11:33,947 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:16:35,953 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:21:39,217 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:26:40,501 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:31:41,748 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:36:45,549 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:41:46,106 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:46:46,297 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:50:40,747 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>
2026-02-28 09:50:40,748 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:50:40,749 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>
2026-02-28 09:50:40,751 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:50:40,753 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:50:34.874508+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 09:50:40,754 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:50:34.874508+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:50:40,757 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:50:34.874508+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:50:46,248 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:50:34.874508+00:00', try_number=1, map_index=-1)
2026-02-28 09:50:46,257 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:50:34.874508+00:00, map_index=-1, run_start_date=2026-02-28 01:50:45.293671+00:00, run_end_date=2026-02-28 01:50:45.507550+00:00, run_duration=0.213879, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=580, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 01:50:40.750517+00:00, queued_by_job_id=576, pid=4286
2026-02-28 09:50:48,964 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>
2026-02-28 09:50:48,965 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:50:48,966 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>
2026-02-28 09:50:48,968 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:50:48,969 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:50:34.874508+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 09:50:48,970 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:50:34.874508+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:50:48,973 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:50:34.874508+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:51:04,142 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:50:34.874508+00:00', try_number=1, map_index=-1)
2026-02-28 09:51:04,152 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:50:34.874508+00:00, map_index=-1, run_start_date=2026-02-28 01:50:53.934386+00:00, run_end_date=2026-02-28 01:51:03.376288+00:00, run_duration=9.441902, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=581, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 01:50:48.967427+00:00, queued_by_job_id=576, pid=4289
2026-02-28 09:51:07,706 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>
2026-02-28 09:51:07,707 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:51:07,709 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>
2026-02-28 09:51:07,711 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:50:34.874508+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:51:07,712 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:50:34.874508+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 09:51:07,713 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:50:34.874508+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:51:07,715 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:50:34.874508+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:51:12,950 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:50:34.874508+00:00', try_number=1, map_index=-1)
2026-02-28 09:51:12,960 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:50:34.874508+00:00, map_index=-1, run_start_date=2026-02-28 01:51:12.034871+00:00, run_end_date=2026-02-28 01:51:12.247224+00:00, run_duration=0.212353, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=582, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 01:51:07.710192+00:00, queued_by_job_id=576, pid=4317
2026-02-28 09:51:20,322 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 01:50:34.874508+00:00: manual__2026-02-28T01:50:34.874508+00:00, state:running, queued_at: 2026-02-28 01:50:34.894130+00:00. externally triggered: True> successful
2026-02-28 09:51:20,323 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 01:50:34.874508+00:00, run_id=manual__2026-02-28T01:50:34.874508+00:00, run_start_date=2026-02-28 01:50:35.963167+00:00, run_end_date=2026-02-28 01:51:20.323257+00:00, run_duration=44.36009, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 01:50:34.874508+00:00, data_interval_end=2026-02-28 01:50:34.874508+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 09:51:49,565 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:52:46,510 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>
2026-02-28 09:52:46,511 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:52:46,512 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>
2026-02-28 09:52:46,516 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:52:46,517 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:52:38.012176+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 09:52:46,518 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:52:38.012176+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:52:46,521 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:52:38.012176+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:52:51,500 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:52:38.012176+00:00', try_number=1, map_index=-1)
2026-02-28 09:52:51,510 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:52:38.012176+00:00, map_index=-1, run_start_date=2026-02-28 01:52:50.585256+00:00, run_end_date=2026-02-28 01:52:50.798090+00:00, run_duration=0.212834, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=583, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 01:52:46.514005+00:00, queued_by_job_id=576, pid=4381
2026-02-28 09:52:54,267 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>
2026-02-28 09:52:54,268 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:52:54,269 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>
2026-02-28 09:52:54,271 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:52:54,272 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:52:38.012176+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 09:52:54,273 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:52:38.012176+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:52:54,275 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:52:38.012176+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:53:07,602 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:52:38.012176+00:00', try_number=1, map_index=-1)
2026-02-28 09:53:07,614 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:52:38.012176+00:00, map_index=-1, run_start_date=2026-02-28 01:52:58.343191+00:00, run_end_date=2026-02-28 01:53:06.837479+00:00, run_duration=8.494288, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=584, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 01:52:54.270206+00:00, queued_by_job_id=576, pid=4384
2026-02-28 09:53:11,380 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>
2026-02-28 09:53:11,381 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:53:11,382 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>
2026-02-28 09:53:11,386 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:52:38.012176+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:53:11,387 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:52:38.012176+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 09:53:11,388 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:52:38.012176+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:53:11,390 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:52:38.012176+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:53:16,449 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:52:38.012176+00:00', try_number=1, map_index=-1)
2026-02-28 09:53:16,460 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:52:38.012176+00:00, map_index=-1, run_start_date=2026-02-28 01:53:15.470852+00:00, run_end_date=2026-02-28 01:53:15.744099+00:00, run_duration=0.273247, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=585, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 01:53:11.384464+00:00, queued_by_job_id=576, pid=4410
2026-02-28 09:53:23,276 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 01:52:38.012176+00:00: manual__2026-02-28T01:52:38.012176+00:00, state:running, queued_at: 2026-02-28 01:52:38.035574+00:00. externally triggered: True> successful
2026-02-28 09:53:23,277 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 01:52:38.012176+00:00, run_id=manual__2026-02-28T01:52:38.012176+00:00, run_start_date=2026-02-28 01:52:42.104304+00:00, run_end_date=2026-02-28 01:53:23.276896+00:00, run_duration=41.172592, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 01:52:38.012176+00:00, data_interval_end=2026-02-28 01:52:38.012176+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 09:56:23,500 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>
2026-02-28 09:56:23,502 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:56:23,503 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>
2026-02-28 09:56:23,506 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:56:23,508 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:56:16.283715+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 09:56:23,509 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:56:16.283715+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:56:23,512 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:56:16.283715+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:56:28,728 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:56:16.283715+00:00', try_number=1, map_index=-1)
2026-02-28 09:56:28,737 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:56:16.283715+00:00, map_index=-1, run_start_date=2026-02-28 01:56:27.708296+00:00, run_end_date=2026-02-28 01:56:27.913675+00:00, run_duration=0.205379, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=586, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 01:56:23.504650+00:00, queued_by_job_id=576, pid=4529
2026-02-28 09:56:31,476 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>
2026-02-28 09:56:31,477 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:56:31,478 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>
2026-02-28 09:56:31,481 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:56:31,482 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:56:16.283715+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 09:56:31,483 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:56:16.283715+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:56:31,485 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:56:16.283715+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:56:44,745 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:56:16.283715+00:00', try_number=1, map_index=-1)
2026-02-28 09:56:44,757 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:56:16.283715+00:00, map_index=-1, run_start_date=2026-02-28 01:56:35.570966+00:00, run_end_date=2026-02-28 01:56:43.814638+00:00, run_duration=8.243672, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=587, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 01:56:31.479769+00:00, queued_by_job_id=576, pid=4535
2026-02-28 09:56:48,670 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>
2026-02-28 09:56:48,671 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 09:56:48,672 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>
2026-02-28 09:56:48,674 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T01:56:16.283715+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 09:56:48,675 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:56:16.283715+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 09:56:48,676 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:56:16.283715+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:56:48,679 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T01:56:16.283715+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 09:56:53,371 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T01:56:16.283715+00:00', try_number=1, map_index=-1)
2026-02-28 09:56:53,381 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T01:56:16.283715+00:00, map_index=-1, run_start_date=2026-02-28 01:56:52.469357+00:00, run_end_date=2026-02-28 01:56:52.651910+00:00, run_duration=0.182553, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=588, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 01:56:48.672968+00:00, queued_by_job_id=576, pid=4579
2026-02-28 09:56:53,407 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 09:57:01,686 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 01:56:16.283715+00:00: manual__2026-02-28T01:56:16.283715+00:00, state:running, queued_at: 2026-02-28 01:56:16.515903+00:00. externally triggered: True> successful
2026-02-28 09:57:01,687 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 01:56:16.283715+00:00, run_id=manual__2026-02-28T01:56:16.283715+00:00, run_start_date=2026-02-28 01:56:19.959662+00:00, run_end_date=2026-02-28 01:57:01.687500+00:00, run_duration=41.727838, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 01:56:16.283715+00:00, data_interval_end=2026-02-28 01:56:16.283715+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:00:24,601 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>
2026-02-28 10:00:24,602 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:00:24,603 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>
2026-02-28 10:00:24,606 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:00:24,607 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:00:15.823734+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:00:24,607 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:00:15.823734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:00:24,609 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:00:15.823734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:00:29,680 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:00:15.823734+00:00', try_number=1, map_index=-1)
2026-02-28 10:00:29,691 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:00:15.823734+00:00, map_index=-1, run_start_date=2026-02-28 02:00:28.666812+00:00, run_end_date=2026-02-28 02:00:28.883570+00:00, run_duration=0.216758, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=589, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:00:24.604444+00:00, queued_by_job_id=576, pid=4715
2026-02-28 10:00:33,242 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>
2026-02-28 10:00:33,243 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:00:33,244 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>
2026-02-28 10:00:33,247 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:00:33,248 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:00:15.823734+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:00:33,248 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:00:15.823734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:00:33,251 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:00:15.823734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:00:47,498 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:00:15.823734+00:00', try_number=1, map_index=-1)
2026-02-28 10:00:47,512 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:00:15.823734+00:00, map_index=-1, run_start_date=2026-02-28 02:00:37.320658+00:00, run_end_date=2026-02-28 02:00:46.527669+00:00, run_duration=9.207011, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=590, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:00:33.245866+00:00, queued_by_job_id=576, pid=4718
2026-02-28 10:00:51,175 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>
2026-02-28 10:00:51,176 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:00:51,177 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>
2026-02-28 10:00:51,179 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:00:15.823734+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:00:51,180 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:00:15.823734+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:00:51,181 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:00:15.823734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:00:51,184 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:00:15.823734+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:00:56,400 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:00:15.823734+00:00', try_number=1, map_index=-1)
2026-02-28 10:00:56,409 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:00:15.823734+00:00, map_index=-1, run_start_date=2026-02-28 02:00:55.520306+00:00, run_end_date=2026-02-28 02:00:55.701946+00:00, run_duration=0.18164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=591, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:00:51.178491+00:00, queued_by_job_id=576, pid=4745
2026-02-28 10:01:03,788 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:00:15.823734+00:00: manual__2026-02-28T02:00:15.823734+00:00, state:running, queued_at: 2026-02-28 02:00:15.833049+00:00. externally triggered: True> successful
2026-02-28 10:01:03,789 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:00:15.823734+00:00, run_id=manual__2026-02-28T02:00:15.823734+00:00, run_start_date=2026-02-28 02:00:19.998997+00:00, run_end_date=2026-02-28 02:01:03.789813+00:00, run_duration=43.790816, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:00:15.823734+00:00, data_interval_end=2026-02-28 02:00:15.823734+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:01:55,849 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:02:39,196 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>
2026-02-28 10:02:39,197 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:02:39,199 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>
2026-02-28 10:02:39,201 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:02:39,203 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:02:33.024377+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:02:39,203 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:02:33.024377+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:02:39,207 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:02:33.024377+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:02:44,751 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:02:33.024377+00:00', try_number=1, map_index=-1)
2026-02-28 10:02:44,761 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:02:33.024377+00:00, map_index=-1, run_start_date=2026-02-28 02:02:43.779209+00:00, run_end_date=2026-02-28 02:02:44.008418+00:00, run_duration=0.229209, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=592, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:02:39.200772+00:00, queued_by_job_id=576, pid=4816
2026-02-28 10:02:48,891 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>
2026-02-28 10:02:48,892 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:02:48,893 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>
2026-02-28 10:02:48,895 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:02:48,896 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:02:33.024377+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:02:48,897 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:02:33.024377+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:02:48,899 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:02:33.024377+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:03:02,488 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:02:33.024377+00:00', try_number=1, map_index=-1)
2026-02-28 10:03:02,498 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:02:33.024377+00:00, map_index=-1, run_start_date=2026-02-28 02:02:52.862591+00:00, run_end_date=2026-02-28 02:03:01.500656+00:00, run_duration=8.638065, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=593, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:02:48.894799+00:00, queued_by_job_id=576, pid=4819
2026-02-28 10:03:07,387 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>
2026-02-28 10:03:07,388 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:03:07,389 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>
2026-02-28 10:03:07,393 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:02:33.024377+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:03:07,394 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:02:33.024377+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:03:07,395 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:02:33.024377+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:03:07,397 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:02:33.024377+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:03:12,459 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:02:33.024377+00:00', try_number=1, map_index=-1)
2026-02-28 10:03:12,468 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:02:33.024377+00:00, map_index=-1, run_start_date=2026-02-28 02:03:11.476104+00:00, run_end_date=2026-02-28 02:03:11.692615+00:00, run_duration=0.216511, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=594, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:03:07.391797+00:00, queued_by_job_id=576, pid=4853
2026-02-28 10:03:20,018 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:02:33.024377+00:00: manual__2026-02-28T02:02:33.024377+00:00, state:running, queued_at: 2026-02-28 02:02:33.032700+00:00. externally triggered: True> successful
2026-02-28 10:03:20,019 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:02:33.024377+00:00, run_id=manual__2026-02-28T02:02:33.024377+00:00, run_start_date=2026-02-28 02:02:35.499183+00:00, run_end_date=2026-02-28 02:03:20.019252+00:00, run_duration=44.520069, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:02:33.024377+00:00, data_interval_end=2026-02-28 02:02:33.024377+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:06:58,300 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:09:29,930 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>
2026-02-28 10:09:29,933 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:09:29,934 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>
2026-02-28 10:09:29,937 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:09:29,939 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:09:24.539258+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:09:29,940 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:09:24.539258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:09:29,944 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:09:24.539258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:09:35,634 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:09:24.539258+00:00', try_number=1, map_index=-1)
2026-02-28 10:09:35,643 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:09:24.539258+00:00, map_index=-1, run_start_date=2026-02-28 02:09:34.657583+00:00, run_end_date=2026-02-28 02:09:34.879510+00:00, run_duration=0.221927, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=595, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:09:29.935667+00:00, queued_by_job_id=576, pid=5086
2026-02-28 10:09:39,283 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>
2026-02-28 10:09:39,284 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:09:39,285 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>
2026-02-28 10:09:39,288 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:09:39,289 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:09:24.539258+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:09:39,290 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:09:24.539258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:09:39,292 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:09:24.539258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:09:44,735 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:09:24.539258+00:00', try_number=1, map_index=-1)
2026-02-28 10:09:44,745 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:09:24.539258+00:00, map_index=-1, run_start_date=2026-02-28 02:09:43.258443+00:00, run_end_date=2026-02-28 02:09:43.906800+00:00, run_duration=0.648357, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=596, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:09:39.286548+00:00, queued_by_job_id=576, pid=5092
2026-02-28 10:09:48,549 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>
2026-02-28 10:09:48,550 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:09:48,551 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>
2026-02-28 10:09:48,553 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:09:24.539258+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:09:48,554 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:09:24.539258+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:09:48,555 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:09:24.539258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:09:48,558 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:09:24.539258+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:09:53,552 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:09:24.539258+00:00', try_number=1, map_index=-1)
2026-02-28 10:09:53,562 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:09:24.539258+00:00, map_index=-1, run_start_date=2026-02-28 02:09:52.656767+00:00, run_end_date=2026-02-28 02:09:52.850328+00:00, run_duration=0.193561, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=597, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:09:48.552160+00:00, queued_by_job_id=576, pid=5096
2026-02-28 10:10:00,470 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:09:24.539258+00:00: manual__2026-02-28T02:09:24.539258+00:00, state:running, queued_at: 2026-02-28 02:09:24.562737+00:00. externally triggered: True> successful
2026-02-28 10:10:00,471 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:09:24.539258+00:00, run_id=manual__2026-02-28T02:09:24.539258+00:00, run_start_date=2026-02-28 02:09:25.033769+00:00, run_end_date=2026-02-28 02:10:00.471167+00:00, run_duration=35.437398, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:09:24.539258+00:00, data_interval_end=2026-02-28 02:09:24.539258+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:11:59,634 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:12:17,572 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>
2026-02-28 10:12:17,575 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:12:17,575 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>
2026-02-28 10:12:17,578 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:12:17,578 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:12:11.393059+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:12:17,579 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:12:11.393059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:12:17,581 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:12:11.393059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:12:22,910 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:12:11.393059+00:00', try_number=1, map_index=-1)
2026-02-28 10:12:22,919 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:12:11.393059+00:00, map_index=-1, run_start_date=2026-02-28 02:12:21.955055+00:00, run_end_date=2026-02-28 02:12:22.164981+00:00, run_duration=0.209926, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=598, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:12:17.576848+00:00, queued_by_job_id=576, pid=5202
2026-02-28 10:12:26,623 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>
2026-02-28 10:12:26,625 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:12:26,626 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>
2026-02-28 10:12:26,628 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:12:26,629 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:12:11.393059+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:12:26,630 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:12:11.393059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:12:26,632 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:12:11.393059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:12:41,695 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:12:11.393059+00:00', try_number=1, map_index=-1)
2026-02-28 10:12:41,707 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:12:11.393059+00:00, map_index=-1, run_start_date=2026-02-28 02:12:30.580151+00:00, run_end_date=2026-02-28 02:12:40.907181+00:00, run_duration=10.32703, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=599, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:12:26.627353+00:00, queued_by_job_id=576, pid=5205
2026-02-28 10:12:45,633 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>
2026-02-28 10:12:45,634 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:12:45,635 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>
2026-02-28 10:12:45,638 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:12:11.393059+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:12:45,639 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:12:11.393059+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:12:45,640 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:12:11.393059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:12:45,643 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:12:11.393059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:12:51,420 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:12:11.393059+00:00', try_number=1, map_index=-1)
2026-02-28 10:12:51,429 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:12:11.393059+00:00, map_index=-1, run_start_date=2026-02-28 02:12:50.523114+00:00, run_end_date=2026-02-28 02:12:50.723482+00:00, run_duration=0.200368, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=600, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:12:45.636647+00:00, queued_by_job_id=576, pid=5240
2026-02-28 10:12:58,611 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:12:11.393059+00:00: manual__2026-02-28T02:12:11.393059+00:00, state:running, queued_at: 2026-02-28 02:12:11.419351+00:00. externally triggered: True> successful
2026-02-28 10:12:58,613 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:12:11.393059+00:00, run_id=manual__2026-02-28T02:12:11.393059+00:00, run_start_date=2026-02-28 02:12:13.037716+00:00, run_end_date=2026-02-28 02:12:58.613201+00:00, run_duration=45.575485, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:12:11.393059+00:00, data_interval_end=2026-02-28 02:12:11.393059+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:17:03,253 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:21:09,787 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>
2026-02-28 10:21:09,789 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:21:09,790 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>
2026-02-28 10:21:09,792 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:21:09,793 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:21:02.990034+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:21:09,794 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:21:02.990034+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:21:09,797 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:21:02.990034+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:21:15,200 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:21:02.990034+00:00', try_number=1, map_index=-1)
2026-02-28 10:21:15,209 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:21:02.990034+00:00, map_index=-1, run_start_date=2026-02-28 02:21:14.209584+00:00, run_end_date=2026-02-28 02:21:14.424307+00:00, run_duration=0.214723, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=601, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:21:09.791544+00:00, queued_by_job_id=576, pid=5492
2026-02-28 10:21:17,948 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>
2026-02-28 10:21:17,949 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:21:17,950 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>
2026-02-28 10:21:17,952 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:21:17,953 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:21:02.990034+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:21:17,954 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:21:02.990034+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:21:17,957 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:21:02.990034+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:21:32,586 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:21:02.990034+00:00', try_number=1, map_index=-1)
2026-02-28 10:21:32,598 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:21:02.990034+00:00, map_index=-1, run_start_date=2026-02-28 02:21:21.876091+00:00, run_end_date=2026-02-28 02:21:31.686080+00:00, run_duration=9.809989, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=602, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:21:17.951241+00:00, queued_by_job_id=576, pid=5497
2026-02-28 10:21:36,114 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>
2026-02-28 10:21:36,115 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:21:36,116 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>
2026-02-28 10:21:36,118 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:21:02.990034+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:21:36,119 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:21:02.990034+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:21:36,120 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:21:02.990034+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:21:36,122 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:21:02.990034+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:21:41,227 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:21:02.990034+00:00', try_number=1, map_index=-1)
2026-02-28 10:21:41,237 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:21:02.990034+00:00, map_index=-1, run_start_date=2026-02-28 02:21:40.187608+00:00, run_end_date=2026-02-28 02:21:40.397002+00:00, run_duration=0.209394, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=603, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:21:36.117226+00:00, queued_by_job_id=576, pid=5520
2026-02-28 10:21:49,012 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:21:02.990034+00:00: manual__2026-02-28T02:21:02.990034+00:00, state:running, queued_at: 2026-02-28 02:21:03.007067+00:00. externally triggered: True> successful
2026-02-28 10:21:49,013 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:21:02.990034+00:00, run_id=manual__2026-02-28T02:21:02.990034+00:00, run_start_date=2026-02-28 02:21:04.801826+00:00, run_end_date=2026-02-28 02:21:49.013510+00:00, run_duration=44.211684, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:21:02.990034+00:00, data_interval_end=2026-02-28 02:21:02.990034+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:22:03,335 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:23:50,614 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>
2026-02-28 10:23:50,615 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:23:50,616 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>
2026-02-28 10:23:50,618 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:23:50,619 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:23:41.820373+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:23:50,620 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:23:41.820373+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:23:50,622 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:23:41.820373+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:23:55,604 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:23:41.820373+00:00', try_number=1, map_index=-1)
2026-02-28 10:23:55,613 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:23:41.820373+00:00, map_index=-1, run_start_date=2026-02-28 02:23:54.600561+00:00, run_end_date=2026-02-28 02:23:54.836704+00:00, run_duration=0.236143, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=604, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:23:50.617122+00:00, queued_by_job_id=576, pid=5605
2026-02-28 10:23:59,547 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>
2026-02-28 10:23:59,549 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:23:59,550 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>
2026-02-28 10:23:59,552 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:23:59,554 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:23:41.820373+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:23:59,554 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:23:41.820373+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:23:59,557 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:23:41.820373+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:24:13,030 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:23:41.820373+00:00', try_number=1, map_index=-1)
2026-02-28 10:24:13,043 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:23:41.820373+00:00, map_index=-1, run_start_date=2026-02-28 02:24:03.599854+00:00, run_end_date=2026-02-28 02:24:12.095948+00:00, run_duration=8.496094, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=605, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:23:59.551566+00:00, queued_by_job_id=576, pid=5611
2026-02-28 10:24:15,670 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>
2026-02-28 10:24:15,671 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:24:15,672 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>
2026-02-28 10:24:15,674 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:23:41.820373+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:24:15,675 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:23:41.820373+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:24:15,676 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:23:41.820373+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:24:15,678 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:23:41.820373+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:24:20,648 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:23:41.820373+00:00', try_number=1, map_index=-1)
2026-02-28 10:24:20,659 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:23:41.820373+00:00, map_index=-1, run_start_date=2026-02-28 02:24:19.654303+00:00, run_end_date=2026-02-28 02:24:19.864917+00:00, run_duration=0.210614, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=606, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:24:15.673324+00:00, queued_by_job_id=576, pid=5641
2026-02-28 10:24:27,380 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:23:41.820373+00:00: manual__2026-02-28T02:23:41.820373+00:00, state:running, queued_at: 2026-02-28 02:23:41.829893+00:00. externally triggered: True> successful
2026-02-28 10:24:27,381 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:23:41.820373+00:00, run_id=manual__2026-02-28T02:23:41.820373+00:00, run_start_date=2026-02-28 02:23:46.131679+00:00, run_end_date=2026-02-28 02:24:27.381182+00:00, run_duration=41.249503, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:23:41.820373+00:00, data_interval_end=2026-02-28 02:23:41.820373+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:26:00,725 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>
2026-02-28 10:26:00,726 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:26:00,727 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>
2026-02-28 10:26:00,729 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:26:00,730 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:25:56.401429+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:26:00,732 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:25:56.401429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:26:00,735 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:25:56.401429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:26:06,079 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:25:56.401429+00:00', try_number=1, map_index=-1)
2026-02-28 10:26:06,089 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:25:56.401429+00:00, map_index=-1, run_start_date=2026-02-28 02:26:05.053998+00:00, run_end_date=2026-02-28 02:26:05.261343+00:00, run_duration=0.207345, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=607, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:26:00.728236+00:00, queued_by_job_id=576, pid=5722
2026-02-28 10:26:08,968 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>
2026-02-28 10:26:08,969 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:26:08,970 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>
2026-02-28 10:26:08,973 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:26:08,974 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:25:56.401429+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:26:08,975 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:25:56.401429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:26:08,977 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:25:56.401429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:26:22,809 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:25:56.401429+00:00', try_number=1, map_index=-1)
2026-02-28 10:26:22,824 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:25:56.401429+00:00, map_index=-1, run_start_date=2026-02-28 02:26:12.947512+00:00, run_end_date=2026-02-28 02:26:21.874410+00:00, run_duration=8.926898, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=608, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:26:08.971815+00:00, queued_by_job_id=576, pid=5725
2026-02-28 10:26:26,323 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>
2026-02-28 10:26:26,323 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:26:26,324 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>
2026-02-28 10:26:26,327 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:25:56.401429+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:26:26,328 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:25:56.401429+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:26:26,328 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:25:56.401429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:26:26,331 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:25:56.401429+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:26:31,285 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:25:56.401429+00:00', try_number=1, map_index=-1)
2026-02-28 10:26:31,294 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:25:56.401429+00:00, map_index=-1, run_start_date=2026-02-28 02:26:30.358049+00:00, run_end_date=2026-02-28 02:26:30.554159+00:00, run_duration=0.19611, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=609, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:26:26.325962+00:00, queued_by_job_id=576, pid=5753
2026-02-28 10:26:38,790 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:25:56.401429+00:00: manual__2026-02-28T02:25:56.401429+00:00, state:running, queued_at: 2026-02-28 02:25:56.418063+00:00. externally triggered: True> successful
2026-02-28 10:26:38,791 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:25:56.401429+00:00, run_id=manual__2026-02-28T02:25:56.401429+00:00, run_start_date=2026-02-28 02:25:57.528608+00:00, run_end_date=2026-02-28 02:26:38.791439+00:00, run_duration=41.262831, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:25:56.401429+00:00, data_interval_end=2026-02-28 02:25:56.401429+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:27:03,993 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:32:04,590 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:37:08,099 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:42:09,466 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:47:08,448 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>
2026-02-28 10:47:08,449 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:47:08,450 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>
2026-02-28 10:47:08,453 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:47:08,454 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:47:00.754253+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:47:08,455 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:47:00.754253+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:47:08,457 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:47:00.754253+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:47:13,864 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:47:00.754253+00:00', try_number=1, map_index=-1)
2026-02-28 10:47:13,874 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:47:00.754253+00:00, map_index=-1, run_start_date=2026-02-28 02:47:12.836530+00:00, run_end_date=2026-02-28 02:47:13.048169+00:00, run_duration=0.211639, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=610, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:47:08.452577+00:00, queued_by_job_id=576, pid=6546
2026-02-28 10:47:13,902 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:47:16,806 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>
2026-02-28 10:47:16,807 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:47:16,808 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>
2026-02-28 10:47:16,810 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:47:16,811 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:47:00.754253+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:47:16,812 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:47:00.754253+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:47:16,814 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:47:00.754253+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:47:21,870 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:47:00.754253+00:00', try_number=1, map_index=-1)
2026-02-28 10:47:21,879 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:47:00.754253+00:00, map_index=-1, run_start_date=2026-02-28 02:47:20.814114+00:00, run_end_date=2026-02-28 02:47:21.028382+00:00, run_duration=0.214268, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=611, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:47:16.809670+00:00, queued_by_job_id=576, pid=6549
2026-02-28 10:47:24,786 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>
2026-02-28 10:47:24,787 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:47:24,788 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>
2026-02-28 10:47:24,791 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:47:00.754253+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:47:24,792 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:47:00.754253+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:47:24,792 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:47:00.754253+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:47:24,795 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:47:00.754253+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:47:29,762 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:47:00.754253+00:00', try_number=1, map_index=-1)
2026-02-28 10:47:29,772 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:47:00.754253+00:00, map_index=-1, run_start_date=2026-02-28 02:47:28.826062+00:00, run_end_date=2026-02-28 02:47:29.049692+00:00, run_duration=0.22363, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=612, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:47:24.789719+00:00, queued_by_job_id=576, pid=6552
2026-02-28 10:47:36,804 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:47:00.754253+00:00: manual__2026-02-28T02:47:00.754253+00:00, state:running, queued_at: 2026-02-28 02:47:00.764288+00:00. externally triggered: True> successful
2026-02-28 10:47:36,806 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:47:00.754253+00:00, run_id=manual__2026-02-28T02:47:00.754253+00:00, run_start_date=2026-02-28 02:47:04.614188+00:00, run_end_date=2026-02-28 02:47:36.805920+00:00, run_duration=32.191732, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:47:00.754253+00:00, data_interval_end=2026-02-28 02:47:00.754253+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:48:46,504 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>
2026-02-28 10:48:46,506 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:48:46,506 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>
2026-02-28 10:48:46,509 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:48:46,510 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:48:40.168891+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:48:46,510 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:48:40.168891+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:48:46,512 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:48:40.168891+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:48:52,027 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:48:40.168891+00:00', try_number=1, map_index=-1)
2026-02-28 10:48:52,037 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:48:40.168891+00:00, map_index=-1, run_start_date=2026-02-28 02:48:51.079691+00:00, run_end_date=2026-02-28 02:48:51.284431+00:00, run_duration=0.20474, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=613, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:48:46.507771+00:00, queued_by_job_id=576, pid=6617
2026-02-28 10:48:54,828 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>
2026-02-28 10:48:54,828 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:48:54,829 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>
2026-02-28 10:48:54,831 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:48:54,833 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:48:40.168891+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:48:54,834 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:48:40.168891+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:48:54,836 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:48:40.168891+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:49:10,715 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:48:40.168891+00:00', try_number=1, map_index=-1)
2026-02-28 10:49:10,728 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:48:40.168891+00:00, map_index=-1, run_start_date=2026-02-28 02:48:58.804269+00:00, run_end_date=2026-02-28 02:49:09.826483+00:00, run_duration=11.022214, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=614, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:48:54.830531+00:00, queued_by_job_id=576, pid=6626
2026-02-28 10:49:14,063 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>
2026-02-28 10:49:14,063 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:49:14,064 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>
2026-02-28 10:49:14,067 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:48:40.168891+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:49:14,068 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:48:40.168891+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:49:14,069 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:48:40.168891+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:49:14,072 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:48:40.168891+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:49:19,005 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:48:40.168891+00:00', try_number=1, map_index=-1)
2026-02-28 10:49:19,014 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:48:40.168891+00:00, map_index=-1, run_start_date=2026-02-28 02:49:18.125526+00:00, run_end_date=2026-02-28 02:49:18.324019+00:00, run_duration=0.198493, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=615, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:49:14.065819+00:00, queued_by_job_id=576, pid=6668
2026-02-28 10:49:25,515 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:48:40.168891+00:00: manual__2026-02-28T02:48:40.168891+00:00, state:running, queued_at: 2026-02-28 02:48:40.184348+00:00. externally triggered: True> successful
2026-02-28 10:49:25,516 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:48:40.168891+00:00, run_id=manual__2026-02-28T02:48:40.168891+00:00, run_start_date=2026-02-28 02:48:42.452746+00:00, run_end_date=2026-02-28 02:49:25.516809+00:00, run_duration=43.064063, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:48:40.168891+00:00, data_interval_end=2026-02-28 02:48:40.168891+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 10:52:16,184 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:57:16,849 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 10:58:32,456 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>
2026-02-28 10:58:32,457 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:58:32,457 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>
2026-02-28 10:58:32,460 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:58:32,461 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:58:27.015659+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 10:58:32,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:58:27.015659+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:58:32,465 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:58:27.015659+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:58:37,622 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:58:27.015659+00:00', try_number=1, map_index=-1)
2026-02-28 10:58:37,632 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:58:27.015659+00:00, map_index=-1, run_start_date=2026-02-28 02:58:36.631961+00:00, run_end_date=2026-02-28 02:58:36.835300+00:00, run_duration=0.203339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=616, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 02:58:32.459006+00:00, queued_by_job_id=576, pid=7032
2026-02-28 10:58:40,461 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>
2026-02-28 10:58:40,461 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:58:40,464 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>
2026-02-28 10:58:40,467 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:58:40,468 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:58:27.015659+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 10:58:40,468 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:58:27.015659+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:58:40,471 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:58:27.015659+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:58:54,924 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:58:27.015659+00:00', try_number=1, map_index=-1)
2026-02-28 10:58:54,937 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:58:27.015659+00:00, map_index=-1, run_start_date=2026-02-28 02:58:44.597889+00:00, run_end_date=2026-02-28 02:58:54.011090+00:00, run_duration=9.413201, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=617, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 02:58:40.465684+00:00, queued_by_job_id=576, pid=7039
2026-02-28 10:58:59,000 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>
2026-02-28 10:58:59,001 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 10:58:59,002 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>
2026-02-28 10:58:59,004 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T02:58:27.015659+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 10:58:59,005 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:58:27.015659+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 10:58:59,006 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:58:27.015659+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:58:59,009 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T02:58:27.015659+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 10:59:04,009 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T02:58:27.015659+00:00', try_number=1, map_index=-1)
2026-02-28 10:59:04,020 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T02:58:27.015659+00:00, map_index=-1, run_start_date=2026-02-28 02:59:02.968476+00:00, run_end_date=2026-02-28 02:59:03.174868+00:00, run_duration=0.206392, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=618, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 02:58:59.003317+00:00, queued_by_job_id=576, pid=7079
2026-02-28 10:59:13,202 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 02:58:27.015659+00:00: manual__2026-02-28T02:58:27.015659+00:00, state:running, queued_at: 2026-02-28 02:58:27.030669+00:00. externally triggered: True> successful
2026-02-28 10:59:13,203 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 02:58:27.015659+00:00, run_id=manual__2026-02-28T02:58:27.015659+00:00, run_start_date=2026-02-28 02:58:28.971298+00:00, run_end_date=2026-02-28 02:59:13.203855+00:00, run_duration=44.232557, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 02:58:27.015659+00:00, data_interval_end=2026-02-28 02:58:27.015659+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 11:02:18,484 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:07:21,388 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:12:24,726 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:17:27,447 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:22:28,773 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:27:31,596 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:32:32,921 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:37:33,510 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:42:33,913 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:47:35,687 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:52:38,165 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 11:57:40,723 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:02:42,636 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:07:45,351 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:12:46,159 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:14:09,619 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:14:01.540572+00:00 [scheduled]>
2026-02-28 12:14:09,620 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:14:09,621 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:14:01.540572+00:00 [scheduled]>
2026-02-28 12:14:09,623 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:14:01.540572+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:14:09,625 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:14:01.540572+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 12:14:09,626 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:14:01.540572+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:14:09,629 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:14:01.540572+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:14:14,901 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:14:01.540572+00:00', try_number=1, map_index=-1)
2026-02-28 12:14:14,910 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:14:01.540572+00:00, map_index=-1, run_start_date=2026-02-28 04:14:13.758859+00:00, run_end_date=2026-02-28 04:14:14.115702+00:00, run_duration=0.356843, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=619, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 04:14:09.622000+00:00, queued_by_job_id=576, pid=10303
2026-02-28 12:14:27,629 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 04:14:01.540572+00:00: manual__2026-02-28T04:14:01.540572+00:00, state:running, queued_at: 2026-02-28 04:14:01.569655+00:00. externally triggered: True> failed
2026-02-28 12:14:27,630 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 04:14:01.540572+00:00, run_id=manual__2026-02-28T04:14:01.540572+00:00, run_start_date=2026-02-28 04:14:05.080841+00:00, run_end_date=2026-02-28 04:14:27.630262+00:00, run_duration=22.549421, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 04:14:01.540572+00:00, data_interval_end=2026-02-28 04:14:01.540572+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 12:17:27,423 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>
2026-02-28 12:17:27,424 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:17:27,426 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>
2026-02-28 12:17:27,429 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:17:27,430 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:17:16.542760+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 12:17:27,431 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:17:16.542760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:17:27,433 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:17:16.542760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:17:33,099 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:17:16.542760+00:00', try_number=1, map_index=-1)
2026-02-28 12:17:33,107 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:17:16.542760+00:00, map_index=-1, run_start_date=2026-02-28 04:17:32.109044+00:00, run_end_date=2026-02-28 04:17:32.354171+00:00, run_duration=0.245127, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=620, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 04:17:27.427845+00:00, queued_by_job_id=576, pid=10434
2026-02-28 12:17:36,955 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>
2026-02-28 12:17:36,956 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:17:36,957 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>
2026-02-28 12:17:36,960 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:17:36,961 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:17:16.542760+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 12:17:36,962 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:17:16.542760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:17:36,964 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:17:16.542760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:17:46,450 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:17:16.542760+00:00', try_number=1, map_index=-1)
2026-02-28 12:17:46,463 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:17:16.542760+00:00, map_index=-1, run_start_date=2026-02-28 04:17:40.838628+00:00, run_end_date=2026-02-28 04:17:45.696653+00:00, run_duration=4.858025, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=621, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 04:17:36.958362+00:00, queued_by_job_id=576, pid=10440
2026-02-28 12:17:46,493 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:17:49,102 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>
2026-02-28 12:17:49,103 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:17:49,104 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>
2026-02-28 12:17:49,106 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:17:16.542760+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:17:49,107 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:17:16.542760+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 12:17:49,108 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:17:16.542760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:17:49,110 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:17:16.542760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:17:54,085 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:17:16.542760+00:00', try_number=1, map_index=-1)
2026-02-28 12:17:54,096 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:17:16.542760+00:00, map_index=-1, run_start_date=2026-02-28 04:17:53.134934+00:00, run_end_date=2026-02-28 04:17:53.331785+00:00, run_duration=0.196851, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=622, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 04:17:49.105511+00:00, queued_by_job_id=576, pid=10471
2026-02-28 12:18:00,592 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 04:17:16.542760+00:00: manual__2026-02-28T04:17:16.542760+00:00, state:running, queued_at: 2026-02-28 04:17:16.552901+00:00. externally triggered: True> successful
2026-02-28 12:18:00,593 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 04:17:16.542760+00:00, run_id=manual__2026-02-28T04:17:16.542760+00:00, run_start_date=2026-02-28 04:17:22.649129+00:00, run_end_date=2026-02-28 04:18:00.593362+00:00, run_duration=37.944233, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 04:17:16.542760+00:00, data_interval_end=2026-02-28 04:17:16.542760+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 12:19:10,797 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>
2026-02-28 12:19:10,798 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:19:10,799 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>
2026-02-28 12:19:10,801 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:19:10,802 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:19:04.241865+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 12:19:10,803 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:19:04.241865+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:19:10,806 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:19:04.241865+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:19:16,050 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:19:04.241865+00:00', try_number=1, map_index=-1)
2026-02-28 12:19:16,060 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:19:04.241865+00:00, map_index=-1, run_start_date=2026-02-28 04:19:15.082127+00:00, run_end_date=2026-02-28 04:19:15.316075+00:00, run_duration=0.233948, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=623, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 04:19:10.800379+00:00, queued_by_job_id=576, pid=10540
2026-02-28 12:19:18,861 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>
2026-02-28 12:19:18,862 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:19:18,863 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>
2026-02-28 12:19:18,866 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:19:18,867 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:19:04.241865+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 12:19:18,868 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:19:04.241865+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:19:18,872 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:19:04.241865+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:19:26,426 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:19:04.241865+00:00', try_number=1, map_index=-1)
2026-02-28 12:19:26,438 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:19:04.241865+00:00, map_index=-1, run_start_date=2026-02-28 04:19:22.735320+00:00, run_end_date=2026-02-28 04:19:25.646063+00:00, run_duration=2.910743, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=624, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 04:19:18.864780+00:00, queued_by_job_id=576, pid=10544
2026-02-28 12:19:30,243 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>
2026-02-28 12:19:30,244 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:19:30,245 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>
2026-02-28 12:19:30,247 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:19:04.241865+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:19:30,249 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:19:04.241865+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 12:19:30,250 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:19:04.241865+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:19:30,252 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:19:04.241865+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:19:35,195 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:19:04.241865+00:00', try_number=1, map_index=-1)
2026-02-28 12:19:35,204 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:19:04.241865+00:00, map_index=-1, run_start_date=2026-02-28 04:19:34.332266+00:00, run_end_date=2026-02-28 04:19:34.526045+00:00, run_duration=0.193779, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=625, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 04:19:30.246714+00:00, queued_by_job_id=576, pid=10567
2026-02-28 12:19:43,356 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 04:19:04.241865+00:00: manual__2026-02-28T04:19:04.241865+00:00, state:running, queued_at: 2026-02-28 04:19:04.256018+00:00. externally triggered: True> successful
2026-02-28 12:19:43,357 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 04:19:04.241865+00:00, run_id=manual__2026-02-28T04:19:04.241865+00:00, run_start_date=2026-02-28 04:19:07.444269+00:00, run_end_date=2026-02-28 04:19:43.357173+00:00, run_duration=35.912904, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 04:19:04.241865+00:00, data_interval_end=2026-02-28 04:19:04.241865+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 12:20:50,722 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>
2026-02-28 12:20:50,723 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:20:50,724 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>
2026-02-28 12:20:50,726 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:20:50,727 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:20:41.804840+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 12:20:50,728 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:20:41.804840+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:20:50,731 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:20:41.804840+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:20:55,784 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:20:41.804840+00:00', try_number=1, map_index=-1)
2026-02-28 12:20:55,795 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:20:41.804840+00:00, map_index=-1, run_start_date=2026-02-28 04:20:54.722758+00:00, run_end_date=2026-02-28 04:20:54.945997+00:00, run_duration=0.223239, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=626, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 04:20:50.725632+00:00, queued_by_job_id=576, pid=10629
2026-02-28 12:20:59,538 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>
2026-02-28 12:20:59,538 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:20:59,539 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>
2026-02-28 12:20:59,542 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:20:59,543 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:20:41.804840+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 12:20:59,543 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:20:41.804840+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:20:59,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:20:41.804840+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:21:14,220 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:20:41.804840+00:00', try_number=1, map_index=-1)
2026-02-28 12:21:14,235 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:20:41.804840+00:00, map_index=-1, run_start_date=2026-02-28 04:21:03.675894+00:00, run_end_date=2026-02-28 04:21:13.361684+00:00, run_duration=9.68579, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=627, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 04:20:59.540846+00:00, queued_by_job_id=576, pid=10642
2026-02-28 12:21:18,548 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>
2026-02-28 12:21:18,549 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 12:21:18,549 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>
2026-02-28 12:21:18,552 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T04:20:41.804840+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 12:21:18,553 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:20:41.804840+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 12:21:18,554 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:20:41.804840+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:21:18,557 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T04:20:41.804840+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 12:21:23,301 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T04:20:41.804840+00:00', try_number=1, map_index=-1)
2026-02-28 12:21:23,310 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T04:20:41.804840+00:00, map_index=-1, run_start_date=2026-02-28 04:21:22.425288+00:00, run_end_date=2026-02-28 04:21:22.607927+00:00, run_duration=0.182639, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=628, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 04:21:18.550859+00:00, queued_by_job_id=576, pid=10667
2026-02-28 12:21:29,963 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 04:20:41.804840+00:00: manual__2026-02-28T04:20:41.804840+00:00, state:running, queued_at: 2026-02-28 04:20:41.819910+00:00. externally triggered: True> successful
2026-02-28 12:21:29,964 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 04:20:41.804840+00:00, run_id=manual__2026-02-28T04:20:41.804840+00:00, run_start_date=2026-02-28 04:20:46.106185+00:00, run_end_date=2026-02-28 04:21:29.964407+00:00, run_duration=43.858222, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 04:20:41.804840+00:00, data_interval_end=2026-02-28 04:20:41.804840+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 12:22:49,278 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:27:50,627 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:32:53,728 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:37:54,486 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:42:56,162 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:47:58,512 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:52:59,829 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 12:58:02,257 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:03:04,184 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:08:05,294 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:12:20,114 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>
2026-02-28 13:12:20,115 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:12:20,116 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>
2026-02-28 13:12:20,119 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:12:20,121 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:12:14.199197+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:12:20,121 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:12:14.199197+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:12:20,124 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:12:14.199197+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:12:25,304 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:12:14.199197+00:00', try_number=1, map_index=-1)
2026-02-28 13:12:25,315 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:12:14.199197+00:00, map_index=-1, run_start_date=2026-02-28 05:12:24.326913+00:00, run_end_date=2026-02-28 05:12:24.552762+00:00, run_duration=0.225849, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=629, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:12:20.118019+00:00, queued_by_job_id=576, pid=13393
2026-02-28 13:12:27,891 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>
2026-02-28 13:12:27,892 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:12:27,894 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>
2026-02-28 13:12:27,897 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:12:27,899 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:12:14.199197+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:12:27,899 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:12:14.199197+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:12:27,902 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:12:14.199197+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:13:12,297 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:12:14.199197+00:00', try_number=1, map_index=-1)
2026-02-28 13:13:12,308 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:12:14.199197+00:00, map_index=-1, run_start_date=2026-02-28 05:12:32.143294+00:00, run_end_date=2026-02-28 05:13:11.431010+00:00, run_duration=39.287716, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=630, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:12:27.896440+00:00, queued_by_job_id=576, pid=13396
2026-02-28 13:13:12,329 INFO - Heartbeat recovered after 47.00 seconds
2026-02-28 13:13:12,351 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:13:15,314 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>
2026-02-28 13:13:15,315 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:13:15,317 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>
2026-02-28 13:13:15,319 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:12:14.199197+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:13:15,320 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:12:14.199197+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:13:15,321 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:12:14.199197+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:13:15,324 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:12:14.199197+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:13:20,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:12:14.199197+00:00', try_number=1, map_index=-1)
2026-02-28 13:13:20,251 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:12:14.199197+00:00, map_index=-1, run_start_date=2026-02-28 05:13:19.335502+00:00, run_end_date=2026-02-28 05:13:19.528490+00:00, run_duration=0.192988, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=631, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:13:15.318572+00:00, queued_by_job_id=576, pid=13424
2026-02-28 13:13:28,918 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:12:14.199197+00:00: manual__2026-02-28T05:12:14.199197+00:00, state:running, queued_at: 2026-02-28 05:12:14.212152+00:00. externally triggered: True> successful
2026-02-28 13:13:28,920 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:12:14.199197+00:00, run_id=manual__2026-02-28T05:12:14.199197+00:00, run_start_date=2026-02-28 05:12:15.231673+00:00, run_end_date=2026-02-28 05:13:28.919878+00:00, run_duration=73.688205, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:12:14.199197+00:00, data_interval_end=2026-02-28 05:12:14.199197+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:18:13,247 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:20:00,463 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>
2026-02-28 13:20:00,464 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:20:00,465 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>
2026-02-28 13:20:00,467 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:20:00,468 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:19:53.414260+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:20:00,469 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:19:53.414260+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:20:00,471 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:19:53.414260+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:20:05,956 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:19:53.414260+00:00', try_number=1, map_index=-1)
2026-02-28 13:20:05,967 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:19:53.414260+00:00, map_index=-1, run_start_date=2026-02-28 05:20:04.887785+00:00, run_end_date=2026-02-28 05:20:05.100218+00:00, run_duration=0.212433, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=632, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:20:00.466566+00:00, queued_by_job_id=576, pid=13635
2026-02-28 13:20:09,545 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>
2026-02-28 13:20:09,546 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:20:09,547 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>
2026-02-28 13:20:09,549 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:20:09,550 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:19:53.414260+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:20:09,551 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:19:53.414260+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:20:09,553 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:19:53.414260+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:20:32,936 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:19:53.414260+00:00', try_number=1, map_index=-1)
2026-02-28 13:20:32,946 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:19:53.414260+00:00, map_index=-1, run_start_date=2026-02-28 05:20:13.533131+00:00, run_end_date=2026-02-28 05:20:32.117387+00:00, run_duration=18.584256, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=633, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:20:09.548332+00:00, queued_by_job_id=576, pid=13638
2026-02-28 13:20:37,714 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>
2026-02-28 13:20:37,715 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:20:37,716 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>
2026-02-28 13:20:37,718 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:19:53.414260+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:20:37,720 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:19:53.414260+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:20:37,721 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:19:53.414260+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:20:37,723 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:19:53.414260+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:20:42,997 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:19:53.414260+00:00', try_number=1, map_index=-1)
2026-02-28 13:20:43,011 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:19:53.414260+00:00, map_index=-1, run_start_date=2026-02-28 05:20:42.034269+00:00, run_end_date=2026-02-28 05:20:42.233915+00:00, run_duration=0.199646, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=634, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:20:37.717560+00:00, queued_by_job_id=576, pid=13679
2026-02-28 13:20:50,499 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:19:53.414260+00:00: manual__2026-02-28T05:19:53.414260+00:00, state:running, queued_at: 2026-02-28 05:19:53.430558+00:00. externally triggered: True> successful
2026-02-28 13:20:50,500 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:19:53.414260+00:00, run_id=manual__2026-02-28T05:19:53.414260+00:00, run_start_date=2026-02-28 05:19:55.919316+00:00, run_end_date=2026-02-28 05:20:50.500126+00:00, run_duration=54.58081, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:19:53.414260+00:00, data_interval_end=2026-02-28 05:19:53.414260+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:21:10,155 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>
2026-02-28 13:21:10,156 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:21:10,157 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>
2026-02-28 13:21:10,159 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:21:10,160 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:21:05.633035+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:21:10,161 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:21:05.633035+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:21:10,163 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:21:05.633035+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:21:15,125 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:21:05.633035+00:00', try_number=1, map_index=-1)
2026-02-28 13:21:15,133 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:21:05.633035+00:00, map_index=-1, run_start_date=2026-02-28 05:21:14.111435+00:00, run_end_date=2026-02-28 05:21:14.316789+00:00, run_duration=0.205354, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=635, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:21:10.158380+00:00, queued_by_job_id=576, pid=13706
2026-02-28 13:21:17,883 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>
2026-02-28 13:21:17,884 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:21:17,885 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>
2026-02-28 13:21:17,888 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:21:17,889 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:21:05.633035+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:21:17,889 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:21:05.633035+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:21:17,892 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:21:05.633035+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:21:30,334 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:21:05.633035+00:00', try_number=1, map_index=-1)
2026-02-28 13:21:30,348 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:21:05.633035+00:00, map_index=-1, run_start_date=2026-02-28 05:21:21.903986+00:00, run_end_date=2026-02-28 05:21:29.542451+00:00, run_duration=7.638465, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=636, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:21:17.886664+00:00, queued_by_job_id=576, pid=13711
2026-02-28 13:21:34,720 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>
2026-02-28 13:21:34,721 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:21:34,722 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>
2026-02-28 13:21:34,724 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:21:05.633035+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:21:34,725 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:21:05.633035+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:21:34,726 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:21:05.633035+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:21:34,729 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:21:05.633035+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:21:39,674 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:21:05.633035+00:00', try_number=1, map_index=-1)
2026-02-28 13:21:39,682 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:21:05.633035+00:00, map_index=-1, run_start_date=2026-02-28 05:21:38.797795+00:00, run_end_date=2026-02-28 05:21:38.988273+00:00, run_duration=0.190478, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=637, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:21:34.723405+00:00, queued_by_job_id=576, pid=13735
2026-02-28 13:21:48,448 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:21:05.633035+00:00: manual__2026-02-28T05:21:05.633035+00:00, state:running, queued_at: 2026-02-28 05:21:05.645614+00:00. externally triggered: True> successful
2026-02-28 13:21:48,449 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:21:05.633035+00:00, run_id=manual__2026-02-28T05:21:05.633035+00:00, run_start_date=2026-02-28 05:21:06.405069+00:00, run_end_date=2026-02-28 05:21:48.449361+00:00, run_duration=42.044292, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:21:05.633035+00:00, data_interval_end=2026-02-28 05:21:05.633035+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:23:14,209 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:26:38,569 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>
2026-02-28 13:26:38,570 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:26:38,571 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>
2026-02-28 13:26:38,573 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:26:38,574 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:26:29.733678+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:26:38,575 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:26:29.733678+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:26:38,577 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:26:29.733678+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:26:43,680 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:26:29.733678+00:00', try_number=1, map_index=-1)
2026-02-28 13:26:43,690 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:26:29.733678+00:00, map_index=-1, run_start_date=2026-02-28 05:26:42.603737+00:00, run_end_date=2026-02-28 05:26:42.872398+00:00, run_duration=0.268661, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=638, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:26:38.572116+00:00, queued_by_job_id=576, pid=13868
2026-02-28 13:26:46,266 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>
2026-02-28 13:26:46,267 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:26:46,268 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>
2026-02-28 13:26:46,270 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:26:46,271 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:26:29.733678+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:26:46,272 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:26:29.733678+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:26:46,275 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:26:29.733678+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:26:59,363 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:26:29.733678+00:00', try_number=1, map_index=-1)
2026-02-28 13:26:59,374 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:26:29.733678+00:00, map_index=-1, run_start_date=2026-02-28 05:26:50.314116+00:00, run_end_date=2026-02-28 05:26:58.430533+00:00, run_duration=8.116417, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=639, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:26:46.269054+00:00, queued_by_job_id=576, pid=13871
2026-02-28 13:27:02,290 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>
2026-02-28 13:27:02,291 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:27:02,292 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>
2026-02-28 13:27:02,294 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:26:29.733678+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:27:02,295 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:26:29.733678+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:27:02,296 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:26:29.733678+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:27:02,299 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:26:29.733678+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:27:07,012 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:26:29.733678+00:00', try_number=1, map_index=-1)
2026-02-28 13:27:07,023 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:26:29.733678+00:00, map_index=-1, run_start_date=2026-02-28 05:27:06.045044+00:00, run_end_date=2026-02-28 05:27:06.245208+00:00, run_duration=0.200164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=640, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:27:02.293331+00:00, queued_by_job_id=576, pid=13897
2026-02-28 13:27:14,264 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:26:29.733678+00:00: manual__2026-02-28T05:26:29.733678+00:00, state:running, queued_at: 2026-02-28 05:26:29.747783+00:00. externally triggered: True> successful
2026-02-28 13:27:14,265 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:26:29.733678+00:00, run_id=manual__2026-02-28T05:26:29.733678+00:00, run_start_date=2026-02-28 05:26:34.082794+00:00, run_end_date=2026-02-28 05:27:14.265887+00:00, run_duration=40.183093, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:26:29.733678+00:00, data_interval_end=2026-02-28 05:26:29.733678+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:28:16,730 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:31:11,833 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>
2026-02-28 13:31:11,835 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:31:11,836 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>
2026-02-28 13:31:11,838 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:31:11,839 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:31:05.186745+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:31:11,840 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:31:05.186745+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:31:11,843 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:31:05.186745+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:31:16,814 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:31:05.186745+00:00', try_number=1, map_index=-1)
2026-02-28 13:31:16,824 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:31:05.186745+00:00, map_index=-1, run_start_date=2026-02-28 05:31:15.847815+00:00, run_end_date=2026-02-28 05:31:16.046682+00:00, run_duration=0.198867, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=641, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:31:11.837527+00:00, queued_by_job_id=576, pid=14040
2026-02-28 13:31:20,754 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>
2026-02-28 13:31:20,755 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:31:20,756 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>
2026-02-28 13:31:20,758 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:31:20,759 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:31:05.186745+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:31:20,760 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:31:05.186745+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:31:20,763 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:31:05.186745+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:31:33,263 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:31:05.186745+00:00', try_number=1, map_index=-1)
2026-02-28 13:31:33,277 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:31:05.186745+00:00, map_index=-1, run_start_date=2026-02-28 05:31:24.703971+00:00, run_end_date=2026-02-28 05:31:32.401791+00:00, run_duration=7.69782, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=642, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:31:20.757745+00:00, queued_by_job_id=576, pid=14045
2026-02-28 13:31:37,976 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>
2026-02-28 13:31:37,977 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:31:37,978 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>
2026-02-28 13:31:37,980 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:31:05.186745+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:31:37,981 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:31:05.186745+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:31:37,982 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:31:05.186745+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:31:37,984 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:31:05.186745+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:31:42,698 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:31:05.186745+00:00', try_number=1, map_index=-1)
2026-02-28 13:31:42,708 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:31:05.186745+00:00, map_index=-1, run_start_date=2026-02-28 05:31:41.724916+00:00, run_end_date=2026-02-28 05:31:41.919098+00:00, run_duration=0.194182, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=643, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:31:37.979614+00:00, queued_by_job_id=576, pid=14068
2026-02-28 13:31:50,473 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:31:05.186745+00:00: manual__2026-02-28T05:31:05.186745+00:00, state:running, queued_at: 2026-02-28 05:31:05.200332+00:00. externally triggered: True> successful
2026-02-28 13:31:50,475 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:31:05.186745+00:00, run_id=manual__2026-02-28T05:31:05.186745+00:00, run_start_date=2026-02-28 05:31:08.155544+00:00, run_end_date=2026-02-28 05:31:50.475226+00:00, run_duration=42.319682, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:31:05.186745+00:00, data_interval_end=2026-02-28 05:31:05.186745+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:33:17,489 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:38:19,980 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:43:20,406 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:47:08,205 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>
2026-02-28 13:47:08,207 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:47:08,207 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>
2026-02-28 13:47:08,209 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:47:08,210 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:46:59.649666+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:47:08,211 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:46:59.649666+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:47:08,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:46:59.649666+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:47:13,550 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:46:59.649666+00:00', try_number=1, map_index=-1)
2026-02-28 13:47:13,560 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:46:59.649666+00:00, map_index=-1, run_start_date=2026-02-28 05:47:12.557421+00:00, run_end_date=2026-02-28 05:47:12.777068+00:00, run_duration=0.219647, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=644, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:47:08.208801+00:00, queued_by_job_id=576, pid=14609
2026-02-28 13:47:16,154 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>
2026-02-28 13:47:16,155 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:47:16,156 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>
2026-02-28 13:47:16,158 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:47:16,159 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:46:59.649666+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:47:16,160 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:46:59.649666+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:47:16,162 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:46:59.649666+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:47:30,225 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:46:59.649666+00:00', try_number=1, map_index=-1)
2026-02-28 13:47:30,238 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:46:59.649666+00:00, map_index=-1, run_start_date=2026-02-28 05:47:20.137770+00:00, run_end_date=2026-02-28 05:47:29.291429+00:00, run_duration=9.153659, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=645, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:47:16.157440+00:00, queued_by_job_id=576, pid=14612
2026-02-28 13:47:33,446 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>
2026-02-28 13:47:33,447 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:47:33,447 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>
2026-02-28 13:47:33,449 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:46:59.649666+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:47:33,451 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:46:59.649666+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:47:33,452 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:46:59.649666+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:47:33,454 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:46:59.649666+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:47:38,303 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:46:59.649666+00:00', try_number=1, map_index=-1)
2026-02-28 13:47:38,315 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:46:59.649666+00:00, map_index=-1, run_start_date=2026-02-28 05:47:37.333872+00:00, run_end_date=2026-02-28 05:47:37.554052+00:00, run_duration=0.22018, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=646, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:47:33.448817+00:00, queued_by_job_id=576, pid=14644
2026-02-28 13:47:45,387 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:46:59.649666+00:00: manual__2026-02-28T05:46:59.649666+00:00, state:running, queued_at: 2026-02-28 05:46:59.659379+00:00. externally triggered: True> successful
2026-02-28 13:47:45,389 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:46:59.649666+00:00, run_id=manual__2026-02-28T05:46:59.649666+00:00, run_start_date=2026-02-28 05:47:04.217832+00:00, run_end_date=2026-02-28 05:47:45.389086+00:00, run_duration=41.171254, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:46:59.649666+00:00, data_interval_end=2026-02-28 05:46:59.649666+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:48:21,712 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:51:07,483 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>
2026-02-28 13:51:07,485 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:51:07,486 INFO - DAG cdrd_ has 1/16 running and queued tasks
2026-02-28 13:51:07,487 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>
2026-02-28 13:51:07,490 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:51:07,491 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:00.352973+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:51:07,492 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:00.352973+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:07,493 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:02.451200+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:51:07,494 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:02.451200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:07,496 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:00.352973+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:12,795 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:02.451200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:17,924 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:00.352973+00:00', try_number=1, map_index=-1)
2026-02-28 13:51:17,927 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:02.451200+00:00', try_number=1, map_index=-1)
2026-02-28 13:51:17,939 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:51:00.352973+00:00, map_index=-1, run_start_date=2026-02-28 05:51:11.815234+00:00, run_end_date=2026-02-28 05:51:12.023182+00:00, run_duration=0.207948, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=647, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:51:07.488371+00:00, queued_by_job_id=576, pid=14750
2026-02-28 13:51:17,941 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:51:02.451200+00:00, map_index=-1, run_start_date=2026-02-28 05:51:16.908832+00:00, run_end_date=2026-02-28 05:51:17.109907+00:00, run_duration=0.201075, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=648, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:51:07.488371+00:00, queued_by_job_id=576, pid=14752
2026-02-28 13:51:20,399 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>
2026-02-28 13:51:20,401 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:51:20,402 INFO - DAG cdrd_ has 1/16 running and queued tasks
2026-02-28 13:51:20,402 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>
2026-02-28 13:51:20,405 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:51:20,406 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:00.352973+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:51:20,407 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:00.352973+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:20,407 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:02.451200+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:51:20,408 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:02.451200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:20,411 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:00.352973+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:34,474 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:02.451200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:46,889 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:00.352973+00:00', try_number=1, map_index=-1)
2026-02-28 13:51:46,891 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:02.451200+00:00', try_number=1, map_index=-1)
2026-02-28 13:51:46,898 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:51:00.352973+00:00, map_index=-1, run_start_date=2026-02-28 05:51:24.372349+00:00, run_end_date=2026-02-28 05:51:33.712661+00:00, run_duration=9.340312, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=649, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:51:20.403988+00:00, queued_by_job_id=576, pid=14757
2026-02-28 13:51:46,900 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:51:02.451200+00:00, map_index=-1, run_start_date=2026-02-28 05:51:38.526891+00:00, run_end_date=2026-02-28 05:51:46.120058+00:00, run_duration=7.593167, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=650, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:51:20.403988+00:00, queued_by_job_id=576, pid=14779
2026-02-28 13:51:50,541 INFO - 2 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>
2026-02-28 13:51:50,542 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:51:50,543 INFO - DAG cdrd_ has 1/16 running and queued tasks
2026-02-28 13:51:50,543 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>
	<TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>
2026-02-28 13:51:50,545 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:51:00.352973+00:00 [scheduled]>, <TaskInstance: cdrd_. manual__2026-02-28T05:51:02.451200+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:51:50,546 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:00.352973+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:51:50,547 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:00.352973+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:50,548 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:02.451200+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:51:50,549 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:02.451200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:50,552 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:00.352973+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:51:55,300 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:51:02.451200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:52:00,069 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:00.352973+00:00', try_number=1, map_index=-1)
2026-02-28 13:52:00,072 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:51:02.451200+00:00', try_number=1, map_index=-1)
2026-02-28 13:52:00,079 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:51:00.352973+00:00, map_index=-1, run_start_date=2026-02-28 05:51:54.441166+00:00, run_end_date=2026-02-28 05:51:54.625647+00:00, run_duration=0.184481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=651, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:51:50.544639+00:00, queued_by_job_id=576, pid=14799
2026-02-28 13:52:00,081 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:51:02.451200+00:00, map_index=-1, run_start_date=2026-02-28 05:51:59.181192+00:00, run_end_date=2026-02-28 05:51:59.365497+00:00, run_duration=0.184305, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=652, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:51:50.544639+00:00, queued_by_job_id=576, pid=14801
2026-02-28 13:52:08,114 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:51:00.352973+00:00: manual__2026-02-28T05:51:00.352973+00:00, state:running, queued_at: 2026-02-28 05:51:00.371983+00:00. externally triggered: True> successful
2026-02-28 13:52:08,115 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:51:00.352973+00:00, run_id=manual__2026-02-28T05:51:00.352973+00:00, run_start_date=2026-02-28 05:51:03.961253+00:00, run_end_date=2026-02-28 05:52:08.115261+00:00, run_duration=64.154008, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:51:00.352973+00:00, data_interval_end=2026-02-28 05:51:00.352973+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:52:08,120 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:51:02.451200+00:00: manual__2026-02-28T05:51:02.451200+00:00, state:running, queued_at: 2026-02-28 05:51:02.469260+00:00. externally triggered: True> successful
2026-02-28 13:52:08,120 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:51:02.451200+00:00, run_id=manual__2026-02-28T05:51:02.451200+00:00, run_start_date=2026-02-28 05:51:03.961357+00:00, run_end_date=2026-02-28 05:52:08.120907+00:00, run_duration=64.15955, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:51:02.451200+00:00, data_interval_end=2026-02-28 05:51:02.451200+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:53:24,557 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 13:55:20,564 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>
2026-02-28 13:55:20,566 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:55:20,567 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>
2026-02-28 13:55:20,569 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:55:20,570 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:55:12.151132+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 13:55:20,571 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:55:12.151132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:55:20,574 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:55:12.151132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:55:25,572 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:55:12.151132+00:00', try_number=1, map_index=-1)
2026-02-28 13:55:25,581 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:55:12.151132+00:00, map_index=-1, run_start_date=2026-02-28 05:55:24.559952+00:00, run_end_date=2026-02-28 05:55:24.786487+00:00, run_duration=0.226535, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=653, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 05:55:20.568284+00:00, queued_by_job_id=576, pid=14924
2026-02-28 13:55:29,142 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>
2026-02-28 13:55:29,143 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:55:29,144 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>
2026-02-28 13:55:29,146 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:55:29,147 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:55:12.151132+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 13:55:29,148 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:55:12.151132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:55:29,151 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:55:12.151132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:55:41,149 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:55:12.151132+00:00', try_number=1, map_index=-1)
2026-02-28 13:55:41,159 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:55:12.151132+00:00, map_index=-1, run_start_date=2026-02-28 05:55:33.110483+00:00, run_end_date=2026-02-28 05:55:40.406818+00:00, run_duration=7.296335, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=654, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 05:55:29.145134+00:00, queued_by_job_id=576, pid=14927
2026-02-28 13:55:45,034 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>
2026-02-28 13:55:45,035 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 13:55:45,036 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>
2026-02-28 13:55:45,039 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T05:55:12.151132+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 13:55:45,040 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:55:12.151132+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 13:55:45,040 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:55:12.151132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:55:45,043 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T05:55:12.151132+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 13:55:49,762 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T05:55:12.151132+00:00', try_number=1, map_index=-1)
2026-02-28 13:55:49,772 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T05:55:12.151132+00:00, map_index=-1, run_start_date=2026-02-28 05:55:48.779719+00:00, run_end_date=2026-02-28 05:55:48.975442+00:00, run_duration=0.195723, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=655, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 05:55:45.037672+00:00, queued_by_job_id=576, pid=14950
2026-02-28 13:55:56,563 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 05:55:12.151132+00:00: manual__2026-02-28T05:55:12.151132+00:00, state:running, queued_at: 2026-02-28 05:55:12.165475+00:00. externally triggered: True> successful
2026-02-28 13:55:56,564 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 05:55:12.151132+00:00, run_id=manual__2026-02-28T05:55:12.151132+00:00, run_start_date=2026-02-28 05:55:15.989468+00:00, run_end_date=2026-02-28 05:55:56.564409+00:00, run_duration=40.574941, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 05:55:12.151132+00:00, data_interval_end=2026-02-28 05:55:12.151132+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 13:58:26,940 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:03:29,411 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:08:30,019 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:09:50,050 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>
2026-02-28 14:09:50,051 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:09:50,052 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>
2026-02-28 14:09:50,054 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:09:50,055 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:09:42.483226+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 14:09:50,056 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:09:42.483226+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:09:50,058 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:09:42.483226+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:09:55,385 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:09:42.483226+00:00', try_number=1, map_index=-1)
2026-02-28 14:09:55,395 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:09:42.483226+00:00, map_index=-1, run_start_date=2026-02-28 06:09:54.403165+00:00, run_end_date=2026-02-28 06:09:54.614735+00:00, run_duration=0.21157, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=656, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 06:09:50.053286+00:00, queued_by_job_id=576, pid=15406
2026-02-28 14:09:58,985 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>
2026-02-28 14:09:58,986 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:09:58,987 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>
2026-02-28 14:09:58,989 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:09:58,990 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:09:42.483226+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 14:09:58,991 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:09:42.483226+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:09:58,993 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:09:42.483226+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:10:13,538 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:09:42.483226+00:00', try_number=1, map_index=-1)
2026-02-28 14:10:13,548 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:09:42.483226+00:00, map_index=-1, run_start_date=2026-02-28 06:10:03.419832+00:00, run_end_date=2026-02-28 06:10:12.738584+00:00, run_duration=9.318752, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=657, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 06:09:58.988497+00:00, queued_by_job_id=576, pid=15418
2026-02-28 14:10:16,913 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>
2026-02-28 14:10:16,914 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:10:16,915 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>
2026-02-28 14:10:16,918 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:09:42.483226+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:10:16,919 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:09:42.483226+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 14:10:16,919 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:09:42.483226+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:10:16,922 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:09:42.483226+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:10:21,774 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:09:42.483226+00:00', try_number=1, map_index=-1)
2026-02-28 14:10:21,784 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:09:42.483226+00:00, map_index=-1, run_start_date=2026-02-28 06:10:20.861015+00:00, run_end_date=2026-02-28 06:10:21.056022+00:00, run_duration=0.195007, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=658, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 06:10:16.916647+00:00, queued_by_job_id=576, pid=15456
2026-02-28 14:10:28,581 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 06:09:42.483226+00:00: manual__2026-02-28T06:09:42.483226+00:00, state:running, queued_at: 2026-02-28 06:09:42.496768+00:00. externally triggered: True> successful
2026-02-28 14:10:28,583 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 06:09:42.483226+00:00, run_id=manual__2026-02-28T06:09:42.483226+00:00, run_start_date=2026-02-28 06:09:45.237772+00:00, run_end_date=2026-02-28 06:10:28.582976+00:00, run_duration=43.345204, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 06:09:42.483226+00:00, data_interval_end=2026-02-28 06:09:42.483226+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 14:13:32,907 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:15:53,602 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>
2026-02-28 14:15:53,603 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:15:53,604 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>
2026-02-28 14:15:53,606 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:15:53,607 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:15:47.216166+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 14:15:53,608 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:15:47.216166+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:15:53,610 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:15:47.216166+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:15:58,617 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:15:47.216166+00:00', try_number=1, map_index=-1)
2026-02-28 14:15:58,626 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:15:47.216166+00:00, map_index=-1, run_start_date=2026-02-28 06:15:57.652041+00:00, run_end_date=2026-02-28 06:15:57.866313+00:00, run_duration=0.214272, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=659, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 06:15:53.605438+00:00, queued_by_job_id=576, pid=15685
2026-02-28 14:16:02,562 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>
2026-02-28 14:16:02,563 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:16:02,564 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>
2026-02-28 14:16:02,567 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:16:02,569 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:15:47.216166+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 14:16:02,569 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:15:47.216166+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:16:02,572 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:15:47.216166+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:16:16,272 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:15:47.216166+00:00', try_number=1, map_index=-1)
2026-02-28 14:16:16,282 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:15:47.216166+00:00, map_index=-1, run_start_date=2026-02-28 06:16:06.605817+00:00, run_end_date=2026-02-28 06:16:15.452959+00:00, run_duration=8.847142, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=660, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 06:16:02.566320+00:00, queued_by_job_id=576, pid=15691
2026-02-28 14:16:20,873 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>
2026-02-28 14:16:20,874 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:16:20,875 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>
2026-02-28 14:16:20,877 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:15:47.216166+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:16:20,878 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:15:47.216166+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 14:16:20,879 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:15:47.216166+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:16:20,882 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:15:47.216166+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:16:25,721 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:15:47.216166+00:00', try_number=1, map_index=-1)
2026-02-28 14:16:25,730 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:15:47.216166+00:00, map_index=-1, run_start_date=2026-02-28 06:16:24.756747+00:00, run_end_date=2026-02-28 06:16:24.958292+00:00, run_duration=0.201545, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=661, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 06:16:20.876487+00:00, queued_by_job_id=576, pid=15715
2026-02-28 14:16:33,239 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 06:15:47.216166+00:00: manual__2026-02-28T06:15:47.216166+00:00, state:running, queued_at: 2026-02-28 06:15:47.232207+00:00. externally triggered: True> successful
2026-02-28 14:16:33,240 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 06:15:47.216166+00:00, run_id=manual__2026-02-28T06:15:47.216166+00:00, run_start_date=2026-02-28 06:15:50.030637+00:00, run_end_date=2026-02-28 06:16:33.240666+00:00, run_duration=43.210029, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 06:15:47.216166+00:00, data_interval_end=2026-02-28 06:15:47.216166+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 14:18:34,912 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:23:37,456 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:23:56,624 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>
2026-02-28 14:23:56,624 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:23:56,626 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>
2026-02-28 14:23:56,628 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:23:56,629 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:23:51.663389+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 14:23:56,630 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:23:51.663389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:23:56,632 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:23:51.663389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:24:02,123 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:23:51.663389+00:00', try_number=1, map_index=-1)
2026-02-28 14:24:02,132 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:23:51.663389+00:00, map_index=-1, run_start_date=2026-02-28 06:24:01.130977+00:00, run_end_date=2026-02-28 06:24:01.337705+00:00, run_duration=0.206728, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=662, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 06:23:56.627541+00:00, queued_by_job_id=576, pid=15980
2026-02-28 14:24:06,109 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>
2026-02-28 14:24:06,110 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:24:06,111 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>
2026-02-28 14:24:06,113 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:24:06,114 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:23:51.663389+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 14:24:06,115 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:23:51.663389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:24:06,118 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:23:51.663389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:24:19,997 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:23:51.663389+00:00', try_number=1, map_index=-1)
2026-02-28 14:24:20,013 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:23:51.663389+00:00, map_index=-1, run_start_date=2026-02-28 06:24:10.090233+00:00, run_end_date=2026-02-28 06:24:19.045217+00:00, run_duration=8.954984, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=663, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 06:24:06.112476+00:00, queued_by_job_id=576, pid=15983
2026-02-28 14:24:24,523 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>
2026-02-28 14:24:24,524 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:24:24,525 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>
2026-02-28 14:24:24,528 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:23:51.663389+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:24:24,529 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:23:51.663389+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 14:24:24,530 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:23:51.663389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:24:24,532 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:23:51.663389+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:24:29,538 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:23:51.663389+00:00', try_number=1, map_index=-1)
2026-02-28 14:24:29,547 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:23:51.663389+00:00, map_index=-1, run_start_date=2026-02-28 06:24:28.553150+00:00, run_end_date=2026-02-28 06:24:28.756196+00:00, run_duration=0.203046, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=664, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 06:24:24.526242+00:00, queued_by_job_id=576, pid=16007
2026-02-28 14:24:37,045 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 06:23:51.663389+00:00: manual__2026-02-28T06:23:51.663389+00:00, state:running, queued_at: 2026-02-28 06:23:51.679137+00:00. externally triggered: True> successful
2026-02-28 14:24:37,047 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 06:23:51.663389+00:00, run_id=manual__2026-02-28T06:23:51.663389+00:00, run_start_date=2026-02-28 06:23:53.294401+00:00, run_end_date=2026-02-28 06:24:37.047573+00:00, run_duration=43.753172, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 06:23:51.663389+00:00, data_interval_end=2026-02-28 06:23:51.663389+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 14:28:38,308 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:33:38,806 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:38:41,376 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:43:44,785 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:48:45,736 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:53:48,550 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 14:57:43,398 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>
2026-02-28 14:57:43,400 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:57:43,400 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>
2026-02-28 14:57:43,403 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:57:43,404 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:57:36.452827+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 14:57:43,405 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:57:36.452827+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:57:43,407 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:57:36.452827+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:57:49,081 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:57:36.452827+00:00', try_number=1, map_index=-1)
2026-02-28 14:57:49,092 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:57:36.452827+00:00, map_index=-1, run_start_date=2026-02-28 06:57:48.058762+00:00, run_end_date=2026-02-28 06:57:48.342292+00:00, run_duration=0.28353, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=665, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 06:57:43.401958+00:00, queued_by_job_id=576, pid=17191
2026-02-28 14:57:53,086 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>
2026-02-28 14:57:53,087 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:57:53,087 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>
2026-02-28 14:57:53,089 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:57:53,091 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:57:36.452827+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 14:57:53,092 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:57:36.452827+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:57:53,095 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:57:36.452827+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:58:09,681 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:57:36.452827+00:00', try_number=1, map_index=-1)
2026-02-28 14:58:09,693 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:57:36.452827+00:00, map_index=-1, run_start_date=2026-02-28 06:57:57.211585+00:00, run_end_date=2026-02-28 06:58:08.793439+00:00, run_duration=11.581854, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=666, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 06:57:53.088886+00:00, queued_by_job_id=576, pid=17199
2026-02-28 14:58:12,855 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>
2026-02-28 14:58:12,856 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 14:58:12,857 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>
2026-02-28 14:58:12,859 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T06:57:36.452827+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 14:58:12,860 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:57:36.452827+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 14:58:12,861 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:57:36.452827+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:58:12,864 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T06:57:36.452827+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 14:58:18,220 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T06:57:36.452827+00:00', try_number=1, map_index=-1)
2026-02-28 14:58:18,233 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T06:57:36.452827+00:00, map_index=-1, run_start_date=2026-02-28 06:58:17.289444+00:00, run_end_date=2026-02-28 06:58:17.476198+00:00, run_duration=0.186754, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=667, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 06:58:12.858675+00:00, queued_by_job_id=576, pid=17231
2026-02-28 14:58:24,612 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 06:57:36.452827+00:00: manual__2026-02-28T06:57:36.452827+00:00, state:running, queued_at: 2026-02-28 06:57:36.481669+00:00. externally triggered: True> successful
2026-02-28 14:58:24,614 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 06:57:36.452827+00:00, run_id=manual__2026-02-28T06:57:36.452827+00:00, run_start_date=2026-02-28 06:57:38.156749+00:00, run_end_date=2026-02-28 06:58:24.613993+00:00, run_duration=46.457244, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 06:57:36.452827+00:00, data_interval_end=2026-02-28 06:57:36.452827+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 14:58:50,957 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:03:53,673 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:05:09,502 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>
2026-02-28 15:05:09,503 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:05:09,503 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>
2026-02-28 15:05:09,506 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:05:09,507 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:05:02.403945+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 15:05:09,508 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:05:02.403945+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:05:09,510 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:05:02.403945+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:05:14,682 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:05:02.403945+00:00', try_number=1, map_index=-1)
2026-02-28 15:05:14,696 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:05:02.403945+00:00, map_index=-1, run_start_date=2026-02-28 07:05:13.691718+00:00, run_end_date=2026-02-28 07:05:13.898727+00:00, run_duration=0.207009, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=668, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 07:05:09.505081+00:00, queued_by_job_id=576, pid=17455
2026-02-28 15:05:17,380 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>
2026-02-28 15:05:17,381 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:05:17,382 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>
2026-02-28 15:05:17,385 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:05:17,387 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:05:02.403945+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 15:05:17,387 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:05:02.403945+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:05:17,390 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:05:02.403945+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:05:31,924 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:05:02.403945+00:00', try_number=1, map_index=-1)
2026-02-28 15:05:31,936 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:05:02.403945+00:00, map_index=-1, run_start_date=2026-02-28 07:05:21.391028+00:00, run_end_date=2026-02-28 07:05:31.048313+00:00, run_duration=9.657285, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=669, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 07:05:17.384142+00:00, queued_by_job_id=576, pid=17458
2026-02-28 15:05:35,347 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>
2026-02-28 15:05:35,348 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:05:35,349 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>
2026-02-28 15:05:35,351 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:05:02.403945+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:05:35,353 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:05:02.403945+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 15:05:35,354 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:05:02.403945+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:05:35,357 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:05:02.403945+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:05:40,299 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:05:02.403945+00:00', try_number=1, map_index=-1)
2026-02-28 15:05:40,311 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:05:02.403945+00:00, map_index=-1, run_start_date=2026-02-28 07:05:39.358314+00:00, run_end_date=2026-02-28 07:05:39.561612+00:00, run_duration=0.203298, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=670, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 07:05:35.350496+00:00, queued_by_job_id=576, pid=17483
2026-02-28 15:05:47,888 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 07:05:02.403945+00:00: manual__2026-02-28T07:05:02.403945+00:00, state:running, queued_at: 2026-02-28 07:05:02.423088+00:00. externally triggered: True> successful
2026-02-28 15:05:47,889 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 07:05:02.403945+00:00, run_id=manual__2026-02-28T07:05:02.403945+00:00, run_start_date=2026-02-28 07:05:04.539027+00:00, run_end_date=2026-02-28 07:05:47.889583+00:00, run_duration=43.350556, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 07:05:02.403945+00:00, data_interval_end=2026-02-28 07:05:02.403945+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 15:08:54,842 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:13:57,323 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:19:00,220 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:24:02,028 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:28:09,987 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:28:03.493107+00:00 [scheduled]>
2026-02-28 15:28:09,988 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:28:09,989 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:28:03.493107+00:00 [scheduled]>
2026-02-28 15:28:09,991 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:28:03.493107+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:28:09,993 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:28:03.493107+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 15:28:09,994 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:28:03.493107+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:28:09,996 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:28:03.493107+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:28:15,569 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:28:03.493107+00:00', try_number=1, map_index=-1)
2026-02-28 15:28:15,578 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:28:03.493107+00:00, map_index=-1, run_start_date=2026-02-28 07:28:14.591430+00:00, run_end_date=2026-02-28 07:28:14.846116+00:00, run_duration=0.254686, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=671, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 07:28:09.990340+00:00, queued_by_job_id=576, pid=18195
2026-02-28 15:28:26,233 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 07:28:03.493107+00:00: manual__2026-02-28T07:28:03.493107+00:00, state:running, queued_at: 2026-02-28 07:28:03.509582+00:00. externally triggered: True> failed
2026-02-28 15:28:26,234 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 07:28:03.493107+00:00, run_id=manual__2026-02-28T07:28:03.493107+00:00, run_start_date=2026-02-28 07:28:06.377817+00:00, run_end_date=2026-02-28 07:28:26.234508+00:00, run_duration=19.856691, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 07:28:03.493107+00:00, data_interval_end=2026-02-28 07:28:03.493107+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 15:29:05,634 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:30:05,759 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:30:00.235902+00:00 [scheduled]>
2026-02-28 15:30:05,760 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:30:05,761 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:30:00.235902+00:00 [scheduled]>
2026-02-28 15:30:05,767 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:30:00.235902+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:30:05,769 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:30:00.235902+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 15:30:05,770 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:30:00.235902+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:30:05,782 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:30:00.235902+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:30:11,040 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:30:00.235902+00:00', try_number=1, map_index=-1)
2026-02-28 15:30:11,051 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:30:00.235902+00:00, map_index=-1, run_start_date=2026-02-28 07:30:10.062887+00:00, run_end_date=2026-02-28 07:30:10.262363+00:00, run_duration=0.199476, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=672, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 07:30:05.762851+00:00, queued_by_job_id=576, pid=18261
2026-02-28 15:30:23,255 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 07:30:00.235902+00:00: manual__2026-02-28T07:30:00.235902+00:00, state:running, queued_at: 2026-02-28 07:30:00.253836+00:00. externally triggered: True> failed
2026-02-28 15:30:23,257 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 07:30:00.235902+00:00, run_id=manual__2026-02-28T07:30:00.235902+00:00, run_start_date=2026-02-28 07:30:02.148535+00:00, run_end_date=2026-02-28 07:30:23.257079+00:00, run_duration=21.108544, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 07:30:00.235902+00:00, data_interval_end=2026-02-28 07:30:00.235902+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 15:34:08,541 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:35:52,126 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>
2026-02-28 15:35:52,127 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:35:52,128 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>
2026-02-28 15:35:52,130 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:35:52,131 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:35:46.056240+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 15:35:52,132 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:35:46.056240+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:35:52,135 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:35:46.056240+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:35:57,652 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:35:46.056240+00:00', try_number=1, map_index=-1)
2026-02-28 15:35:57,662 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:35:46.056240+00:00, map_index=-1, run_start_date=2026-02-28 07:35:56.683697+00:00, run_end_date=2026-02-28 07:35:56.890871+00:00, run_duration=0.207174, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=673, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 07:35:52.129564+00:00, queued_by_job_id=576, pid=18464
2026-02-28 15:36:00,247 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>
2026-02-28 15:36:00,248 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:36:00,249 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>
2026-02-28 15:36:00,252 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:36:00,253 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:35:46.056240+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 15:36:00,254 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:35:46.056240+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:36:00,256 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:35:46.056240+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:36:17,363 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:35:46.056240+00:00', try_number=1, map_index=-1)
2026-02-28 15:36:17,374 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:35:46.056240+00:00, map_index=-1, run_start_date=2026-02-28 07:36:04.173839+00:00, run_end_date=2026-02-28 07:36:16.442576+00:00, run_duration=12.268737, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=674, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 07:36:00.250070+00:00, queued_by_job_id=576, pid=18471
2026-02-28 15:36:21,970 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>
2026-02-28 15:36:21,971 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:36:21,972 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>
2026-02-28 15:36:21,975 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:35:46.056240+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:36:21,976 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:35:46.056240+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 15:36:21,977 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:35:46.056240+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:36:21,979 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:35:46.056240+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:36:27,333 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:35:46.056240+00:00', try_number=1, map_index=-1)
2026-02-28 15:36:27,344 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:35:46.056240+00:00, map_index=-1, run_start_date=2026-02-28 07:36:26.500840+00:00, run_end_date=2026-02-28 07:36:26.702456+00:00, run_duration=0.201616, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=675, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 07:36:21.973929+00:00, queued_by_job_id=576, pid=18514
2026-02-28 15:36:35,869 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 07:35:46.056240+00:00: manual__2026-02-28T07:35:46.056240+00:00, state:running, queued_at: 2026-02-28 07:35:46.073672+00:00. externally triggered: True> successful
2026-02-28 15:36:35,871 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 07:35:46.056240+00:00, run_id=manual__2026-02-28T07:35:46.056240+00:00, run_start_date=2026-02-28 07:35:48.582489+00:00, run_end_date=2026-02-28 07:36:35.870900+00:00, run_duration=47.288411, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 07:35:46.056240+00:00, data_interval_end=2026-02-28 07:35:46.056240+00:00, dag_hash=52a393adf5e7a2346c990af78c50c2eb
2026-02-28 15:39:11,460 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:44:13,124 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:49:16,310 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:54:17,541 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 15:54:45,016 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:54:40.129700+00:00 [scheduled]>
2026-02-28 15:54:45,017 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:54:45,018 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:54:40.129700+00:00 [scheduled]>
2026-02-28 15:54:45,020 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:54:40.129700+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:54:45,022 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:54:40.129700+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 15:54:45,022 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:54:40.129700+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:54:45,025 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:54:40.129700+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:54:50,570 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:54:40.129700+00:00', try_number=1, map_index=-1)
2026-02-28 15:54:50,584 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:54:40.129700+00:00, map_index=-1, run_start_date=2026-02-28 07:54:49.601487+00:00, run_end_date=2026-02-28 07:54:49.823664+00:00, run_duration=0.222177, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=676, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 07:54:45.019612+00:00, queued_by_job_id=576, pid=19203
2026-02-28 15:54:53,577 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T07:54:40.129700+00:00 [scheduled]>
2026-02-28 15:54:53,579 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 15:54:53,580 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T07:54:40.129700+00:00 [scheduled]>
2026-02-28 15:54:53,582 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T07:54:40.129700+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 15:54:53,583 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:54:40.129700+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 15:54:53,584 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:54:40.129700+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:54:53,587 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T07:54:40.129700+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 15:55:08,911 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T07:54:40.129700+00:00', try_number=1, map_index=-1)
2026-02-28 15:55:08,923 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T07:54:40.129700+00:00, map_index=-1, run_start_date=2026-02-28 07:54:57.724952+00:00, run_end_date=2026-02-28 07:55:08.043874+00:00, run_duration=10.318922, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=677, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 07:54:53.581663+00:00, queued_by_job_id=576, pid=19206
2026-02-28 15:55:16,919 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 07:54:40.129700+00:00: manual__2026-02-28T07:54:40.129700+00:00, state:running, queued_at: 2026-02-28 07:54:40.143276+00:00. externally triggered: True> successful
2026-02-28 15:55:16,920 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 07:54:40.129700+00:00, run_id=manual__2026-02-28T07:54:40.129700+00:00, run_start_date=2026-02-28 07:54:41.588949+00:00, run_end_date=2026-02-28 07:55:16.920125+00:00, run_duration=35.331176, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 07:54:40.129700+00:00, data_interval_end=2026-02-28 07:54:40.129700+00:00, dag_hash=14851c9c84d59bd7c289c15ef21a1d4d
2026-02-28 15:59:18,846 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:01:40,597 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T08:01:31.463620+00:00 [scheduled]>
2026-02-28 16:01:40,598 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 16:01:40,599 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T08:01:31.463620+00:00 [scheduled]>
2026-02-28 16:01:40,601 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T08:01:31.463620+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:01:40,602 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:01:31.463620+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 16:01:40,603 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:01:31.463620+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:01:40,605 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:01:31.463620+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:01:46,147 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:01:31.463620+00:00', try_number=1, map_index=-1)
2026-02-28 16:01:46,156 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T08:01:31.463620+00:00, map_index=-1, run_start_date=2026-02-28 08:01:45.105442+00:00, run_end_date=2026-02-28 08:01:45.343938+00:00, run_duration=0.238496, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=678, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 08:01:40.600245+00:00, queued_by_job_id=576, pid=19455
2026-02-28 16:01:50,027 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T08:01:31.463620+00:00 [scheduled]>
2026-02-28 16:01:50,028 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 16:01:50,029 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T08:01:31.463620+00:00 [scheduled]>
2026-02-28 16:01:50,032 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T08:01:31.463620+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:01:50,033 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:01:31.463620+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 16:01:50,034 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:01:31.463620+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:01:50,036 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:01:31.463620+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:02:06,086 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:01:31.463620+00:00', try_number=1, map_index=-1)
2026-02-28 16:02:06,097 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T08:01:31.463620+00:00, map_index=-1, run_start_date=2026-02-28 08:01:54.079053+00:00, run_end_date=2026-02-28 08:02:05.235698+00:00, run_duration=11.156645, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=679, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 08:01:50.031105+00:00, queued_by_job_id=576, pid=19464
2026-02-28 16:02:13,080 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 08:01:31.463620+00:00: manual__2026-02-28T08:01:31.463620+00:00, state:running, queued_at: 2026-02-28 08:01:31.472489+00:00. externally triggered: True> successful
2026-02-28 16:02:13,081 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 08:01:31.463620+00:00, run_id=manual__2026-02-28T08:01:31.463620+00:00, run_start_date=2026-02-28 08:01:35.707496+00:00, run_end_date=2026-02-28 08:02:13.081725+00:00, run_duration=37.374229, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 08:01:31.463620+00:00, data_interval_end=2026-02-28 08:01:31.463620+00:00, dag_hash=14851c9c84d59bd7c289c15ef21a1d4d
2026-02-28 16:04:19,909 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:09:23,734 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:14:25,080 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:14:55,534 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T08:14:47.880663+00:00 [scheduled]>
2026-02-28 16:14:55,536 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 16:14:55,537 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T08:14:47.880663+00:00 [scheduled]>
2026-02-28 16:14:55,541 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T08:14:47.880663+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:14:55,542 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:14:47.880663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 16:14:55,543 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:14:47.880663+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:14:55,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:14:47.880663+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:15:00,967 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:14:47.880663+00:00', try_number=1, map_index=-1)
2026-02-28 16:15:00,976 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T08:14:47.880663+00:00, map_index=-1, run_start_date=2026-02-28 08:15:00.000031+00:00, run_end_date=2026-02-28 08:15:00.210946+00:00, run_duration=0.210915, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=680, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 08:14:55.539259+00:00, queued_by_job_id=576, pid=20230
2026-02-28 16:15:03,631 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T08:14:47.880663+00:00 [scheduled]>
2026-02-28 16:15:03,632 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 16:15:03,633 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T08:14:47.880663+00:00 [scheduled]>
2026-02-28 16:15:03,635 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T08:14:47.880663+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:15:03,636 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:14:47.880663+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 16:15:03,637 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:14:47.880663+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:15:03,639 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T08:14:47.880663+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 16:15:19,827 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T08:14:47.880663+00:00', try_number=1, map_index=-1)
2026-02-28 16:15:19,860 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T08:14:47.880663+00:00, map_index=-1, run_start_date=2026-02-28 08:15:07.701609+00:00, run_end_date=2026-02-28 08:15:18.939305+00:00, run_duration=11.237696, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=681, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 08:15:03.634497+00:00, queued_by_job_id=576, pid=20236
2026-02-28 16:15:26,603 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 08:14:47.880663+00:00: manual__2026-02-28T08:14:47.880663+00:00, state:running, queued_at: 2026-02-28 08:14:47.890995+00:00. externally triggered: True> successful
2026-02-28 16:15:26,604 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 08:14:47.880663+00:00, run_id=manual__2026-02-28T08:14:47.880663+00:00, run_start_date=2026-02-28 08:14:50.648069+00:00, run_end_date=2026-02-28 08:15:26.604125+00:00, run_duration=35.956056, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 08:14:47.880663+00:00, data_interval_end=2026-02-28 08:14:47.880663+00:00, dag_hash=14851c9c84d59bd7c289c15ef21a1d4d
2026-02-28 16:19:27,465 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:24:29,416 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:29:29,668 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:34:31,651 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:36:16,771 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:36:10.709825+00:00 [scheduled]>
2026-02-28 16:36:16,772 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 16:36:16,774 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:36:10.709825+00:00 [scheduled]>
2026-02-28 16:36:16,777 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:36:10.709825+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:36:16,778 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:36:10.709825+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 16:36:16,779 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:36:10.709825+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:36:16,782 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:36:10.709825+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:36:22,231 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:36:10.709825+00:00', try_number=1, map_index=-1)
2026-02-28 16:36:22,240 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:36:10.709825+00:00, map_index=-1, run_start_date=2026-02-28 08:36:21.273457+00:00, run_end_date=2026-02-28 08:36:21.480169+00:00, run_duration=0.206712, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=682, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 08:36:16.775552+00:00, queued_by_job_id=576, pid=21063
2026-02-28 16:36:26,010 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:36:10.709825+00:00 [scheduled]>
2026-02-28 16:36:26,011 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 16:36:26,011 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:36:10.709825+00:00 [scheduled]>
2026-02-28 16:36:26,014 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:36:10.709825+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:36:26,015 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:36:10.709825+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 16:36:26,016 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:36:10.709825+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:36:26,019 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:36:10.709825+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:36:30,990 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:36:10.709825+00:00', try_number=1, map_index=-1)
2026-02-28 16:36:31,001 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:36:10.709825+00:00, map_index=-1, run_start_date=2026-02-28 08:36:29.987038+00:00, run_end_date=2026-02-28 08:36:30.204865+00:00, run_duration=0.217827, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=683, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 08:36:26.013049+00:00, queued_by_job_id=576, pid=21066
2026-02-28 16:36:39,441 INFO - Marking run <DagRun cdrd__ @ 2026-02-28 08:36:10.709825+00:00: manual__2026-02-28T08:36:10.709825+00:00, state:running, queued_at: 2026-02-28 08:36:10.722471+00:00. externally triggered: True> successful
2026-02-28 16:36:39,442 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 08:36:10.709825+00:00, run_id=manual__2026-02-28T08:36:10.709825+00:00, run_start_date=2026-02-28 08:36:13.260608+00:00, run_end_date=2026-02-28 08:36:39.442632+00:00, run_duration=26.182024, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 08:36:10.709825+00:00, data_interval_end=2026-02-28 08:36:10.709825+00:00, dag_hash=9370a686bfe468188246a4a4cef8bef4
2026-02-28 16:37:35,612 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:37:30.880685+00:00 [scheduled]>
2026-02-28 16:37:35,614 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 16:37:35,615 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:37:30.880685+00:00 [scheduled]>
2026-02-28 16:37:35,619 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:37:30.880685+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:37:35,621 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:37:30.880685+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 16:37:35,621 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:37:30.880685+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:37:35,624 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:37:30.880685+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:37:41,264 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:37:30.880685+00:00', try_number=1, map_index=-1)
2026-02-28 16:37:41,275 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:37:30.880685+00:00, map_index=-1, run_start_date=2026-02-28 08:37:40.266399+00:00, run_end_date=2026-02-28 08:37:40.496243+00:00, run_duration=0.229844, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=684, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 08:37:35.617186+00:00, queued_by_job_id=576, pid=21111
2026-02-28 16:37:44,376 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:37:30.880685+00:00 [scheduled]>
2026-02-28 16:37:44,377 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 16:37:44,378 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:37:30.880685+00:00 [scheduled]>
2026-02-28 16:37:44,380 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:37:30.880685+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:37:44,381 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:37:30.880685+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 16:37:44,382 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:37:30.880685+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:37:44,385 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:37:30.880685+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:38:05,983 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:37:30.880685+00:00', try_number=1, map_index=-1)
2026-02-28 16:38:05,993 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:37:30.880685+00:00, map_index=-1, run_start_date=2026-02-28 08:37:48.337645+00:00, run_end_date=2026-02-28 08:38:05.111029+00:00, run_duration=16.773384, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=685, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 08:37:44.379326+00:00, queued_by_job_id=576, pid=21114
2026-02-28 16:38:14,138 INFO - Marking run <DagRun cdrd__ @ 2026-02-28 08:37:30.880685+00:00: manual__2026-02-28T08:37:30.880685+00:00, state:running, queued_at: 2026-02-28 08:37:30.895584+00:00. externally triggered: True> successful
2026-02-28 16:38:14,140 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 08:37:30.880685+00:00, run_id=manual__2026-02-28T08:37:30.880685+00:00, run_start_date=2026-02-28 08:37:32.506527+00:00, run_end_date=2026-02-28 08:38:14.140273+00:00, run_duration=41.633746, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 08:37:30.880685+00:00, data_interval_end=2026-02-28 08:37:30.880685+00:00, dag_hash=9370a686bfe468188246a4a4cef8bef4
2026-02-28 16:39:33,057 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:44:33,593 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:49:34,981 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:54:37,075 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 16:57:27,132 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:57:21.725702+00:00 [scheduled]>
2026-02-28 16:57:27,132 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 16:57:27,133 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:57:21.725702+00:00 [scheduled]>
2026-02-28 16:57:27,135 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:57:21.725702+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:57:27,137 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:57:21.725702+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 16:57:27,138 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:57:21.725702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:57:27,141 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:57:21.725702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:57:32,633 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:57:21.725702+00:00', try_number=1, map_index=-1)
2026-02-28 16:57:32,645 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:57:21.725702+00:00, map_index=-1, run_start_date=2026-02-28 08:57:31.655177+00:00, run_end_date=2026-02-28 08:57:31.874324+00:00, run_duration=0.219147, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=686, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 08:57:27.134921+00:00, queued_by_job_id=576, pid=22133
2026-02-28 16:57:35,663 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:57:21.725702+00:00 [scheduled]>
2026-02-28 16:57:35,664 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 16:57:35,666 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:57:21.725702+00:00 [scheduled]>
2026-02-28 16:57:35,671 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:57:21.725702+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 16:57:35,672 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:57:21.725702+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 16:57:35,674 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:57:21.725702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:57:35,677 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:57:21.725702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 16:57:53,970 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:57:21.725702+00:00', try_number=1, map_index=-1)
2026-02-28 16:57:53,983 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:57:21.725702+00:00, map_index=-1, run_start_date=2026-02-28 08:57:39.956642+00:00, run_end_date=2026-02-28 08:57:53.162858+00:00, run_duration=13.206216, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=687, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 08:57:35.668880+00:00, queued_by_job_id=576, pid=22147
2026-02-28 16:58:01,895 INFO - Marking run <DagRun cdrd__ @ 2026-02-28 08:57:21.725702+00:00: manual__2026-02-28T08:57:21.725702+00:00, state:running, queued_at: 2026-02-28 08:57:21.736279+00:00. externally triggered: True> successful
2026-02-28 16:58:01,896 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 08:57:21.725702+00:00, run_id=manual__2026-02-28T08:57:21.725702+00:00, run_start_date=2026-02-28 08:57:24.151810+00:00, run_end_date=2026-02-28 08:58:01.896424+00:00, run_duration=37.744614, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 08:57:21.725702+00:00, data_interval_end=2026-02-28 08:57:21.725702+00:00, dag_hash=9370a686bfe468188246a4a4cef8bef4
2026-02-28 16:59:37,763 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:00:03,038 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:59:56.694792+00:00 [scheduled]>
2026-02-28 17:00:03,039 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:00:03,039 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:59:56.694792+00:00 [scheduled]>
2026-02-28 17:00:03,042 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:59:56.694792+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:00:03,043 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:59:56.694792+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:00:03,044 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:59:56.694792+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:00:03,046 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:59:56.694792+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:00:08,284 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:59:56.694792+00:00', try_number=1, map_index=-1)
2026-02-28 17:00:08,294 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:59:56.694792+00:00, map_index=-1, run_start_date=2026-02-28 09:00:07.248632+00:00, run_end_date=2026-02-28 09:00:07.455030+00:00, run_duration=0.206398, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=688, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:00:03.041007+00:00, queued_by_job_id=576, pid=22274
2026-02-28 17:00:10,948 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T08:59:56.694792+00:00 [scheduled]>
2026-02-28 17:00:10,949 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:00:10,950 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T08:59:56.694792+00:00 [scheduled]>
2026-02-28 17:00:10,952 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T08:59:56.694792+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:00:10,953 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:59:56.694792+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:00:10,954 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:59:56.694792+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:00:10,956 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T08:59:56.694792+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:00:22,388 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T08:59:56.694792+00:00', try_number=1, map_index=-1)
2026-02-28 17:00:22,399 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T08:59:56.694792+00:00, map_index=-1, run_start_date=2026-02-28 09:00:14.899659+00:00, run_end_date=2026-02-28 09:00:21.536937+00:00, run_duration=6.637278, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=689, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:00:10.951074+00:00, queued_by_job_id=576, pid=22277
2026-02-28 17:00:26,478 ERROR - Marking run <DagRun cdrd__ @ 2026-02-28 08:59:56.694792+00:00: manual__2026-02-28T08:59:56.694792+00:00, state:running, queued_at: 2026-02-28 08:59:56.705038+00:00. externally triggered: True> failed
2026-02-28 17:00:26,480 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 08:59:56.694792+00:00, run_id=manual__2026-02-28T08:59:56.694792+00:00, run_start_date=2026-02-28 08:59:58.114407+00:00, run_end_date=2026-02-28 09:00:26.479979+00:00, run_duration=28.365572, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 08:59:56.694792+00:00, data_interval_end=2026-02-28 08:59:56.694792+00:00, dag_hash=9370a686bfe468188246a4a4cef8bef4
2026-02-28 17:04:40,103 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:05:02,309 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:04:57.531181+00:00 [scheduled]>
2026-02-28 17:05:02,310 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:05:02,311 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:04:57.531181+00:00 [scheduled]>
2026-02-28 17:05:02,313 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:04:57.531181+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:05:02,314 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:04:57.531181+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:05:02,315 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:04:57.531181+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:05:02,317 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:04:57.531181+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:05:07,791 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:04:57.531181+00:00', try_number=1, map_index=-1)
2026-02-28 17:05:07,802 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:04:57.531181+00:00, map_index=-1, run_start_date=2026-02-28 09:05:06.818540+00:00, run_end_date=2026-02-28 09:05:07.034415+00:00, run_duration=0.215875, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=690, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:05:02.312312+00:00, queued_by_job_id=576, pid=22453
2026-02-28 17:05:10,586 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:04:57.531181+00:00 [scheduled]>
2026-02-28 17:05:10,587 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:05:10,588 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:04:57.531181+00:00 [scheduled]>
2026-02-28 17:05:10,590 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:04:57.531181+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:05:10,591 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:04:57.531181+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:05:10,592 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:04:57.531181+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:05:10,595 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:04:57.531181+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:05:28,441 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:04:57.531181+00:00', try_number=1, map_index=-1)
2026-02-28 17:05:28,452 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:04:57.531181+00:00, map_index=-1, run_start_date=2026-02-28 09:05:14.702195+00:00, run_end_date=2026-02-28 09:05:27.679028+00:00, run_duration=12.976833, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=691, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:05:10.589270+00:00, queued_by_job_id=576, pid=22456
2026-02-28 17:05:31,930 ERROR - Marking run <DagRun cdrd__ @ 2026-02-28 09:04:57.531181+00:00: manual__2026-02-28T09:04:57.531181+00:00, state:running, queued_at: 2026-02-28 09:04:57.545029+00:00. externally triggered: True> failed
2026-02-28 17:05:31,931 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 09:04:57.531181+00:00, run_id=manual__2026-02-28T09:04:57.531181+00:00, run_start_date=2026-02-28 09:04:58.498728+00:00, run_end_date=2026-02-28 09:05:31.931187+00:00, run_duration=33.432459, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:04:57.531181+00:00, data_interval_end=2026-02-28 09:04:57.531181+00:00, dag_hash=9370a686bfe468188246a4a4cef8bef4
2026-02-28 17:07:43,062 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:07:37.367407+00:00 [scheduled]>
2026-02-28 17:07:43,063 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:07:43,064 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:07:37.367407+00:00 [scheduled]>
2026-02-28 17:07:43,066 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:07:37.367407+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:07:43,067 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:07:37.367407+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:07:43,068 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:07:37.367407+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:07:43,071 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:07:37.367407+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:07:48,326 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:07:37.367407+00:00', try_number=1, map_index=-1)
2026-02-28 17:07:48,335 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:07:37.367407+00:00, map_index=-1, run_start_date=2026-02-28 09:07:47.339560+00:00, run_end_date=2026-02-28 09:07:47.544041+00:00, run_duration=0.204481, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=692, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:07:43.065755+00:00, queued_by_job_id=576, pid=22578
2026-02-28 17:07:50,958 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:07:37.367407+00:00 [scheduled]>
2026-02-28 17:07:50,959 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:07:50,960 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:07:37.367407+00:00 [scheduled]>
2026-02-28 17:07:50,962 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:07:37.367407+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:07:50,964 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:07:37.367407+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:07:50,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:07:37.367407+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:07:50,967 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:07:37.367407+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:08:07,655 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:07:37.367407+00:00', try_number=1, map_index=-1)
2026-02-28 17:08:07,665 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:07:37.367407+00:00, map_index=-1, run_start_date=2026-02-28 09:07:54.949320+00:00, run_end_date=2026-02-28 09:08:06.820777+00:00, run_duration=11.871457, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=693, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:07:50.961417+00:00, queued_by_job_id=576, pid=22581
2026-02-28 17:08:16,518 INFO - Marking run <DagRun cdrd__ @ 2026-02-28 09:07:37.367407+00:00: manual__2026-02-28T09:07:37.367407+00:00, state:running, queued_at: 2026-02-28 09:07:37.375715+00:00. externally triggered: True> successful
2026-02-28 17:08:16,519 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 09:07:37.367407+00:00, run_id=manual__2026-02-28T09:07:37.367407+00:00, run_start_date=2026-02-28 09:07:40.082220+00:00, run_end_date=2026-02-28 09:08:16.519831+00:00, run_duration=36.437611, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:07:37.367407+00:00, data_interval_end=2026-02-28 09:07:37.367407+00:00, dag_hash=9370a686bfe468188246a4a4cef8bef4
2026-02-28 17:09:42,664 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:11:36,515 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:11:29.750370+00:00 [scheduled]>
2026-02-28 17:11:36,516 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:11:36,517 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:11:29.750370+00:00 [scheduled]>
2026-02-28 17:11:36,519 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:11:29.750370+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:11:36,521 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:11:29.750370+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:11:36,522 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:11:29.750370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:11:36,525 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:11:29.750370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:11:41,860 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:11:29.750370+00:00', try_number=1, map_index=-1)
2026-02-28 17:11:41,870 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:11:29.750370+00:00, map_index=-1, run_start_date=2026-02-28 09:11:40.824470+00:00, run_end_date=2026-02-28 09:11:41.032354+00:00, run_duration=0.207884, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=694, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:11:36.518535+00:00, queued_by_job_id=576, pid=22768
2026-02-28 17:11:45,921 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:11:29.750370+00:00 [scheduled]>
2026-02-28 17:11:45,922 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:11:45,922 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:11:29.750370+00:00 [scheduled]>
2026-02-28 17:11:45,925 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:11:29.750370+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:11:45,926 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:11:29.750370+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:11:45,926 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:11:29.750370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:11:45,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:11:29.750370+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag__.py']
2026-02-28 17:12:03,404 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:11:29.750370+00:00', try_number=1, map_index=-1)
2026-02-28 17:12:03,415 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:11:29.750370+00:00, map_index=-1, run_start_date=2026-02-28 09:11:49.883088+00:00, run_end_date=2026-02-28 09:12:02.623104+00:00, run_duration=12.740016, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=695, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:11:45.923969+00:00, queued_by_job_id=576, pid=22771
2026-02-28 17:12:10,289 INFO - Marking run <DagRun cdrd__ @ 2026-02-28 09:11:29.750370+00:00: manual__2026-02-28T09:11:29.750370+00:00, state:running, queued_at: 2026-02-28 09:11:29.769972+00:00. externally triggered: True> successful
2026-02-28 17:12:10,290 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 09:11:29.750370+00:00, run_id=manual__2026-02-28T09:11:29.750370+00:00, run_start_date=2026-02-28 09:11:32.852270+00:00, run_end_date=2026-02-28 09:12:10.290625+00:00, run_duration=37.438355, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:11:29.750370+00:00, data_interval_end=2026-02-28 09:11:29.750370+00:00, dag_hash=9370a686bfe468188246a4a4cef8bef4
2026-02-28 17:14:45,315 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:19:47,627 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:24:50,063 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:28:55,721 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:28:54.338536+00:00 [scheduled]>
2026-02-28 17:28:55,722 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:28:55,723 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:28:54.338536+00:00 [scheduled]>
2026-02-28 17:28:55,725 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:28:54.338536+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:28:55,726 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:28:54.338536+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 17:28:55,727 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:28:54.338536+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:28:55,729 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:28:54.338536+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:29:01,523 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:28:54.338536+00:00', try_number=1, map_index=-1)
2026-02-28 17:29:01,533 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:28:54.338536+00:00, map_index=-1, run_start_date=2026-02-28 09:29:00.113807+00:00, run_end_date=2026-02-28 09:29:00.565039+00:00, run_duration=0.451232, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=696, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 09:28:55.724311+00:00, queued_by_job_id=576, pid=23325
2026-02-28 17:29:04,419 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:28:54.338536+00:00 [scheduled]>
2026-02-28 17:29:04,420 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:29:04,422 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:28:54.338536+00:00 [scheduled]>
2026-02-28 17:29:04,424 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:28:54.338536+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:29:04,425 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:28:54.338536+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:29:04,426 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:28:54.338536+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:29:04,428 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:28:54.338536+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:29:10,306 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:28:54.338536+00:00', try_number=1, map_index=-1)
2026-02-28 17:29:10,318 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:28:54.338536+00:00, map_index=-1, run_start_date=2026-02-28 09:29:08.995177+00:00, run_end_date=2026-02-28 09:29:09.455973+00:00, run_duration=0.460796, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=697, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:29:04.423349+00:00, queued_by_job_id=576, pid=23331
2026-02-28 17:29:18,431 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 09:28:54.338536+00:00: manual__2026-02-28T09:28:54.338536+00:00, state:running, queued_at: 2026-02-28 09:28:54.362751+00:00. externally triggered: True> failed
2026-02-28 17:29:18,432 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 09:28:54.338536+00:00, run_id=manual__2026-02-28T09:28:54.338536+00:00, run_start_date=2026-02-28 09:28:55.691756+00:00, run_end_date=2026-02-28 09:29:18.432641+00:00, run_duration=22.740885, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:28:54.338536+00:00, data_interval_end=2026-02-28 09:28:54.338536+00:00, dag_hash=c38e4d01d8794edab9c26738273f0d92
2026-02-28 17:29:53,407 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:30:14,661 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:30:12.383522+00:00 [scheduled]>
2026-02-28 17:30:14,662 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:30:14,663 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:30:12.383522+00:00 [scheduled]>
2026-02-28 17:30:14,665 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:30:12.383522+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:30:14,666 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:30:12.383522+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 17:30:14,667 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:30:12.383522+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:30:14,669 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:30:12.383522+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:30:19,978 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:30:12.383522+00:00', try_number=1, map_index=-1)
2026-02-28 17:30:19,988 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:30:12.383522+00:00, map_index=-1, run_start_date=2026-02-28 09:30:18.583503+00:00, run_end_date=2026-02-28 09:30:19.048820+00:00, run_duration=0.465317, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=698, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 09:30:14.664748+00:00, queued_by_job_id=576, pid=23378
2026-02-28 17:30:22,763 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:30:12.383522+00:00 [scheduled]>
2026-02-28 17:30:22,765 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:30:22,766 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:30:12.383522+00:00 [scheduled]>
2026-02-28 17:30:22,768 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:30:12.383522+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:30:22,769 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:30:12.383522+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:30:22,770 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:30:12.383522+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:30:22,773 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:30:12.383522+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:30:28,041 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:30:12.383522+00:00', try_number=1, map_index=-1)
2026-02-28 17:30:28,054 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:30:12.383522+00:00, map_index=-1, run_start_date=2026-02-28 09:30:26.744437+00:00, run_end_date=2026-02-28 09:30:27.186557+00:00, run_duration=0.44212, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=699, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:30:22.767610+00:00, queued_by_job_id=576, pid=23381
2026-02-28 17:30:35,720 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 09:30:12.383522+00:00: manual__2026-02-28T09:30:12.383522+00:00, state:running, queued_at: 2026-02-28 09:30:12.394807+00:00. externally triggered: True> failed
2026-02-28 17:30:35,721 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 09:30:12.383522+00:00, run_id=manual__2026-02-28T09:30:12.383522+00:00, run_start_date=2026-02-28 09:30:14.632745+00:00, run_end_date=2026-02-28 09:30:35.721793+00:00, run_duration=21.089048, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:30:12.383522+00:00, data_interval_end=2026-02-28 09:30:12.383522+00:00, dag_hash=c38e4d01d8794edab9c26738273f0d92
2026-02-28 17:32:15,600 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:32:12.680318+00:00 [scheduled]>
2026-02-28 17:32:15,601 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:32:15,602 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:32:12.680318+00:00 [scheduled]>
2026-02-28 17:32:15,604 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:32:12.680318+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:32:15,606 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:32:12.680318+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 17:32:15,606 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:32:12.680318+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:32:15,609 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:32:12.680318+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:32:21,231 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:32:12.680318+00:00', try_number=1, map_index=-1)
2026-02-28 17:32:21,240 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:32:12.680318+00:00, map_index=-1, run_start_date=2026-02-28 09:32:19.832775+00:00, run_end_date=2026-02-28 09:32:20.294215+00:00, run_duration=0.46144, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=696, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 09:32:15.603823+00:00, queued_by_job_id=576, pid=23448
2026-02-28 17:32:25,019 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:32:12.680318+00:00 [scheduled]>
2026-02-28 17:32:25,020 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:32:25,022 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:32:12.680318+00:00 [scheduled]>
2026-02-28 17:32:25,025 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:32:12.680318+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:32:25,026 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:32:12.680318+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:32:25,027 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:32:12.680318+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:32:25,030 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:32:12.680318+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:32:30,542 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:32:12.680318+00:00', try_number=1, map_index=-1)
2026-02-28 17:32:30,555 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:32:12.680318+00:00, map_index=-1, run_start_date=2026-02-28 09:32:29.287967+00:00, run_end_date=2026-02-28 09:32:29.619830+00:00, run_duration=0.331863, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=697, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:32:25.024153+00:00, queued_by_job_id=576, pid=23451
2026-02-28 17:32:38,555 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 09:32:12.680318+00:00: manual__2026-02-28T09:32:12.680318+00:00, state:running, queued_at: 2026-02-28 09:32:12.701383+00:00. externally triggered: True> failed
2026-02-28 17:32:38,557 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 09:32:12.680318+00:00, run_id=manual__2026-02-28T09:32:12.680318+00:00, run_start_date=2026-02-28 09:32:15.573364+00:00, run_end_date=2026-02-28 09:32:38.556812+00:00, run_duration=22.983448, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:32:12.680318+00:00, data_interval_end=2026-02-28 09:32:12.680318+00:00, dag_hash=c38e4d01d8794edab9c26738273f0d92
2026-02-28 17:33:47,360 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>
2026-02-28 17:33:47,361 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:33:47,362 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>
2026-02-28 17:33:47,364 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:33:47,366 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:33:42.309925+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 17:33:47,367 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:33:42.309925+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:33:47,369 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:33:42.309925+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:33:52,849 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:33:42.309925+00:00', try_number=1, map_index=-1)
2026-02-28 17:33:52,859 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:33:42.309925+00:00, map_index=-1, run_start_date=2026-02-28 09:33:51.691699+00:00, run_end_date=2026-02-28 09:33:52.058240+00:00, run_duration=0.366541, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=698, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 09:33:47.363334+00:00, queued_by_job_id=576, pid=23515
2026-02-28 17:33:56,884 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>
2026-02-28 17:33:56,885 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:33:56,886 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>
2026-02-28 17:33:56,888 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:33:56,890 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:33:42.309925+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:33:56,891 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:33:42.309925+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:33:56,893 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:33:42.309925+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:34:01,799 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:33:42.309925+00:00', try_number=1, map_index=-1)
2026-02-28 17:34:01,810 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:33:42.309925+00:00, map_index=-1, run_start_date=2026-02-28 09:34:00.779157+00:00, run_end_date=2026-02-28 09:34:00.993468+00:00, run_duration=0.214311, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=699, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:33:56.887251+00:00, queued_by_job_id=576, pid=23523
2026-02-28 17:34:04,452 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>
2026-02-28 17:34:04,453 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:34:04,454 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>
2026-02-28 17:34:04,456 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:33:42.309925+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:34:04,457 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:33:42.309925+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:34:04,458 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:33:42.309925+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:34:04,461 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:33:42.309925+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:34:09,626 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:33:42.309925+00:00', try_number=1, map_index=-1)
2026-02-28 17:34:09,636 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:33:42.309925+00:00, map_index=-1, run_start_date=2026-02-28 09:34:08.584450+00:00, run_end_date=2026-02-28 09:34:08.838856+00:00, run_duration=0.254406, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=700, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:34:04.455343+00:00, queued_by_job_id=576, pid=23526
2026-02-28 17:34:15,934 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 09:33:42.309925+00:00: manual__2026-02-28T09:33:42.309925+00:00, state:running, queued_at: 2026-02-28 09:33:42.318917+00:00. externally triggered: True> successful
2026-02-28 17:34:15,935 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 09:33:42.309925+00:00, run_id=manual__2026-02-28T09:33:42.309925+00:00, run_start_date=2026-02-28 09:33:47.332806+00:00, run_end_date=2026-02-28 09:34:15.935097+00:00, run_duration=28.602291, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:33:42.309925+00:00, data_interval_end=2026-02-28 09:33:42.309925+00:00, dag_hash=c38e4d01d8794edab9c26738273f0d92
2026-02-28 17:34:55,130 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:39:57,921 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:45:00,427 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:48:25,031 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:48:16.098450+00:00 [scheduled]>
2026-02-28 17:48:25,032 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:48:25,034 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:48:16.098450+00:00 [scheduled]>
2026-02-28 17:48:25,037 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:48:16.098450+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:48:25,038 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:48:16.098450+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:48:25,039 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:48:16.098450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:48:25,042 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:48:16.098450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:48:30,638 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:48:16.098450+00:00', try_number=1, map_index=-1)
2026-02-28 17:48:30,649 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:48:16.098450+00:00, map_index=-1, run_start_date=2026-02-28 09:48:29.604905+00:00, run_end_date=2026-02-28 09:48:29.834235+00:00, run_duration=0.22933, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=701, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:48:25.035590+00:00, queued_by_job_id=576, pid=24055
2026-02-28 17:48:34,618 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:48:16.098450+00:00 [scheduled]>
2026-02-28 17:48:34,619 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:48:34,620 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:48:16.098450+00:00 [scheduled]>
2026-02-28 17:48:34,622 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:48:16.098450+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:48:34,623 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:48:16.098450+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:48:34,624 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:48:16.098450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:48:34,626 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:48:16.098450+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:48:56,870 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:48:16.098450+00:00', try_number=1, map_index=-1)
2026-02-28 17:48:56,883 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:48:16.098450+00:00, map_index=-1, run_start_date=2026-02-28 09:48:38.875179+00:00, run_end_date=2026-02-28 09:48:56.153821+00:00, run_duration=17.278642, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=702, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:48:34.621263+00:00, queued_by_job_id=576, pid=24063
2026-02-28 17:49:04,397 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 09:48:16.098450+00:00: manual__2026-02-28T09:48:16.098450+00:00, state:running, queued_at: 2026-02-28 09:48:16.114653+00:00. externally triggered: True> successful
2026-02-28 17:49:04,398 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 09:48:16.098450+00:00, run_id=manual__2026-02-28T09:48:16.098450+00:00, run_start_date=2026-02-28 09:48:21.753609+00:00, run_end_date=2026-02-28 09:49:04.398531+00:00, run_duration=42.644922, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:48:16.098450+00:00, data_interval_end=2026-02-28 09:48:16.098450+00:00, dag_hash=f6d86e3ad2a752a337ab85c41f8dd4d3
2026-02-28 17:50:03,442 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:51:01,100 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:50:53.900992+00:00 [scheduled]>
2026-02-28 17:51:01,101 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:51:01,102 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:50:53.900992+00:00 [scheduled]>
2026-02-28 17:51:01,104 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:50:53.900992+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:51:01,105 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:50:53.900992+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:51:01,106 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:50:53.900992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:51:01,108 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:50:53.900992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:51:06,445 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:50:53.900992+00:00', try_number=1, map_index=-1)
2026-02-28 17:51:06,458 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:50:53.900992+00:00, map_index=-1, run_start_date=2026-02-28 09:51:05.478601+00:00, run_end_date=2026-02-28 09:51:05.685540+00:00, run_duration=0.206939, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=703, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:51:01.103087+00:00, queued_by_job_id=576, pid=24170
2026-02-28 17:51:09,162 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T09:50:53.900992+00:00 [scheduled]>
2026-02-28 17:51:09,163 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 17:51:09,164 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T09:50:53.900992+00:00 [scheduled]>
2026-02-28 17:51:09,167 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T09:50:53.900992+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:51:09,168 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:50:53.900992+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:51:09,169 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:50:53.900992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:51:09,171 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T09:50:53.900992+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 17:51:27,234 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T09:50:53.900992+00:00', try_number=1, map_index=-1)
2026-02-28 17:51:27,251 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T09:50:53.900992+00:00, map_index=-1, run_start_date=2026-02-28 09:51:13.083057+00:00, run_end_date=2026-02-28 09:51:26.396228+00:00, run_duration=13.313171, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=704, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:51:09.165816+00:00, queued_by_job_id=576, pid=24173
2026-02-28 17:51:38,008 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 09:50:53.900992+00:00: manual__2026-02-28T09:50:53.900992+00:00, state:running, queued_at: 2026-02-28 09:50:53.916687+00:00. externally triggered: True> successful
2026-02-28 17:51:38,009 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 09:50:53.900992+00:00, run_id=manual__2026-02-28T09:50:53.900992+00:00, run_start_date=2026-02-28 09:50:57.273084+00:00, run_end_date=2026-02-28 09:51:38.009390+00:00, run_duration=40.736306, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:50:53.900992+00:00, data_interval_end=2026-02-28 09:50:53.900992+00:00, dag_hash=f6d86e3ad2a752a337ab85c41f8dd4d3
2026-02-28 17:55:05,244 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 17:59:32,884 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>
2026-02-28 17:59:32,885 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:59:32,886 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>
2026-02-28 17:59:32,889 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:59:32,892 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:59:30.071893+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 17:59:32,893 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:59:30.071893+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 17:59:32,895 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:59:30.071893+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 17:59:39,189 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:59:30.071893+00:00', try_number=1, map_index=-1)
2026-02-28 17:59:39,202 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:59:30.071893+00:00, map_index=-1, run_start_date=2026-02-28 09:59:38.067153+00:00, run_end_date=2026-02-28 09:59:38.484926+00:00, run_duration=0.417773, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=705, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 09:59:32.887734+00:00, queued_by_job_id=576, pid=24584
2026-02-28 17:59:42,962 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>
2026-02-28 17:59:42,963 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:59:42,964 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>
2026-02-28 17:59:42,967 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:59:42,970 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:59:30.071893+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 17:59:42,971 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:59:30.071893+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 17:59:42,974 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:59:30.071893+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 17:59:48,554 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:59:30.071893+00:00', try_number=1, map_index=-1)
2026-02-28 17:59:48,567 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:59:30.071893+00:00, map_index=-1, run_start_date=2026-02-28 09:59:47.517321+00:00, run_end_date=2026-02-28 09:59:47.735359+00:00, run_duration=0.218038, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=706, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 09:59:42.966378+00:00, queued_by_job_id=576, pid=24590
2026-02-28 17:59:52,715 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>
2026-02-28 17:59:52,715 INFO - DAG cdrd__ has 0/16 running and queued tasks
2026-02-28 17:59:52,717 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>
2026-02-28 17:59:52,720 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd__. manual__2026-02-28T09:59:30.071893+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 17:59:52,721 INFO - Sending TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:59:30.071893+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 17:59:52,722 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:59:30.071893+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 17:59:52,724 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd__', '', 'manual__2026-02-28T09:59:30.071893+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 17:59:57,857 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd__', task_id='', run_id='manual__2026-02-28T09:59:30.071893+00:00', try_number=1, map_index=-1)
2026-02-28 17:59:57,865 INFO - TaskInstance Finished: dag_id=cdrd__, task_id=, run_id=manual__2026-02-28T09:59:30.071893+00:00, map_index=-1, run_start_date=2026-02-28 09:59:56.868887+00:00, run_end_date=2026-02-28 09:59:57.115665+00:00, run_duration=0.246778, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=707, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 09:59:52.718635+00:00, queued_by_job_id=576, pid=24593
2026-02-28 18:00:04,449 INFO - Marking run <DagRun cdrd__ @ 2026-02-28 09:59:30.071893+00:00: manual__2026-02-28T09:59:30.071893+00:00, state:running, queued_at: 2026-02-28 09:59:30.098244+00:00. externally triggered: True> successful
2026-02-28 18:00:04,450 INFO - DagRun Finished: dag_id=cdrd__, execution_date=2026-02-28 09:59:30.071893+00:00, run_id=manual__2026-02-28T09:59:30.071893+00:00, run_start_date=2026-02-28 09:59:32.853401+00:00, run_end_date=2026-02-28 10:00:04.450751+00:00, run_duration=31.59735, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 09:59:30.071893+00:00, data_interval_end=2026-02-28 09:59:30.071893+00:00, dag_hash=06f8fc68913b0048439e7c0b91f01ab6
2026-02-28 18:00:07,822 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 18:01:54,195 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>
2026-02-28 18:01:54,196 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 18:01:54,197 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>
2026-02-28 18:01:54,200 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 18:01:54,201 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T10:01:49.122791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 18:01:54,202 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T10:01:49.122791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 18:01:54,205 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T10:01:49.122791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 18:01:59,844 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T10:01:49.122791+00:00', try_number=1, map_index=-1)
2026-02-28 18:01:59,853 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T10:01:49.122791+00:00, map_index=-1, run_start_date=2026-02-28 10:01:58.766043+00:00, run_end_date=2026-02-28 10:01:59.061425+00:00, run_duration=0.295382, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=708, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 10:01:54.199440+00:00, queued_by_job_id=576, pid=24678
2026-02-28 18:02:02,728 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>
2026-02-28 18:02:02,729 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 18:02:02,730 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>
2026-02-28 18:02:02,733 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 18:02:02,734 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T10:01:49.122791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 18:02:02,735 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T10:01:49.122791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 18:02:02,738 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T10:01:49.122791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 18:02:07,834 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T10:01:49.122791+00:00', try_number=1, map_index=-1)
2026-02-28 18:02:07,844 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T10:01:49.122791+00:00, map_index=-1, run_start_date=2026-02-28 10:02:06.831555+00:00, run_end_date=2026-02-28 10:02:07.038279+00:00, run_duration=0.206724, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=709, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 10:02:02.731392+00:00, queued_by_job_id=576, pid=24688
2026-02-28 18:02:11,123 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>
2026-02-28 18:02:11,124 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 18:02:11,125 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>
2026-02-28 18:02:11,127 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T10:01:49.122791+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 18:02:11,129 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T10:01:49.122791+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 18:02:11,129 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T10:01:49.122791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 18:02:11,132 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T10:01:49.122791+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 18:02:25,986 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T10:01:49.122791+00:00', try_number=1, map_index=-1)
2026-02-28 18:02:25,998 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T10:01:49.122791+00:00, map_index=-1, run_start_date=2026-02-28 10:02:15.178774+00:00, run_end_date=2026-02-28 10:02:25.097921+00:00, run_duration=9.919147, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=710, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 10:02:11.126512+00:00, queued_by_job_id=576, pid=24693
2026-02-28 18:02:33,555 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 10:01:49.122791+00:00: manual__2026-02-28T10:01:49.122791+00:00, state:running, queued_at: 2026-02-28 10:01:49.151790+00:00. externally triggered: True> successful
2026-02-28 18:02:33,556 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 10:01:49.122791+00:00, run_id=manual__2026-02-28T10:01:49.122791+00:00, run_start_date=2026-02-28 10:01:54.163882+00:00, run_end_date=2026-02-28 10:02:33.556132+00:00, run_duration=39.39225, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 10:01:49.122791+00:00, data_interval_end=2026-02-28 10:01:49.122791+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 18:05:09,797 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 18:05:52,528 INFO - Exiting gracefully upon receiving signal 15
2026-02-28 18:05:53,552 INFO - Sending Signals.SIGTERM to group 861. PIDs of all processes in the group: [861]
2026-02-28 18:05:53,553 INFO - Sending the signal Signals.SIGTERM to group 861
2026-02-28 18:05:53,647 ERROR - Exception when executing SchedulerJob._run_scheduler_loop
Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/utils/process_utils.py", line 88, in signal_procs
    os.killpg(process_group_id, sig)
PermissionError: [Errno 1] Operation not permitted

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 999, in _execute
    self._run_scheduler_loop()
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 1134, in _run_scheduler_loop
    self.processor_agent.wait_until_finished()
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 208, in wait_until_finished
    while self._parent_signal_conn.poll(timeout=None):
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/multiprocessing/connection.py", line 262, in poll
    return self._poll(timeout)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/multiprocessing/connection.py", line 429, in _poll
    r = wait([self], timeout)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/multiprocessing/connection.py", line 936, in wait
    ready = selector.select(timeout)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/jobs/scheduler_job_runner.py", line 274, in _exit_gracefully
    self.processor_agent.end()
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/dag_processing/manager.py", line 335, in end
    reap_process_group(self._process.pid, logger=self.log)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/utils/process_utils.py", line 139, in reap_process_group
    signal_procs(sig)
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/site-packages/airflow/utils/process_utils.py", line 93, in signal_procs
    subprocess.check_call(
  File "/Users/linghuchong/miniconda3/envs/py310/lib/python3.10/subprocess.py", line 369, in check_call
    raise CalledProcessError(retcode, cmd)
subprocess.CalledProcessError: Command '['sudo', '-n', 'kill', '-15', '861']' returned non-zero exit status 1.
2026-02-28 18:05:53,666 INFO - Sending Signals.SIGTERM to group 861. PIDs of all processes in the group: []
2026-02-28 18:05:53,667 INFO - Sending the signal Signals.SIGTERM to group 861
2026-02-28 18:05:53,668 INFO - Sending the signal Signals.SIGTERM to process 861 as process group is missing.
2026-02-28 18:05:53,668 INFO - Exited execute loop
2026-02-28 19:46:50,619 INFO - Loaded executor: SequentialExecutor
2026-02-28 19:46:51,329 INFO - Starting the scheduler
2026-02-28 19:46:51,330 INFO - Processing each file at most -1 times
2026-02-28 19:46:51,337 INFO - Launched DagFileProcessorManager with pid: 989
2026-02-28 19:46:51,341 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 19:51:53,720 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 19:56:55,996 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 19:57:24,430 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>
2026-02-28 19:57:24,431 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 19:57:24,432 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>
2026-02-28 19:57:24,435 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 19:57:24,436 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:57:21.042366+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 19:57:24,436 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:57:21.042366+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:57:24,439 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:57:21.042366+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:57:29,348 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:57:21.042366+00:00', try_number=1, map_index=-1)
2026-02-28 19:57:29,363 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T11:57:21.042366+00:00, map_index=-1, run_start_date=2026-02-28 11:57:28.315512+00:00, run_end_date=2026-02-28 11:57:28.600877+00:00, run_duration=0.285365, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=712, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 11:57:24.433674+00:00, queued_by_job_id=711, pid=1684
2026-02-28 19:57:32,670 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>
2026-02-28 19:57:32,671 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 19:57:32,671 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>
2026-02-28 19:57:32,674 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 19:57:32,675 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:57:21.042366+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 19:57:32,676 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:57:21.042366+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:57:32,678 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:57:21.042366+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:57:37,556 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:57:21.042366+00:00', try_number=1, map_index=-1)
2026-02-28 19:57:37,566 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T11:57:21.042366+00:00, map_index=-1, run_start_date=2026-02-28 11:57:36.660407+00:00, run_end_date=2026-02-28 11:57:36.856883+00:00, run_duration=0.196476, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=713, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 11:57:32.672809+00:00, queued_by_job_id=711, pid=1688
2026-02-28 19:57:40,871 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>
2026-02-28 19:57:40,872 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 19:57:40,874 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>
2026-02-28 19:57:40,876 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T11:57:21.042366+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 19:57:40,877 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:57:21.042366+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 19:57:40,878 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:57:21.042366+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:57:40,880 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:57:21.042366+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:57:55,475 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:57:21.042366+00:00', try_number=1, map_index=-1)
2026-02-28 19:57:55,486 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T11:57:21.042366+00:00, map_index=-1, run_start_date=2026-02-28 11:57:44.588839+00:00, run_end_date=2026-02-28 11:57:54.840891+00:00, run_duration=10.252052, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=714, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 11:57:40.875289+00:00, queued_by_job_id=711, pid=1691
2026-02-28 19:58:01,286 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 11:57:21.042366+00:00: manual__2026-02-28T11:57:21.042366+00:00, state:running, queued_at: 2026-02-28 11:57:21.058336+00:00. externally triggered: True> successful
2026-02-28 19:58:01,288 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 11:57:21.042366+00:00, run_id=manual__2026-02-28T11:57:21.042366+00:00, run_start_date=2026-02-28 11:57:24.391284+00:00, run_end_date=2026-02-28 11:58:01.288346+00:00, run_duration=36.897062, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 11:57:21.042366+00:00, data_interval_end=2026-02-28 11:57:21.042366+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 19:59:26,323 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>
2026-02-28 19:59:26,324 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 19:59:26,325 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>
2026-02-28 19:59:26,327 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 19:59:26,329 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:59:25.624982+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 19:59:26,329 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:59:25.624982+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:59:26,332 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:59:25.624982+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:59:31,157 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:59:25.624982+00:00', try_number=1, map_index=-1)
2026-02-28 19:59:31,167 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T11:59:25.624982+00:00, map_index=-1, run_start_date=2026-02-28 11:59:30.201053+00:00, run_end_date=2026-02-28 11:59:30.454579+00:00, run_duration=0.253526, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=715, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 11:59:26.326447+00:00, queued_by_job_id=711, pid=1784
2026-02-28 19:59:33,788 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>
2026-02-28 19:59:33,789 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 19:59:33,790 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>
2026-02-28 19:59:33,792 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 19:59:33,793 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:59:25.624982+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 19:59:33,794 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:59:25.624982+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:59:33,797 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:59:25.624982+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:59:38,340 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:59:25.624982+00:00', try_number=1, map_index=-1)
2026-02-28 19:59:38,352 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T11:59:25.624982+00:00, map_index=-1, run_start_date=2026-02-28 11:59:37.451401+00:00, run_end_date=2026-02-28 11:59:37.634513+00:00, run_duration=0.183112, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=716, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 11:59:33.791381+00:00, queued_by_job_id=711, pid=1788
2026-02-28 19:59:40,921 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>
2026-02-28 19:59:40,922 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 19:59:40,923 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>
2026-02-28 19:59:40,925 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T11:59:25.624982+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 19:59:40,927 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:59:25.624982+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 19:59:40,927 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:59:25.624982+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 19:59:40,930 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T11:59:25.624982+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:00:05,630 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T11:59:25.624982+00:00', try_number=1, map_index=-1)
2026-02-28 20:00:05,640 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T11:59:25.624982+00:00, map_index=-1, run_start_date=2026-02-28 11:59:44.455093+00:00, run_end_date=2026-02-28 12:00:04.982781+00:00, run_duration=20.527688, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=717, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 11:59:40.924531+00:00, queued_by_job_id=711, pid=1791
2026-02-28 20:00:13,428 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 11:59:25.624982+00:00: manual__2026-02-28T11:59:25.624982+00:00, state:running, queued_at: 2026-02-28 11:59:25.634815+00:00. externally triggered: True> successful
2026-02-28 20:00:13,429 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 11:59:25.624982+00:00, run_id=manual__2026-02-28T11:59:25.624982+00:00, run_start_date=2026-02-28 11:59:26.299318+00:00, run_end_date=2026-02-28 12:00:13.429639+00:00, run_duration=47.130321, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 11:59:25.624982+00:00, data_interval_end=2026-02-28 11:59:25.624982+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:00:34,223 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>
2026-02-28 20:00:34,224 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:00:34,225 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>
2026-02-28 20:00:34,227 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:00:34,228 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:00:33.254984+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:00:34,229 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:00:33.254984+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:00:34,231 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:00:33.254984+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:00:38,820 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:00:33.254984+00:00', try_number=1, map_index=-1)
2026-02-28 20:00:38,830 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:00:33.254984+00:00, map_index=-1, run_start_date=2026-02-28 12:00:37.838604+00:00, run_end_date=2026-02-28 12:00:38.095092+00:00, run_duration=0.256488, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=718, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:00:34.226646+00:00, queued_by_job_id=711, pid=1841
2026-02-28 20:00:41,381 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>
2026-02-28 20:00:41,382 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:00:41,383 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>
2026-02-28 20:00:41,385 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:00:41,386 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:00:33.254984+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:00:41,387 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:00:33.254984+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:00:41,389 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:00:33.254984+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:00:45,886 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:00:33.254984+00:00', try_number=1, map_index=-1)
2026-02-28 20:00:45,897 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:00:33.254984+00:00, map_index=-1, run_start_date=2026-02-28 12:00:44.974908+00:00, run_end_date=2026-02-28 12:00:45.163440+00:00, run_duration=0.188532, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=719, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:00:41.384511+00:00, queued_by_job_id=711, pid=1845
2026-02-28 20:00:48,354 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>
2026-02-28 20:00:48,355 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:00:48,356 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>
2026-02-28 20:00:48,358 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:00:33.254984+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:00:48,359 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:00:33.254984+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:00:48,360 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:00:33.254984+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:00:48,362 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:00:33.254984+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:01:03,624 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:00:33.254984+00:00', try_number=1, map_index=-1)
2026-02-28 20:01:03,642 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:00:33.254984+00:00, map_index=-1, run_start_date=2026-02-28 12:00:52.134768+00:00, run_end_date=2026-02-28 12:01:02.939923+00:00, run_duration=10.805155, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=720, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:00:48.357078+00:00, queued_by_job_id=711, pid=1848
2026-02-28 20:01:12,689 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:00:33.254984+00:00: manual__2026-02-28T12:00:33.254984+00:00, state:running, queued_at: 2026-02-28 12:00:33.265060+00:00. externally triggered: True> successful
2026-02-28 20:01:12,690 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:00:33.254984+00:00, run_id=manual__2026-02-28T12:00:33.254984+00:00, run_start_date=2026-02-28 12:00:34.198894+00:00, run_end_date=2026-02-28 12:01:12.690530+00:00, run_duration=38.491636, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:00:33.254984+00:00, data_interval_end=2026-02-28 12:00:33.254984+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:01:57,818 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:02:10,409 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>
2026-02-28 20:02:10,410 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:02:10,411 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>
2026-02-28 20:02:10,413 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:02:10,414 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:02:07.380290+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:02:10,415 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:02:07.380290+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:02:10,417 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:02:07.380290+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:02:15,295 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:02:07.380290+00:00', try_number=1, map_index=-1)
2026-02-28 20:02:15,306 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:02:07.380290+00:00, map_index=-1, run_start_date=2026-02-28 12:02:14.290753+00:00, run_end_date=2026-02-28 12:02:14.565236+00:00, run_duration=0.274483, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=721, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:02:10.412279+00:00, queued_by_job_id=711, pid=1938
2026-02-28 20:02:17,586 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>
2026-02-28 20:02:17,587 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:02:17,588 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>
2026-02-28 20:02:17,590 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:02:17,591 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:02:07.380290+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:02:17,592 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:02:07.380290+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:02:17,594 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:02:07.380290+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:02:22,182 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:02:07.380290+00:00', try_number=1, map_index=-1)
2026-02-28 20:02:22,192 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:02:07.380290+00:00, map_index=-1, run_start_date=2026-02-28 12:02:21.246265+00:00, run_end_date=2026-02-28 12:02:21.439216+00:00, run_duration=0.192951, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=722, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:02:17.589424+00:00, queued_by_job_id=711, pid=1942
2026-02-28 20:02:24,629 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>
2026-02-28 20:02:24,630 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:02:24,630 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>
2026-02-28 20:02:24,633 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:02:07.380290+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:02:24,634 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:02:07.380290+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:02:24,635 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:02:07.380290+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:02:24,637 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:02:07.380290+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:02:39,930 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:02:07.380290+00:00', try_number=1, map_index=-1)
2026-02-28 20:02:39,942 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:02:07.380290+00:00, map_index=-1, run_start_date=2026-02-28 12:02:28.506760+00:00, run_end_date=2026-02-28 12:02:39.251100+00:00, run_duration=10.74434, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=723, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:02:24.632213+00:00, queued_by_job_id=711, pid=1945
2026-02-28 20:02:46,797 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:02:07.380290+00:00: manual__2026-02-28T12:02:07.380290+00:00, state:running, queued_at: 2026-02-28 12:02:07.393945+00:00. externally triggered: True> successful
2026-02-28 20:02:46,798 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:02:07.380290+00:00, run_id=manual__2026-02-28T12:02:07.380290+00:00, run_start_date=2026-02-28 12:02:10.386028+00:00, run_end_date=2026-02-28 12:02:46.798714+00:00, run_duration=36.412686, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:02:07.380290+00:00, data_interval_end=2026-02-28 12:02:07.380290+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:03:07,026 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>
2026-02-28 20:03:07,027 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:03:07,028 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>
2026-02-28 20:03:07,030 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:03:07,031 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:03:04.413475+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:03:07,032 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:03:04.413475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:03:07,034 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:03:04.413475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:03:11,683 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:03:04.413475+00:00', try_number=1, map_index=-1)
2026-02-28 20:03:11,694 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:03:04.413475+00:00, map_index=-1, run_start_date=2026-02-28 12:03:10.635223+00:00, run_end_date=2026-02-28 12:03:10.928126+00:00, run_duration=0.292903, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=724, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:03:07.029308+00:00, queued_by_job_id=711, pid=2014
2026-02-28 20:03:14,971 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>
2026-02-28 20:03:14,972 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:03:14,973 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>
2026-02-28 20:03:14,975 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:03:14,976 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:03:04.413475+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:03:14,977 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:03:04.413475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:03:14,979 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:03:04.413475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:03:19,632 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:03:04.413475+00:00', try_number=1, map_index=-1)
2026-02-28 20:03:19,642 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:03:04.413475+00:00, map_index=-1, run_start_date=2026-02-28 12:03:18.712333+00:00, run_end_date=2026-02-28 12:03:18.902905+00:00, run_duration=0.190572, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=725, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:03:14.974116+00:00, queued_by_job_id=711, pid=2017
2026-02-28 20:03:22,925 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>
2026-02-28 20:03:22,926 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:03:22,927 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>
2026-02-28 20:03:22,930 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:03:04.413475+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:03:22,931 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:03:04.413475+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:03:22,932 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:03:04.413475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:03:22,934 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:03:04.413475+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:03:37,627 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:03:04.413475+00:00', try_number=1, map_index=-1)
2026-02-28 20:03:37,640 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:03:04.413475+00:00, map_index=-1, run_start_date=2026-02-28 12:03:26.639400+00:00, run_end_date=2026-02-28 12:03:37.001772+00:00, run_duration=10.362372, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=726, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:03:22.928872+00:00, queued_by_job_id=711, pid=2020
2026-02-28 20:03:44,889 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:03:04.413475+00:00: manual__2026-02-28T12:03:04.413475+00:00, state:running, queued_at: 2026-02-28 12:03:04.425371+00:00. externally triggered: True> successful
2026-02-28 20:03:44,890 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:03:04.413475+00:00, run_id=manual__2026-02-28T12:03:04.413475+00:00, run_start_date=2026-02-28 12:03:07.001896+00:00, run_end_date=2026-02-28 12:03:44.890764+00:00, run_duration=37.888868, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:03:04.413475+00:00, data_interval_end=2026-02-28 12:03:04.413475+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:04:27,067 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>
2026-02-28 20:04:27,068 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:04:27,069 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>
2026-02-28 20:04:27,071 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:04:27,072 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:04:25.979216+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:04:27,073 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:04:25.979216+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:04:27,076 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:04:25.979216+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:04:31,744 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:04:25.979216+00:00', try_number=1, map_index=-1)
2026-02-28 20:04:31,754 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:04:25.979216+00:00, map_index=-1, run_start_date=2026-02-28 12:04:30.790550+00:00, run_end_date=2026-02-28 12:04:31.051961+00:00, run_duration=0.261411, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=727, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:04:27.070748+00:00, queued_by_job_id=711, pid=2092
2026-02-28 20:04:34,145 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>
2026-02-28 20:04:34,146 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:04:34,147 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>
2026-02-28 20:04:34,149 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:04:34,150 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:04:25.979216+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:04:34,151 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:04:25.979216+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:04:34,154 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:04:25.979216+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:04:38,647 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:04:25.979216+00:00', try_number=1, map_index=-1)
2026-02-28 20:04:38,659 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:04:25.979216+00:00, map_index=-1, run_start_date=2026-02-28 12:04:37.679618+00:00, run_end_date=2026-02-28 12:04:37.882889+00:00, run_duration=0.203271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=728, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:04:34.148379+00:00, queued_by_job_id=711, pid=2096
2026-02-28 20:04:41,177 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>
2026-02-28 20:04:41,178 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:04:41,179 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>
2026-02-28 20:04:41,182 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:04:25.979216+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:04:41,183 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:04:25.979216+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:04:41,184 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:04:25.979216+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:04:41,186 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:04:25.979216+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:05:06,373 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:04:25.979216+00:00', try_number=1, map_index=-1)
2026-02-28 20:05:06,384 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:04:25.979216+00:00, map_index=-1, run_start_date=2026-02-28 12:04:44.773224+00:00, run_end_date=2026-02-28 12:05:05.682854+00:00, run_duration=20.90963, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=729, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:04:41.180909+00:00, queued_by_job_id=711, pid=2099
2026-02-28 20:05:29,340 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>
2026-02-28 20:05:29,341 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:05:29,342 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>
2026-02-28 20:05:29,344 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:05:29,346 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:05:28.425196+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:05:29,349 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:05:28.425196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:05:29,352 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:05:28.425196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:05:33,918 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:05:28.425196+00:00', try_number=1, map_index=-1)
2026-02-28 20:05:33,929 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:05:28.425196+00:00, map_index=-1, run_start_date=2026-02-28 12:05:32.958199+00:00, run_end_date=2026-02-28 12:05:33.223976+00:00, run_duration=0.265777, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=712, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:05:29.343350+00:00, queued_by_job_id=711, pid=2150
2026-02-28 20:05:36,462 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>
2026-02-28 20:05:36,462 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:05:36,463 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>
2026-02-28 20:05:36,466 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:05:36,467 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:05:28.425196+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:05:36,468 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:05:28.425196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:05:36,470 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:05:28.425196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:05:40,879 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:05:28.425196+00:00', try_number=1, map_index=-1)
2026-02-28 20:05:40,890 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:05:28.425196+00:00, map_index=-1, run_start_date=2026-02-28 12:05:40.000553+00:00, run_end_date=2026-02-28 12:05:40.181296+00:00, run_duration=0.180743, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=713, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:05:36.465483+00:00, queued_by_job_id=711, pid=2154
2026-02-28 20:05:43,530 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>
2026-02-28 20:05:43,531 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:05:43,532 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>
2026-02-28 20:05:43,534 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:05:28.425196+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:05:43,536 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:05:28.425196+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:05:43,536 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:05:28.425196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:05:43,539 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:05:28.425196+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:05:58,061 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:05:28.425196+00:00', try_number=1, map_index=-1)
2026-02-28 20:05:58,075 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:05:28.425196+00:00, map_index=-1, run_start_date=2026-02-28 12:05:47.106922+00:00, run_end_date=2026-02-28 12:05:57.321623+00:00, run_duration=10.214701, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=714, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:05:43.533419+00:00, queued_by_job_id=711, pid=2157
2026-02-28 20:06:04,781 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:05:28.425196+00:00: manual__2026-02-28T12:05:28.425196+00:00, state:running, queued_at: 2026-02-28 12:05:28.444511+00:00. externally triggered: True> successful
2026-02-28 20:06:04,783 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:05:28.425196+00:00, run_id=manual__2026-02-28T12:05:28.425196+00:00, run_start_date=2026-02-28 12:05:29.316335+00:00, run_end_date=2026-02-28 12:06:04.783062+00:00, run_duration=35.466727, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:05:28.425196+00:00, data_interval_end=2026-02-28 12:05:28.425196+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:07:00,991 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:07:12,842 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>
2026-02-28 20:07:12,843 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:07:12,844 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>
2026-02-28 20:07:12,846 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:07:12,847 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:07:11.294617+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:07:12,848 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:07:11.294617+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:07:12,851 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:07:11.294617+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:07:17,593 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:07:11.294617+00:00', try_number=1, map_index=-1)
2026-02-28 20:07:17,604 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:07:11.294617+00:00, map_index=-1, run_start_date=2026-02-28 12:07:16.612754+00:00, run_end_date=2026-02-28 12:07:16.874212+00:00, run_duration=0.261458, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=715, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:07:12.845560+00:00, queued_by_job_id=711, pid=2245
2026-02-28 20:07:20,314 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>
2026-02-28 20:07:20,315 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:07:20,316 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>
2026-02-28 20:07:20,318 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:07:20,319 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:07:11.294617+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:07:20,320 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:07:11.294617+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:07:20,322 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:07:11.294617+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:07:24,844 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:07:11.294617+00:00', try_number=1, map_index=-1)
2026-02-28 20:07:24,856 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:07:11.294617+00:00, map_index=-1, run_start_date=2026-02-28 12:07:23.865052+00:00, run_end_date=2026-02-28 12:07:24.060841+00:00, run_duration=0.195789, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=716, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:07:20.317561+00:00, queued_by_job_id=711, pid=2249
2026-02-28 20:07:27,398 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>
2026-02-28 20:07:27,399 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:07:27,400 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>
2026-02-28 20:07:27,403 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:07:11.294617+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:07:27,404 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:07:11.294617+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:07:27,405 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:07:11.294617+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:07:27,407 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:07:11.294617+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:07:39,707 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:07:11.294617+00:00', try_number=1, map_index=-1)
2026-02-28 20:07:39,720 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:07:11.294617+00:00, map_index=-1, run_start_date=2026-02-28 12:07:31.050822+00:00, run_end_date=2026-02-28 12:07:38.987971+00:00, run_duration=7.937149, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=717, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:07:27.402021+00:00, queued_by_job_id=711, pid=2254
2026-02-28 20:07:45,961 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:07:11.294617+00:00: manual__2026-02-28T12:07:11.294617+00:00, state:running, queued_at: 2026-02-28 12:07:11.308031+00:00. externally triggered: True> successful
2026-02-28 20:07:45,962 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:07:11.294617+00:00, run_id=manual__2026-02-28T12:07:11.294617+00:00, run_start_date=2026-02-28 12:07:12.817837+00:00, run_end_date=2026-02-28 12:07:45.962529+00:00, run_duration=33.144692, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:07:11.294617+00:00, data_interval_end=2026-02-28 12:07:11.294617+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:12:01,131 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:17:04,371 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:22:05,485 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:27:07,737 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:32:08,881 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:34:17,256 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>
2026-02-28 20:34:17,257 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:34:17,258 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>
2026-02-28 20:34:17,260 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:34:17,261 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:34:16.630760+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:34:17,262 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:34:16.630760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:34:17,271 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:34:16.630760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:34:22,406 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:34:16.630760+00:00', try_number=1, map_index=-1)
2026-02-28 20:34:22,416 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:34:16.630760+00:00, map_index=-1, run_start_date=2026-02-28 12:34:21.437819+00:00, run_end_date=2026-02-28 12:34:21.710425+00:00, run_duration=0.272606, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=718, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:34:17.259085+00:00, queued_by_job_id=711, pid=3187
2026-02-28 20:34:24,937 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>
2026-02-28 20:34:24,937 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:34:24,938 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>
2026-02-28 20:34:24,940 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:34:24,941 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:34:16.630760+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:34:24,942 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:34:16.630760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:34:24,945 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:34:16.630760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:34:29,531 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:34:16.630760+00:00', try_number=1, map_index=-1)
2026-02-28 20:34:29,542 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:34:16.630760+00:00, map_index=-1, run_start_date=2026-02-28 12:34:28.675196+00:00, run_end_date=2026-02-28 12:34:28.860002+00:00, run_duration=0.184806, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=719, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:34:24.939606+00:00, queued_by_job_id=711, pid=3191
2026-02-28 20:34:32,004 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>
2026-02-28 20:34:32,005 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:34:32,005 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>
2026-02-28 20:34:32,008 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:34:16.630760+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:34:32,009 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:34:16.630760+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:34:32,010 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:34:16.630760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:34:32,012 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:34:16.630760+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:35:01,820 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:34:16.630760+00:00', try_number=1, map_index=-1)
2026-02-28 20:35:01,834 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:34:16.630760+00:00, map_index=-1, run_start_date=2026-02-28 12:34:35.756846+00:00, run_end_date=2026-02-28 12:35:01.062188+00:00, run_duration=25.305342, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=720, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:34:32.007008+00:00, queued_by_job_id=711, pid=3194
2026-02-28 20:35:01,855 INFO - Heartbeat recovered after 32.29 seconds
2026-02-28 20:35:09,998 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:34:16.630760+00:00: manual__2026-02-28T12:34:16.630760+00:00, state:running, queued_at: 2026-02-28 12:34:16.641030+00:00. externally triggered: True> successful
2026-02-28 20:35:09,999 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:34:16.630760+00:00, run_id=manual__2026-02-28T12:34:16.630760+00:00, run_start_date=2026-02-28 12:34:17.225254+00:00, run_end_date=2026-02-28 12:35:09.999667+00:00, run_duration=52.774413, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:34:16.630760+00:00, data_interval_end=2026-02-28 12:34:16.630760+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:37:09,712 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:38:29,881 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>
2026-02-28 20:38:29,882 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:38:29,884 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>
2026-02-28 20:38:29,886 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:38:29,887 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:38:26.976266+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:38:29,888 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:38:26.976266+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:38:29,890 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:38:26.976266+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:38:34,723 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:38:26.976266+00:00', try_number=1, map_index=-1)
2026-02-28 20:38:34,734 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:38:26.976266+00:00, map_index=-1, run_start_date=2026-02-28 12:38:33.768495+00:00, run_end_date=2026-02-28 12:38:34.050022+00:00, run_duration=0.281527, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=712, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:38:29.885523+00:00, queued_by_job_id=711, pid=3357
2026-02-28 20:38:37,108 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>
2026-02-28 20:38:37,109 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:38:37,109 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>
2026-02-28 20:38:37,111 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:38:37,112 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:38:26.976266+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:38:37,113 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:38:26.976266+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:38:37,116 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:38:26.976266+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:38:41,813 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:38:26.976266+00:00', try_number=1, map_index=-1)
2026-02-28 20:38:41,825 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:38:26.976266+00:00, map_index=-1, run_start_date=2026-02-28 12:38:40.813973+00:00, run_end_date=2026-02-28 12:38:41.020666+00:00, run_duration=0.206693, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=713, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:38:37.110854+00:00, queued_by_job_id=711, pid=3361
2026-02-28 20:38:45,006 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>
2026-02-28 20:38:45,007 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:38:45,008 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>
2026-02-28 20:38:45,010 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:38:26.976266+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:38:45,011 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:38:26.976266+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:38:45,012 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:38:26.976266+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:38:45,014 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:38:26.976266+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:39:02,223 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:38:26.976266+00:00', try_number=1, map_index=-1)
2026-02-28 20:39:02,238 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:38:26.976266+00:00, map_index=-1, run_start_date=2026-02-28 12:38:48.819539+00:00, run_end_date=2026-02-28 12:39:01.520985+00:00, run_duration=12.701446, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=714, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:38:45.009437+00:00, queued_by_job_id=711, pid=3365
2026-02-28 20:41:46,449 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>
2026-02-28 20:41:46,451 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:41:46,452 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>
2026-02-28 20:41:46,454 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:41:46,454 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:41:44.969822+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:41:46,455 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:41:44.969822+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:41:46,458 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:41:44.969822+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:41:51,035 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:41:44.969822+00:00', try_number=1, map_index=-1)
2026-02-28 20:41:51,046 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:41:44.969822+00:00, map_index=-1, run_start_date=2026-02-28 12:41:50.066383+00:00, run_end_date=2026-02-28 12:41:50.345813+00:00, run_duration=0.27943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=712, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:41:46.453008+00:00, queued_by_job_id=711, pid=3514
2026-02-28 20:41:54,392 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>
2026-02-28 20:41:54,393 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:41:54,393 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>
2026-02-28 20:41:54,395 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:41:54,396 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:41:44.969822+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:41:54,397 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:41:44.969822+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:41:54,400 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:41:44.969822+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:41:59,037 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:41:44.969822+00:00', try_number=1, map_index=-1)
2026-02-28 20:41:59,048 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:41:44.969822+00:00, map_index=-1, run_start_date=2026-02-28 12:41:58.115988+00:00, run_end_date=2026-02-28 12:41:58.310928+00:00, run_duration=0.19494, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=713, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:41:54.394680+00:00, queued_by_job_id=711, pid=3518
2026-02-28 20:42:01,484 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>
2026-02-28 20:42:01,485 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:42:01,486 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>
2026-02-28 20:42:01,488 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:41:44.969822+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:42:01,489 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:41:44.969822+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:42:01,490 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:41:44.969822+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:42:01,492 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:41:44.969822+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:42:14,061 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:41:44.969822+00:00', try_number=1, map_index=-1)
2026-02-28 20:42:14,074 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:41:44.969822+00:00, map_index=-1, run_start_date=2026-02-28 12:42:05.117607+00:00, run_end_date=2026-02-28 12:42:13.307078+00:00, run_duration=8.189471, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=714, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:42:01.487522+00:00, queued_by_job_id=711, pid=3524
2026-02-28 20:42:14,106 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:42:20,524 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:41:44.969822+00:00: manual__2026-02-28T12:41:44.969822+00:00, state:running, queued_at: 2026-02-28 12:41:44.989810+00:00. externally triggered: True> successful
2026-02-28 20:42:20,525 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:41:44.969822+00:00, run_id=manual__2026-02-28T12:41:44.969822+00:00, run_start_date=2026-02-28 12:41:46.424523+00:00, run_end_date=2026-02-28 12:42:20.525833+00:00, run_duration=34.10131, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:41:44.969822+00:00, data_interval_end=2026-02-28 12:41:44.969822+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:43:57,303 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>
2026-02-28 20:43:57,304 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:43:57,305 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>
2026-02-28 20:43:57,307 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:43:57,309 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:43:54.229530+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:43:57,309 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:43:54.229530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:43:57,312 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:43:54.229530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:44:02,327 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:43:54.229530+00:00', try_number=1, map_index=-1)
2026-02-28 20:44:02,337 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:43:54.229530+00:00, map_index=-1, run_start_date=2026-02-28 12:44:01.310440+00:00, run_end_date=2026-02-28 12:44:01.596404+00:00, run_duration=0.285964, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=715, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:43:57.306493+00:00, queued_by_job_id=711, pid=3631
2026-02-28 20:44:04,807 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>
2026-02-28 20:44:04,808 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:44:04,809 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>
2026-02-28 20:44:04,811 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:44:04,813 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:43:54.229530+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:44:04,814 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:43:54.229530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:44:04,816 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:43:54.229530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:44:09,422 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:43:54.229530+00:00', try_number=1, map_index=-1)
2026-02-28 20:44:09,434 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:43:54.229530+00:00, map_index=-1, run_start_date=2026-02-28 12:44:08.520003+00:00, run_end_date=2026-02-28 12:44:08.708821+00:00, run_duration=0.188818, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=716, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:44:04.810216+00:00, queued_by_job_id=711, pid=3635
2026-02-28 20:44:13,031 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>
2026-02-28 20:44:13,032 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:44:13,033 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>
2026-02-28 20:44:13,036 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:43:54.229530+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:44:13,037 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:43:54.229530+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:44:13,037 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:43:54.229530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:44:13,040 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:43:54.229530+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:44:28,369 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:43:54.229530+00:00', try_number=1, map_index=-1)
2026-02-28 20:44:28,379 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:43:54.229530+00:00, map_index=-1, run_start_date=2026-02-28 12:44:16.689008+00:00, run_end_date=2026-02-28 12:44:27.664345+00:00, run_duration=10.975337, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=717, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:44:13.034747+00:00, queued_by_job_id=711, pid=3638
2026-02-28 20:44:35,546 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:43:54.229530+00:00: manual__2026-02-28T12:43:54.229530+00:00, state:running, queued_at: 2026-02-28 12:43:54.241622+00:00. externally triggered: True> successful
2026-02-28 20:44:35,547 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:43:54.229530+00:00, run_id=manual__2026-02-28T12:43:54.229530+00:00, run_start_date=2026-02-28 12:43:57.280761+00:00, run_end_date=2026-02-28 12:44:35.547570+00:00, run_duration=38.266809, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:43:54.229530+00:00, data_interval_end=2026-02-28 12:43:54.229530+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:47:15,192 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:49:44,871 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>
2026-02-28 20:49:44,872 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:49:44,872 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>
2026-02-28 20:49:44,875 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:49:44,876 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:49:43.498646+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:49:44,877 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:49:43.498646+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:49:44,879 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:49:43.498646+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:49:49,519 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:49:43.498646+00:00', try_number=1, map_index=-1)
2026-02-28 20:49:49,530 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:49:43.498646+00:00, map_index=-1, run_start_date=2026-02-28 12:49:48.563897+00:00, run_end_date=2026-02-28 12:49:48.826635+00:00, run_duration=0.262738, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=718, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:49:44.873998+00:00, queued_by_job_id=711, pid=3884
2026-02-28 20:49:52,133 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>
2026-02-28 20:49:52,134 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:49:52,135 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>
2026-02-28 20:49:52,137 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:49:52,138 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:49:43.498646+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:49:52,139 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:49:43.498646+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:49:52,141 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:49:43.498646+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:49:56,692 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:49:43.498646+00:00', try_number=1, map_index=-1)
2026-02-28 20:49:56,703 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:49:43.498646+00:00, map_index=-1, run_start_date=2026-02-28 12:49:55.708679+00:00, run_end_date=2026-02-28 12:49:55.905137+00:00, run_duration=0.196458, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=719, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:49:52.136349+00:00, queued_by_job_id=711, pid=3888
2026-02-28 20:49:59,283 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>
2026-02-28 20:49:59,284 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:49:59,285 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>
2026-02-28 20:49:59,287 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:49:43.498646+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:49:59,288 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:49:43.498646+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:49:59,289 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:49:43.498646+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:49:59,291 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:49:43.498646+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:50:16,343 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:49:43.498646+00:00', try_number=1, map_index=-1)
2026-02-28 20:50:16,356 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:49:43.498646+00:00, map_index=-1, run_start_date=2026-02-28 12:50:03.026148+00:00, run_end_date=2026-02-28 12:50:15.624763+00:00, run_duration=12.598615, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=720, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:49:59.285960+00:00, queued_by_job_id=711, pid=3894
2026-02-28 20:50:23,881 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:49:43.498646+00:00: manual__2026-02-28T12:49:43.498646+00:00, state:running, queued_at: 2026-02-28 12:49:43.507851+00:00. externally triggered: True> successful
2026-02-28 20:50:23,882 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:49:43.498646+00:00, run_id=manual__2026-02-28T12:49:43.498646+00:00, run_start_date=2026-02-28 12:49:44.846207+00:00, run_end_date=2026-02-28 12:50:23.882372+00:00, run_duration=39.036165, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:49:43.498646+00:00, data_interval_end=2026-02-28 12:49:43.498646+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:52:16,880 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>
2026-02-28 20:52:16,881 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:52:16,882 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>
2026-02-28 20:52:16,884 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:52:16,885 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:52:14.037710+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:52:16,886 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:52:14.037710+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:52:16,888 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:52:14.037710+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:52:21,617 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:52:14.037710+00:00', try_number=1, map_index=-1)
2026-02-28 20:52:21,628 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:52:14.037710+00:00, map_index=-1, run_start_date=2026-02-28 12:52:20.602302+00:00, run_end_date=2026-02-28 12:52:20.887455+00:00, run_duration=0.285153, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=721, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:52:16.883306+00:00, queued_by_job_id=711, pid=4022
2026-02-28 20:52:21,658 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:52:24,075 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>
2026-02-28 20:52:24,076 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:52:24,077 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>
2026-02-28 20:52:24,079 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:52:24,080 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:52:14.037710+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:52:24,080 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:52:14.037710+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:52:24,083 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:52:14.037710+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:52:28,761 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:52:14.037710+00:00', try_number=1, map_index=-1)
2026-02-28 20:52:28,772 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:52:14.037710+00:00, map_index=-1, run_start_date=2026-02-28 12:52:27.784394+00:00, run_end_date=2026-02-28 12:52:27.981275+00:00, run_duration=0.196881, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=722, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:52:24.078178+00:00, queued_by_job_id=711, pid=4026
2026-02-28 20:52:31,114 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>
2026-02-28 20:52:31,115 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:52:31,116 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>
2026-02-28 20:52:31,118 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:52:14.037710+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:52:31,119 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:52:14.037710+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:52:31,120 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:52:14.037710+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:52:31,122 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:52:14.037710+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:52:43,362 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:52:14.037710+00:00', try_number=1, map_index=-1)
2026-02-28 20:52:43,375 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:52:14.037710+00:00, map_index=-1, run_start_date=2026-02-28 12:52:34.917399+00:00, run_end_date=2026-02-28 12:52:42.574917+00:00, run_duration=7.657518, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=723, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:52:31.117144+00:00, queued_by_job_id=711, pid=4029
2026-02-28 20:52:50,030 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:52:14.037710+00:00: manual__2026-02-28T12:52:14.037710+00:00, state:running, queued_at: 2026-02-28 12:52:14.050725+00:00. externally triggered: True> successful
2026-02-28 20:52:50,031 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:52:14.037710+00:00, run_id=manual__2026-02-28T12:52:14.037710+00:00, run_start_date=2026-02-28 12:52:16.855347+00:00, run_end_date=2026-02-28 12:52:50.031293+00:00, run_duration=33.175946, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:52:14.037710+00:00, data_interval_end=2026-02-28 12:52:14.037710+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:56:39,282 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>
2026-02-28 20:56:39,283 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:56:39,284 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>
2026-02-28 20:56:39,286 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:56:39,287 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:56:35.929125+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:56:39,288 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:56:35.929125+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:56:39,290 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:56:35.929125+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:56:44,474 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:56:35.929125+00:00', try_number=1, map_index=-1)
2026-02-28 20:56:44,484 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:56:35.929125+00:00, map_index=-1, run_start_date=2026-02-28 12:56:43.430600+00:00, run_end_date=2026-02-28 12:56:43.715088+00:00, run_duration=0.284488, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=724, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:56:39.285509+00:00, queued_by_job_id=711, pid=4230
2026-02-28 20:56:46,982 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>
2026-02-28 20:56:46,983 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:56:46,983 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>
2026-02-28 20:56:46,985 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:56:46,986 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:56:35.929125+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:56:46,987 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:56:35.929125+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:56:46,989 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:56:35.929125+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:56:51,630 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:56:35.929125+00:00', try_number=1, map_index=-1)
2026-02-28 20:56:51,639 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:56:35.929125+00:00, map_index=-1, run_start_date=2026-02-28 12:56:50.728724+00:00, run_end_date=2026-02-28 12:56:50.910828+00:00, run_duration=0.182104, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=725, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:56:46.984546+00:00, queued_by_job_id=711, pid=4234
2026-02-28 20:56:54,239 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>
2026-02-28 20:56:54,240 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:56:54,241 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>
2026-02-28 20:56:54,243 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:56:35.929125+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:56:54,244 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:56:35.929125+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:56:54,245 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:56:35.929125+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:56:54,247 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:56:35.929125+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:57:06,669 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:56:35.929125+00:00', try_number=1, map_index=-1)
2026-02-28 20:57:06,679 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:56:35.929125+00:00, map_index=-1, run_start_date=2026-02-28 12:56:58.167105+00:00, run_end_date=2026-02-28 12:57:05.933294+00:00, run_duration=7.766189, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=726, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:56:54.242084+00:00, queued_by_job_id=711, pid=4237
2026-02-28 20:57:14,188 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:56:35.929125+00:00: manual__2026-02-28T12:56:35.929125+00:00, state:running, queued_at: 2026-02-28 12:56:35.941304+00:00. externally triggered: True> successful
2026-02-28 20:57:14,189 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:56:35.929125+00:00, run_id=manual__2026-02-28T12:56:35.929125+00:00, run_start_date=2026-02-28 12:56:39.260343+00:00, run_end_date=2026-02-28 12:57:14.189394+00:00, run_duration=34.929051, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:56:35.929125+00:00, data_interval_end=2026-02-28 12:56:35.929125+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 20:57:22,492 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 20:59:28,213 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>
2026-02-28 20:59:28,214 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:59:28,214 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>
2026-02-28 20:59:28,217 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:59:28,218 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:59:25.462755+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 20:59:28,218 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:59:25.462755+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:59:28,221 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:59:25.462755+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:59:33,046 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:59:25.462755+00:00', try_number=1, map_index=-1)
2026-02-28 20:59:33,055 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:59:25.462755+00:00, map_index=-1, run_start_date=2026-02-28 12:59:31.990090+00:00, run_end_date=2026-02-28 12:59:32.277110+00:00, run_duration=0.28702, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=727, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 12:59:28.216145+00:00, queued_by_job_id=711, pid=4374
2026-02-28 20:59:36,342 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>
2026-02-28 20:59:36,343 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:59:36,344 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>
2026-02-28 20:59:36,346 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:59:36,347 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:59:25.462755+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 20:59:36,348 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:59:25.462755+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:59:36,350 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:59:25.462755+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:59:40,937 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:59:25.462755+00:00', try_number=1, map_index=-1)
2026-02-28 20:59:40,946 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:59:25.462755+00:00, map_index=-1, run_start_date=2026-02-28 12:59:40.060495+00:00, run_end_date=2026-02-28 12:59:40.245834+00:00, run_duration=0.185339, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=728, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 12:59:36.345115+00:00, queued_by_job_id=711, pid=4378
2026-02-28 20:59:44,089 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>
2026-02-28 20:59:44,090 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 20:59:44,091 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>
2026-02-28 20:59:44,093 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T12:59:25.462755+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 20:59:44,094 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:59:25.462755+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 20:59:44,095 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:59:25.462755+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:59:44,098 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T12:59:25.462755+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 20:59:56,277 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T12:59:25.462755+00:00', try_number=1, map_index=-1)
2026-02-28 20:59:56,289 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T12:59:25.462755+00:00, map_index=-1, run_start_date=2026-02-28 12:59:47.868078+00:00, run_end_date=2026-02-28 12:59:55.593217+00:00, run_duration=7.725139, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=729, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 12:59:44.092327+00:00, queued_by_job_id=711, pid=4446
2026-02-28 21:00:04,295 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 12:59:25.462755+00:00: manual__2026-02-28T12:59:25.462755+00:00, state:running, queued_at: 2026-02-28 12:59:25.470587+00:00. externally triggered: True> successful
2026-02-28 21:00:04,296 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 12:59:25.462755+00:00, run_id=manual__2026-02-28T12:59:25.462755+00:00, run_start_date=2026-02-28 12:59:28.188230+00:00, run_end_date=2026-02-28 13:00:04.296861+00:00, run_duration=36.108631, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 12:59:25.462755+00:00, data_interval_end=2026-02-28 12:59:25.462755+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 21:02:22,893 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:04:29,680 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>
2026-02-28 21:04:29,681 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:04:29,682 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>
2026-02-28 21:04:29,684 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:04:29,685 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:04:27.659484+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:04:29,685 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:04:27.659484+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:04:29,688 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:04:27.659484+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:04:34,478 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:04:27.659484+00:00', try_number=1, map_index=-1)
2026-02-28 21:04:34,488 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:04:27.659484+00:00, map_index=-1, run_start_date=2026-02-28 13:04:33.488446+00:00, run_end_date=2026-02-28 13:04:33.747530+00:00, run_duration=0.259084, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=730, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:04:29.682976+00:00, queued_by_job_id=711, pid=4642
2026-02-28 21:04:36,958 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>
2026-02-28 21:04:36,959 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:04:36,960 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>
2026-02-28 21:04:36,962 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:04:36,963 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:04:27.659484+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:04:36,964 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:04:27.659484+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:04:36,966 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:04:27.659484+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:04:41,425 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:04:27.659484+00:00', try_number=1, map_index=-1)
2026-02-28 21:04:41,436 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:04:27.659484+00:00, map_index=-1, run_start_date=2026-02-28 13:04:40.537057+00:00, run_end_date=2026-02-28 13:04:40.749328+00:00, run_duration=0.212271, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=731, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:04:36.961484+00:00, queued_by_job_id=711, pid=4646
2026-02-28 21:04:43,728 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>
2026-02-28 21:04:43,729 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:04:43,730 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>
2026-02-28 21:04:43,732 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:04:27.659484+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:04:43,733 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:04:27.659484+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:04:43,734 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:04:27.659484+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:04:43,736 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:04:27.659484+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:04:59,046 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:04:27.659484+00:00', try_number=1, map_index=-1)
2026-02-28 21:04:59,057 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:04:27.659484+00:00, map_index=-1, run_start_date=2026-02-28 13:04:47.345465+00:00, run_end_date=2026-02-28 13:04:58.385383+00:00, run_duration=11.039918, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=732, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:04:43.731302+00:00, queued_by_job_id=711, pid=4649
2026-02-28 21:05:06,910 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 13:04:27.659484+00:00: manual__2026-02-28T13:04:27.659484+00:00, state:running, queued_at: 2026-02-28 13:04:27.676595+00:00. externally triggered: True> successful
2026-02-28 21:05:06,911 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 13:04:27.659484+00:00, run_id=manual__2026-02-28T13:04:27.659484+00:00, run_start_date=2026-02-28 13:04:29.655836+00:00, run_end_date=2026-02-28 13:05:06.911534+00:00, run_duration=37.255698, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:04:27.659484+00:00, data_interval_end=2026-02-28 13:04:27.659484+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 21:07:10,502 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>
2026-02-28 21:07:10,502 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:07:10,503 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>
2026-02-28 21:07:10,505 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:07:10,506 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:07:07.491102+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:07:10,507 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:07:07.491102+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:07:10,509 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:07:07.491102+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:07:15,270 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:07:07.491102+00:00', try_number=1, map_index=-1)
2026-02-28 21:07:15,280 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:07:07.491102+00:00, map_index=-1, run_start_date=2026-02-28 13:07:14.220983+00:00, run_end_date=2026-02-28 13:07:14.503984+00:00, run_duration=0.283001, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=733, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:07:10.504660+00:00, queued_by_job_id=711, pid=4764
2026-02-28 21:07:17,631 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>
2026-02-28 21:07:17,632 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:07:17,633 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>
2026-02-28 21:07:17,636 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:07:17,637 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:07:07.491102+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:07:17,638 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:07:07.491102+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:07:17,640 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:07:07.491102+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:07:22,331 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:07:07.491102+00:00', try_number=1, map_index=-1)
2026-02-28 21:07:22,340 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:07:07.491102+00:00, map_index=-1, run_start_date=2026-02-28 13:07:21.343179+00:00, run_end_date=2026-02-28 13:07:21.539052+00:00, run_duration=0.195873, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=734, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:07:17.635008+00:00, queued_by_job_id=711, pid=4768
2026-02-28 21:07:24,659 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>
2026-02-28 21:07:24,660 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:07:24,660 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>
2026-02-28 21:07:24,663 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:07:07.491102+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:07:24,664 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:07:07.491102+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:07:24,664 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:07:07.491102+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:07:24,667 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:07:07.491102+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:07:38,774 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:07:07.491102+00:00', try_number=1, map_index=-1)
2026-02-28 21:07:38,784 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:07:07.491102+00:00, map_index=-1, run_start_date=2026-02-28 13:07:28.421895+00:00, run_end_date=2026-02-28 13:07:38.081093+00:00, run_duration=9.659198, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=735, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:07:24.661778+00:00, queued_by_job_id=711, pid=4773
2026-02-28 21:07:38,805 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:07:46,356 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 13:07:07.491102+00:00: manual__2026-02-28T13:07:07.491102+00:00, state:running, queued_at: 2026-02-28 13:07:07.502625+00:00. externally triggered: True> successful
2026-02-28 21:07:46,357 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 13:07:07.491102+00:00, run_id=manual__2026-02-28T13:07:07.491102+00:00, run_start_date=2026-02-28 13:07:10.478914+00:00, run_end_date=2026-02-28 13:07:46.357840+00:00, run_duration=35.878926, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:07:07.491102+00:00, data_interval_end=2026-02-28 13:07:07.491102+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 21:08:15,811 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>
2026-02-28 21:08:15,812 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:08:15,813 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>
2026-02-28 21:08:15,816 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:08:15,817 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:08:12.672214+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:08:15,817 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:08:12.672214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:08:15,820 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:08:12.672214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:08:20,423 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:08:12.672214+00:00', try_number=1, map_index=-1)
2026-02-28 21:08:20,432 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:08:12.672214+00:00, map_index=-1, run_start_date=2026-02-28 13:08:19.387044+00:00, run_end_date=2026-02-28 13:08:19.666152+00:00, run_duration=0.279108, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=736, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:08:15.815017+00:00, queued_by_job_id=711, pid=4845
2026-02-28 21:08:22,912 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>
2026-02-28 21:08:22,913 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:08:22,914 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>
2026-02-28 21:08:22,916 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:08:22,917 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:08:12.672214+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:08:22,918 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:08:12.672214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:08:22,920 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:08:12.672214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:08:27,628 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:08:12.672214+00:00', try_number=1, map_index=-1)
2026-02-28 21:08:27,637 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:08:12.672214+00:00, map_index=-1, run_start_date=2026-02-28 13:08:26.684076+00:00, run_end_date=2026-02-28 13:08:26.899359+00:00, run_duration=0.215283, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=737, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:08:22.915586+00:00, queued_by_job_id=711, pid=4849
2026-02-28 21:08:30,104 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>
2026-02-28 21:08:30,105 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:08:30,106 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>
2026-02-28 21:08:30,108 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:08:12.672214+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:08:30,109 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:08:12.672214+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:08:30,109 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:08:12.672214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:08:30,111 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:08:12.672214+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:08:42,750 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:08:12.672214+00:00', try_number=1, map_index=-1)
2026-02-28 21:08:42,759 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:08:12.672214+00:00, map_index=-1, run_start_date=2026-02-28 13:08:33.905245+00:00, run_end_date=2026-02-28 13:08:42.073610+00:00, run_duration=8.168365, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=738, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:08:30.107132+00:00, queued_by_job_id=711, pid=4852
2026-02-28 21:08:52,317 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 13:08:12.672214+00:00: manual__2026-02-28T13:08:12.672214+00:00, state:running, queued_at: 2026-02-28 13:08:12.684548+00:00. externally triggered: True> successful
2026-02-28 21:08:52,318 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 13:08:12.672214+00:00, run_id=manual__2026-02-28T13:08:12.672214+00:00, run_start_date=2026-02-28 13:08:15.788661+00:00, run_end_date=2026-02-28 13:08:52.318790+00:00, run_duration=36.530129, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:08:12.672214+00:00, data_interval_end=2026-02-28 13:08:12.672214+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 21:10:29,907 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>
2026-02-28 21:10:29,908 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:10:29,909 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>
2026-02-28 21:10:29,911 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:10:29,912 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:10:26.640602+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:10:29,913 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:10:26.640602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:10:29,915 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:10:26.640602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:10:34,682 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:10:26.640602+00:00', try_number=1, map_index=-1)
2026-02-28 21:10:34,692 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:10:26.640602+00:00, map_index=-1, run_start_date=2026-02-28 13:10:33.641266+00:00, run_end_date=2026-02-28 13:10:33.921724+00:00, run_duration=0.280458, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=739, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:10:29.910177+00:00, queued_by_job_id=711, pid=4957
2026-02-28 21:10:37,025 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>
2026-02-28 21:10:37,026 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:10:37,027 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>
2026-02-28 21:10:37,030 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:10:37,031 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:10:26.640602+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:10:37,031 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:10:26.640602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:10:37,034 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:10:26.640602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:10:41,729 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:10:26.640602+00:00', try_number=1, map_index=-1)
2026-02-28 21:10:41,740 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:10:26.640602+00:00, map_index=-1, run_start_date=2026-02-28 13:10:40.760734+00:00, run_end_date=2026-02-28 13:10:40.961072+00:00, run_duration=0.200338, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=740, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:10:37.028594+00:00, queued_by_job_id=711, pid=4962
2026-02-28 21:10:44,165 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>
2026-02-28 21:10:44,166 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:10:44,167 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>
2026-02-28 21:10:44,169 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:10:26.640602+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:10:44,170 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:10:26.640602+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:10:44,171 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:10:26.640602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:10:44,173 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:10:26.640602+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:10:57,405 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:10:26.640602+00:00', try_number=1, map_index=-1)
2026-02-28 21:10:57,416 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:10:26.640602+00:00, map_index=-1, run_start_date=2026-02-28 13:10:48.004687+00:00, run_end_date=2026-02-28 13:10:56.711102+00:00, run_duration=8.706415, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=741, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:10:44.168088+00:00, queued_by_job_id=711, pid=4967
2026-02-28 21:11:04,346 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 13:10:26.640602+00:00: manual__2026-02-28T13:10:26.640602+00:00, state:running, queued_at: 2026-02-28 13:10:26.653395+00:00. externally triggered: True> successful
2026-02-28 21:11:04,347 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 13:10:26.640602+00:00, run_id=manual__2026-02-28T13:10:26.640602+00:00, run_start_date=2026-02-28 13:10:29.881725+00:00, run_end_date=2026-02-28 13:11:04.347764+00:00, run_duration=34.466039, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:10:26.640602+00:00, data_interval_end=2026-02-28 13:10:26.640602+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 21:12:39,233 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:14:51,913 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>
2026-02-28 21:14:51,914 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:14:51,914 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>
2026-02-28 21:14:51,916 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:14:51,917 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:14:49.556128+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:14:51,918 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:14:49.556128+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:14:51,920 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:14:49.556128+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:14:57,283 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:14:49.556128+00:00', try_number=1, map_index=-1)
2026-02-28 21:14:57,292 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:14:49.556128+00:00, map_index=-1, run_start_date=2026-02-28 13:14:56.282262+00:00, run_end_date=2026-02-28 13:14:56.561916+00:00, run_duration=0.279654, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=742, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:14:51.915756+00:00, queued_by_job_id=711, pid=5125
2026-02-28 21:14:59,686 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>
2026-02-28 21:14:59,687 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:14:59,688 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>
2026-02-28 21:14:59,690 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:14:59,690 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:14:49.556128+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:14:59,691 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:14:49.556128+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:14:59,694 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:14:49.556128+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:15:04,410 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:14:49.556128+00:00', try_number=1, map_index=-1)
2026-02-28 21:15:04,419 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:14:49.556128+00:00, map_index=-1, run_start_date=2026-02-28 13:15:03.438979+00:00, run_end_date=2026-02-28 13:15:03.636143+00:00, run_duration=0.197164, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=743, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:14:59.689012+00:00, queued_by_job_id=711, pid=5132
2026-02-28 21:15:06,717 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>
2026-02-28 21:15:06,718 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:15:06,718 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>
2026-02-28 21:15:06,720 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:14:49.556128+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:15:06,721 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:14:49.556128+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:15:06,722 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:14:49.556128+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:15:06,724 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:14:49.556128+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:15:18,935 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:14:49.556128+00:00', try_number=1, map_index=-1)
2026-02-28 21:15:18,946 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:14:49.556128+00:00, map_index=-1, run_start_date=2026-02-28 13:15:10.437744+00:00, run_end_date=2026-02-28 13:15:18.066393+00:00, run_duration=7.628649, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=744, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:15:06.719653+00:00, queued_by_job_id=711, pid=5135
2026-02-28 21:15:26,918 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 13:14:49.556128+00:00: manual__2026-02-28T13:14:49.556128+00:00, state:running, queued_at: 2026-02-28 13:14:49.568172+00:00. externally triggered: True> successful
2026-02-28 21:15:26,919 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 13:14:49.556128+00:00, run_id=manual__2026-02-28T13:14:49.556128+00:00, run_start_date=2026-02-28 13:14:51.888048+00:00, run_end_date=2026-02-28 13:15:26.919105+00:00, run_duration=35.031057, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:14:49.556128+00:00, data_interval_end=2026-02-28 13:14:49.556128+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 21:17:39,650 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:19:48,777 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>
2026-02-28 21:19:48,778 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:19:48,778 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>
2026-02-28 21:19:48,780 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:19:48,781 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:19:46.846735+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:19:48,782 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:19:46.846735+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:19:48,785 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:19:46.846735+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:19:53,606 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:19:46.846735+00:00', try_number=1, map_index=-1)
2026-02-28 21:19:53,616 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:19:46.846735+00:00, map_index=-1, run_start_date=2026-02-28 13:19:52.618383+00:00, run_end_date=2026-02-28 13:19:52.879511+00:00, run_duration=0.261128, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=745, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:19:48.779771+00:00, queued_by_job_id=711, pid=5336
2026-02-28 21:19:56,089 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>
2026-02-28 21:19:56,090 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:19:56,091 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>
2026-02-28 21:19:56,093 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:19:56,094 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:19:46.846735+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:19:56,095 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:19:46.846735+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:19:56,097 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:19:46.846735+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:20:00,697 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:19:46.846735+00:00', try_number=1, map_index=-1)
2026-02-28 21:20:00,707 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:19:46.846735+00:00, map_index=-1, run_start_date=2026-02-28 13:19:59.762459+00:00, run_end_date=2026-02-28 13:19:59.958506+00:00, run_duration=0.196047, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=746, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:19:56.092390+00:00, queued_by_job_id=711, pid=5348
2026-02-28 21:20:03,063 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>
2026-02-28 21:20:03,064 INFO - DAG cdrd___ has 0/16 running and queued tasks
2026-02-28 21:20:03,065 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>
2026-02-28 21:20:03,067 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd___. manual__2026-02-28T13:19:46.846735+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:20:03,068 INFO - Sending TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:19:46.846735+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:20:03,069 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:19:46.846735+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:20:03,071 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd___', '', 'manual__2026-02-28T13:19:46.846735+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag___.py']
2026-02-28 21:20:15,468 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd___', task_id='', run_id='manual__2026-02-28T13:19:46.846735+00:00', try_number=1, map_index=-1)
2026-02-28 21:20:15,480 INFO - TaskInstance Finished: dag_id=cdrd___, task_id=, run_id=manual__2026-02-28T13:19:46.846735+00:00, map_index=-1, run_start_date=2026-02-28 13:20:06.863799+00:00, run_end_date=2026-02-28 13:20:14.710628+00:00, run_duration=7.846829, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=747, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:20:03.066551+00:00, queued_by_job_id=711, pid=5356
2026-02-28 21:20:21,480 INFO - Marking run <DagRun cdrd___ @ 2026-02-28 13:19:46.846735+00:00: manual__2026-02-28T13:19:46.846735+00:00, state:running, queued_at: 2026-02-28 13:19:46.857043+00:00. externally triggered: True> successful
2026-02-28 21:20:21,481 INFO - DagRun Finished: dag_id=cdrd___, execution_date=2026-02-28 13:19:46.846735+00:00, run_id=manual__2026-02-28T13:19:46.846735+00:00, run_start_date=2026-02-28 13:19:48.751910+00:00, run_end_date=2026-02-28 13:20:21.481236+00:00, run_duration=32.729326, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:19:46.846735+00:00, data_interval_end=2026-02-28 13:19:46.846735+00:00, dag_hash=45552dbb8c249f80331172f4fa2904d7
2026-02-28 21:22:39,740 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:27:41,332 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:32:41,358 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:36:08,061 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>
2026-02-28 21:36:08,062 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:36:08,062 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>
2026-02-28 21:36:08,064 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:36:08,065 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:36:04.521105+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:36:08,066 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:36:04.521105+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:36:08,069 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:36:04.521105+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:36:13,739 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:36:04.521105+00:00', try_number=1, map_index=-1)
2026-02-28 21:36:13,748 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:36:04.521105+00:00, map_index=-1, run_start_date=2026-02-28 13:36:12.688666+00:00, run_end_date=2026-02-28 13:36:12.988222+00:00, run_duration=0.299556, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=748, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:36:08.063832+00:00, queued_by_job_id=711, pid=6055
2026-02-28 21:36:16,314 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>
2026-02-28 21:36:16,315 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:36:16,316 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>
2026-02-28 21:36:16,319 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:36:16,320 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:36:04.521105+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:36:16,320 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:36:04.521105+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:36:16,323 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:36:04.521105+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:36:20,999 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:36:04.521105+00:00', try_number=1, map_index=-1)
2026-02-28 21:36:21,008 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:36:04.521105+00:00, map_index=-1, run_start_date=2026-02-28 13:36:20.093939+00:00, run_end_date=2026-02-28 13:36:20.281831+00:00, run_duration=0.187892, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=749, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:36:16.317861+00:00, queued_by_job_id=711, pid=6059
2026-02-28 21:36:23,622 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>
2026-02-28 21:36:23,623 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:36:23,624 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>
2026-02-28 21:36:23,627 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:36:04.521105+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:36:23,628 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:36:04.521105+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:36:23,629 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:36:04.521105+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:36:23,632 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:36:04.521105+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:36:41,993 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:36:04.521105+00:00', try_number=1, map_index=-1)
2026-02-28 21:36:42,008 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:36:04.521105+00:00, map_index=-1, run_start_date=2026-02-28 13:36:28.493657+00:00, run_end_date=2026-02-28 13:36:41.250975+00:00, run_duration=12.757318, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=750, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:36:23.625367+00:00, queued_by_job_id=711, pid=6062
2026-02-28 21:36:50,812 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 13:36:04.521105+00:00: manual__2026-02-28T13:36:04.521105+00:00, state:running, queued_at: 2026-02-28 13:36:04.533932+00:00. externally triggered: True> successful
2026-02-28 21:36:50,813 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 13:36:04.521105+00:00, run_id=manual__2026-02-28T13:36:04.521105+00:00, run_start_date=2026-02-28 13:36:08.036949+00:00, run_end_date=2026-02-28 13:36:50.813705+00:00, run_duration=42.776756, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:36:04.521105+00:00, data_interval_end=2026-02-28 13:36:04.521105+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 21:37:44,260 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:38:20,731 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>
2026-02-28 21:38:20,732 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:38:20,733 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>
2026-02-28 21:38:20,735 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:38:20,736 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:38:18.655118+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:38:20,736 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:38:18.655118+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:38:20,739 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:38:18.655118+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:38:25,794 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:38:18.655118+00:00', try_number=1, map_index=-1)
2026-02-28 21:38:25,803 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:38:18.655118+00:00, map_index=-1, run_start_date=2026-02-28 13:38:24.724032+00:00, run_end_date=2026-02-28 13:38:25.012547+00:00, run_duration=0.288515, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=751, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:38:20.734139+00:00, queued_by_job_id=711, pid=6172
2026-02-28 21:38:29,500 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>
2026-02-28 21:38:29,501 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:38:29,502 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>
2026-02-28 21:38:29,504 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:38:29,505 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:38:18.655118+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:38:29,506 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:38:18.655118+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:38:29,508 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:38:18.655118+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:38:34,392 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:38:18.655118+00:00', try_number=1, map_index=-1)
2026-02-28 21:38:34,400 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:38:18.655118+00:00, map_index=-1, run_start_date=2026-02-28 13:38:33.447424+00:00, run_end_date=2026-02-28 13:38:33.640020+00:00, run_duration=0.192596, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=752, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:38:29.503409+00:00, queued_by_job_id=711, pid=6175
2026-02-28 21:38:38,084 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>
2026-02-28 21:38:38,085 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:38:38,086 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>
2026-02-28 21:38:38,088 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:38:18.655118+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:38:38,089 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:38:18.655118+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:38:38,090 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:38:18.655118+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:38:38,092 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:38:18.655118+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:39:03,773 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:38:18.655118+00:00', try_number=1, map_index=-1)
2026-02-28 21:39:03,787 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:38:18.655118+00:00, map_index=-1, run_start_date=2026-02-28 13:38:41.943194+00:00, run_end_date=2026-02-28 13:39:02.923137+00:00, run_duration=20.979943, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=753, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:38:38.087297+00:00, queued_by_job_id=711, pid=6178
2026-02-28 21:39:10,158 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 13:38:18.655118+00:00: manual__2026-02-28T13:38:18.655118+00:00, state:running, queued_at: 2026-02-28 13:38:18.664325+00:00. externally triggered: True> successful
2026-02-28 21:39:10,159 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 13:38:18.655118+00:00, run_id=manual__2026-02-28T13:38:18.655118+00:00, run_start_date=2026-02-28 13:38:20.709294+00:00, run_end_date=2026-02-28 13:39:10.159631+00:00, run_duration=49.450337, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:38:18.655118+00:00, data_interval_end=2026-02-28 13:38:18.655118+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 21:42:49,121 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:43:40,491 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>
2026-02-28 21:43:40,492 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:43:40,492 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>
2026-02-28 21:43:40,494 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:43:40,495 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:43:38.312095+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:43:40,496 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:43:38.312095+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:43:40,498 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:43:38.312095+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:43:45,567 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:43:38.312095+00:00', try_number=1, map_index=-1)
2026-02-28 21:43:45,577 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:43:38.312095+00:00, map_index=-1, run_start_date=2026-02-28 13:43:44.512848+00:00, run_end_date=2026-02-28 13:43:44.809657+00:00, run_duration=0.296809, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=754, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:43:40.493842+00:00, queued_by_job_id=711, pid=6394
2026-02-28 21:43:48,082 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>
2026-02-28 21:43:48,083 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:43:48,083 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>
2026-02-28 21:43:48,086 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:43:48,087 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:43:38.312095+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:43:48,087 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:43:38.312095+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:43:48,090 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:43:38.312095+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:43:52,725 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:43:38.312095+00:00', try_number=1, map_index=-1)
2026-02-28 21:43:52,734 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:43:38.312095+00:00, map_index=-1, run_start_date=2026-02-28 13:43:51.769557+00:00, run_end_date=2026-02-28 13:43:51.964151+00:00, run_duration=0.194594, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=755, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:43:48.085108+00:00, queued_by_job_id=711, pid=6398
2026-02-28 21:43:55,206 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>
2026-02-28 21:43:55,207 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:43:55,208 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>
2026-02-28 21:43:55,210 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:43:38.312095+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:43:55,211 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:43:38.312095+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:43:55,212 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:43:38.312095+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:43:55,215 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:43:38.312095+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:44:10,579 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:43:38.312095+00:00', try_number=1, map_index=-1)
2026-02-28 21:44:10,590 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:43:38.312095+00:00, map_index=-1, run_start_date=2026-02-28 13:43:59.264895+00:00, run_end_date=2026-02-28 13:44:09.772601+00:00, run_duration=10.507706, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=756, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:43:55.209528+00:00, queued_by_job_id=711, pid=6401
2026-02-28 21:44:18,048 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 13:43:38.312095+00:00: manual__2026-02-28T13:43:38.312095+00:00, state:running, queued_at: 2026-02-28 13:43:38.326549+00:00. externally triggered: True> successful
2026-02-28 21:44:18,049 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 13:43:38.312095+00:00, run_id=manual__2026-02-28T13:43:38.312095+00:00, run_start_date=2026-02-28 13:43:40.465746+00:00, run_end_date=2026-02-28 13:44:18.049881+00:00, run_duration=37.584135, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:43:38.312095+00:00, data_interval_end=2026-02-28 13:43:38.312095+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 21:46:28,265 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>
2026-02-28 21:46:28,266 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:46:28,267 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>
2026-02-28 21:46:28,270 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:46:28,271 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:46:27.731416+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:46:28,272 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:46:27.731416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:46:28,274 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:46:27.731416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:46:33,232 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:46:27.731416+00:00', try_number=1, map_index=-1)
2026-02-28 21:46:33,241 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:46:27.731416+00:00, map_index=-1, run_start_date=2026-02-28 13:46:32.279173+00:00, run_end_date=2026-02-28 13:46:32.542706+00:00, run_duration=0.263533, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=757, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:46:28.268692+00:00, queued_by_job_id=711, pid=6535
2026-02-28 21:46:36,692 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>
2026-02-28 21:46:36,693 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:46:36,694 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>
2026-02-28 21:46:36,696 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:46:36,697 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:46:27.731416+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:46:36,698 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:46:27.731416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:46:36,700 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:46:27.731416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:46:41,307 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:46:27.731416+00:00', try_number=1, map_index=-1)
2026-02-28 21:46:41,316 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:46:27.731416+00:00, map_index=-1, run_start_date=2026-02-28 13:46:40.359528+00:00, run_end_date=2026-02-28 13:46:40.559114+00:00, run_duration=0.199586, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=758, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:46:36.695189+00:00, queued_by_job_id=711, pid=6542
2026-02-28 21:46:44,686 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>
2026-02-28 21:46:44,687 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:46:44,687 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>
2026-02-28 21:46:44,689 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:46:27.731416+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:46:44,690 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:46:27.731416+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:46:44,691 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:46:27.731416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:46:44,693 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:46:27.731416+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:46:59,651 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:46:27.731416+00:00', try_number=1, map_index=-1)
2026-02-28 21:46:59,661 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:46:27.731416+00:00, map_index=-1, run_start_date=2026-02-28 13:46:48.510927+00:00, run_end_date=2026-02-28 13:46:58.844139+00:00, run_duration=10.333212, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=759, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:46:44.688691+00:00, queued_by_job_id=711, pid=6546
2026-02-28 21:47:08,199 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 13:46:27.731416+00:00: manual__2026-02-28T13:46:27.731416+00:00, state:running, queued_at: 2026-02-28 13:46:27.752456+00:00. externally triggered: True> successful
2026-02-28 21:47:08,200 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 13:46:27.731416+00:00, run_id=manual__2026-02-28T13:46:27.731416+00:00, run_start_date=2026-02-28 13:46:28.226995+00:00, run_end_date=2026-02-28 13:47:08.200338+00:00, run_duration=39.973343, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:46:27.731416+00:00, data_interval_end=2026-02-28 13:46:27.731416+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 21:47:50,020 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:51:52,921 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>
2026-02-28 21:51:52,921 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:51:52,922 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>
2026-02-28 21:51:52,924 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:51:52,925 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:51:48.241376+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:51:52,926 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:51:48.241376+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:51:52,929 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:51:48.241376+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:51:57,918 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:51:48.241376+00:00', try_number=1, map_index=-1)
2026-02-28 21:51:57,927 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:51:48.241376+00:00, map_index=-1, run_start_date=2026-02-28 13:51:56.907192+00:00, run_end_date=2026-02-28 13:51:57.181354+00:00, run_duration=0.274162, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=760, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:51:52.923600+00:00, queued_by_job_id=711, pid=6790
2026-02-28 21:52:01,149 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>
2026-02-28 21:52:01,150 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:52:01,150 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>
2026-02-28 21:52:01,153 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:52:01,154 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:51:48.241376+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:52:01,155 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:51:48.241376+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:52:01,157 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:51:48.241376+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:52:05,886 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:51:48.241376+00:00', try_number=1, map_index=-1)
2026-02-28 21:52:05,895 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:51:48.241376+00:00, map_index=-1, run_start_date=2026-02-28 13:52:04.934166+00:00, run_end_date=2026-02-28 13:52:05.131129+00:00, run_duration=0.196963, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=761, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:52:01.152030+00:00, queued_by_job_id=711, pid=6797
2026-02-28 21:52:09,321 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>
2026-02-28 21:52:09,322 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:52:09,323 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>
2026-02-28 21:52:09,326 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:51:48.241376+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:52:09,327 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:51:48.241376+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:52:09,327 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:51:48.241376+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:52:09,330 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:51:48.241376+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:52:24,240 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:51:48.241376+00:00', try_number=1, map_index=-1)
2026-02-28 21:52:24,249 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:51:48.241376+00:00, map_index=-1, run_start_date=2026-02-28 13:52:13.234022+00:00, run_end_date=2026-02-28 13:52:23.402013+00:00, run_duration=10.167991, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=762, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:52:09.324931+00:00, queued_by_job_id=711, pid=6800
2026-02-28 21:52:31,540 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 13:51:48.241376+00:00: manual__2026-02-28T13:51:48.241376+00:00, state:running, queued_at: 2026-02-28 13:51:48.251680+00:00. externally triggered: True> successful
2026-02-28 21:52:31,542 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 13:51:48.241376+00:00, run_id=manual__2026-02-28T13:51:48.241376+00:00, run_start_date=2026-02-28 13:51:52.896348+00:00, run_end_date=2026-02-28 13:52:31.541935+00:00, run_duration=38.645587, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:51:48.241376+00:00, data_interval_end=2026-02-28 13:51:48.241376+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 21:52:52,906 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:56:17,410 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>
2026-02-28 21:56:17,411 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:56:17,412 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>
2026-02-28 21:56:17,414 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:56:17,415 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:56:15.921124+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:56:17,416 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:56:15.921124+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:56:17,418 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:56:15.921124+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:56:22,532 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:56:15.921124+00:00', try_number=1, map_index=-1)
2026-02-28 21:56:22,541 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:56:15.921124+00:00, map_index=-1, run_start_date=2026-02-28 13:56:21.551443+00:00, run_end_date=2026-02-28 13:56:21.815122+00:00, run_duration=0.263679, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=763, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:56:17.413120+00:00, queued_by_job_id=711, pid=6987
2026-02-28 21:56:25,246 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>
2026-02-28 21:56:25,247 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:56:25,248 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>
2026-02-28 21:56:25,251 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:56:25,252 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:56:15.921124+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:56:25,252 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:56:15.921124+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:56:25,255 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:56:15.921124+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:56:29,957 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:56:15.921124+00:00', try_number=1, map_index=-1)
2026-02-28 21:56:29,966 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:56:15.921124+00:00, map_index=-1, run_start_date=2026-02-28 13:56:28.955255+00:00, run_end_date=2026-02-28 13:56:29.170023+00:00, run_duration=0.214768, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=764, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:56:25.249816+00:00, queued_by_job_id=711, pid=6991
2026-02-28 21:56:32,470 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>
2026-02-28 21:56:32,471 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:56:32,472 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>
2026-02-28 21:56:32,474 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:56:15.921124+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:56:32,476 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:56:15.921124+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:56:32,476 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:56:15.921124+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:56:32,479 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:56:15.921124+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:56:49,407 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:56:15.921124+00:00', try_number=1, map_index=-1)
2026-02-28 21:56:49,422 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:56:15.921124+00:00, map_index=-1, run_start_date=2026-02-28 13:56:36.495363+00:00, run_end_date=2026-02-28 13:56:48.541324+00:00, run_duration=12.045961, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=765, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:56:32.473603+00:00, queued_by_job_id=711, pid=6996
2026-02-28 21:56:52,946 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 13:56:15.921124+00:00: manual__2026-02-28T13:56:15.921124+00:00, state:running, queued_at: 2026-02-28 13:56:15.935680+00:00. externally triggered: True> failed
2026-02-28 21:56:52,947 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 13:56:15.921124+00:00, run_id=manual__2026-02-28T13:56:15.921124+00:00, run_start_date=2026-02-28 13:56:17.384909+00:00, run_end_date=2026-02-28 13:56:52.947575+00:00, run_duration=35.562666, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:56:15.921124+00:00, data_interval_end=2026-02-28 13:56:15.921124+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 21:57:56,160 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 21:58:05,242 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>
2026-02-28 21:58:05,244 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:58:05,248 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>
2026-02-28 21:58:05,251 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:58:05,252 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:58:04.684635+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 21:58:05,253 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:58:04.684635+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:58:05,257 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:58:04.684635+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:58:10,289 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:58:04.684635+00:00', try_number=1, map_index=-1)
2026-02-28 21:58:10,297 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:58:04.684635+00:00, map_index=-1, run_start_date=2026-02-28 13:58:09.314357+00:00, run_end_date=2026-02-28 13:58:09.585270+00:00, run_duration=0.270913, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=766, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 13:58:05.249955+00:00, queued_by_job_id=711, pid=7084
2026-02-28 21:58:12,882 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>
2026-02-28 21:58:12,882 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:58:12,883 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>
2026-02-28 21:58:12,885 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:58:12,886 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:58:04.684635+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 21:58:12,887 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:58:04.684635+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:58:12,889 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:58:04.684635+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:58:17,421 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:58:04.684635+00:00', try_number=1, map_index=-1)
2026-02-28 21:58:17,431 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:58:04.684635+00:00, map_index=-1, run_start_date=2026-02-28 13:58:16.549785+00:00, run_end_date=2026-02-28 13:58:16.735423+00:00, run_duration=0.185638, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=767, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 13:58:12.884495+00:00, queued_by_job_id=711, pid=7087
2026-02-28 21:58:20,107 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>
2026-02-28 21:58:20,108 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 21:58:20,109 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>
2026-02-28 21:58:20,111 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T13:58:04.684635+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 21:58:20,112 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:58:04.684635+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 21:58:20,112 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:58:04.684635+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:58:20,115 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T13:58:04.684635+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 21:58:34,922 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T13:58:04.684635+00:00', try_number=1, map_index=-1)
2026-02-28 21:58:34,933 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T13:58:04.684635+00:00, map_index=-1, run_start_date=2026-02-28 13:58:24.035613+00:00, run_end_date=2026-02-28 13:58:34.123520+00:00, run_duration=10.087907, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=768, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 13:58:20.110091+00:00, queued_by_job_id=711, pid=7090
2026-02-28 21:58:38,380 ERROR - Marking run <DagRun cdrd_ @ 2026-02-28 13:58:04.684635+00:00: manual__2026-02-28T13:58:04.684635+00:00, state:running, queued_at: 2026-02-28 13:58:04.696389+00:00. externally triggered: True> failed
2026-02-28 21:58:38,381 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 13:58:04.684635+00:00, run_id=manual__2026-02-28T13:58:04.684635+00:00, run_start_date=2026-02-28 13:58:05.212705+00:00, run_end_date=2026-02-28 13:58:38.381184+00:00, run_duration=33.168479, state=failed, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 13:58:04.684635+00:00, data_interval_end=2026-02-28 13:58:04.684635+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 22:00:50,960 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>
2026-02-28 22:00:50,961 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:00:50,961 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>
2026-02-28 22:00:50,964 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:00:50,965 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:00:49.397996+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 22:00:50,965 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:00:49.397996+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:00:50,968 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:00:49.397996+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:00:55,934 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:00:49.397996+00:00', try_number=1, map_index=-1)
2026-02-28 22:00:55,943 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:00:49.397996+00:00, map_index=-1, run_start_date=2026-02-28 14:00:54.971978+00:00, run_end_date=2026-02-28 14:00:55.236792+00:00, run_duration=0.264814, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=769, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 14:00:50.962993+00:00, queued_by_job_id=711, pid=7228
2026-02-28 22:00:58,524 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>
2026-02-28 22:00:58,525 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:00:58,526 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>
2026-02-28 22:00:58,529 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:00:58,530 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:00:49.397996+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 22:00:58,531 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:00:49.397996+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:00:58,533 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:00:49.397996+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:01:03,187 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:00:49.397996+00:00', try_number=1, map_index=-1)
2026-02-28 22:01:03,196 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:00:49.397996+00:00, map_index=-1, run_start_date=2026-02-28 14:01:02.232200+00:00, run_end_date=2026-02-28 14:01:02.430691+00:00, run_duration=0.198491, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=770, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 14:00:58.527798+00:00, queued_by_job_id=711, pid=7235
2026-02-28 22:01:05,705 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>
2026-02-28 22:01:05,706 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:01:05,707 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>
2026-02-28 22:01:05,709 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:00:49.397996+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:01:05,710 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:00:49.397996+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 22:01:05,711 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:00:49.397996+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:01:05,713 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:00:49.397996+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:01:20,444 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:00:49.397996+00:00', try_number=1, map_index=-1)
2026-02-28 22:01:20,457 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:00:49.397996+00:00, map_index=-1, run_start_date=2026-02-28 14:01:09.685288+00:00, run_end_date=2026-02-28 14:01:19.566160+00:00, run_duration=9.880872, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=771, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 14:01:05.708450+00:00, queued_by_job_id=711, pid=7238
2026-02-28 22:01:28,819 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 14:00:49.397996+00:00: manual__2026-02-28T14:00:49.397996+00:00, state:running, queued_at: 2026-02-28 14:00:49.406214+00:00. externally triggered: True> successful
2026-02-28 22:01:28,820 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 14:00:49.397996+00:00, run_id=manual__2026-02-28T14:00:49.397996+00:00, run_start_date=2026-02-28 14:00:50.934902+00:00, run_end_date=2026-02-28 14:01:28.820840+00:00, run_duration=37.885938, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 14:00:49.397996+00:00, data_interval_end=2026-02-28 14:00:49.397996+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 22:02:58,301 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:03:59,472 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>
2026-02-28 22:03:59,473 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:03:59,474 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>
2026-02-28 22:03:59,476 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:03:59,477 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:03:55.890148+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 22:03:59,478 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:03:55.890148+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:03:59,480 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:03:55.890148+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:04:04,573 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:03:55.890148+00:00', try_number=1, map_index=-1)
2026-02-28 22:04:04,582 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:03:55.890148+00:00, map_index=-1, run_start_date=2026-02-28 14:04:03.565459+00:00, run_end_date=2026-02-28 14:04:03.840873+00:00, run_duration=0.275414, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=772, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 14:03:59.475400+00:00, queued_by_job_id=711, pid=7392
2026-02-28 22:04:07,771 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>
2026-02-28 22:04:07,772 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:04:07,773 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>
2026-02-28 22:04:07,775 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:04:07,776 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:03:55.890148+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 22:04:07,777 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:03:55.890148+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:04:07,779 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:03:55.890148+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:04:12,564 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:03:55.890148+00:00', try_number=1, map_index=-1)
2026-02-28 22:04:12,573 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:03:55.890148+00:00, map_index=-1, run_start_date=2026-02-28 14:04:11.662019+00:00, run_end_date=2026-02-28 14:04:11.850774+00:00, run_duration=0.188755, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=773, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 14:04:07.774307+00:00, queued_by_job_id=711, pid=7396
2026-02-28 22:04:15,784 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>
2026-02-28 22:04:15,785 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:04:15,786 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>
2026-02-28 22:04:15,788 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:03:55.890148+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:04:15,789 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:03:55.890148+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 22:04:15,790 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:03:55.890148+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:04:15,792 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:03:55.890148+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:04:30,363 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:03:55.890148+00:00', try_number=1, map_index=-1)
2026-02-28 22:04:30,373 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:03:55.890148+00:00, map_index=-1, run_start_date=2026-02-28 14:04:19.435331+00:00, run_end_date=2026-02-28 14:04:29.621634+00:00, run_duration=10.186303, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=774, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 14:04:15.787347+00:00, queued_by_job_id=711, pid=7399
2026-02-28 22:04:38,079 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 14:03:55.890148+00:00: manual__2026-02-28T14:03:55.890148+00:00, state:running, queued_at: 2026-02-28 14:03:55.899399+00:00. externally triggered: True> successful
2026-02-28 22:04:38,080 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 14:03:55.890148+00:00, run_id=manual__2026-02-28T14:03:55.890148+00:00, run_start_date=2026-02-28 14:03:59.448363+00:00, run_end_date=2026-02-28 14:04:38.080092+00:00, run_duration=38.631729, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 14:03:55.890148+00:00, data_interval_end=2026-02-28 14:03:55.890148+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 22:07:10,929 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>
2026-02-28 22:07:10,929 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:07:10,930 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>
2026-02-28 22:07:10,932 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:07:10,933 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:07:08.608449+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 22:07:10,934 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:07:08.608449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:07:10,937 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:07:08.608449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:07:15,946 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:07:08.608449+00:00', try_number=1, map_index=-1)
2026-02-28 22:07:15,955 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:07:08.608449+00:00, map_index=-1, run_start_date=2026-02-28 14:07:14.925697+00:00, run_end_date=2026-02-28 14:07:15.219461+00:00, run_duration=0.293764, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=748, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 14:07:10.931704+00:00, queued_by_job_id=711, pid=7547
2026-02-28 22:07:18,619 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>
2026-02-28 22:07:18,620 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:07:18,621 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>
2026-02-28 22:07:18,623 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:07:18,624 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:07:08.608449+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 22:07:18,624 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:07:08.608449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:07:18,627 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:07:08.608449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:07:23,254 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:07:08.608449+00:00', try_number=1, map_index=-1)
2026-02-28 22:07:23,264 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:07:08.608449+00:00, map_index=-1, run_start_date=2026-02-28 14:07:22.319321+00:00, run_end_date=2026-02-28 14:07:22.519579+00:00, run_duration=0.200258, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=749, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 14:07:18.621965+00:00, queued_by_job_id=711, pid=7551
2026-02-28 22:07:25,772 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>
2026-02-28 22:07:25,773 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:07:25,774 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>
2026-02-28 22:07:25,777 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:07:08.608449+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:07:25,778 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:07:08.608449+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 22:07:25,778 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:07:08.608449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:07:25,781 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:07:08.608449+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:07:39,374 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:07:08.608449+00:00', try_number=1, map_index=-1)
2026-02-28 22:07:39,385 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:07:08.608449+00:00, map_index=-1, run_start_date=2026-02-28 14:07:29.558057+00:00, run_end_date=2026-02-28 14:07:38.633962+00:00, run_duration=9.075905, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=750, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 14:07:25.775729+00:00, queued_by_job_id=711, pid=7557
2026-02-28 22:07:46,409 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 14:07:08.608449+00:00: manual__2026-02-28T14:07:08.608449+00:00, state:running, queued_at: 2026-02-28 14:07:08.628146+00:00. externally triggered: True> successful
2026-02-28 22:07:46,410 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 14:07:08.608449+00:00, run_id=manual__2026-02-28T14:07:08.608449+00:00, run_start_date=2026-02-28 14:07:10.901221+00:00, run_end_date=2026-02-28 14:07:46.410270+00:00, run_duration=35.509049, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 14:07:08.608449+00:00, data_interval_end=2026-02-28 14:07:08.608449+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 22:07:58,565 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:11:55,042 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>
2026-02-28 22:11:55,043 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:11:55,044 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>
2026-02-28 22:11:55,046 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:11:55,047 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:11:52.347557+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 22:11:55,047 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:11:52.347557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:11:55,050 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:11:52.347557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:12:00,131 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:11:52.347557+00:00', try_number=1, map_index=-1)
2026-02-28 22:12:00,140 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:11:52.347557+00:00, map_index=-1, run_start_date=2026-02-28 14:11:59.101157+00:00, run_end_date=2026-02-28 14:11:59.378031+00:00, run_duration=0.276874, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=751, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 14:11:55.045238+00:00, queued_by_job_id=711, pid=7758
2026-02-28 22:12:02,538 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>
2026-02-28 22:12:02,539 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:12:02,540 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>
2026-02-28 22:12:02,542 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:12:02,543 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:11:52.347557+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 22:12:02,544 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:11:52.347557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:12:02,546 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:11:52.347557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:12:07,273 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:11:52.347557+00:00', try_number=1, map_index=-1)
2026-02-28 22:12:07,282 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:11:52.347557+00:00, map_index=-1, run_start_date=2026-02-28 14:12:06.286487+00:00, run_end_date=2026-02-28 14:12:06.481779+00:00, run_duration=0.195292, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=752, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 14:12:02.541168+00:00, queued_by_job_id=711, pid=7765
2026-02-28 22:12:10,901 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>
2026-02-28 22:12:10,902 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:12:10,903 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>
2026-02-28 22:12:10,905 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:11:52.347557+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:12:10,906 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:11:52.347557+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 22:12:10,907 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:11:52.347557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:12:10,909 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:11:52.347557+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:12:25,502 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:11:52.347557+00:00', try_number=1, map_index=-1)
2026-02-28 22:12:25,514 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:11:52.347557+00:00, map_index=-1, run_start_date=2026-02-28 14:12:14.661590+00:00, run_end_date=2026-02-28 14:12:24.821348+00:00, run_duration=10.159758, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=753, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 14:12:10.904569+00:00, queued_by_job_id=711, pid=7768
2026-02-28 22:12:32,969 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 14:11:52.347557+00:00: manual__2026-02-28T14:11:52.347557+00:00, state:running, queued_at: 2026-02-28 14:11:52.355522+00:00. externally triggered: True> successful
2026-02-28 22:12:32,970 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 14:11:52.347557+00:00, run_id=manual__2026-02-28T14:11:52.347557+00:00, run_start_date=2026-02-28 14:11:55.018244+00:00, run_end_date=2026-02-28 14:12:32.970868+00:00, run_duration=37.952624, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 14:11:52.347557+00:00, data_interval_end=2026-02-28 14:11:52.347557+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 22:13:00,883 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:14:50,366 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>
2026-02-28 22:14:50,367 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:14:50,368 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>
2026-02-28 22:14:50,370 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:14:50,371 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:14:46.829052+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2026-02-28 22:14:50,372 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:14:46.829052+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:14:50,374 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:14:46.829052+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:14:55,485 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:14:46.829052+00:00', try_number=1, map_index=-1)
2026-02-28 22:14:55,495 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:14:46.829052+00:00, map_index=-1, run_start_date=2026-02-28 14:14:54.501876+00:00, run_end_date=2026-02-28 14:14:54.779498+00:00, run_duration=0.277622, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=754, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-28 14:14:50.369295+00:00, queued_by_job_id=711, pid=7909
2026-02-28 22:14:57,947 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>
2026-02-28 22:14:57,948 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:14:57,949 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>
2026-02-28 22:14:57,951 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:14:57,952 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:14:46.829052+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 22:14:57,953 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:14:46.829052+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:14:57,955 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:14:46.829052+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:15:02,706 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:14:46.829052+00:00', try_number=1, map_index=-1)
2026-02-28 22:15:02,714 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:14:46.829052+00:00, map_index=-1, run_start_date=2026-02-28 14:15:01.807527+00:00, run_end_date=2026-02-28 14:15:01.996778+00:00, run_duration=0.189251, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=755, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 14:14:57.950567+00:00, queued_by_job_id=711, pid=7916
2026-02-28 22:15:05,148 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>
2026-02-28 22:15:05,150 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:15:05,151 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>
2026-02-28 22:15:05,155 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:14:46.829052+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:15:05,156 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:14:46.829052+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 22:15:05,158 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:14:46.829052+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:15:05,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:14:46.829052+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:15:20,329 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:14:46.829052+00:00', try_number=1, map_index=-1)
2026-02-28 22:15:20,338 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:14:46.829052+00:00, map_index=-1, run_start_date=2026-02-28 14:15:08.890136+00:00, run_end_date=2026-02-28 14:15:19.627289+00:00, run_duration=10.737153, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=756, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 14:15:05.153535+00:00, queued_by_job_id=711, pid=7919
2026-02-28 22:15:27,236 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 14:14:46.829052+00:00: manual__2026-02-28T14:14:46.829052+00:00, state:running, queued_at: 2026-02-28 14:14:46.838402+00:00. externally triggered: True> successful
2026-02-28 22:15:27,237 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 14:14:46.829052+00:00, run_id=manual__2026-02-28T14:14:46.829052+00:00, run_start_date=2026-02-28 14:14:50.342326+00:00, run_end_date=2026-02-28 14:15:27.237301+00:00, run_duration=36.894975, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 14:14:46.829052+00:00, data_interval_end=2026-02-28 14:14:46.829052+00:00, dag_hash=b7ac5ba03ba3ec578ddf88d63312f21f
2026-02-28 22:18:01,316 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:23:03,551 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:27:40,687 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>
2026-02-28 22:27:40,688 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:27:40,688 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>
2026-02-28 22:27:40,691 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:27:40,692 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:27:33.434494+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 4 and queue default
2026-02-28 22:27:40,693 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:27:33.434494+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:27:40,695 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:27:33.434494+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:27:45,786 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:27:33.434494+00:00', try_number=1, map_index=-1)
2026-02-28 22:27:45,802 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:27:33.434494+00:00, map_index=-1, run_start_date=2026-02-28 14:27:44.857945+00:00, run_end_date=2026-02-28 14:27:45.048983+00:00, run_duration=0.191038, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=757, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2026-02-28 14:27:40.689947+00:00, queued_by_job_id=711, pid=8344
2026-02-28 22:27:49,446 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>
2026-02-28 22:27:49,447 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:27:49,448 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>
2026-02-28 22:27:49,451 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:27:49,452 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:27:33.434494+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 22:27:49,453 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:27:33.434494+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:27:49,455 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:27:33.434494+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:28:04,746 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:27:33.434494+00:00', try_number=1, map_index=-1)
2026-02-28 22:28:04,760 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:27:33.434494+00:00, map_index=-1, run_start_date=2026-02-28 14:27:53.084870+00:00, run_end_date=2026-02-28 14:28:03.928030+00:00, run_duration=10.84316, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=758, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 14:27:49.450002+00:00, queued_by_job_id=711, pid=8347
2026-02-28 22:28:04,802 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:28:09,528 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>
2026-02-28 22:28:09,529 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:28:09,530 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>
2026-02-28 22:28:09,532 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:27:33.434494+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:28:09,533 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:27:33.434494+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 22:28:09,534 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:27:33.434494+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:28:09,536 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:27:33.434494+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:28:14,478 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:27:33.434494+00:00', try_number=1, map_index=-1)
2026-02-28 22:28:14,488 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:27:33.434494+00:00, map_index=-1, run_start_date=2026-02-28 14:28:13.548236+00:00, run_end_date=2026-02-28 14:28:13.828708+00:00, run_duration=0.280472, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=759, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 14:28:09.531455+00:00, queued_by_job_id=711, pid=8409
2026-02-28 22:28:20,155 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 14:27:33.434494+00:00: manual__2026-02-28T14:27:33.434494+00:00, state:running, queued_at: 2026-02-28 14:27:33.443802+00:00. externally triggered: True> successful
2026-02-28 22:28:20,156 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 14:27:33.434494+00:00, run_id=manual__2026-02-28T14:27:33.434494+00:00, run_start_date=2026-02-28 14:27:37.256003+00:00, run_end_date=2026-02-28 14:28:20.155970+00:00, run_duration=42.899967, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 14:27:33.434494+00:00, data_interval_end=2026-02-28 14:27:33.434494+00:00, dag_hash=6f0ef6e7e5976768c63233e78fc20e37
2026-02-28 22:33:05,990 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:38:09,557 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:43:11,337 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:48:13,723 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:53:14,946 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 22:56:26,984 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:56:20.403419+00:00 [scheduled]>
2026-02-28 22:56:26,985 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:56:26,986 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:56:20.403419+00:00 [scheduled]>
2026-02-28 22:56:26,988 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:56:20.403419+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:56:26,989 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:56:20.403419+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 22:56:26,990 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:56:20.403419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:56:26,993 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:56:20.403419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:56:31,987 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:56:20.403419+00:00', try_number=1, map_index=-1)
2026-02-28 22:56:31,997 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:56:20.403419+00:00, map_index=-1, run_start_date=2026-02-28 14:56:31.097023+00:00, run_end_date=2026-02-28 14:56:31.290225+00:00, run_duration=0.193202, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=760, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 14:56:26.987476+00:00, queued_by_job_id=711, pid=9371
2026-02-28 22:56:34,591 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T14:56:20.403419+00:00 [scheduled]>
2026-02-28 22:56:34,592 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 22:56:34,593 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T14:56:20.403419+00:00 [scheduled]>
2026-02-28 22:56:34,596 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T14:56:20.403419+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 22:56:34,597 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:56:20.403419+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 22:56:34,598 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:56:20.403419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:56:34,600 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T14:56:20.403419+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_.py']
2026-02-28 22:56:49,603 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T14:56:20.403419+00:00', try_number=1, map_index=-1)
2026-02-28 22:56:49,618 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T14:56:20.403419+00:00, map_index=-1, run_start_date=2026-02-28 14:56:38.119095+00:00, run_end_date=2026-02-28 14:56:48.762214+00:00, run_duration=10.643119, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=761, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 14:56:34.595029+00:00, queued_by_job_id=711, pid=9376
2026-02-28 22:56:56,576 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 14:56:20.403419+00:00: manual__2026-02-28T14:56:20.403419+00:00, state:running, queued_at: 2026-02-28 14:56:20.410944+00:00. externally triggered: True> successful
2026-02-28 22:56:56,577 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 14:56:20.403419+00:00, run_id=manual__2026-02-28T14:56:20.403419+00:00, run_start_date=2026-02-28 14:56:23.500644+00:00, run_end_date=2026-02-28 14:56:56.577638+00:00, run_duration=33.076994, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 14:56:20.403419+00:00, data_interval_end=2026-02-28 14:56:20.403419+00:00, dag_hash=482d927267cbcf71aecd81bffadda037
2026-02-28 22:58:17,440 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 23:11:59,174 INFO - Heartbeat recovered after 589.34 seconds
2026-02-28 23:13:02,911 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 23:46:09,418 INFO - Heartbeat recovered after 1959.60 seconds
2026-02-28 23:50:41,610 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 23:55:43,409 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-28 23:58:07,086 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T15:58:01.229062+00:00 [scheduled]>
2026-02-28 23:58:07,087 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 23:58:07,088 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T15:58:01.229062+00:00 [scheduled]>
2026-02-28 23:58:07,090 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T15:58:01.229062+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 23:58:07,091 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T15:58:01.229062+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2026-02-28 23:58:07,092 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T15:58:01.229062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_2.py']
2026-02-28 23:58:07,095 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T15:58:01.229062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_2.py']
2026-02-28 23:58:12,105 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T15:58:01.229062+00:00', try_number=1, map_index=-1)
2026-02-28 23:58:12,117 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T15:58:01.229062+00:00, map_index=-1, run_start_date=2026-02-28 15:58:11.184042+00:00, run_end_date=2026-02-28 15:58:11.380775+00:00, run_duration=0.196733, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=762, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-28 15:58:07.089601+00:00, queued_by_job_id=711, pid=10209
2026-02-28 23:58:14,837 INFO - 1 tasks up for execution:
	<TaskInstance: cdrd_. manual__2026-02-28T15:58:01.229062+00:00 [scheduled]>
2026-02-28 23:58:14,838 INFO - DAG cdrd_ has 0/16 running and queued tasks
2026-02-28 23:58:14,839 INFO - Setting the following tasks to queued state:
	<TaskInstance: cdrd_. manual__2026-02-28T15:58:01.229062+00:00 [scheduled]>
2026-02-28 23:58:14,842 INFO - Trying to enqueue tasks: [<TaskInstance: cdrd_. manual__2026-02-28T15:58:01.229062+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2026-02-28 23:58:14,843 INFO - Sending TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T15:58:01.229062+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2026-02-28 23:58:14,844 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T15:58:01.229062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_2.py']
2026-02-28 23:58:14,846 INFO - Executing command: ['airflow', 'tasks', 'run', 'cdrd_', '', 'manual__2026-02-28T15:58:01.229062+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_CDRD///dag_2.py']
2026-02-28 23:58:35,706 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='cdrd_', task_id='', run_id='manual__2026-02-28T15:58:01.229062+00:00', try_number=1, map_index=-1)
2026-02-28 23:58:35,719 INFO - TaskInstance Finished: dag_id=cdrd_, task_id=, run_id=manual__2026-02-28T15:58:01.229062+00:00, map_index=-1, run_start_date=2026-02-28 15:58:18.726530+00:00, run_end_date=2026-02-28 15:58:34.978972+00:00, run_duration=16.252442, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=763, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-28 15:58:14.840424+00:00, queued_by_job_id=711, pid=10212
2026-02-28 23:58:43,745 INFO - Marking run <DagRun cdrd_ @ 2026-02-28 15:58:01.229062+00:00: manual__2026-02-28T15:58:01.229062+00:00, state:running, queued_at: 2026-02-28 15:58:01.250399+00:00. externally triggered: True> successful
2026-02-28 23:58:43,747 INFO - DagRun Finished: dag_id=cdrd_, execution_date=2026-02-28 15:58:01.229062+00:00, run_id=manual__2026-02-28T15:58:01.229062+00:00, run_start_date=2026-02-28 15:58:03.542264+00:00, run_end_date=2026-02-28 15:58:43.747074+00:00, run_duration=40.20481, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-28 15:58:01.229062+00:00, data_interval_end=2026-02-28 15:58:01.229062+00:00, dag_hash=3dfcd20aed7f2a4c39abfade622ccac7
2026-03-01 00:00:44,913 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-03-01 00:05:45,271 INFO - Adopting or resetting orphaned tasks for active dag runs
