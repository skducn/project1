# coding=utf-8
# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> >>
# Author     : John
# Created on : 2026-2-27
# Description: ä¸»æ§DAG - é›†æˆå­DAGæ—¥å¿—åˆ°AllureæŠ¥å‘Š
# airflow UIï¼šcdrd_ä¸»æ§æµ‹è¯•æµç¨‹
# *****************************************************************

from datetime import datetime as dt, timedelta
import os
import json
import uuid
import time
import requests
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.dummy import DummyOperator
from airflow.operators.python import PythonOperator
from airflow.configuration import conf


def get_airflow_api_config():
    """è·å–Airflow APIé…ç½®ä¿¡æ¯"""
    try:
        # ä»Airflowé…ç½®ä¸­è·å–APIä¿¡æ¯
        airflow_home = conf.get('core', 'airflow_home')
        web_server_port = conf.get('webserver', 'web_server_port', fallback='8080')
        web_server_host = conf.get('webserver', 'web_server_host', fallback='localhost')

        return {
            'base_url': f"http://{web_server_host}:{web_server_port}",
            'airflow_home': airflow_home
        }
    except Exception as e:
        print(f"âš ï¸ è·å–Airflowé…ç½®å¤±è´¥: {str(e)}")
        # ä½¿ç”¨é»˜è®¤é…ç½®
        return {
            'base_url': "http://localhost:8080",
            'airflow_home': "/Users/linghuchong/Downloads/51/Python/project/instance/airflow284"
        }


def generate_allure_test_result_with_logs(test_name, execution_result, start_time, stop_time):
    """ç”ŸæˆåŒ…å«æ—¥å¿—çš„Allureæµ‹è¯•ç»“æœ"""
    test_uuid = str(uuid.uuid4())

    # æ„å»ºæµ‹è¯•æè¿°å’Œæ—¥å¿—é™„ä»¶
    description = f"æµ‹è¯•DAG: {execution_result['dag_id']}\n"
    description += f"è¿è¡ŒID: {execution_result['dag_run_id']}\n"
    description += f"æ‰§è¡ŒçŠ¶æ€: {execution_result['status']}\n"
    description += f"æ‰§è¡Œæ—¶é—´: {execution_result['execution_time']:.2f}ç§’\n"

    if 'error' in execution_result:
        description += f"é”™è¯¯ä¿¡æ¯: {execution_result['error']}\n"

    # åˆ›å»ºæ—¥å¿—é™„ä»¶
    attachments = []
    for i, task_log in enumerate(execution_result['task_logs']):
        if task_log['log']:
            attachment_name = f"{task_log['task_id']}_log.txt"
            attachments.append({
                "name": attachment_name,
                "source": f"logs/{attachment_name}",
                "type": "text/plain"
            })

    result = {
        "uuid": test_uuid,
        "name": test_name,
        "fullName": f"ç³»ç»Ÿç®¡ç†.{test_name}",
        "historyId": test_uuid,
        "status": "passed" if execution_result['status'] == 'success' else "failed",
        "stage": "finished",
        "description": description,
        "start": int(start_time * 1000),
        "stop": int(stop_time * 1000),
        "labels": [
            {"name": "suite", "value": "ç³»ç»Ÿç®¡ç†æµ‹è¯•å¥—ä»¶"},
            {"name": "subSuite", "value": "ä¸»æ§æµ‹è¯•"},
            {"name": "host", "value": "localhost"},
            {"name": "thread", "value": "main"},
            {"name": "framework", "value": "Airflow"},
            {"name": "language", "value": "python"},
            {"name": "tag", "value": execution_result['status']}
        ],
        "links": [],
        "parameters": [
            {"name": "dag_id", "value": execution_result['dag_id']},
            {"name": "dag_run_id", "value": execution_result['dag_run_id']}
        ]
    }

    # æ·»åŠ é™„ä»¶ä¿¡æ¯
    if attachments:
        result["attachments"] = attachments

    return result, attachments


def save_task_logs_to_files(allure_results_dir, execution_result):
    """å°†ä»»åŠ¡æ—¥å¿—ä¿å­˜åˆ°æ–‡ä»¶"""
    logs_dir = os.path.join(allure_results_dir, "logs")
    os.makedirs(logs_dir, exist_ok=True)

    saved_attachments = []

    for task_log in execution_result['task_logs']:
        if task_log['log']:
            log_filename = f"{task_log['task_id']}_log.txt"
            log_filepath = os.path.join(logs_dir, log_filename)

            try:
                with open(log_filepath, 'w', encoding='utf-8') as f:
                    f.write(f"Task ID: {task_log['task_id']}\n")
                    f.write(f"State: {task_log['state']}\n")
                    f.write(f"Start Time: {task_log.get('start_date', 'N/A')}\n")
                    f.write(f"End Time: {task_log.get('end_date', 'N/A')}\n")
                    f.write("=" * 50 + "\n")
                    f.write(task_log['log'])

                saved_attachments.append({
                    "name": log_filename,
                    "path": log_filepath
                })
                print(f"ğŸ’¾ å·²ä¿å­˜æ—¥å¿—æ–‡ä»¶: {log_filename}")

            except Exception as e:
                print(f"âŒ ä¿å­˜æ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_filename}: {str(e)}")

    return saved_attachments


def generate_allure_report(**context):
    """ç”ŸæˆåŒ…å«å­DAGæ—¥å¿—çš„Allureæµ‹è¯•æŠ¥å‘Š"""
    try:
        print("=" * 60)
        print("ğŸ“Š å¼€å§‹ç”ŸæˆåŒ…å«å­DAGæ—¥å¿—çš„Allureæµ‹è¯•æŠ¥å‘Š...")
        print("=" * 60)

        # è·å–æ‰§è¡Œç»“æœï¼ˆä»XComï¼‰
        user_result = context['task_instance'].xcom_pull(task_ids='execute_user_management_test')
        role_result = context['task_instance'].xcom_pull(task_ids='execute_role_management_test')

        if not user_result or not role_result:
            print("âš ï¸ æœªæ‰¾åˆ°å­DAGæ‰§è¡Œç»“æœ")
            return False

        # AllureæŠ¥å‘Šç›¸å…³è·¯å¾„é…ç½®
        project_root = "/Users/linghuchong/Downloads/51/Python/project"
        allure_results_dir = f"{project_root}/instance/airflow284/allure-results"
        allure_report_dir = f"{project_root}/instance/airflow284/allure-report"

        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs(allure_results_dir, exist_ok=True)
        os.makedirs(allure_report_dir, exist_ok=True)

        # ç”ŸæˆAllureæµ‹è¯•ç»“æœæ•°æ®
        current_timestamp = time.time()
        base_time = current_timestamp - 120  # 2åˆ†é’Ÿå‰ä½œä¸ºåŸºå‡†æ—¶é—´

        # å¤„ç†ç”¨æˆ·ç®¡ç†æµ‹è¯•ç»“æœ
        user_test_result, user_attachments = generate_allure_test_result_with_logs(
            "ç”¨æˆ·ç®¡ç†æµ‹è¯•",
            user_result,
            base_time,
            base_time + user_result['execution_time']
        )

        # ä¿å­˜ç”¨æˆ·ç®¡ç†æ—¥å¿—æ–‡ä»¶
        user_log_attachments = save_task_logs_to_files(allure_results_dir, user_result)

        # å¤„ç†è§’è‰²ç®¡ç†æµ‹è¯•ç»“æœ
        role_test_result, role_attachments = generate_allure_test_result_with_logs(
            "è§’è‰²ç®¡ç†æµ‹è¯•",
            role_result,
            base_time + 30,
            base_time + 30 + role_result['execution_time']
        )

        # ä¿å­˜è§’è‰²ç®¡ç†æ—¥å¿—æ–‡ä»¶
        role_log_attachments = save_task_logs_to_files(allure_results_dir, role_result)

        # ç”Ÿæˆæµ‹è¯•ç»“æœæ–‡ä»¶
        test_results = [user_test_result, role_test_result]
        for i, test_result in enumerate(test_results):
            result_file = f"{allure_results_dir}/{test_result['uuid']}-result.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(test_result, f, ensure_ascii=False, indent=2)

        # ç”Ÿæˆå®¹å™¨æ–‡ä»¶
        container_uuid = str(uuid.uuid4())
        container_data = {
            "uuid": container_uuid,
            "name": "ç³»ç»Ÿç®¡ç†æµ‹è¯•å¥—ä»¶",
            "children": [test['uuid'] for test in test_results],
            "befores": [],
            "afters": [],
            "start": int(base_time * 1000),
            "stop": int((base_time + max(user_result['execution_time'], role_result['execution_time']) + 60) * 1000)
        }

        container_file = f"{allure_results_dir}/{container_uuid}-container.json"
        with open(container_file, 'w', encoding='utf-8') as f:
            json.dump(container_data, f, ensure_ascii=False, indent=2)

        # ç”Ÿæˆç¯å¢ƒä¿¡æ¯
        environment_info = {
            "Environment": "æµ‹è¯•ç¯å¢ƒ",
            "Operating System": "macOS",
            "Python Version": "3.x",
            "Airflow Version": "2.8.4",
            "Test Execution Time": dt.now().strftime("%Y-%m-%d %H:%M:%S"),
            "Project Path": project_root,
            "Main DAG": "master_system_management_with_logs",
            "Sub DAGs": f"{user_result['dag_id']}, {role_result['dag_id']}"
        }

        env_file = f"{allure_results_dir}/environment.properties"
        with open(env_file, 'w', encoding='utf-8') as f:
            for key, value in environment_info.items():
                safe_value = str(value).replace('\n', '\\n').replace('\r', '\\r')
                f.write(f"{key}={safe_value}\n")

        # ç”ŸæˆCategoriesæ–‡ä»¶
        categories = [
            {
                "name": "Successful Tests",
                "matchedStatuses": ["passed"]
            },
            {
                "name": "Failed Tests",
                "matchedStatuses": ["failed", "broken"]
            },
            {
                "name": "Skipped Tests",
                "matchedStatuses": ["skipped"]
            }
        ]

        categories_file = f"{allure_results_dir}/categories.json"
        with open(categories_file, 'w', encoding='utf-8') as f:
            json.dump(categories, f, ensure_ascii=False, indent=2)

        # ç”Ÿæˆæ‰§è¡Œå™¨ä¿¡æ¯
        executor_info = {
            "name": "Airflow Master Executor with Logs",
            "type": "custom",
            "url": get_airflow_api_config()['base_url'],
            "buildOrder": 1,
            "buildName": "System Management Test with Sub-DAG Logs",
            "buildUrl": get_airflow_api_config()['base_url'],
            "reportUrl": f"file://{allure_report_dir}/index.html",
            "version": "2.0.0"
        }

        executor_file = f"{allure_results_dir}/executor.json"
        with open(executor_file, 'w', encoding='utf-8') as f:
            json.dump(executor_info, f, ensure_ascii=False, indent=2)

        print(f"âœ… Allureç»“æœæ•°æ®å·²ç”Ÿæˆåˆ°: {allure_results_dir}")
        print(f"ğŸ“Š ç”Ÿæˆäº† {len(test_results)} ä¸ªæµ‹è¯•ç»“æœæ–‡ä»¶")
        print(f"ğŸ“ ä¿å­˜äº† {len(user_log_attachments) + len(role_log_attachments)} ä¸ªæ—¥å¿—æ–‡ä»¶")

        # éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ” éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶:")
        for filename in os.listdir(allure_results_dir):
            if filename.endswith('-result.json') or filename.endswith('-container.json'):
                print(f"   âœ“ {filename}")

        if os.path.exists(f"{allure_results_dir}/logs"):
            log_files = os.listdir(f"{allure_results_dir}/logs")
            print(f"   âœ“ æ—¥å¿—æ–‡ä»¶ ({len(log_files)} ä¸ª): {log_files}")

        # ç”ŸæˆHTMLæŠ¥å‘Š
        try:
            generate_cmd = f"""
                cd {project_root}
                if command -v allure &> /dev/null; then
                    echo "ğŸš€ ç”ŸæˆAllure HTMLæŠ¥å‘Š..."
                    allure generate "{allure_results_dir}" -o "{allure_report_dir}" --clean
                    if [ -f "{allure_report_dir}/index.html" ]; then
                        echo "âœ… AllureæŠ¥å‘Šç”ŸæˆæˆåŠŸ: {allure_report_dir}/index.html"
                    else
                        echo "âš ï¸ AllureæŠ¥å‘Šæ–‡ä»¶æœªæ‰¾åˆ°"
                    fi
                else
                    echo "âš ï¸ æœªæ‰¾åˆ°allureå‘½ä»¤ï¼Œè¯·å®‰è£…allure-commandline"
                    echo "ğŸ’¡ å®‰è£…æ–¹æ³•: brew install allure"
                    echo "ğŸ’¡ æ‰‹åŠ¨æ‰§è¡Œ: allure generate \"{allure_results_dir}\" -o \"{allure_report_dir}\" --clean"
                fi
            """

            import subprocess
            result = subprocess.run(generate_cmd, shell=True, capture_output=True, text=True, encoding='utf-8')
            print(result.stdout)
            if result.stderr:
                print(f"stderr: {result.stderr}")

        except Exception as e:
            print(f"âš ï¸ ç”ŸæˆAllureæŠ¥å‘Šæ—¶å‡ºç°è­¦å‘Š: {str(e)}")
            print("ğŸ’¡ ä½ å¯ä»¥æ‰‹åŠ¨æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ç”ŸæˆæŠ¥å‘Š:")
            print(f"   allure generate \"{allure_results_dir}\" -o \"{allure_report_dir}\" --clean")

        print("=" * 60)
        print("ğŸ‰ åŒ…å«å­DAGæ—¥å¿—çš„Allureæµ‹è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ“ ç»“æœç›®å½•: {allure_results_dir}")
        print(f"ğŸŒ æŠ¥å‘Šç›®å½•: {allure_report_dir}")
        print(f"â° ç”Ÿæˆæ—¶é—´: {dt.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        return True

    except Exception as e:
        print(f"âŒ ç”ŸæˆAllureæŠ¥å‘Šå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False




def execute_role_management_test(**context):
    """æ‰§è¡Œè§’è‰²ç®¡ç†æµ‹è¯•å¹¶æ”¶é›†æ—¥å¿— - çœŸå®æ‰§è¡Œç‰ˆæœ¬"""
    print("=" * 50)
    print("ğŸ“ å¼€å§‹æ‰§è¡Œè§’è‰²ç®¡ç†æµ‹è¯•ä»»åŠ¡...")
    print("=" * 50)

    try:
        # æ‰§è¡ŒçœŸå®çš„DAGä»»åŠ¡
        result = trigger_and_monitor_dag("cdrd_è§’è‰²ç®¡ç†_å¹¶å‘", "è§’è‰²ç®¡ç†æµ‹è¯•")
        print("âœ… è§’è‰²ç®¡ç†æµ‹è¯•æ‰§è¡Œå®Œæˆ")
        return result

    except Exception as e:
        print(f"âŒ è§’è‰²ç®¡ç†æµ‹è¯•æ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            'dag_id': 'cdrd_è§’è‰²ç®¡ç†_å¹¶å‘',
            'task_name': 'è§’è‰²ç®¡ç†æµ‹è¯•',
            'status': 'failed',
            'error': str(e),
            'task_logs': [],
            'execution_time': 0
        }


def execute_user_management_test(**context):
    """æ‰§è¡Œç”¨æˆ·ç®¡ç†æµ‹è¯•å¹¶æ”¶é›†æ—¥å¿— - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
    print("=" * 60)
    print("ğŸ“ å¼€å§‹æ‰§è¡Œç”¨æˆ·ç®¡ç†æµ‹è¯•ä»»åŠ¡...")
    print("=" * 60)
    print(f"â° å¼€å§‹æ—¶é—´: {dt.now().strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        print("ğŸ” æ­£åœ¨è°ƒç”¨ trigger_and_monitor_dag å‡½æ•°...")
        # æ·»åŠ è¶…æ—¶æ§åˆ¶
        import signal

        def timeout_handler(signum, frame):
            raise TimeoutError("æ‰§è¡Œè¶…æ—¶")

        # è®¾ç½®5åˆ†é’Ÿè¶…æ—¶
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(300)  # 300ç§’ = 5åˆ†é’Ÿ

        try:
            print("ğŸš€ å¼€å§‹æ‰§è¡ŒçœŸå®DAGä»»åŠ¡...")
            result = trigger_and_monitor_dag("cdrd_ç”¨æˆ·ç®¡ç†_å¹¶å‘", "ç”¨æˆ·ç®¡ç†æµ‹è¯•", timeout=180)
            print("âœ… ç”¨æˆ·ç®¡ç†æµ‹è¯•æ‰§è¡Œå®Œæˆ")
            signal.alarm(0)  # å–æ¶ˆè¶…æ—¶
            return result
        except TimeoutError:
            print("â° æ‰§è¡Œè¶…æ—¶ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœä»¥ç¡®ä¿æµç¨‹ç»§ç»­...")
            # è¶…æ—¶æƒ…å†µä¸‹è¿”å›æ¨¡æ‹Ÿç»“æœ
            return {
                'dag_id': 'cdrd_ç”¨æˆ·ç®¡ç†_å¹¶å‘',
                'dag_run_id': f"timeout_run_{int(time.time())}",
                'task_name': 'ç”¨æˆ·ç®¡ç†æµ‹è¯•',
                'status': 'timeout',
                'execution_time': 300,
                'task_logs': [{
                    'task_id': 'timeout_task',
                    'log': 'æ‰§è¡Œè¶…æ—¶ï¼Œæœªèƒ½è·å–å®Œæ•´æ—¥å¿—',
                    'state': 'failed',
                    'start_date': dt.now().isoformat(),
                    'end_date': dt.now().isoformat()
                }],
                'error': 'æ‰§è¡Œè¶…æ—¶'
            }

    except Exception as e:
        print(f"âŒ ç”¨æˆ·ç®¡ç†æµ‹è¯•æ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            'dag_id': 'cdrd_ç”¨æˆ·ç®¡ç†_å¹¶å‘',
            'task_name': 'ç”¨æˆ·ç®¡ç†æµ‹è¯•',
            'status': 'failed',
            'error': str(e),
            'task_logs': [],
            'execution_time': 0
        }
    finally:
        try:
            signal.alarm(0)  # ç¡®ä¿å–æ¶ˆè¶…æ—¶
        except:
            pass


def trigger_and_monitor_dag(dag_id, task_name, timeout=180):
    """è§¦å‘DAGå¹¶ç›‘æ§æ‰§è¡Œï¼Œæ”¶é›†æ—¥å¿—ä¿¡æ¯ - å¢å¼ºè°ƒè¯•ç‰ˆæœ¬"""
    print(f"ğŸ”§ è¿›å…¥ trigger_and_monitor_dag å‡½æ•°")
    print(f"ğŸ“‹ å‚æ•°: dag_id={dag_id}, task_name={task_name}, timeout={timeout}")

    try:
        api_config = get_airflow_api_config()
        base_url = api_config['base_url']

        print(f"ğŸŒ APIé…ç½®è·å–å®Œæˆ: {base_url}")

        # 1. éªŒè¯APIè¿æ¥
        print("ğŸ” éªŒè¯APIè¿æ¥...")
        try:
            health_check = requests.get(f"{base_url}/health", timeout=10)
            print(f"âœ… APIè¿æ¥æ­£å¸¸ï¼ŒçŠ¶æ€ç : {health_check.status_code}")
        except Exception as e:
            print(f"âŒ APIè¿æ¥å¤±è´¥: {str(e)}")
            raise Exception(f"æ— æ³•è¿æ¥åˆ°Airflow API: {str(e)}")

        # 2. æ£€æŸ¥DAGæ˜¯å¦å­˜åœ¨
        print("ğŸ” æ£€æŸ¥ç›®æ ‡DAGæ˜¯å¦å­˜åœ¨...")
        dag_check_url = f"{base_url}/api/v1/dags/{dag_id}"
        try:
            dag_response = requests.get(dag_check_url, timeout=10)
            print(f"ğŸ“Š DAGæ£€æŸ¥å“åº”: {dag_response.status_code}")
            if dag_response.status_code == 200:
                dag_info = dag_response.json()
                print(f"âœ… DAGå­˜åœ¨ï¼Œæ˜¯å¦æš‚åœ: {dag_info.get('is_paused', 'unknown')}")
            else:
                print(f"âš ï¸ DAGå¯èƒ½ä¸å­˜åœ¨æˆ–ä¸å¯è®¿é—®: {dag_response.text}")
                # ç»§ç»­æ‰§è¡Œï¼Œä½†è®°å½•è­¦å‘Š
        except Exception as e:
            print(f"âš ï¸ DAGæ£€æŸ¥å¼‚å¸¸: {str(e)}")

        # 3. è§¦å‘DAG
        print("ğŸ“¤ å‡†å¤‡è§¦å‘DAG...")
        trigger_url = f"{base_url}/api/v1/dags/{dag_id}/dagRuns"
        trigger_data = {
            "dag_run_id": f"{dag_id}_run_{int(time.time())}",
            "conf": {}
        }

        print(f"ğŸ“ è§¦å‘URL: {trigger_url}")

        response = requests.post(trigger_url, json=trigger_data, timeout=30)
        print(f"ğŸ“Š è§¦å‘å“åº”çŠ¶æ€: {response.status_code}")

        if response.status_code != 200:
            print(f"âŒ è§¦å‘å¤±è´¥: {response.text}")
            raise Exception(f"è§¦å‘DAGå¤±è´¥: {response.text}")

        dag_run_id = response.json()['dag_run_id']
        print(f"âœ… DAGè§¦å‘æˆåŠŸï¼Œè¿è¡ŒID: {dag_run_id}")

        # 4. ç›‘æ§æ‰§è¡ŒçŠ¶æ€
        print("ğŸ‘€ å¼€å§‹ç›‘æ§æ‰§è¡ŒçŠ¶æ€...")
        start_time = time.time()
        task_instances_log = []

        poll_count = 0
        max_polls = int(timeout / 10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡

        while time.time() - start_time < timeout and poll_count < max_polls:
            poll_count += 1
            elapsed_time = time.time() - start_time
            print(f"ğŸ” ç¬¬{poll_count}æ¬¡çŠ¶æ€æ£€æŸ¥ (å·²ç”¨æ—¶: {elapsed_time:.1f}ç§’)")

            # è·å–DAGè¿è¡ŒçŠ¶æ€
            status_url = f"{base_url}/api/v1/dags/{dag_id}/dagRuns/{dag_run_id}"
            try:
                status_response = requests.get(status_url, timeout=10)
                print(f"ğŸ“Š çŠ¶æ€æ£€æŸ¥å“åº”: {status_response.status_code}")

                if status_response.status_code == 200:
                    dag_status = status_response.json()['state']
                    print(f"ğŸ“Š å½“å‰çŠ¶æ€: {dag_status}")

                    if dag_status in ['success', 'failed']:
                        print(f"âœ… DAGæ‰§è¡Œå®Œæˆï¼Œæœ€ç»ˆçŠ¶æ€: {dag_status}")

                        # è·å–ä»»åŠ¡å®ä¾‹ä¿¡æ¯
                        tasks_url = f"{base_url}/api/v1/dags/{dag_id}/dagRuns/{dag_run_id}/taskInstances"
                        try:
                            tasks_response = requests.get(tasks_url, timeout=30)
                            if tasks_response.status_code == 200:
                                task_instances = tasks_response.json()['task_instances']
                                print(f"ğŸ“Š æ‰¾åˆ° {len(task_instances)} ä¸ªä»»åŠ¡å®ä¾‹")

                                # æ”¶é›†æ—¥å¿—
                                for task_instance in task_instances:
                                    task_id = task_instance['task_id']
                                    print(f"ğŸ“ æ”¶é›†ä»»åŠ¡ '{task_id}' çš„æ—¥å¿—...")
                                    try:
                                        log_url = f"{base_url}/api/v1/dags/{dag_id}/dagRuns/{dag_run_id}/taskInstances/{task_id}/logs/1"
                                        log_response = requests.get(log_url, timeout=30)

                                        if log_response.status_code == 200:
                                            log_content = log_response.json().get('content', '')
                                            task_instances_log.append({
                                                'task_id': task_id,
                                                'log': log_content,
                                                'state': task_instance['state'],
                                                'start_date': task_instance.get('start_date'),
                                                'end_date': task_instance.get('end_date')
                                            })
                                            print(f"âœ… å·²æ”¶é›†ä»»åŠ¡ '{task_id}' çš„æ—¥å¿—")
                                    except Exception as log_error:
                                        print(f"âš ï¸ æ”¶é›†æ—¥å¿—å¤±è´¥: {str(log_error)}")

                        except Exception as tasks_error:
                            print(f"âš ï¸ è·å–ä»»åŠ¡å®ä¾‹å¤±è´¥: {str(tasks_error)}")

                        break
                    else:
                        print(f"â³ DAGä»åœ¨æ‰§è¡Œä¸­...")
                else:
                    print(f"âŒ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {status_response.status_code}")

            except Exception as status_error:
                print(f"âš ï¸ çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {str(status_error)}")

            # é¿å…è¿‡äºé¢‘ç¹çš„æ£€æŸ¥
            if time.time() - start_time < timeout:
                print("â° ç­‰å¾…10ç§’åç»§ç»­æ£€æŸ¥...")
                time.sleep(10)

        # 5. è¿”å›ç»“æœ
        final_status = dag_status if 'dag_status' in locals() else 'timeout'
        execution_time = time.time() - start_time

        print(f"âœ… {task_name} æ‰§è¡Œå®Œæˆ")
        print(f"ğŸ“Š æœ€ç»ˆçŠ¶æ€: {final_status}")
        print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"ğŸ“ æ”¶é›†åˆ° {len(task_instances_log)} ä¸ªä»»åŠ¡æ—¥å¿—")

        return {
            'dag_id': dag_id,
            'dag_run_id': dag_run_id,
            'task_name': task_name,
            'status': final_status,
            'task_logs': task_instances_log,
            'execution_time': execution_time
        }

    except Exception as e:
        print(f"âŒ trigger_and_monitor_dag æ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        raise e


def cleanup_old_reports(**context):
    """æ¸…ç†æ—§çš„æµ‹è¯•æŠ¥å‘Š"""
    try:
        print("ğŸ§¹ å¼€å§‹æ¸…ç†æ—§çš„æµ‹è¯•æŠ¥å‘Š...")

        project_root = "/Users/linghuchong/Downloads/51/Python/project"
        allure_results_dir = f"{project_root}/instance/airflow284/allure-results"

        from datetime import datetime, timedelta
        cutoff_time = datetime.now() - timedelta(days=3)

        cleaned_count = 0
        if os.path.exists(allure_results_dir):
            for filename in os.listdir(allure_results_dir):
                file_path = os.path.join(allure_results_dir, filename)
                if os.path.isfile(file_path):
                    file_mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                    if file_mtime < cutoff_time:
                        try:
                            os.remove(file_path)
                            print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§æ–‡ä»¶: {filename}")
                            cleaned_count += 1
                        except Exception as e:
                            print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {filename}: {str(e)}")

        print(f"âœ… æ—§æŠ¥å‘Šæ¸…ç†å®Œæˆï¼Œå…±æ¸…ç† {cleaned_count} ä¸ªæ–‡ä»¶")
        return True

    except Exception as e:
        print(f"âš ï¸ æ¸…ç†æ—§æŠ¥å‘Šæ—¶å‡ºç°è­¦å‘Š: {str(e)}")
        return True


# ä¸»æ§DAGå®šä¹‰ - ä¿®å¤è¯­æ³•é”™è¯¯
dag = DAG(
    dag_id="master_system_management_with_logs",
    start_date=dt(2026, 2, 13),
    schedule_interval=None,
    catchup=False,
    tags=["cdrd", "master", "system_management", "allure", "log_integration"],
    dagrun_timeout=timedelta(minutes=60),
)

# å®šä¹‰ä»»åŠ¡
start = DummyOperator(task_id="start", dag=dag)
end = DummyOperator(task_id="end", dag=dag)

# æ¸…ç†æ—§æŠ¥å‘Šä»»åŠ¡
cleanup_reports = PythonOperator(
    task_id="cleanup_old_reports",
    python_callable=cleanup_old_reports,
    provide_context=True,
    dag=dag
)

# æ‰§è¡Œç”¨æˆ·ç®¡ç†æµ‹è¯•ï¼ˆæ”¶é›†æ—¥å¿—ï¼‰
user_test = PythonOperator(
    task_id="execute_user_management_test",
    python_callable=execute_user_management_test,
    provide_context=True,
    dag=dag
)

# æ‰§è¡Œè§’è‰²ç®¡ç†æµ‹è¯•ï¼ˆæ”¶é›†æ—¥å¿—ï¼‰
role_test = PythonOperator(
    task_id="execute_role_management_test",
    python_callable=execute_role_management_test,
    provide_context=True,
    dag=dag
)

# ç”ŸæˆåŒ…å«æ—¥å¿—çš„AllureæŠ¥å‘Šä»»åŠ¡
generate_allure = PythonOperator(
    task_id="generate_allure_report",
    python_callable=generate_allure_report,
    provide_context=True,
    dag=dag
)

# è®¾ç½®æ‰§è¡Œæµç¨‹ï¼šæ¸…ç† -> å¹¶è¡Œæ‰§è¡Œæµ‹è¯• -> ç”ŸæˆæŠ¥å‘Š -> ç»“æŸ
start >> cleanup_reports >> [user_test, role_test] >> generate_allure >> end
