[[34m2026-02-12T10:44:46.536+0800[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2026-02-12T10:44:46.538+0800[0m] {[34mexecutor_loader.py:[0m115} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2026-02-12T10:44:46.598+0800[0m] {[34mscheduler_job_runner.py:[0m807} INFO[0m - Starting the scheduler[0m
[[34m2026-02-12T10:44:46.599+0800[0m] {[34mscheduler_job_runner.py:[0m814} INFO[0m - Processing each file at most -1 times[0m
[[34m2026-02-12T10:44:46.606+0800[0m] {[34mmanager.py:[0m169} INFO[0m - Launched DagFileProcessorManager with pid: 2220[0m
[[34m2026-02-12T10:44:46.611+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T10:44:48.805+0800[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[2026-02-12T10:44:48.858+0800] {manager.py:392} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2026-02-12T10:49:47.173+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T10:54:49.675+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:07:17.250+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:12:19.709+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:17:22.611+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:22:25.375+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:27:27.067+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:32:29.230+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:37:32.112+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:39:46.172+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:39:45.982344+00:00 [scheduled]>[0m
[[34m2026-02-12T11:39:46.173+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-12T11:39:46.175+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:39:45.982344+00:00 [scheduled]>[0m
[[34m2026-02-12T11:39:46.178+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-12T11:39:46.183+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-12T03:39:45.982344+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2026-02-12T11:39:46.184+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-12T03:39:45.982344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:39:46.189+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-12T03:39:45.982344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:39:48.947+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:39:50.774+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:39:45.982344+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:39:51.763+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-12T03:39:45.982344+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:39:51.778+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-12T03:39:45.982344+00:00, map_index=-1, run_start_date=2026-02-12 03:39:50.861733+00:00, run_end_date=2026-02-12 03:39:51.071677+00:00, run_duration=0.209944, state=success, executor_state=success, try_number=1, max_tries=0, job_id=141, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-12 03:39:46.176096+00:00, queued_by_job_id=140, pid=4363[0m
[[34m2026-02-12T11:39:54.898+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 2 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:39:46.101513+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:39:45.982344+00:00 [scheduled]>[0m
[[34m2026-02-12T11:39:54.899+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-12T11:39:54.899+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 1/16 running and queued tasks[0m
[[34m2026-02-12T11:39:54.900+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:39:46.101513+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:39:45.982344+00:00 [scheduled]>[0m
[[34m2026-02-12T11:39:54.903+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-12T11:39:54.903+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-12T11:39:54.905+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-12T03:39:46.101513+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2026-02-12T11:39:54.905+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-12T03:39:46.101513+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:39:54.906+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-12T03:39:45.982344+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-12T11:39:54.906+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-12T03:39:45.982344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:39:54.909+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-12T03:39:46.101513+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:39:57.637+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:39:58.917+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:39:46.101513+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:39:59.862+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-12T03:39:45.982344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:40:02.243+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:40:03.497+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:39:45.982344+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:40:17.873+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-12T03:39:46.101513+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:40:17.878+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-12T03:39:45.982344+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:40:17.892+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-12T03:39:45.982344+00:00, map_index=-1, run_start_date=2026-02-12 03:40:03.576898+00:00, run_end_date=2026-02-12 03:40:17.172774+00:00, run_duration=13.595876, state=success, executor_state=success, try_number=1, max_tries=0, job_id=143, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-12 03:39:54.901170+00:00, queued_by_job_id=140, pid=4373[0m
[[34m2026-02-12T11:40:17.893+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-12T03:39:46.101513+00:00, map_index=-1, run_start_date=2026-02-12 03:39:58.993439+00:00, run_end_date=2026-02-12 03:39:59.180348+00:00, run_duration=0.186909, state=success, executor_state=success, try_number=1, max_tries=0, job_id=142, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-12 03:39:54.901170+00:00, queued_by_job_id=140, pid=4367[0m
[[34m2026-02-12T11:40:21.923+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 2 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:39:46.101513+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:39:45.982344+00:00 [scheduled]>[0m
[[34m2026-02-12T11:40:21.924+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-12T11:40:21.925+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 1/16 running and queued tasks[0m
[[34m2026-02-12T11:40:21.926+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:39:46.101513+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:39:45.982344+00:00 [scheduled]>[0m
[[34m2026-02-12T11:40:21.929+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-12T11:40:21.929+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test2 because previous state change time has not been saved[0m
[[34m2026-02-12T11:40:21.931+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-12T03:39:46.101513+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-12T11:40:21.931+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-12T03:39:46.101513+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:40:21.932+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-12T03:39:45.982344+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-12T11:40:21.933+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-12T03:39:45.982344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:40:21.935+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-12T03:39:46.101513+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:40:24.314+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:40:25.721+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:39:46.101513+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:40:40.082+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-12T03:39:45.982344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:40:43.182+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:40:44.614+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:39:45.982344+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:40:58.697+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-12T03:39:46.101513+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:40:58.699+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-12T03:39:45.982344+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:40:58.709+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-12T03:39:45.982344+00:00, map_index=-1, run_start_date=2026-02-12 03:40:44.697393+00:00, run_end_date=2026-02-12 03:40:58.105736+00:00, run_duration=13.408343, state=success, executor_state=success, try_number=1, max_tries=0, job_id=145, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-12 03:40:21.927478+00:00, queued_by_job_id=140, pid=4424[0m
[[34m2026-02-12T11:40:58.710+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-12T03:39:46.101513+00:00, map_index=-1, run_start_date=2026-02-12 03:40:25.799089+00:00, run_end_date=2026-02-12 03:40:39.449716+00:00, run_duration=13.650627, state=success, executor_state=success, try_number=1, max_tries=0, job_id=144, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-12 03:40:21.927478+00:00, queued_by_job_id=140, pid=4403[0m
[[34m2026-02-12T11:41:01.700+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-12 03:39:45.982344+00:00: manual__2026-02-12T03:39:45.982344+00:00, state:running, queued_at: 2026-02-12 03:39:45.999076+00:00. externally triggered: True> successful[0m
[[34m2026-02-12T11:41:01.701+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-12 03:39:45.982344+00:00, run_id=manual__2026-02-12T03:39:45.982344+00:00, run_start_date=2026-02-12 03:39:46.075076+00:00, run_end_date=2026-02-12 03:41:01.701510+00:00, run_duration=75.626434, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-11 00:00:00+00:00, data_interval_end=2026-02-12 00:00:00+00:00, dag_hash=f13b1da68a23e4f9a4db4a08843edabe[0m
[[34m2026-02-12T11:41:01.714+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:39:46.101513+00:00 [scheduled]>[0m
[[34m2026-02-12T11:41:01.714+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-12T11:41:01.715+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:39:46.101513+00:00 [scheduled]>[0m
[[34m2026-02-12T11:41:01.717+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test2 because previous state change time has not been saved[0m
[[34m2026-02-12T11:41:01.718+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-12T03:39:46.101513+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-12T11:41:01.719+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-12T03:39:46.101513+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:41:01.721+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-12T03:39:46.101513+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:41:04.091+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:41:05.443+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:39:46.101513+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:41:19.557+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-12T03:39:46.101513+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:41:19.570+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-12T03:39:46.101513+00:00, map_index=-1, run_start_date=2026-02-12 03:41:05.528787+00:00, run_end_date=2026-02-12 03:41:18.948990+00:00, run_duration=13.420203, state=success, executor_state=success, try_number=1, max_tries=0, job_id=146, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-12 03:41:01.716341+00:00, queued_by_job_id=140, pid=4448[0m
[[34m2026-02-12T11:41:22.493+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-12 03:39:46.101513+00:00: manual__2026-02-12T03:39:46.101513+00:00, state:running, queued_at: 2026-02-12 03:39:46.181745+00:00. externally triggered: True> successful[0m
[[34m2026-02-12T11:41:22.494+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-12 03:39:46.101513+00:00, run_id=manual__2026-02-12T03:39:46.101513+00:00, run_start_date=2026-02-12 03:39:54.871166+00:00, run_end_date=2026-02-12 03:41:22.494479+00:00, run_duration=87.623313, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-11 00:00:00+00:00, data_interval_end=2026-02-12 00:00:00+00:00, dag_hash=f13b1da68a23e4f9a4db4a08843edabe[0m
[[34m2026-02-12T11:42:02.569+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:41:59.967172+00:00 [scheduled]>[0m
[[34m2026-02-12T11:42:02.570+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-12T11:42:02.570+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:41:59.967172+00:00 [scheduled]>[0m
[[34m2026-02-12T11:42:02.572+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-12T11:42:02.573+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-12T03:41:59.967172+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2026-02-12T11:42:02.574+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-12T03:41:59.967172+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:42:02.576+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-12T03:41:59.967172+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:42:04.754+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:42:05.917+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-12T03:41:59.967172+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:42:06.822+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-12T03:41:59.967172+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:42:06.832+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-12T03:41:59.967172+00:00, map_index=-1, run_start_date=2026-02-12 03:42:05.990019+00:00, run_end_date=2026-02-12 03:42:06.159190+00:00, run_duration=0.169171, state=success, executor_state=success, try_number=1, max_tries=0, job_id=147, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-12 03:42:02.571682+00:00, queued_by_job_id=140, pid=4490[0m
[[34m2026-02-12T11:42:09.642+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:41:59.967172+00:00 [scheduled]>[0m
[[34m2026-02-12T11:42:09.643+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-12T11:42:09.644+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:41:59.967172+00:00 [scheduled]>[0m
[[34m2026-02-12T11:42:09.646+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-12T11:42:09.647+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-12T03:41:59.967172+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-12T11:42:09.648+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-12T03:41:59.967172+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:42:09.650+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-12T03:41:59.967172+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:42:11.820+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:42:13.028+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-12T03:41:59.967172+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:42:27.061+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-12T03:41:59.967172+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:42:27.072+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-12T03:41:59.967172+00:00, map_index=-1, run_start_date=2026-02-12 03:42:13.107087+00:00, run_end_date=2026-02-12 03:42:26.379439+00:00, run_duration=13.272352, state=success, executor_state=success, try_number=1, max_tries=0, job_id=148, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-12 03:42:09.645297+00:00, queued_by_job_id=140, pid=4495[0m
[[34m2026-02-12T11:42:29.715+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:41:59.967172+00:00 [scheduled]>[0m
[[34m2026-02-12T11:42:29.716+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-12T11:42:29.717+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:41:59.967172+00:00 [scheduled]>[0m
[[34m2026-02-12T11:42:29.719+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test2 because previous state change time has not been saved[0m
[[34m2026-02-12T11:42:29.720+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-12T03:41:59.967172+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-12T11:42:29.721+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-12T03:41:59.967172+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:42:29.723+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test2', 'manual__2026-02-12T03:41:59.967172+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-12T11:42:32.045+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-12T11:42:33.242+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test2 manual__2026-02-12T03:41:59.967172+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-12T11:42:47.061+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test2', run_id='manual__2026-02-12T03:41:59.967172+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-12T11:42:47.073+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test2, run_id=manual__2026-02-12T03:41:59.967172+00:00, map_index=-1, run_start_date=2026-02-12 03:42:33.315329+00:00, run_end_date=2026-02-12 03:42:46.458677+00:00, run_duration=13.143348, state=success, executor_state=success, try_number=1, max_tries=0, job_id=149, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-12 03:42:29.718318+00:00, queued_by_job_id=140, pid=4516[0m
[[34m2026-02-12T11:42:47.097+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:42:50.521+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-12 03:41:59.967172+00:00: manual__2026-02-12T03:41:59.967172+00:00, state:running, queued_at: 2026-02-12 03:41:59.988255+00:00. externally triggered: True> successful[0m
[[34m2026-02-12T11:42:50.521+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-12 03:41:59.967172+00:00, run_id=manual__2026-02-12T03:41:59.967172+00:00, run_start_date=2026-02-12 03:42:02.549340+00:00, run_end_date=2026-02-12 03:42:50.521838+00:00, run_duration=47.972498, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-11 00:00:00+00:00, data_interval_end=2026-02-12 00:00:00+00:00, dag_hash=f13b1da68a23e4f9a4db4a08843edabe[0m
[[34m2026-02-12T11:47:48.387+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-12T11:52:49.167+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
