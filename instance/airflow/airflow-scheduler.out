[[34m2026-02-11T19:49:47.099+0800[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2026-02-11T19:49:47.103+0800[0m] {[34mexecutor_loader.py:[0m115} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2026-02-11T19:49:47.187+0800[0m] {[34mscheduler_job_runner.py:[0m807} INFO[0m - Starting the scheduler[0m
[[34m2026-02-11T19:49:47.188+0800[0m] {[34mscheduler_job_runner.py:[0m814} INFO[0m - Processing each file at most -1 times[0m
[[34m2026-02-11T19:49:47.195+0800[0m] {[34mmanager.py:[0m169} INFO[0m - Launched DagFileProcessorManager with pid: 1103[0m
[[34m2026-02-11T19:49:47.202+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T19:49:50.286+0800[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[2026-02-11T19:49:50.328+0800] {manager.py:392} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2026-02-11T19:50:47.209+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>[0m
[[34m2026-02-11T19:50:47.210+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T19:50:47.211+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>[0m
[[34m2026-02-11T19:50:47.213+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T19:50:47.214+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T19:50:47.215+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T19:50:47.217+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T19:50:49.747+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T19:50:51.491+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T11:50:44.236059+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T19:50:53.631+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T19:50:53.649+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T11:50:44.236059+00:00, map_index=-1, run_start_date=2026-02-11 11:50:51.638132+00:00, run_end_date=2026-02-11 11:50:52.437203+00:00, run_duration=0.799071, state=success, executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 11:50:47.211969+00:00, queued_by_job_id=93, pid=1149[0m
[[34m2026-02-11T19:50:57.049+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>[0m
[[34m2026-02-11T19:50:57.050+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T19:50:57.051+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>[0m
[[34m2026-02-11T19:50:57.053+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T19:50:57.054+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T19:50:57.056+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T19:50:57.058+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T19:51:00.093+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T19:51:01.573+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T11:50:44.236059+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T19:51:18.050+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T19:51:18.069+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T11:50:44.236059+00:00, map_index=-1, run_start_date=2026-02-11 11:51:01.651825+00:00, run_end_date=2026-02-11 11:51:17.206445+00:00, run_duration=15.55462, state=success, executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 11:50:57.052619+00:00, queued_by_job_id=93, pid=1156[0m
[[34m2026-02-11T19:51:21.889+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 11:50:44.236059+00:00: manual__2026-02-11T11:50:44.236059+00:00, state:running, queued_at: 2026-02-11 11:50:44.272227+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T19:51:21.891+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 11:50:44.236059+00:00, run_id=manual__2026-02-11T11:50:44.236059+00:00, run_start_date=2026-02-11 11:50:47.163710+00:00, run_end_date=2026-02-11 11:51:21.891202+00:00, run_duration=34.727492, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T19:54:48.303+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T20:59:51.203+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:04:53.801+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:05:06.008+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>[0m
[[34m2026-02-11T21:05:06.009+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:05:06.009+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>[0m
[[34m2026-02-11T21:05:06.011+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:05:06.012+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:05:06.013+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:05:06.015+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:05:08.432+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:05:09.835+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:05:02.341510+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:05:10.757+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:05:10.770+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:05:02.341510+00:00, map_index=-1, run_start_date=2026-02-11 13:05:09.926357+00:00, run_end_date=2026-02-11 13:05:10.132033+00:00, run_duration=0.205676, state=success, executor_state=success, try_number=1, max_tries=0, job_id=96, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:05:06.010785+00:00, queued_by_job_id=93, pid=2031[0m
[[34m2026-02-11T21:05:14.139+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>[0m
[[34m2026-02-11T21:05:14.140+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:05:14.140+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>[0m
[[34m2026-02-11T21:05:14.142+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:05:14.144+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:05:14.144+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:05:14.147+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:05:16.617+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:05:17.927+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:05:02.341510+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:05:25.851+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:05:25.862+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:05:02.341510+00:00, map_index=-1, run_start_date=2026-02-11 13:05:18.016573+00:00, run_end_date=2026-02-11 13:05:25.202756+00:00, run_duration=7.186183, state=success, executor_state=success, try_number=1, max_tries=0, job_id=97, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:05:14.141781+00:00, queued_by_job_id=93, pid=2035[0m
[[34m2026-02-11T21:05:29.454+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:05:02.341510+00:00: manual__2026-02-11T13:05:02.341510+00:00, state:running, queued_at: 2026-02-11 13:05:02.372774+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:05:29.455+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:05:02.341510+00:00, run_id=manual__2026-02-11T13:05:02.341510+00:00, run_start_date=2026-02-11 13:05:05.989542+00:00, run_end_date=2026-02-11 13:05:29.455430+00:00, run_duration=23.465888, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:09:55.171+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:14:04.705+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>[0m
[[34m2026-02-11T21:14:04.706+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:14:04.706+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>[0m
[[34m2026-02-11T21:14:04.709+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:14:04.711+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:14:04.712+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:14:04.714+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:14:07.491+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:14:09.290+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:14:02.480310+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:14:10.193+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:14:10.207+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:14:02.480310+00:00, map_index=-1, run_start_date=2026-02-11 13:14:09.371338+00:00, run_end_date=2026-02-11 13:14:09.551631+00:00, run_duration=0.180293, state=success, executor_state=success, try_number=1, max_tries=0, job_id=98, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:14:04.707798+00:00, queued_by_job_id=93, pid=2627[0m
[[34m2026-02-11T21:14:13.294+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>[0m
[[34m2026-02-11T21:14:13.294+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:14:13.295+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>[0m
[[34m2026-02-11T21:14:13.298+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:14:13.299+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:14:13.299+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:14:13.302+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:14:15.655+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:14:16.882+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:14:02.480310+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:14:19.874+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:14:19.888+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:14:02.480310+00:00, map_index=-1, run_start_date=2026-02-11 13:14:16.970903+00:00, run_end_date=2026-02-11 13:14:19.194837+00:00, run_duration=2.223934, state=success, executor_state=success, try_number=1, max_tries=0, job_id=99, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:14:13.297008+00:00, queued_by_job_id=93, pid=2631[0m
[[34m2026-02-11T21:14:22.887+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:14:02.480310+00:00: manual__2026-02-11T13:14:02.480310+00:00, state:running, queued_at: 2026-02-11 13:14:02.506343+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:14:22.887+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:14:02.480310+00:00, run_id=manual__2026-02-11T13:14:02.480310+00:00, run_start_date=2026-02-11 13:14:04.682347+00:00, run_end_date=2026-02-11 13:14:22.887842+00:00, run_duration=18.205495, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:14:55.634+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:19:06.197+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>[0m
[[34m2026-02-11T21:19:06.198+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:19:06.199+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>[0m
[[34m2026-02-11T21:19:06.201+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:19:06.202+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:19:06.202+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:19:06.204+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:19:09.045+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:19:10.325+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:19:03.976200+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:19:11.264+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:19:11.273+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:19:03.976200+00:00, map_index=-1, run_start_date=2026-02-11 13:19:10.406433+00:00, run_end_date=2026-02-11 13:19:10.583585+00:00, run_duration=0.177152, state=success, executor_state=success, try_number=1, max_tries=0, job_id=100, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:19:06.199988+00:00, queued_by_job_id=93, pid=2899[0m
[[34m2026-02-11T21:19:14.153+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>[0m
[[34m2026-02-11T21:19:14.154+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:19:14.155+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>[0m
[[34m2026-02-11T21:19:14.157+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:19:14.158+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:19:14.158+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:19:14.161+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:19:16.565+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:19:17.797+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:19:03.976200+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:19:20.505+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:19:20.514+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:19:03.976200+00:00, map_index=-1, run_start_date=2026-02-11 13:19:17.872533+00:00, run_end_date=2026-02-11 13:19:19.856529+00:00, run_duration=1.983996, state=success, executor_state=success, try_number=1, max_tries=0, job_id=101, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:19:14.156003+00:00, queued_by_job_id=93, pid=2905[0m
[[34m2026-02-11T21:19:23.508+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:19:03.976200+00:00: manual__2026-02-11T13:19:03.976200+00:00, state:running, queued_at: 2026-02-11 13:19:03.996122+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:19:23.509+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:19:03.976200+00:00, run_id=manual__2026-02-11T13:19:03.976200+00:00, run_start_date=2026-02-11 13:19:06.175764+00:00, run_end_date=2026-02-11 13:19:23.509103+00:00, run_duration=17.333339, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:19:58.070+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:23:25.767+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>[0m
[[34m2026-02-11T21:23:25.768+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:23:25.769+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>[0m
[[34m2026-02-11T21:23:25.771+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:23:25.772+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:23:25.772+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:23:25.774+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:23:28.014+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:23:29.795+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:23:22.474344+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:23:30.828+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:23:30.840+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:23:22.474344+00:00, map_index=-1, run_start_date=2026-02-11 13:23:29.878014+00:00, run_end_date=2026-02-11 13:23:30.055923+00:00, run_duration=0.177909, state=success, executor_state=success, try_number=1, max_tries=0, job_id=102, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:23:25.770124+00:00, queued_by_job_id=93, pid=3165[0m
[[34m2026-02-11T21:23:34.057+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>[0m
[[34m2026-02-11T21:23:34.059+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:23:34.060+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>[0m
[[34m2026-02-11T21:23:34.062+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:23:34.063+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:23:34.064+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:23:34.066+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:23:36.612+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:23:38.164+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:23:22.474344+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:23:41.294+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:23:41.303+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:23:22.474344+00:00, map_index=-1, run_start_date=2026-02-11 13:23:38.253564+00:00, run_end_date=2026-02-11 13:23:40.613808+00:00, run_duration=2.360244, state=success, executor_state=success, try_number=1, max_tries=0, job_id=103, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:23:34.061620+00:00, queued_by_job_id=93, pid=3175[0m
[[34m2026-02-11T21:23:44.486+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:23:22.474344+00:00: manual__2026-02-11T13:23:22.474344+00:00, state:running, queued_at: 2026-02-11 13:23:22.486240+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:23:44.487+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:23:22.474344+00:00, run_id=manual__2026-02-11T13:23:22.474344+00:00, run_start_date=2026-02-11 13:23:25.749502+00:00, run_end_date=2026-02-11 13:23:44.487725+00:00, run_duration=18.738223, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:25:00.407+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:30:01.937+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:34:40.014+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>[0m
[[34m2026-02-11T21:34:40.015+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:34:40.016+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>[0m
[[34m2026-02-11T21:34:40.019+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:34:40.020+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:34:40.020+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:34:40.023+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:34:42.687+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:34:44.299+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:34:36.593158+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:34:45.188+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:34:45.196+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:34:36.593158+00:00, map_index=-1, run_start_date=2026-02-11 13:34:44.379490+00:00, run_end_date=2026-02-11 13:34:44.568175+00:00, run_duration=0.188685, state=success, executor_state=success, try_number=1, max_tries=0, job_id=104, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:34:40.017800+00:00, queued_by_job_id=93, pid=3765[0m
[[34m2026-02-11T21:34:48.071+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>[0m
[[34m2026-02-11T21:34:48.072+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:34:48.073+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>[0m
[[34m2026-02-11T21:34:48.075+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:34:48.076+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:34:48.077+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:34:48.079+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:34:50.369+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:34:51.581+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:34:36.593158+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:34:54.368+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:34:54.377+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:34:36.593158+00:00, map_index=-1, run_start_date=2026-02-11 13:34:51.657620+00:00, run_end_date=2026-02-11 13:34:53.677940+00:00, run_duration=2.02032, state=success, executor_state=success, try_number=1, max_tries=0, job_id=105, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:34:48.074138+00:00, queued_by_job_id=93, pid=3769[0m
[[34m2026-02-11T21:34:57.421+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:34:36.593158+00:00: manual__2026-02-11T13:34:36.593158+00:00, state:running, queued_at: 2026-02-11 13:34:36.605715+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:34:57.422+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:34:36.593158+00:00, run_id=manual__2026-02-11T13:34:36.593158+00:00, run_start_date=2026-02-11 13:34:39.990771+00:00, run_end_date=2026-02-11 13:34:57.422034+00:00, run_duration=17.431263, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:35:04.605+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:37:37.320+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>[0m
[[34m2026-02-11T21:37:37.323+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:37:37.325+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>[0m
[[34m2026-02-11T21:37:37.328+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:37:37.329+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:37:37.329+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:37:37.332+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:37:40.003+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:37:41.803+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:37:36.537391+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:37:42.734+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:37:42.746+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:37:36.537391+00:00, map_index=-1, run_start_date=2026-02-11 13:37:41.882286+00:00, run_end_date=2026-02-11 13:37:42.065775+00:00, run_duration=0.183489, state=success, executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:37:37.326976+00:00, queued_by_job_id=93, pid=3943[0m
[[34m2026-02-11T21:37:45.656+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>[0m
[[34m2026-02-11T21:37:45.656+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:37:45.658+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>[0m
[[34m2026-02-11T21:37:45.660+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:37:45.661+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:37:45.661+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:37:45.663+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:37:47.986+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:37:49.219+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:37:36.537391+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:37:51.986+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:37:51.995+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:37:36.537391+00:00, map_index=-1, run_start_date=2026-02-11 13:37:49.300973+00:00, run_end_date=2026-02-11 13:37:51.291899+00:00, run_duration=1.990926, state=success, executor_state=success, try_number=1, max_tries=0, job_id=107, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:37:45.659179+00:00, queued_by_job_id=93, pid=3947[0m
[[34m2026-02-11T21:37:54.897+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:37:36.537391+00:00: manual__2026-02-11T13:37:36.537391+00:00, state:running, queued_at: 2026-02-11 13:37:36.548199+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:37:54.898+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:37:36.537391+00:00, run_id=manual__2026-02-11T13:37:36.537391+00:00, run_start_date=2026-02-11 13:37:37.280574+00:00, run_end_date=2026-02-11 13:37:54.898275+00:00, run_duration=17.617701, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:40:05.432+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:42:10.068+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>[0m
[[34m2026-02-11T21:42:10.069+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:42:10.070+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>[0m
[[34m2026-02-11T21:42:10.072+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:42:10.073+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:42:10.074+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:42:10.076+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:42:12.914+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:42:14.831+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:42:06.098390+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:42:16.009+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:42:16.021+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:42:06.098390+00:00, map_index=-1, run_start_date=2026-02-11 13:42:14.977714+00:00, run_end_date=2026-02-11 13:42:15.202350+00:00, run_duration=0.224636, state=success, executor_state=success, try_number=1, max_tries=0, job_id=108, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:42:10.071255+00:00, queued_by_job_id=93, pid=4261[0m
[[34m2026-02-11T21:42:19.036+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>[0m
[[34m2026-02-11T21:42:19.037+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:42:19.038+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>[0m
[[34m2026-02-11T21:42:19.040+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:42:19.041+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:42:19.042+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:42:19.044+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:42:21.579+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:42:22.971+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:42:06.098390+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:42:26.033+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:42:26.044+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:42:06.098390+00:00, map_index=-1, run_start_date=2026-02-11 13:42:23.050722+00:00, run_end_date=2026-02-11 13:42:25.358396+00:00, run_duration=2.307674, state=success, executor_state=success, try_number=1, max_tries=0, job_id=109, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:42:19.039312+00:00, queued_by_job_id=93, pid=4265[0m
[[34m2026-02-11T21:42:28.890+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:42:06.098390+00:00: manual__2026-02-11T13:42:06.098390+00:00, state:running, queued_at: 2026-02-11 13:42:06.109305+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:42:28.891+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:42:06.098390+00:00, run_id=manual__2026-02-11T13:42:06.098390+00:00, run_start_date=2026-02-11 13:42:10.043511+00:00, run_end_date=2026-02-11 13:42:28.891156+00:00, run_duration=18.847645, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:45:08.342+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:45:12.598+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>[0m
[[34m2026-02-11T21:45:12.599+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:45:12.600+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>[0m
[[34m2026-02-11T21:45:12.602+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:45:12.602+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:45:12.603+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:45:12.605+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:45:15.213+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:45:17.053+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:45:11.332773+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:45:17.971+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:45:17.979+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:45:11.332773+00:00, map_index=-1, run_start_date=2026-02-11 13:45:17.144642+00:00, run_end_date=2026-02-11 13:45:17.320385+00:00, run_duration=0.175743, state=success, executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:45:12.601087+00:00, queued_by_job_id=93, pid=4445[0m
[[34m2026-02-11T21:45:21.124+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>[0m
[[34m2026-02-11T21:45:21.125+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:45:21.125+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>[0m
[[34m2026-02-11T21:45:21.127+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:45:21.128+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:45:21.129+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:45:21.131+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:45:23.502+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:45:24.734+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:45:11.332773+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:45:27.542+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:45:27.552+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:45:11.332773+00:00, map_index=-1, run_start_date=2026-02-11 13:45:24.808986+00:00, run_end_date=2026-02-11 13:45:26.932855+00:00, run_duration=2.123869, state=success, executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:45:21.126531+00:00, queued_by_job_id=93, pid=4457[0m
[[34m2026-02-11T21:45:30.711+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:45:11.332773+00:00: manual__2026-02-11T13:45:11.332773+00:00, state:running, queued_at: 2026-02-11 13:45:11.343680+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:45:30.712+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:45:11.332773+00:00, run_id=manual__2026-02-11T13:45:11.332773+00:00, run_start_date=2026-02-11 13:45:12.576379+00:00, run_end_date=2026-02-11 13:45:30.712285+00:00, run_duration=18.135906, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:50:09.151+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:51:54.565+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>[0m
[[34m2026-02-11T21:51:54.565+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:51:54.566+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>[0m
[[34m2026-02-11T21:51:54.568+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:51:54.569+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:51:54.570+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:51:54.572+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:51:57.177+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:51:58.847+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:51:53.606280+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:51:59.756+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:51:59.765+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:51:53.606280+00:00, map_index=-1, run_start_date=2026-02-11 13:51:58.929545+00:00, run_end_date=2026-02-11 13:51:59.116235+00:00, run_duration=0.18669, state=success, executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:51:54.567627+00:00, queued_by_job_id=93, pid=4778[0m
[[34m2026-02-11T21:52:02.577+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>[0m
[[34m2026-02-11T21:52:02.578+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:52:02.579+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>[0m
[[34m2026-02-11T21:52:02.581+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:52:02.582+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:52:02.583+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:52:02.585+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:52:04.870+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:52:06.090+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:51:53.606280+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:52:08.971+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:52:08.983+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:51:53.606280+00:00, map_index=-1, run_start_date=2026-02-11 13:52:06.165166+00:00, run_end_date=2026-02-11 13:52:08.284392+00:00, run_duration=2.119226, state=success, executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:52:02.580306+00:00, queued_by_job_id=93, pid=4785[0m
[[34m2026-02-11T21:52:11.769+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:51:53.606280+00:00: manual__2026-02-11T13:51:53.606280+00:00, state:running, queued_at: 2026-02-11 13:51:53.626641+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:52:11.770+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:51:53.606280+00:00, run_id=manual__2026-02-11T13:51:53.606280+00:00, run_start_date=2026-02-11 13:51:54.542967+00:00, run_end_date=2026-02-11 13:52:11.770204+00:00, run_duration=17.227237, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T21:55:10.944+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T21:57:48.651+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>[0m
[[34m2026-02-11T21:57:48.652+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:57:48.652+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>[0m
[[34m2026-02-11T21:57:48.654+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T21:57:48.655+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T21:57:48.655+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:57:48.657+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:57:50.956+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:57:52.441+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:57:45.161908+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:57:53.551+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:57:53.561+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:57:45.161908+00:00, map_index=-1, run_start_date=2026-02-11 13:57:52.568219+00:00, run_end_date=2026-02-11 13:57:52.798058+00:00, run_duration=0.229839, state=success, executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:57:48.653419+00:00, queued_by_job_id=93, pid=5020[0m
[[34m2026-02-11T21:57:56.795+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>[0m
[[34m2026-02-11T21:57:56.796+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T21:57:56.797+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>[0m
[[34m2026-02-11T21:57:56.799+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T21:57:56.800+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T21:57:56.801+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:57:56.803+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T21:57:59.147+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T21:58:00.530+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:57:45.161908+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T21:58:03.725+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T21:58:03.734+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:57:45.161908+00:00, map_index=-1, run_start_date=2026-02-11 13:58:00.613029+00:00, run_end_date=2026-02-11 13:58:03.051725+00:00, run_duration=2.438696, state=success, executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:57:56.798111+00:00, queued_by_job_id=93, pid=5024[0m
[[34m2026-02-11T21:58:07.370+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 13:57:45.161908+00:00: manual__2026-02-11T13:57:45.161908+00:00, state:running, queued_at: 2026-02-11 13:57:45.173955+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T21:58:07.371+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:57:45.161908+00:00, run_id=manual__2026-02-11T13:57:45.161908+00:00, run_start_date=2026-02-11 13:57:48.626749+00:00, run_end_date=2026-02-11 13:58:07.371771+00:00, run_duration=18.745022, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:00:14.735+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:05:16.671+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:10:18.039+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:15:20.563+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:20:21.200+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:22:08.516+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>[0m
[[34m2026-02-11T22:22:08.517+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:22:08.517+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>[0m
[[34m2026-02-11T22:22:08.519+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:22:08.520+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:22:08.521+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:22:08.523+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:22:10.733+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:22:12.020+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:22:04.982000+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:22:13.028+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:22:13.043+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:22:04.982000+00:00, map_index=-1, run_start_date=2026-02-11 14:22:12.100972+00:00, run_end_date=2026-02-11 14:22:12.285802+00:00, run_duration=0.18483, state=success, executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:22:08.518390+00:00, queued_by_job_id=93, pid=5877[0m
[[34m2026-02-11T22:22:16.335+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>[0m
[[34m2026-02-11T22:22:16.336+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:22:16.337+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>[0m
[[34m2026-02-11T22:22:16.339+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:22:16.340+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:22:16.341+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:22:16.343+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:22:18.691+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:22:19.923+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:22:04.982000+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:22:22.992+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:22:23.007+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:22:04.982000+00:00, map_index=-1, run_start_date=2026-02-11 14:22:20.001092+00:00, run_end_date=2026-02-11 14:22:22.310501+00:00, run_duration=2.309409, state=success, executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:22:16.338146+00:00, queued_by_job_id=93, pid=5885[0m
[[34m2026-02-11T22:22:25.813+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:22:04.982000+00:00: manual__2026-02-11T14:22:04.982000+00:00, state:running, queued_at: 2026-02-11 14:22:04.994901+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:22:25.815+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:22:04.982000+00:00, run_id=manual__2026-02-11T14:22:04.982000+00:00, run_start_date=2026-02-11 14:22:08.496444+00:00, run_end_date=2026-02-11 14:22:25.815010+00:00, run_duration=17.318566, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:23:26.305+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>[0m
[[34m2026-02-11T22:23:26.306+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:23:26.307+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>[0m
[[34m2026-02-11T22:23:26.309+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:23:26.310+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:23:26.311+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:23:26.313+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:23:28.470+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:23:29.789+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:23:22.716575+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:23:30.784+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:23:30.801+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:23:22.716575+00:00, map_index=-1, run_start_date=2026-02-11 14:23:29.865013+00:00, run_end_date=2026-02-11 14:23:30.047501+00:00, run_duration=0.182488, state=success, executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:23:26.308389+00:00, queued_by_job_id=93, pid=5957[0m
[[34m2026-02-11T22:23:33.958+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>[0m
[[34m2026-02-11T22:23:33.959+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:23:33.960+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>[0m
[[34m2026-02-11T22:23:33.962+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:23:33.963+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:23:33.964+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:23:33.966+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:23:36.300+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:23:37.530+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:23:22.716575+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:23:40.305+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:23:40.317+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:23:22.716575+00:00, map_index=-1, run_start_date=2026-02-11 14:23:37.607422+00:00, run_end_date=2026-02-11 14:23:39.643012+00:00, run_duration=2.03559, state=success, executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:23:33.961121+00:00, queued_by_job_id=93, pid=5963[0m
[[34m2026-02-11T22:23:43.251+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:23:22.716575+00:00: manual__2026-02-11T14:23:22.716575+00:00, state:running, queued_at: 2026-02-11 14:23:22.728972+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:23:43.252+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:23:22.716575+00:00, run_id=manual__2026-02-11T14:23:22.716575+00:00, run_start_date=2026-02-11 14:23:26.284947+00:00, run_end_date=2026-02-11 14:23:43.252408+00:00, run_duration=16.967461, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:24:29.057+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>[0m
[[34m2026-02-11T22:24:29.057+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:24:29.058+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>[0m
[[34m2026-02-11T22:24:29.060+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:24:29.061+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:24:29.062+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:24:29.064+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:24:31.220+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:24:32.699+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:24:25.278535+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:24:33.769+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:24:33.783+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:24:25.278535+00:00, map_index=-1, run_start_date=2026-02-11 14:24:32.782183+00:00, run_end_date=2026-02-11 14:24:33.018163+00:00, run_duration=0.23598, state=success, executor_state=success, try_number=1, max_tries=0, job_id=120, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:24:29.059208+00:00, queued_by_job_id=93, pid=6025[0m
[[34m2026-02-11T22:24:36.878+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>[0m
[[34m2026-02-11T22:24:36.879+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:24:36.880+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>[0m
[[34m2026-02-11T22:24:36.882+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:24:36.883+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:24:36.885+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:24:36.887+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:24:39.393+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:24:40.680+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:24:25.278535+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:24:43.353+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:24:43.366+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:24:25.278535+00:00, map_index=-1, run_start_date=2026-02-11 14:24:40.756154+00:00, run_end_date=2026-02-11 14:24:42.651397+00:00, run_duration=1.895243, state=success, executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:24:36.880987+00:00, queued_by_job_id=93, pid=6031[0m
[[34m2026-02-11T22:24:46.377+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:24:25.278535+00:00: manual__2026-02-11T14:24:25.278535+00:00, state:running, queued_at: 2026-02-11 14:24:25.290518+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:24:46.378+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:24:25.278535+00:00, run_id=manual__2026-02-11T14:24:25.278535+00:00, run_start_date=2026-02-11 14:24:29.036943+00:00, run_end_date=2026-02-11 14:24:46.378445+00:00, run_duration=17.341502, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:25:23.044+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:30:25.624+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:34:02.793+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>[0m
[[34m2026-02-11T22:34:02.794+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:34:02.795+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>[0m
[[34m2026-02-11T22:34:02.796+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:34:02.797+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:34:02.798+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:34:02.800+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:34:05.227+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:34:06.735+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:34:01.458331+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:34:07.660+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:34:07.671+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:34:01.458331+00:00, map_index=-1, run_start_date=2026-02-11 14:34:06.817026+00:00, run_end_date=2026-02-11 14:34:06.984005+00:00, run_duration=0.166979, state=success, executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:34:02.795914+00:00, queued_by_job_id=93, pid=6356[0m
[[34m2026-02-11T22:34:10.882+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>[0m
[[34m2026-02-11T22:34:10.884+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:34:10.886+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>[0m
[[34m2026-02-11T22:34:10.891+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:34:10.894+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:34:10.896+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:34:10.899+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:34:13.775+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:34:15.193+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:34:01.458331+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:34:18.330+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:34:18.345+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:34:01.458331+00:00, map_index=-1, run_start_date=2026-02-11 14:34:15.274814+00:00, run_end_date=2026-02-11 14:34:17.650822+00:00, run_duration=2.376008, state=success, executor_state=success, try_number=1, max_tries=0, job_id=123, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:34:10.889656+00:00, queued_by_job_id=93, pid=6360[0m
[[34m2026-02-11T22:34:21.201+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:34:01.458331+00:00: manual__2026-02-11T14:34:01.458331+00:00, state:running, queued_at: 2026-02-11 14:34:01.472530+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:34:21.202+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:34:01.458331+00:00, run_id=manual__2026-02-11T14:34:01.458331+00:00, run_start_date=2026-02-11 14:34:02.771449+00:00, run_end_date=2026-02-11 14:34:21.202514+00:00, run_duration=18.431065, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:35:26.556+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:35:30.842+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>[0m
[[34m2026-02-11T22:35:30.843+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:35:30.844+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>[0m
[[34m2026-02-11T22:35:30.846+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:35:30.847+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:35:30.847+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:35:30.849+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:35:33.181+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:35:34.385+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:35:28.256387+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:35:35.306+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:35:35.318+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:35:28.256387+00:00, map_index=-1, run_start_date=2026-02-11 14:35:34.456559+00:00, run_end_date=2026-02-11 14:35:34.622624+00:00, run_duration=0.166065, state=success, executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:35:30.845075+00:00, queued_by_job_id=93, pid=6417[0m
[[34m2026-02-11T22:35:38.456+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>[0m
[[34m2026-02-11T22:35:38.457+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:35:38.457+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>[0m
[[34m2026-02-11T22:35:38.460+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:35:38.461+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:35:38.462+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:35:38.464+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:35:41.074+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:35:42.374+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:35:28.256387+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:35:45.438+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:35:45.451+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:35:28.256387+00:00, map_index=-1, run_start_date=2026-02-11 14:35:42.466015+00:00, run_end_date=2026-02-11 14:35:44.750256+00:00, run_duration=2.284241, state=success, executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:35:38.458848+00:00, queued_by_job_id=93, pid=6421[0m
[[34m2026-02-11T22:35:48.467+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:35:28.256387+00:00: manual__2026-02-11T14:35:28.256387+00:00, state:running, queued_at: 2026-02-11 14:35:28.271560+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:35:48.468+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:35:28.256387+00:00, run_id=manual__2026-02-11T14:35:28.256387+00:00, run_start_date=2026-02-11 14:35:30.823267+00:00, run_end_date=2026-02-11 14:35:48.468835+00:00, run_duration=17.645568, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:38:38.682+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>[0m
[[34m2026-02-11T22:38:38.683+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:38:38.684+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>[0m
[[34m2026-02-11T22:38:38.686+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:38:38.687+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:38:38.687+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:38:38.689+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:38:41.037+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:38:42.374+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:38:36.954264+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:38:43.329+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:38:43.340+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:38:36.954264+00:00, map_index=-1, run_start_date=2026-02-11 14:38:42.458616+00:00, run_end_date=2026-02-11 14:38:42.631193+00:00, run_duration=0.172577, state=success, executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:38:38.685059+00:00, queued_by_job_id=93, pid=6547[0m
[[34m2026-02-11T22:38:46.501+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>[0m
[[34m2026-02-11T22:38:46.502+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:38:46.503+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>[0m
[[34m2026-02-11T22:38:46.505+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:38:46.506+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:38:46.506+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:38:46.508+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:38:49.142+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:38:50.411+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:38:36.954264+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:38:53.514+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:38:53.527+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:38:36.954264+00:00, map_index=-1, run_start_date=2026-02-11 14:38:50.527365+00:00, run_end_date=2026-02-11 14:38:52.875238+00:00, run_duration=2.347873, state=success, executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:38:46.503916+00:00, queued_by_job_id=93, pid=6551[0m
[[34m2026-02-11T22:38:56.730+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:38:36.954264+00:00: manual__2026-02-11T14:38:36.954264+00:00, state:running, queued_at: 2026-02-11 14:38:36.966597+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:38:56.731+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:38:36.954264+00:00, run_id=manual__2026-02-11T14:38:36.954264+00:00, run_start_date=2026-02-11 14:38:38.662196+00:00, run_end_date=2026-02-11 14:38:56.731846+00:00, run_duration=18.06965, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:40:29.125+0800[0m] {[34mscheduler_job_runner.py:[0m1607} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2026-02-11T22:40:45.697+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>[0m
[[34m2026-02-11T22:40:45.698+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:40:45.699+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>[0m
[[34m2026-02-11T22:40:45.700+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:40:45.701+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:40:45.702+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:40:45.704+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:40:47.957+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:40:49.389+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:40:42.202549+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:40:50.410+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:40:50.421+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:40:42.202549+00:00, map_index=-1, run_start_date=2026-02-11 14:40:49.471193+00:00, run_end_date=2026-02-11 14:40:49.735819+00:00, run_duration=0.264626, state=success, executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:40:45.699818+00:00, queued_by_job_id=93, pid=6647[0m
[[34m2026-02-11T22:40:53.334+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>[0m
[[34m2026-02-11T22:40:53.334+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:40:53.335+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>[0m
[[34m2026-02-11T22:40:53.337+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:40:53.338+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:40:53.339+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:40:53.341+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:40:55.992+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:40:57.291+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:40:42.202549+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:41:00.181+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:41:00.192+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:40:42.202549+00:00, map_index=-1, run_start_date=2026-02-11 14:40:57.367827+00:00, run_end_date=2026-02-11 14:40:59.471165+00:00, run_duration=2.103338, state=success, executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:40:53.336536+00:00, queued_by_job_id=93, pid=6656[0m
[[34m2026-02-11T22:41:03.073+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:40:42.202549+00:00: manual__2026-02-11T14:40:42.202549+00:00, state:running, queued_at: 2026-02-11 14:40:42.219959+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:41:03.075+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:40:42.202549+00:00, run_id=manual__2026-02-11T14:40:42.202549+00:00, run_start_date=2026-02-11 14:40:45.676527+00:00, run_end_date=2026-02-11 14:41:03.075445+00:00, run_duration=17.398918, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
[[34m2026-02-11T22:41:53.592+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>[0m
[[34m2026-02-11T22:41:53.593+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:41:53.594+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>[0m
[[34m2026-02-11T22:41:53.596+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved[0m
[[34m2026-02-11T22:41:53.597+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2026-02-11T22:41:53.597+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:41:53.599+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:41:55.705+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:41:56.840+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:41:50.369709+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:41:57.839+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:41:57.879+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:41:50.369709+00:00, map_index=-1, run_start_date=2026-02-11 14:41:56.916014+00:00, run_end_date=2026-02-11 14:41:57.108020+00:00, run_duration=0.192006, state=success, executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:41:53.595162+00:00, queued_by_job_id=93, pid=6695[0m
[[34m2026-02-11T22:42:01.095+0800[0m] {[34mscheduler_job_runner.py:[0m423} INFO[0m - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>[0m
[[34m2026-02-11T22:42:01.096+0800[0m] {[34mscheduler_job_runner.py:[0m486} INFO[0m - DAG dw_order_sync has 0/16 running and queued tasks[0m
[[34m2026-02-11T22:42:01.097+0800[0m] {[34mscheduler_job_runner.py:[0m602} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>[0m
[[34m2026-02-11T22:42:01.099+0800[0m] {[34mtaskinstance.py:[0m2286} WARNING[0m - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved[0m
[[34m2026-02-11T22:42:01.100+0800[0m] {[34mscheduler_job_runner.py:[0m645} INFO[0m - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2026-02-11T22:42:01.101+0800[0m] {[34mbase_executor.py:[0m146} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:42:01.103+0800[0m] {[34msequential_executor.py:[0m73} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py'][0m
[[34m2026-02-11T22:42:03.417+0800[0m] {[34mdagbag.py:[0m540} INFO[0m - Filling up the DagBag from /Users/linghuchong/Downloads/51/Python/project/instance/airflow/dags/tag_data_warehouse/dw_order_sync.py[0m
[[34m2026-02-11T22:42:04.630+0800[0m] {[34mtask_command.py:[0m423} INFO[0m - Running <TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:41:50.369709+00:00 [queued]> on host localhost-2.local[0m
[[34m2026-02-11T22:42:19.015+0800[0m] {[34mscheduler_job_runner.py:[0m695} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1)[0m
[[34m2026-02-11T22:42:19.029+0800[0m] {[34mscheduler_job_runner.py:[0m732} INFO[0m - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:41:50.369709+00:00, map_index=-1, run_start_date=2026-02-11 14:42:04.706372+00:00, run_end_date=2026-02-11 14:42:18.347317+00:00, run_duration=13.640945, state=success, executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:42:01.098519+00:00, queued_by_job_id=93, pid=6702[0m
[[34m2026-02-11T22:42:22.898+0800[0m] {[34mdagrun.py:[0m795} INFO[0m - Marking run <DagRun dw_order_sync @ 2026-02-11 14:41:50.369709+00:00: manual__2026-02-11T14:41:50.369709+00:00, state:running, queued_at: 2026-02-11 14:41:50.381954+00:00. externally triggered: True> successful[0m
[[34m2026-02-11T22:42:22.899+0800[0m] {[34mdagrun.py:[0m846} INFO[0m - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:41:50.369709+00:00, run_id=manual__2026-02-11T14:41:50.369709+00:00, run_start_date=2026-02-11 14:41:53.571963+00:00, run_end_date=2026-02-11 14:42:22.899708+00:00, run_duration=29.327745, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20[0m
