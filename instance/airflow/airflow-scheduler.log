2026-02-11 12:15:43,168 INFO - Task context logging is enabled
2026-02-11 12:15:43,171 INFO - Loaded executor: SequentialExecutor
2026-02-11 12:15:43,243 INFO - Starting the scheduler
2026-02-11 12:15:43,244 INFO - Processing each file at most -1 times
2026-02-11 12:15:43,251 INFO - Launched DagFileProcessorManager with pid: 8074
2026-02-11 12:15:43,257 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 12:16:28,752 INFO - Setting next_dagrun for test_automation_workflow12 to 2026-02-11 00:00:00+00:00, run_after=2026-02-12 00:00:00+00:00
2026-02-11 12:16:28,806 INFO - 2 tasks up for execution:
	<TaskInstance: test_automation_workflow12.set_api_key scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.some_task scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 12:16:28,807 INFO - DAG test_automation_workflow12 has 0/16 running and queued tasks
2026-02-11 12:16:28,808 INFO - DAG test_automation_workflow12 has 1/16 running and queued tasks
2026-02-11 12:16:28,809 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_automation_workflow12.set_api_key scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.some_task scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 12:16:28,811 WARNING - cannot record scheduled_duration for task set_api_key because previous state change time has not been saved
2026-02-11 12:16:28,812 WARNING - cannot record scheduled_duration for task some_task because previous state change time has not been saved
2026-02-11 12:16:28,813 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='set_api_key', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2026-02-11 12:16:28,814 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'set_api_key', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:28,815 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='some_task', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 12:16:28,816 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'some_task', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:28,818 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'set_api_key', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:34,972 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'some_task', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:40,473 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='set_api_key', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 12:16:40,477 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='some_task', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 12:16:40,495 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=set_api_key, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 04:16:33.710082+00:00, run_end_date=2026-02-11 04:16:34.161141+00:00, run_duration=0.451059, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2026-02-11 04:16:28.810295+00:00, queued_by_job_id=1, pid=8111
2026-02-11 12:16:40,496 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=some_task, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 04:16:38.928175+00:00, run_end_date=2026-02-11 04:16:39.552324+00:00, run_duration=0.624149, state=success, executor_state=success, try_number=1, max_tries=1, job_id=3, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 04:16:28.810295+00:00, queued_by_job_id=1, pid=8116
2026-02-11 12:16:43,776 INFO - 3 tasks up for execution:
	<TaskInstance: test_automation_workflow12.set_api_key manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.generate_test_cases scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.some_task manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
2026-02-11 12:16:43,777 INFO - DAG test_automation_workflow12 has 0/16 running and queued tasks
2026-02-11 12:16:43,778 INFO - DAG test_automation_workflow12 has 1/16 running and queued tasks
2026-02-11 12:16:43,778 INFO - DAG test_automation_workflow12 has 2/16 running and queued tasks
2026-02-11 12:16:43,779 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_automation_workflow12.set_api_key manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.generate_test_cases scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.some_task manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
2026-02-11 12:16:43,782 WARNING - cannot record scheduled_duration for task set_api_key because previous state change time has not been saved
2026-02-11 12:16:43,782 WARNING - cannot record scheduled_duration for task generate_test_cases because previous state change time has not been saved
2026-02-11 12:16:43,783 WARNING - cannot record scheduled_duration for task some_task because previous state change time has not been saved
2026-02-11 12:16:43,785 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='set_api_key', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default
2026-02-11 12:16:43,786 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'set_api_key', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:43,786 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='generate_test_cases', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2026-02-11 12:16:43,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'generate_test_cases', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:43,787 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='some_task', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 12:16:43,788 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'some_task', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:43,790 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'set_api_key', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:16:48,528 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'generate_test_cases', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:03,442 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'some_task', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:09,239 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='set_api_key', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:09,242 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='generate_test_cases', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:09,243 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='some_task', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:09,257 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=generate_test_cases, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 04:16:52.463377+00:00, run_end_date=2026-02-11 04:17:02.792984+00:00, run_duration=10.329607, state=success, executor_state=success, try_number=1, max_tries=1, job_id=5, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-11 04:16:43.780359+00:00, queued_by_job_id=1, pid=8130
2026-02-11 12:17:09,258 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=set_api_key, run_id=manual__2026-02-11T04:16:31.174742+00:00, map_index=-1, run_start_date=2026-02-11 04:16:47.426217+00:00, run_end_date=2026-02-11 04:16:47.842060+00:00, run_duration=0.415843, state=success, executor_state=success, try_number=1, max_tries=1, job_id=4, pool=default_pool, queue=default, priority_weight=4, operator=BashOperator, queued_dttm=2026-02-11 04:16:43.780359+00:00, queued_by_job_id=1, pid=8127
2026-02-11 12:17:09,259 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=some_task, run_id=manual__2026-02-11T04:16:31.174742+00:00, map_index=-1, run_start_date=2026-02-11 04:17:08.202784+00:00, run_end_date=2026-02-11 04:17:08.603387+00:00, run_duration=0.400603, state=success, executor_state=success, try_number=1, max_tries=1, job_id=6, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 04:16:43.780359+00:00, queued_by_job_id=1, pid=8146
2026-02-11 12:17:12,227 INFO - 2 tasks up for execution:
	<TaskInstance: test_automation_workflow12.generate_test_cases manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.run_automation_test scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 12:17:12,228 INFO - DAG test_automation_workflow12 has 0/16 running and queued tasks
2026-02-11 12:17:12,228 INFO - DAG test_automation_workflow12 has 1/16 running and queued tasks
2026-02-11 12:17:12,229 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_automation_workflow12.generate_test_cases manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.run_automation_test scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 12:17:12,232 WARNING - cannot record scheduled_duration for task generate_test_cases because previous state change time has not been saved
2026-02-11 12:17:12,233 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 12:17:12,234 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='generate_test_cases', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2026-02-11 12:17:12,235 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'generate_test_cases', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:12,235 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='run_automation_test', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 12:17:12,236 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'run_automation_test', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:12,238 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'generate_test_cases', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:28,116 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'run_automation_test', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:34,426 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='generate_test_cases', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:34,429 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='run_automation_test', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:34,442 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=run_automation_test, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 04:17:31.747725+00:00, run_end_date=2026-02-11 04:17:33.827616+00:00, run_duration=2.079891, state=success, executor_state=success, try_number=1, max_tries=1, job_id=8, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-11 04:17:12.230500+00:00, queued_by_job_id=1, pid=8158
2026-02-11 12:17:34,443 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=generate_test_cases, run_id=manual__2026-02-11T04:16:31.174742+00:00, map_index=-1, run_start_date=2026-02-11 04:17:15.808726+00:00, run_end_date=2026-02-11 04:17:27.510526+00:00, run_duration=11.7018, state=success, executor_state=success, try_number=1, max_tries=1, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2026-02-11 04:17:12.230500+00:00, queued_by_job_id=1, pid=8151
2026-02-11 12:17:37,348 INFO - 2 tasks up for execution:
	<TaskInstance: test_automation_workflow12.run_automation_test manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.send_report scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 12:17:37,349 INFO - DAG test_automation_workflow12 has 0/16 running and queued tasks
2026-02-11 12:17:37,350 INFO - DAG test_automation_workflow12 has 1/16 running and queued tasks
2026-02-11 12:17:37,350 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_automation_workflow12.run_automation_test manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
	<TaskInstance: test_automation_workflow12.send_report scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 12:17:37,353 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 12:17:37,354 WARNING - cannot record scheduled_duration for task send_report because previous state change time has not been saved
2026-02-11 12:17:37,355 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='run_automation_test', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 12:17:37,356 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'run_automation_test', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:37,357 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='send_report', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 12:17:37,358 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'send_report', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:37,361 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'run_automation_test', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:43,360 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'send_report', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:49,924 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='run_automation_test', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:49,926 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='send_report', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:49,937 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=send_report, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 04:17:47.141127+00:00, run_end_date=2026-02-11 04:17:49.292133+00:00, run_duration=2.151006, state=success, executor_state=success, try_number=1, max_tries=1, job_id=10, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 04:17:37.352244+00:00, queued_by_job_id=1, pid=8169
2026-02-11 12:17:49,938 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=run_automation_test, run_id=manual__2026-02-11T04:16:31.174742+00:00, map_index=-1, run_start_date=2026-02-11 04:17:40.904495+00:00, run_end_date=2026-02-11 04:17:42.754879+00:00, run_duration=1.850384, state=success, executor_state=success, try_number=1, max_tries=1, job_id=9, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-11 04:17:37.352244+00:00, queued_by_job_id=1, pid=8164
2026-02-11 12:17:52,876 INFO - Marking run <DagRun test_automation_workflow12 @ 2026-02-10 00:00:00+00:00: scheduled__2026-02-10T00:00:00+00:00, state:running, queued_at: 2026-02-11 04:16:28.739050+00:00. externally triggered: False> successful
2026-02-11 12:17:52,877 INFO - DagRun Finished: dag_id=test_automation_workflow12, execution_date=2026-02-10 00:00:00+00:00, run_id=scheduled__2026-02-10T00:00:00+00:00, run_start_date=2026-02-11 04:16:28.765736+00:00, run_end_date=2026-02-11 04:17:52.877465+00:00, run_duration=84.111729, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=b85f9cddc51f1e0bd97c058683bfe1a6
2026-02-11 12:17:52,882 INFO - Setting next_dagrun for test_automation_workflow12 to 2026-02-11 00:00:00+00:00, run_after=2026-02-12 00:00:00+00:00
2026-02-11 12:17:52,891 INFO - 1 tasks up for execution:
	<TaskInstance: test_automation_workflow12.send_report manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
2026-02-11 12:17:52,892 INFO - DAG test_automation_workflow12 has 0/16 running and queued tasks
2026-02-11 12:17:52,892 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_automation_workflow12.send_report manual__2026-02-11T04:16:31.174742+00:00 [scheduled]>
2026-02-11 12:17:52,894 WARNING - cannot record scheduled_duration for task send_report because previous state change time has not been saved
2026-02-11 12:17:52,895 INFO - Sending TaskInstanceKey(dag_id='test_automation_workflow12', task_id='send_report', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 12:17:52,896 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'send_report', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:52,898 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_automation_workflow12', 'send_report', 'manual__2026-02-11T04:16:31.174742+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 12:17:58,610 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_automation_workflow12', task_id='send_report', run_id='manual__2026-02-11T04:16:31.174742+00:00', try_number=1, map_index=-1)
2026-02-11 12:17:58,624 INFO - TaskInstance Finished: dag_id=test_automation_workflow12, task_id=send_report, run_id=manual__2026-02-11T04:16:31.174742+00:00, map_index=-1, run_start_date=2026-02-11 04:17:56.315176+00:00, run_end_date=2026-02-11 04:17:57.933604+00:00, run_duration=1.618428, state=success, executor_state=success, try_number=1, max_tries=1, job_id=11, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 04:17:52.893689+00:00, queued_by_job_id=1, pid=8172
2026-02-11 12:18:01,591 INFO - Marking run <DagRun test_automation_workflow12 @ 2026-02-11 04:16:31.174742+00:00: manual__2026-02-11T04:16:31.174742+00:00, state:running, queued_at: 2026-02-11 04:16:31.206746+00:00. externally triggered: True> successful
2026-02-11 12:18:01,592 INFO - DagRun Finished: dag_id=test_automation_workflow12, execution_date=2026-02-11 04:16:31.174742+00:00, run_id=manual__2026-02-11T04:16:31.174742+00:00, run_start_date=2026-02-11 04:16:43.745316+00:00, run_end_date=2026-02-11 04:18:01.592397+00:00, run_duration=77.847081, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 04:16:31.174742+00:00, data_interval_end=2026-02-11 04:16:31.174742+00:00, dag_hash=b85f9cddc51f1e0bd97c058683bfe1a6
2026-02-11 12:20:43,449 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 12:25:43,961 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 13:09:10,086 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 13:12:46,276 INFO - Exiting gracefully upon receiving signal 15
2026-02-11 13:12:47,207 INFO - Sending Signals.SIGTERM to group 8074. PIDs of all processes in the group: []
2026-02-11 13:12:47,208 INFO - Sending the signal Signals.SIGTERM to group 8074
2026-02-11 13:12:47,209 INFO - Sending the signal Signals.SIGTERM to process 8074 as process group is missing.
2026-02-11 13:12:47,224 INFO - Sending Signals.SIGTERM to group 8074. PIDs of all processes in the group: []
2026-02-11 13:12:47,225 INFO - Sending the signal Signals.SIGTERM to group 8074
2026-02-11 13:12:47,225 INFO - Sending the signal Signals.SIGTERM to process 8074 as process group is missing.
2026-02-11 13:12:47,226 INFO - Exited execute loop
2026-02-11 13:18:34,892 INFO - Task context logging is enabled
2026-02-11 13:18:34,907 INFO - Loaded executor: SequentialExecutor
2026-02-11 13:18:35,033 INFO - Starting the scheduler
2026-02-11 13:18:35,035 INFO - Processing each file at most -1 times
2026-02-11 13:18:35,042 INFO - Launched DagFileProcessorManager with pid: 9029
2026-02-11 13:18:35,050 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 13:19:25,550 INFO - Setting next_dagrun for 项目_工作流_ to 2026-02-11 00:00:00+00:00, run_after=2026-02-12 00:00:00+00:00
2026-02-11 13:19:25,601 INFO - 2 tasks up for execution:
	<TaskInstance: 项目_工作流_.set_api_key scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: 项目_工作流_.some_task scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 13:19:25,602 INFO - DAG 项目_工作流_ has 0/16 running and queued tasks
2026-02-11 13:19:25,603 INFO - DAG 项目_工作流_ has 1/16 running and queued tasks
2026-02-11 13:19:25,604 INFO - Setting the following tasks to queued state:
	<TaskInstance: 项目_工作流_.set_api_key scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: 项目_工作流_.some_task scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 13:19:25,607 WARNING - cannot record scheduled_duration for task set_api_key because previous state change time has not been saved
2026-02-11 13:19:25,608 WARNING - cannot record scheduled_duration for task some_task because previous state change time has not been saved
2026-02-11 13:19:25,609 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_', task_id='set_api_key', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2026-02-11 13:19:25,610 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_', 'set_api_key', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:19:25,612 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_', task_id='some_task', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 13:19:25,613 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_', 'some_task', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:19:25,615 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_', 'set_api_key', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:19:31,504 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_', 'some_task', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:19:37,175 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_', task_id='set_api_key', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 13:19:37,181 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_', task_id='some_task', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 13:19:37,196 INFO - TaskInstance Finished: dag_id=项目_工作流_, task_id=set_api_key, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 05:19:30.314198+00:00, run_end_date=2026-02-11 05:19:30.739218+00:00, run_duration=0.42502, state=success, executor_state=success, try_number=1, max_tries=1, job_id=13, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-11 05:19:25.605750+00:00, queued_by_job_id=12, pid=9071
2026-02-11 13:19:37,196 INFO - TaskInstance Finished: dag_id=项目_工作流_, task_id=some_task, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 05:19:36.043647+00:00, run_end_date=2026-02-11 05:19:36.463132+00:00, run_duration=0.419485, state=success, executor_state=success, try_number=1, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 05:19:25.605750+00:00, queued_by_job_id=12, pid=9074
2026-02-11 13:19:40,203 INFO - 1 tasks up for execution:
	<TaskInstance: 项目_工作流_.generate_test_cases scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 13:19:40,204 INFO - DAG 项目_工作流_ has 0/16 running and queued tasks
2026-02-11 13:19:40,205 INFO - Setting the following tasks to queued state:
	<TaskInstance: 项目_工作流_.generate_test_cases scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 13:19:40,207 WARNING - cannot record scheduled_duration for task generate_test_cases because previous state change time has not been saved
2026-02-11 13:19:40,209 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_', task_id='generate_test_cases', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 13:19:40,209 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_', 'generate_test_cases', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:19:40,211 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_', 'generate_test_cases', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:19:55,836 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_', task_id='generate_test_cases', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 13:19:55,854 INFO - TaskInstance Finished: dag_id=项目_工作流_, task_id=generate_test_cases, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 05:19:44.112421+00:00, run_end_date=2026-02-11 05:19:55.139594+00:00, run_duration=11.027173, state=success, executor_state=success, try_number=1, max_tries=1, job_id=15, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-11 05:19:40.206641+00:00, queued_by_job_id=12, pid=9080
2026-02-11 13:19:59,599 INFO - 1 tasks up for execution:
	<TaskInstance: 项目_工作流_.run_automation_test scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 13:19:59,600 INFO - DAG 项目_工作流_ has 0/16 running and queued tasks
2026-02-11 13:19:59,601 INFO - Setting the following tasks to queued state:
	<TaskInstance: 项目_工作流_.run_automation_test scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 13:19:59,603 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 13:19:59,604 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_', task_id='run_automation_test', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 13:19:59,605 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_', 'run_automation_test', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:19:59,607 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_', 'run_automation_test', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 13:20:07,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_', task_id='run_automation_test', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 13:20:07,321 INFO - TaskInstance Finished: dag_id=项目_工作流_, task_id=run_automation_test, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 05:20:04.057964+00:00, run_end_date=2026-02-11 05:20:06.411136+00:00, run_duration=2.353172, state=success, executor_state=success, try_number=1, max_tries=1, job_id=16, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 05:19:59.601990+00:00, queued_by_job_id=12, pid=9089
2026-02-11 13:20:10,679 INFO - Marking run <DagRun 项目_工作流_ @ 2026-02-10 00:00:00+00:00: scheduled__2026-02-10T00:00:00+00:00, state:running, queued_at: 2026-02-11 05:19:25.538795+00:00. externally triggered: False> successful
2026-02-11 13:20:10,682 INFO - DagRun Finished: dag_id=项目_工作流_, execution_date=2026-02-10 00:00:00+00:00, run_id=scheduled__2026-02-10T00:00:00+00:00, run_start_date=2026-02-11 05:19:25.561161+00:00, run_end_date=2026-02-11 05:20:10.682557+00:00, run_duration=45.121396, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=e917dda417a4051d857e33be9edbc8c5
2026-02-11 13:20:10,691 INFO - Setting next_dagrun for 项目_工作流_ to 2026-02-11 00:00:00+00:00, run_after=2026-02-12 00:00:00+00:00
2026-02-11 13:23:37,558 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 13:28:37,997 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 13:33:41,466 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 13:36:31,753 INFO - Exiting gracefully upon receiving signal 15
2026-02-11 13:36:32,652 INFO - Sending Signals.SIGTERM to group 9029. PIDs of all processes in the group: []
2026-02-11 13:36:32,653 INFO - Sending the signal Signals.SIGTERM to group 9029
2026-02-11 13:36:32,654 INFO - Sending the signal Signals.SIGTERM to process 9029 as process group is missing.
2026-02-11 13:36:32,668 INFO - Sending Signals.SIGTERM to group 9029. PIDs of all processes in the group: []
2026-02-11 13:36:32,669 INFO - Sending the signal Signals.SIGTERM to group 9029
2026-02-11 13:36:32,669 INFO - Sending the signal Signals.SIGTERM to process 9029 as process group is missing.
2026-02-11 13:36:32,670 INFO - Exited execute loop
2026-02-11 16:14:23,567 INFO - Task context logging is enabled
2026-02-11 16:14:23,571 INFO - Loaded executor: SequentialExecutor
2026-02-11 16:14:23,679 INFO - Starting the scheduler
2026-02-11 16:14:23,680 INFO - Processing each file at most -1 times
2026-02-11 16:14:23,688 INFO - Launched DagFileProcessorManager with pid: 14149
2026-02-11 16:14:23,699 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:14:30,919 INFO - Setting next_dagrun for 项目_工作流_hello to 2026-02-11 00:00:00+00:00, run_after=2026-02-12 00:00:00+00:00
2026-02-11 16:14:30,931 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-02 00:00:00+00:00, run_after=2026-01-03 00:00:00+00:00
2026-02-11 16:14:30,939 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-02 00:00:00+00:00, run_after=2026-01-03 00:00:00+00:00
2026-02-11 16:14:31,047 INFO - 5 tasks up for execution:
	<TaskInstance: 项目_工作流_hello.set_api_key scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:11:04.643098+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: 项目_工作流_hello.some_task scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 16:14:31,048 INFO - DAG 项目_工作流_hello has 0/16 running and queued tasks
2026-02-11 16:14:31,049 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:14:31,050 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:14:31,051 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:14:31,052 INFO - DAG 项目_工作流_hello has 1/16 running and queued tasks
2026-02-11 16:14:31,054 INFO - Setting the following tasks to queued state:
	<TaskInstance: 项目_工作流_hello.set_api_key scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:11:04.643098+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: 项目_工作流_hello.some_task scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 16:14:31,066 WARNING - cannot record scheduled_duration for task set_api_key because previous state change time has not been saved
2026-02-11 16:14:31,067 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:14:31,068 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:14:31,069 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:14:31,070 WARNING - cannot record scheduled_duration for task some_task because previous state change time has not been saved
2026-02-11 16:14:31,071 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_hello', task_id='set_api_key', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default
2026-02-11 16:14:31,072 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'set_api_key', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:31,076 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:11:04.643098+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:14:31,077 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:11:04.643098+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:14:31,078 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:14:31,079 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:31,080 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:14:31,081 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:31,082 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_hello', task_id='some_task', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:14:31,084 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'some_task', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:31,088 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'set_api_key', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:37,459 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:11:04.643098+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:14:42,573 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:48,358 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:53,436 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'some_task', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:14:58,525 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_hello', task_id='set_api_key', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:14:58,529 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:11:04.643098+00:00', try_number=1, map_index=-1)
2026-02-11 16:14:58,530 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-01T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:14:58,530 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-01T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:14:58,531 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_hello', task_id='some_task', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:14:58,551 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-01T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:14:47.187624+00:00, run_end_date=2026-02-11 08:14:47.649859+00:00, run_duration=0.462235, state=success, executor_state=success, try_number=1, max_tries=1, job_id=20, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:14:31.056934+00:00, queued_by_job_id=17, pid=14170
2026-02-11 16:14:58,552 INFO - TaskInstance Finished: dag_id=项目_工作流_hello, task_id=set_api_key, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:14:36.231912+00:00, run_end_date=2026-02-11 08:14:36.771725+00:00, run_duration=0.539813, state=success, executor_state=success, try_number=1, max_tries=1, job_id=18, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2026-02-11 08:14:31.056934+00:00, queued_by_job_id=17, pid=14162
2026-02-11 16:14:58,552 INFO - TaskInstance Finished: dag_id=项目_工作流_hello, task_id=some_task, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:14:57.408666+00:00, run_end_date=2026-02-11 08:14:57.848556+00:00, run_duration=0.43989, state=success, executor_state=success, try_number=1, max_tries=1, job_id=22, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:14:31.056934+00:00, queued_by_job_id=17, pid=14177
2026-02-11 16:14:58,553 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-01T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:14:52.325941+00:00, run_end_date=2026-02-11 08:14:52.779444+00:00, run_duration=0.453503, state=success, executor_state=success, try_number=1, max_tries=1, job_id=21, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:14:31.056934+00:00, queued_by_job_id=17, pid=14174
2026-02-11 16:14:58,554 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:11:04.643098+00:00, map_index=-1, run_start_date=2026-02-11 08:14:41.625100+00:00, run_end_date=2026-02-11 08:14:41.821071+00:00, run_duration=0.195971, state=success, executor_state=success, try_number=1, max_tries=0, job_id=19, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:14:31.056934+00:00, queued_by_job_id=17, pid=14167
2026-02-11 16:15:01,747 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-03 00:00:00+00:00, run_after=2026-01-04 00:00:00+00:00
2026-02-11 16:15:01,757 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-03 00:00:00+00:00, run_after=2026-01-04 00:00:00+00:00
2026-02-11 16:15:01,786 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-01 00:00:00+00:00: scheduled__2026-01-01T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:14:30.935001+00:00. externally triggered: False> successful
2026-02-11 16:15:01,787 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-01 00:00:00+00:00, run_id=scheduled__2026-01-01T00:00:00+00:00, run_start_date=2026-02-11 08:14:30.980823+00:00, run_end_date=2026-02-11 08:15:01.787684+00:00, run_duration=30.806861, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-01 00:00:00+00:00, data_interval_end=2026-01-02 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:15:01,793 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-02 00:00:00+00:00, run_after=2026-01-03 00:00:00+00:00
2026-02-11 16:15:01,796 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-01 00:00:00+00:00: scheduled__2026-01-01T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:14:30.923628+00:00. externally triggered: False> successful
2026-02-11 16:15:01,797 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-01 00:00:00+00:00, run_id=scheduled__2026-01-01T00:00:00+00:00, run_start_date=2026-02-11 08:14:30.981112+00:00, run_end_date=2026-02-11 08:15:01.797395+00:00, run_duration=30.816283, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-01 00:00:00+00:00, data_interval_end=2026-01-02 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:15:01,801 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-02 00:00:00+00:00, run_after=2026-01-03 00:00:00+00:00
2026-02-11 16:15:01,824 INFO - 4 tasks up for execution:
	<TaskInstance: 项目_工作流_hello.generate_test_cases scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:11:04.643098+00:00 [scheduled]>
2026-02-11 16:15:01,825 INFO - DAG 项目_工作流_hello has 0/16 running and queued tasks
2026-02-11 16:15:01,826 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:15:01,826 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:15:01,827 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:15:01,828 INFO - Setting the following tasks to queued state:
	<TaskInstance: 项目_工作流_hello.generate_test_cases scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-02T00:00:00+00:00 [scheduled]>
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:11:04.643098+00:00 [scheduled]>
2026-02-11 16:15:01,832 WARNING - cannot record scheduled_duration for task generate_test_cases because previous state change time has not been saved
2026-02-11 16:15:01,833 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:15:01,834 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:15:01,834 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:15:01,836 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_hello', task_id='generate_test_cases', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:15:01,836 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'generate_test_cases', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:01,837 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:01,838 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:01,838 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-02T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:01,839 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:01,839 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:11:04.643098+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:01,840 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:11:04.643098+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:15:01,842 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'generate_test_cases', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:15,704 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:20,778 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-02T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:25,951 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:11:04.643098+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:15:30,768 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_hello', task_id='generate_test_cases', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:15:30,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-02T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:15:30,771 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-02T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:15:30,772 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:11:04.643098+00:00', try_number=1, map_index=-1)
2026-02-11 16:15:30,788 INFO - TaskInstance Finished: dag_id=项目_工作流_hello, task_id=generate_test_cases, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:15:05.722182+00:00, run_end_date=2026-02-11 08:15:15.055167+00:00, run_duration=9.332985, state=success, executor_state=success, try_number=1, max_tries=1, job_id=23, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2026-02-11 08:15:01.829859+00:00, queued_by_job_id=17, pid=14184
2026-02-11 16:15:30,790 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-02T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:15:19.655829+00:00, run_end_date=2026-02-11 08:15:20.087418+00:00, run_duration=0.431589, state=success, executor_state=success, try_number=1, max_tries=1, job_id=24, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:15:01.829859+00:00, queued_by_job_id=17, pid=14196
2026-02-11 16:15:30,791 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:11:04.643098+00:00, map_index=-1, run_start_date=2026-02-11 08:15:29.885634+00:00, run_end_date=2026-02-11 08:15:30.120666+00:00, run_duration=0.235032, state=success, executor_state=success, try_number=1, max_tries=0, job_id=26, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:15:01.829859+00:00, queued_by_job_id=17, pid=14203
2026-02-11 16:15:30,791 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-02T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:15:24.766845+00:00, run_end_date=2026-02-11 08:15:25.204708+00:00, run_duration=0.437863, state=success, executor_state=success, try_number=1, max_tries=1, job_id=25, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:15:01.829859+00:00, queued_by_job_id=17, pid=14199
2026-02-11 16:15:33,699 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-03 00:00:00+00:00, run_after=2026-01-04 00:00:00+00:00
2026-02-11 16:15:33,702 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-03 00:00:00+00:00, run_after=2026-01-04 00:00:00+00:00
2026-02-11 16:15:33,720 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-02 00:00:00+00:00: scheduled__2026-01-02T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:15:01.743374+00:00. externally triggered: False> successful
2026-02-11 16:15:33,720 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-02 00:00:00+00:00, run_id=scheduled__2026-01-02T00:00:00+00:00, run_start_date=2026-02-11 08:15:01.767864+00:00, run_end_date=2026-02-11 08:15:33.720874+00:00, run_duration=31.95301, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-02 00:00:00+00:00, data_interval_end=2026-01-03 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:15:33,725 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-03 00:00:00+00:00, run_after=2026-01-04 00:00:00+00:00
2026-02-11 16:15:33,729 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-02 00:00:00+00:00: scheduled__2026-01-02T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:15:01.752450+00:00. externally triggered: False> successful
2026-02-11 16:15:33,730 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-02 00:00:00+00:00, run_id=scheduled__2026-01-02T00:00:00+00:00, run_start_date=2026-02-11 08:15:01.768189+00:00, run_end_date=2026-02-11 08:15:33.730030+00:00, run_duration=31.961841, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-02 00:00:00+00:00, data_interval_end=2026-01-03 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:15:33,734 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-03 00:00:00+00:00, run_after=2026-01-04 00:00:00+00:00
2026-02-11 16:15:33,742 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:11:04.643098+00:00: manual__2026-02-11T08:11:04.643098+00:00, state:running, queued_at: 2026-02-11 08:11:04.658477+00:00. externally triggered: True> successful
2026-02-11 16:15:33,743 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:11:04.643098+00:00, run_id=manual__2026-02-11T08:11:04.643098+00:00, run_start_date=2026-02-11 08:14:30.984132+00:00, run_end_date=2026-02-11 08:15:33.743109+00:00, run_duration=62.758977, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:15:33,756 INFO - 1 tasks up for execution:
	<TaskInstance: 项目_工作流_hello.run_automation_test scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 16:15:33,757 INFO - DAG 项目_工作流_hello has 0/16 running and queued tasks
2026-02-11 16:15:33,757 INFO - Setting the following tasks to queued state:
	<TaskInstance: 项目_工作流_hello.run_automation_test scheduled__2026-02-10T00:00:00+00:00 [scheduled]>
2026-02-11 16:15:33,760 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:15:33,761 INFO - Sending TaskInstanceKey(dag_id='项目_工作流_hello', task_id='run_automation_test', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:33,762 INFO - Adding to queue: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'run_automation_test', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:33,764 INFO - Executing command: ['airflow', 'tasks', 'run', '项目_工作流_hello', 'run_automation_test', 'scheduled__2026-02-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:40,227 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='项目_工作流_hello', task_id='run_automation_test', run_id='scheduled__2026-02-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:15:40,245 INFO - TaskInstance Finished: dag_id=项目_工作流_hello, task_id=run_automation_test, run_id=scheduled__2026-02-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:15:37.375641+00:00, run_end_date=2026-02-11 08:15:39.545129+00:00, run_duration=2.169488, state=success, executor_state=success, try_number=1, max_tries=1, job_id=27, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:15:33.758919+00:00, queued_by_job_id=17, pid=14207
2026-02-11 16:15:43,937 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-04 00:00:00+00:00, run_after=2026-01-05 00:00:00+00:00
2026-02-11 16:15:43,942 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-04 00:00:00+00:00, run_after=2026-01-05 00:00:00+00:00
2026-02-11 16:15:43,972 INFO - Marking run <DagRun 项目_工作流_hello @ 2026-02-10 00:00:00+00:00: scheduled__2026-02-10T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:14:30.864314+00:00. externally triggered: False> successful
2026-02-11 16:15:43,973 INFO - DagRun Finished: dag_id=项目_工作流_hello, execution_date=2026-02-10 00:00:00+00:00, run_id=scheduled__2026-02-10T00:00:00+00:00, run_start_date=2026-02-11 08:14:30.981232+00:00, run_end_date=2026-02-11 08:15:43.973687+00:00, run_duration=72.992455, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=fb56d5a9a39933898950c268a7db9144
2026-02-11 16:15:43,976 INFO - Setting next_dagrun for 项目_工作流_hello to 2026-02-11 00:00:00+00:00, run_after=2026-02-12 00:00:00+00:00
2026-02-11 16:15:43,987 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-03T00:00:00+00:00 [scheduled]>
2026-02-11 16:15:43,988 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:15:43,989 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:15:43,989 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-03T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-03T00:00:00+00:00 [scheduled]>
2026-02-11 16:15:43,992 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:15:43,993 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:15:43,994 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:43,994 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:43,995 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-03T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:43,996 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:43,998 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:48,592 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-03T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:54,198 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-03T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:15:54,202 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-03T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:15:54,220 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-03T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:15:53.082374+00:00, run_end_date=2026-02-11 08:15:53.514205+00:00, run_duration=0.431831, state=success, executor_state=success, try_number=1, max_tries=1, job_id=29, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:15:43.990780+00:00, queued_by_job_id=17, pid=14218
2026-02-11 16:15:54,221 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-03T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:15:47.740728+00:00, run_end_date=2026-02-11 08:15:47.929817+00:00, run_duration=0.189089, state=success, executor_state=success, try_number=1, max_tries=1, job_id=28, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:15:43.990780+00:00, queued_by_job_id=17, pid=14215
2026-02-11 16:15:57,093 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-05 00:00:00+00:00, run_after=2026-01-06 00:00:00+00:00
2026-02-11 16:15:57,099 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-05 00:00:00+00:00, run_after=2026-01-06 00:00:00+00:00
2026-02-11 16:15:57,128 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-03 00:00:00+00:00: scheduled__2026-01-03T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:15:43.939230+00:00. externally triggered: False> successful
2026-02-11 16:15:57,129 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-03 00:00:00+00:00, run_id=scheduled__2026-01-03T00:00:00+00:00, run_start_date=2026-02-11 08:15:43.951967+00:00, run_end_date=2026-02-11 08:15:57.129236+00:00, run_duration=13.177269, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-03 00:00:00+00:00, data_interval_end=2026-01-04 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:15:57,133 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-04 00:00:00+00:00, run_after=2026-01-05 00:00:00+00:00
2026-02-11 16:15:57,136 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-03 00:00:00+00:00: scheduled__2026-01-03T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:15:43.932239+00:00. externally triggered: False> successful
2026-02-11 16:15:57,137 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-03 00:00:00+00:00, run_id=scheduled__2026-01-03T00:00:00+00:00, run_start_date=2026-02-11 08:15:43.952870+00:00, run_end_date=2026-02-11 08:15:57.137682+00:00, run_duration=13.184812, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-03 00:00:00+00:00, data_interval_end=2026-01-04 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:15:57,141 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-04 00:00:00+00:00, run_after=2026-01-05 00:00:00+00:00
2026-02-11 16:15:57,152 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-04T00:00:00+00:00 [scheduled]>
2026-02-11 16:15:57,153 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:15:57,153 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:15:57,154 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-04T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-04T00:00:00+00:00 [scheduled]>
2026-02-11 16:15:57,157 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:15:57,157 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:15:57,158 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:57,159 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:57,159 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-04T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:15:57,160 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:15:57,162 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:02,834 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-04T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:07,867 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-04T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:07,871 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-04T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:07,882 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-04T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:01.435998+00:00, run_end_date=2026-02-11 08:16:02.000556+00:00, run_duration=0.564558, state=success, executor_state=success, try_number=1, max_tries=1, job_id=30, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:15:57.155726+00:00, queued_by_job_id=17, pid=14231
2026-02-11 16:16:07,883 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-04T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:06.784468+00:00, run_end_date=2026-02-11 08:16:07.203606+00:00, run_duration=0.419138, state=success, executor_state=success, try_number=1, max_tries=1, job_id=31, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:15:57.155726+00:00, queued_by_job_id=17, pid=14238
2026-02-11 16:16:10,916 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-05 00:00:00+00:00, run_after=2026-01-06 00:00:00+00:00
2026-02-11 16:16:10,920 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-05 00:00:00+00:00, run_after=2026-01-06 00:00:00+00:00
2026-02-11 16:16:10,933 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-04 00:00:00+00:00: scheduled__2026-01-04T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:15:57.088008+00:00. externally triggered: False> successful
2026-02-11 16:16:10,934 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-04 00:00:00+00:00, run_id=scheduled__2026-01-04T00:00:00+00:00, run_start_date=2026-02-11 08:15:57.111089+00:00, run_end_date=2026-02-11 08:16:10.934455+00:00, run_duration=13.823366, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-04 00:00:00+00:00, data_interval_end=2026-01-05 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:16:10,938 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-05 00:00:00+00:00, run_after=2026-01-06 00:00:00+00:00
2026-02-11 16:16:10,941 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-04 00:00:00+00:00: scheduled__2026-01-04T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:15:57.095041+00:00. externally triggered: False> successful
2026-02-11 16:16:10,942 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-04 00:00:00+00:00, run_id=scheduled__2026-01-04T00:00:00+00:00, run_start_date=2026-02-11 08:15:57.111853+00:00, run_end_date=2026-02-11 08:16:10.942716+00:00, run_duration=13.830863, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-04 00:00:00+00:00, data_interval_end=2026-01-05 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:16:10,946 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-05 00:00:00+00:00, run_after=2026-01-06 00:00:00+00:00
2026-02-11 16:16:16,000 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-06 00:00:00+00:00, run_after=2026-01-07 00:00:00+00:00
2026-02-11 16:16:16,024 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-06 00:00:00+00:00, run_after=2026-01-07 00:00:00+00:00
2026-02-11 16:16:16,065 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-05T00:00:00+00:00 [scheduled]>
2026-02-11 16:16:16,066 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:16:16,067 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:16:16,068 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-05T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-05T00:00:00+00:00 [scheduled]>
2026-02-11 16:16:16,070 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:16:16,071 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:16:16,072 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:16:16,074 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:16,075 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-05T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:16:16,075 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:16,077 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:21,315 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-05T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:26,198 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-05T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:26,202 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-05T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:26,215 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-05T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:25.330468+00:00, run_end_date=2026-02-11 08:16:25.529277+00:00, run_duration=0.198809, state=success, executor_state=success, try_number=1, max_tries=1, job_id=33, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:16:16.069324+00:00, queued_by_job_id=17, pid=14261
2026-02-11 16:16:26,217 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-05T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:20.197558+00:00, run_end_date=2026-02-11 08:16:20.630483+00:00, run_duration=0.432925, state=success, executor_state=success, try_number=1, max_tries=1, job_id=32, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:16:16.069324+00:00, queued_by_job_id=17, pid=14255
2026-02-11 16:16:30,000 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-07 00:00:00+00:00, run_after=2026-01-08 00:00:00+00:00
2026-02-11 16:16:30,005 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-07 00:00:00+00:00, run_after=2026-01-08 00:00:00+00:00
2026-02-11 16:16:30,039 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-05 00:00:00+00:00: scheduled__2026-01-05T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:16:16.007899+00:00. externally triggered: False> successful
2026-02-11 16:16:30,040 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-05 00:00:00+00:00, run_id=scheduled__2026-01-05T00:00:00+00:00, run_start_date=2026-02-11 08:16:16.034711+00:00, run_end_date=2026-02-11 08:16:30.040661+00:00, run_duration=14.00595, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-05 00:00:00+00:00, data_interval_end=2026-01-06 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:16:30,044 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-06 00:00:00+00:00, run_after=2026-01-07 00:00:00+00:00
2026-02-11 16:16:30,048 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-05 00:00:00+00:00: scheduled__2026-01-05T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:16:15.992751+00:00. externally triggered: False> successful
2026-02-11 16:16:30,049 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-05 00:00:00+00:00, run_id=scheduled__2026-01-05T00:00:00+00:00, run_start_date=2026-02-11 08:16:16.035580+00:00, run_end_date=2026-02-11 08:16:30.049284+00:00, run_duration=14.013704, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-05 00:00:00+00:00, data_interval_end=2026-01-06 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:16:30,053 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-06 00:00:00+00:00, run_after=2026-01-07 00:00:00+00:00
2026-02-11 16:16:30,065 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-06T00:00:00+00:00 [scheduled]>
2026-02-11 16:16:30,066 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:16:30,067 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:16:30,067 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-06T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-06T00:00:00+00:00 [scheduled]>
2026-02-11 16:16:30,070 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:16:30,070 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:16:30,071 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:16:30,072 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:30,073 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-06T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:16:30,073 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:30,076 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:35,676 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-06T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:40,415 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-06T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:40,420 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-06T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:40,433 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-06T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:34.541104+00:00, run_end_date=2026-02-11 08:16:35.017412+00:00, run_duration=0.476308, state=success, executor_state=success, try_number=1, max_tries=1, job_id=34, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:16:30.069067+00:00, queued_by_job_id=17, pid=14271
2026-02-11 16:16:40,434 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-06T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:39.581139+00:00, run_end_date=2026-02-11 08:16:39.770552+00:00, run_duration=0.189413, state=success, executor_state=success, try_number=1, max_tries=1, job_id=35, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:16:30.069067+00:00, queued_by_job_id=17, pid=14276
2026-02-11 16:16:44,039 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-07 00:00:00+00:00, run_after=2026-01-08 00:00:00+00:00
2026-02-11 16:16:44,042 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-07 00:00:00+00:00, run_after=2026-01-08 00:00:00+00:00
2026-02-11 16:16:44,057 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-06 00:00:00+00:00: scheduled__2026-01-06T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:16:29.994551+00:00. externally triggered: False> successful
2026-02-11 16:16:44,058 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-06 00:00:00+00:00, run_id=scheduled__2026-01-06T00:00:00+00:00, run_start_date=2026-02-11 08:16:30.018470+00:00, run_end_date=2026-02-11 08:16:44.058123+00:00, run_duration=14.039653, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-06 00:00:00+00:00, data_interval_end=2026-01-07 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:16:44,062 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-07 00:00:00+00:00, run_after=2026-01-08 00:00:00+00:00
2026-02-11 16:16:44,067 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-06 00:00:00+00:00: scheduled__2026-01-06T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:16:30.001824+00:00. externally triggered: False> successful
2026-02-11 16:16:44,068 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-06 00:00:00+00:00, run_id=scheduled__2026-01-06T00:00:00+00:00, run_start_date=2026-02-11 08:16:30.019308+00:00, run_end_date=2026-02-11 08:16:44.068162+00:00, run_duration=14.048854, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-06 00:00:00+00:00, data_interval_end=2026-01-07 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:16:44,073 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-07 00:00:00+00:00, run_after=2026-01-08 00:00:00+00:00
2026-02-11 16:16:48,176 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-08 00:00:00+00:00, run_after=2026-01-09 00:00:00+00:00
2026-02-11 16:16:48,183 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-08 00:00:00+00:00, run_after=2026-01-09 00:00:00+00:00
2026-02-11 16:16:48,223 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-07T00:00:00+00:00 [scheduled]>
2026-02-11 16:16:48,224 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:16:48,225 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:16:48,225 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-07T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-07T00:00:00+00:00 [scheduled]>
2026-02-11 16:16:48,228 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:16:48,229 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:16:48,231 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:16:48,231 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:48,232 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-07T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:16:48,233 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:48,235 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:53,748 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-07T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:16:59,369 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-07T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:59,373 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-07T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:16:59,387 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-07T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:52.611182+00:00, run_end_date=2026-02-11 08:16:53.073337+00:00, run_duration=0.462155, state=success, executor_state=success, try_number=1, max_tries=1, job_id=36, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:16:48.227288+00:00, queued_by_job_id=17, pid=14287
2026-02-11 16:16:59,388 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-07T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:16:58.110724+00:00, run_end_date=2026-02-11 08:16:58.539014+00:00, run_duration=0.42829, state=success, executor_state=success, try_number=1, max_tries=1, job_id=37, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:16:48.227288+00:00, queued_by_job_id=17, pid=14297
2026-02-11 16:17:02,892 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-09 00:00:00+00:00, run_after=2026-01-10 00:00:00+00:00
2026-02-11 16:17:02,923 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-09 00:00:00+00:00, run_after=2026-01-10 00:00:00+00:00
2026-02-11 16:17:02,968 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-07 00:00:00+00:00: scheduled__2026-01-07T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:16:48.171616+00:00. externally triggered: False> successful
2026-02-11 16:17:02,969 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-07 00:00:00+00:00, run_id=scheduled__2026-01-07T00:00:00+00:00, run_start_date=2026-02-11 08:16:48.195121+00:00, run_end_date=2026-02-11 08:17:02.969009+00:00, run_duration=14.773888, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-07 00:00:00+00:00, data_interval_end=2026-01-08 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:17:02,973 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-08 00:00:00+00:00, run_after=2026-01-09 00:00:00+00:00
2026-02-11 16:17:02,977 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-07 00:00:00+00:00: scheduled__2026-01-07T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:16:48.179638+00:00. externally triggered: False> successful
2026-02-11 16:17:02,978 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-07 00:00:00+00:00, run_id=scheduled__2026-01-07T00:00:00+00:00, run_start_date=2026-02-11 08:16:48.195756+00:00, run_end_date=2026-02-11 08:17:02.978239+00:00, run_duration=14.782483, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-07 00:00:00+00:00, data_interval_end=2026-01-08 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:17:02,983 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-08 00:00:00+00:00, run_after=2026-01-09 00:00:00+00:00
2026-02-11 16:17:02,993 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-08T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:02,993 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:17:02,994 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:17:02,995 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-08T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-08T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:03,000 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:03,005 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:03,007 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:03,008 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:03,009 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-08T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:03,010 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:03,015 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:08,413 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-08T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:13,142 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-08T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:17:13,146 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-08T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:17:13,157 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-08T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:17:12.285880+00:00, run_end_date=2026-02-11 08:17:12.475109+00:00, run_duration=0.189229, state=success, executor_state=success, try_number=1, max_tries=1, job_id=39, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:17:02.997314+00:00, queued_by_job_id=17, pid=14324
2026-02-11 16:17:13,158 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-08T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:17:07.315425+00:00, run_end_date=2026-02-11 08:17:07.734028+00:00, run_duration=0.418603, state=success, executor_state=success, try_number=1, max_tries=1, job_id=38, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:17:02.997314+00:00, queued_by_job_id=17, pid=14319
2026-02-11 16:17:16,146 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-09 00:00:00+00:00, run_after=2026-01-10 00:00:00+00:00
2026-02-11 16:17:16,149 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-09 00:00:00+00:00, run_after=2026-01-10 00:00:00+00:00
2026-02-11 16:17:16,168 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-08 00:00:00+00:00: scheduled__2026-01-08T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:17:02.914716+00:00. externally triggered: False> successful
2026-02-11 16:17:16,169 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-08 00:00:00+00:00, run_id=scheduled__2026-01-08T00:00:00+00:00, run_start_date=2026-02-11 08:17:02.939047+00:00, run_end_date=2026-02-11 08:17:16.169043+00:00, run_duration=13.229996, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-08 00:00:00+00:00, data_interval_end=2026-01-09 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:17:16,173 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-09 00:00:00+00:00, run_after=2026-01-10 00:00:00+00:00
2026-02-11 16:17:16,177 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-08 00:00:00+00:00: scheduled__2026-01-08T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:17:02.884806+00:00. externally triggered: False> successful
2026-02-11 16:17:16,178 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-08 00:00:00+00:00, run_id=scheduled__2026-01-08T00:00:00+00:00, run_start_date=2026-02-11 08:17:02.939556+00:00, run_end_date=2026-02-11 08:17:16.178227+00:00, run_duration=13.238671, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-08 00:00:00+00:00, data_interval_end=2026-01-09 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:17:16,183 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-09 00:00:00+00:00, run_after=2026-01-10 00:00:00+00:00
2026-02-11 16:17:20,326 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-10 00:00:00+00:00, run_after=2026-01-11 00:00:00+00:00
2026-02-11 16:17:20,332 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-10 00:00:00+00:00, run_after=2026-01-11 00:00:00+00:00
2026-02-11 16:17:20,373 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-09T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:20,375 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:17:20,379 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:17:20,380 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-09T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-09T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:20,383 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:20,384 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:20,386 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:20,387 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:20,388 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-09T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:20,391 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:20,394 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:25,979 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-09T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:32,205 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-09T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:17:32,211 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-09T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:17:32,225 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-09T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:17:30.756139+00:00, run_end_date=2026-02-11 08:17:31.247861+00:00, run_duration=0.491722, state=success, executor_state=success, try_number=1, max_tries=1, job_id=41, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:17:20.381883+00:00, queued_by_job_id=17, pid=14349
2026-02-11 16:17:35,796 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-11 00:00:00+00:00, run_after=2026-01-12 00:00:00+00:00
2026-02-11 16:17:35,803 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-11 00:00:00+00:00, run_after=2026-01-12 00:00:00+00:00
2026-02-11 16:17:35,840 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-09 00:00:00+00:00: scheduled__2026-01-09T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:17:20.329180+00:00. externally triggered: False> successful
2026-02-11 16:17:35,841 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-09 00:00:00+00:00, run_id=scheduled__2026-01-09T00:00:00+00:00, run_start_date=2026-02-11 08:17:20.341849+00:00, run_end_date=2026-02-11 08:17:35.841114+00:00, run_duration=15.499265, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-09 00:00:00+00:00, data_interval_end=2026-01-10 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:17:35,847 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-10 00:00:00+00:00, run_after=2026-01-11 00:00:00+00:00
2026-02-11 16:17:35,859 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-10T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:35,860 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:17:35,861 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:17:35,862 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-10T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-10T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:35,864 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:35,865 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:35,866 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:35,866 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:35,867 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-10T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:35,868 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:35,870 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:41,605 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-10T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:46,603 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:17:46,606 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-10T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:17:46,618 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:17:40.505970+00:00, run_end_date=2026-02-11 08:17:40.978610+00:00, run_duration=0.47264, state=success, executor_state=success, try_number=1, max_tries=1, job_id=42, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:17:35.863489+00:00, queued_by_job_id=17, pid=14353
2026-02-11 16:17:46,619 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-10T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:17:45.765564+00:00, run_end_date=2026-02-11 08:17:45.950321+00:00, run_duration=0.184757, state=success, executor_state=success, try_number=1, max_tries=1, job_id=43, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:17:35.863489+00:00, queued_by_job_id=17, pid=14356
2026-02-11 16:17:49,724 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-12 00:00:00+00:00, run_after=2026-01-13 00:00:00+00:00
2026-02-11 16:17:49,726 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-11 00:00:00+00:00, run_after=2026-01-12 00:00:00+00:00
2026-02-11 16:17:49,753 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-10 00:00:00+00:00: scheduled__2026-01-10T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:17:35.790002+00:00. externally triggered: False> successful
2026-02-11 16:17:49,755 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-10 00:00:00+00:00, run_id=scheduled__2026-01-10T00:00:00+00:00, run_start_date=2026-02-11 08:17:35.818833+00:00, run_end_date=2026-02-11 08:17:49.755163+00:00, run_duration=13.93633, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-10 00:00:00+00:00, data_interval_end=2026-01-11 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:17:49,761 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-11 00:00:00+00:00, run_after=2026-01-12 00:00:00+00:00
2026-02-11 16:17:49,766 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-10 00:00:00+00:00: scheduled__2026-01-10T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:17:35.798764+00:00. externally triggered: False> successful
2026-02-11 16:17:49,767 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-10 00:00:00+00:00, run_id=scheduled__2026-01-10T00:00:00+00:00, run_start_date=2026-02-11 08:17:35.820102+00:00, run_end_date=2026-02-11 08:17:49.767160+00:00, run_duration=13.947058, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-10 00:00:00+00:00, data_interval_end=2026-01-11 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:17:49,772 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-11 00:00:00+00:00, run_after=2026-01-12 00:00:00+00:00
2026-02-11 16:17:49,786 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-11T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:49,786 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:17:49,788 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-11T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:49,790 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:49,791 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:49,792 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:49,795 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:55,795 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:17:55,810 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:17:54.900462+00:00, run_end_date=2026-02-11 08:17:55.122210+00:00, run_duration=0.221748, state=success, executor_state=success, try_number=1, max_tries=1, job_id=44, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:17:49.789089+00:00, queued_by_job_id=17, pid=14370
2026-02-11 16:17:59,223 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-12 00:00:00+00:00, run_after=2026-01-13 00:00:00+00:00
2026-02-11 16:17:59,230 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-12 00:00:00+00:00, run_after=2026-01-13 00:00:00+00:00
2026-02-11 16:17:59,254 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-11 00:00:00+00:00: scheduled__2026-01-11T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:17:49.718396+00:00. externally triggered: False> successful
2026-02-11 16:17:59,255 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-11 00:00:00+00:00, run_id=scheduled__2026-01-11T00:00:00+00:00, run_start_date=2026-02-11 08:17:49.736608+00:00, run_end_date=2026-02-11 08:17:59.255654+00:00, run_duration=9.519046, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-11 00:00:00+00:00, data_interval_end=2026-01-12 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:17:59,260 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-12 00:00:00+00:00, run_after=2026-01-13 00:00:00+00:00
2026-02-11 16:17:59,275 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-11T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:59,276 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:17:59,276 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-11T00:00:00+00:00 [scheduled]>
2026-02-11 16:17:59,279 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:17:59,280 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-11T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:17:59,281 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:17:59,283 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-11T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:04,246 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-11T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:18:04,260 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-11T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:03.338898+00:00, run_end_date=2026-02-11 08:18:03.552517+00:00, run_duration=0.213619, state=success, executor_state=success, try_number=1, max_tries=1, job_id=45, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:17:59.277981+00:00, queued_by_job_id=17, pid=14377
2026-02-11 16:18:08,088 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-13 00:00:00+00:00, run_after=2026-01-14 00:00:00+00:00
2026-02-11 16:18:08,093 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-13 00:00:00+00:00, run_after=2026-01-14 00:00:00+00:00
2026-02-11 16:18:08,135 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-11 00:00:00+00:00: scheduled__2026-01-11T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:17:59.225144+00:00. externally triggered: False> successful
2026-02-11 16:18:08,136 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-11 00:00:00+00:00, run_id=scheduled__2026-01-11T00:00:00+00:00, run_start_date=2026-02-11 08:17:59.239009+00:00, run_end_date=2026-02-11 08:18:08.136346+00:00, run_duration=8.897337, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-11 00:00:00+00:00, data_interval_end=2026-01-12 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:18:08,141 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-12 00:00:00+00:00, run_after=2026-01-13 00:00:00+00:00
2026-02-11 16:18:08,154 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-12T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:08,155 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:18:08,156 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:18:08,156 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-12T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-12T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:08,159 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:18:08,159 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:18:08,161 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:18:08,162 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:08,162 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-12T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:18:08,163 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:08,165 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:13,942 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-12T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:18,853 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-12T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:18:18,858 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-12T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:18:18,873 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-12T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:17.849500+00:00, run_end_date=2026-02-11 08:18:18.048978+00:00, run_duration=0.199478, state=success, executor_state=success, try_number=1, max_tries=1, job_id=47, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:18:08.157828+00:00, queued_by_job_id=17, pid=14395
2026-02-11 16:18:18,875 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-12T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:12.845487+00:00, run_end_date=2026-02-11 08:18:13.319171+00:00, run_duration=0.473684, state=success, executor_state=success, try_number=1, max_tries=1, job_id=46, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:18:08.157828+00:00, queued_by_job_id=17, pid=14392
2026-02-11 16:18:23,015 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-14 00:00:00+00:00, run_after=2026-01-15 00:00:00+00:00
2026-02-11 16:18:23,018 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-13 00:00:00+00:00, run_after=2026-01-14 00:00:00+00:00
2026-02-11 16:18:23,041 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-12 00:00:00+00:00: scheduled__2026-01-12T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:18:08.090638+00:00. externally triggered: False> successful
2026-02-11 16:18:23,042 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-12 00:00:00+00:00, run_id=scheduled__2026-01-12T00:00:00+00:00, run_start_date=2026-02-11 08:18:08.105073+00:00, run_end_date=2026-02-11 08:18:23.042154+00:00, run_duration=14.937081, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-12 00:00:00+00:00, data_interval_end=2026-01-13 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:18:23,046 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-13 00:00:00+00:00, run_after=2026-01-14 00:00:00+00:00
2026-02-11 16:18:23,050 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-12 00:00:00+00:00: scheduled__2026-01-12T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:18:08.083325+00:00. externally triggered: False> successful
2026-02-11 16:18:23,051 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-12 00:00:00+00:00, run_id=scheduled__2026-01-12T00:00:00+00:00, run_start_date=2026-02-11 08:18:08.106211+00:00, run_end_date=2026-02-11 08:18:23.051221+00:00, run_duration=14.94501, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-12 00:00:00+00:00, data_interval_end=2026-01-13 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:18:23,056 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-13 00:00:00+00:00, run_after=2026-01-14 00:00:00+00:00
2026-02-11 16:18:23,067 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-13T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:23,068 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:18:23,068 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-13T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:23,070 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:18:23,071 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:18:23,072 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:23,074 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:28,434 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-13T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:18:28,447 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-13T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:27.619312+00:00, run_end_date=2026-02-11 08:18:27.801743+00:00, run_duration=0.182431, state=success, executor_state=success, try_number=1, max_tries=1, job_id=48, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:18:23.069712+00:00, queued_by_job_id=17, pid=14400
2026-02-11 16:18:32,031 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-14 00:00:00+00:00, run_after=2026-01-15 00:00:00+00:00
2026-02-11 16:18:32,034 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-14 00:00:00+00:00, run_after=2026-01-15 00:00:00+00:00
2026-02-11 16:18:32,058 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-13 00:00:00+00:00: scheduled__2026-01-13T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:18:23.009874+00:00. externally triggered: False> successful
2026-02-11 16:18:32,059 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-13 00:00:00+00:00, run_id=scheduled__2026-01-13T00:00:00+00:00, run_start_date=2026-02-11 08:18:23.026938+00:00, run_end_date=2026-02-11 08:18:32.059677+00:00, run_duration=9.032739, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-13 00:00:00+00:00, data_interval_end=2026-01-14 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:18:32,064 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-14 00:00:00+00:00, run_after=2026-01-15 00:00:00+00:00
2026-02-11 16:18:32,074 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-13T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:32,075 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:18:32,076 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-13T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:32,078 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:18:32,079 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-13T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:18:32,080 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:32,082 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-13T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:37,268 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-13T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:18:37,282 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-13T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:36.276644+00:00, run_end_date=2026-02-11 08:18:36.458118+00:00, run_duration=0.181474, state=success, executor_state=success, try_number=1, max_tries=1, job_id=49, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:18:32.077447+00:00, queued_by_job_id=17, pid=14404
2026-02-11 16:18:40,727 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-15 00:00:00+00:00, run_after=2026-01-16 00:00:00+00:00
2026-02-11 16:18:40,734 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-15 00:00:00+00:00, run_after=2026-01-16 00:00:00+00:00
2026-02-11 16:18:40,766 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-13 00:00:00+00:00: scheduled__2026-01-13T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:18:32.025016+00:00. externally triggered: False> successful
2026-02-11 16:18:40,768 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-13 00:00:00+00:00, run_id=scheduled__2026-01-13T00:00:00+00:00, run_start_date=2026-02-11 08:18:32.045017+00:00, run_end_date=2026-02-11 08:18:40.768092+00:00, run_duration=8.723075, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-13 00:00:00+00:00, data_interval_end=2026-01-14 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:18:40,774 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-14 00:00:00+00:00, run_after=2026-01-15 00:00:00+00:00
2026-02-11 16:18:40,786 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-14T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:40,787 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:18:40,787 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:18:40,788 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-14T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-14T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:40,791 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:18:40,791 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:18:40,792 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:18:40,793 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:40,794 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-14T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:18:40,794 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:40,796 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:45,878 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-14T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:51,222 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-14T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:18:51,225 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-14T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:18:51,238 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-14T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:44.878939+00:00, run_end_date=2026-02-11 08:18:45.100187+00:00, run_duration=0.221248, state=success, executor_state=success, try_number=1, max_tries=1, job_id=50, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:18:40.790087+00:00, queued_by_job_id=17, pid=14408
2026-02-11 16:18:51,239 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-14T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:50.216433+00:00, run_end_date=2026-02-11 08:18:50.423340+00:00, run_duration=0.206907, state=success, executor_state=success, try_number=1, max_tries=1, job_id=51, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:18:40.790087+00:00, queued_by_job_id=17, pid=14411
2026-02-11 16:18:54,944 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-15 00:00:00+00:00, run_after=2026-01-16 00:00:00+00:00
2026-02-11 16:18:54,953 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-16 00:00:00+00:00, run_after=2026-01-17 00:00:00+00:00
2026-02-11 16:18:54,981 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-14 00:00:00+00:00: scheduled__2026-01-14T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:18:40.723046+00:00. externally triggered: False> successful
2026-02-11 16:18:54,982 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-14 00:00:00+00:00, run_id=scheduled__2026-01-14T00:00:00+00:00, run_start_date=2026-02-11 08:18:40.745641+00:00, run_end_date=2026-02-11 08:18:54.982611+00:00, run_duration=14.23697, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-14 00:00:00+00:00, data_interval_end=2026-01-15 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:18:54,989 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-15 00:00:00+00:00, run_after=2026-01-16 00:00:00+00:00
2026-02-11 16:18:54,994 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-14 00:00:00+00:00: scheduled__2026-01-14T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:18:40.730171+00:00. externally triggered: False> successful
2026-02-11 16:18:54,995 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-14 00:00:00+00:00, run_id=scheduled__2026-01-14T00:00:00+00:00, run_start_date=2026-02-11 08:18:40.746431+00:00, run_end_date=2026-02-11 08:18:54.995605+00:00, run_duration=14.249174, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-14 00:00:00+00:00, data_interval_end=2026-01-15 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:18:55,000 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-15 00:00:00+00:00, run_after=2026-01-16 00:00:00+00:00
2026-02-11 16:18:55,018 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-15T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:55,019 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:18:55,020 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-15T00:00:00+00:00 [scheduled]>
2026-02-11 16:18:55,022 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:18:55,024 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:18:55,024 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:18:55,027 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:00,671 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-15T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:00,723 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-15T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:18:59.152750+00:00, run_end_date=2026-02-11 08:18:59.873348+00:00, run_duration=0.720598, state=success, executor_state=success, try_number=1, max_tries=1, job_id=52, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:18:55.021613+00:00, queued_by_job_id=17, pid=14415
2026-02-11 16:19:04,010 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-16 00:00:00+00:00, run_after=2026-01-17 00:00:00+00:00
2026-02-11 16:19:04,013 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-16 00:00:00+00:00, run_after=2026-01-17 00:00:00+00:00
2026-02-11 16:19:04,037 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-15 00:00:00+00:00: scheduled__2026-01-15T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:18:54.946841+00:00. externally triggered: False> successful
2026-02-11 16:19:04,038 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-15 00:00:00+00:00, run_id=scheduled__2026-01-15T00:00:00+00:00, run_start_date=2026-02-11 08:18:54.963583+00:00, run_end_date=2026-02-11 08:19:04.038816+00:00, run_duration=9.075233, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-15 00:00:00+00:00, data_interval_end=2026-01-16 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:19:04,043 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-16 00:00:00+00:00, run_after=2026-01-17 00:00:00+00:00
2026-02-11 16:19:04,054 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-15T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:04,054 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:19:04,055 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-15T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:04,057 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:04,058 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-15T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:04,059 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:04,061 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-15T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:09,175 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-15T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:09,190 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-15T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:19:07.824451+00:00, run_end_date=2026-02-11 08:19:08.351640+00:00, run_duration=0.527189, state=success, executor_state=success, try_number=1, max_tries=1, job_id=53, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:04.056468+00:00, queued_by_job_id=17, pid=14422
2026-02-11 16:19:12,203 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-17 00:00:00+00:00, run_after=2026-01-18 00:00:00+00:00
2026-02-11 16:19:12,212 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-17 00:00:00+00:00, run_after=2026-01-18 00:00:00+00:00
2026-02-11 16:19:12,239 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-15 00:00:00+00:00: scheduled__2026-01-15T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:04.004438+00:00. externally triggered: False> successful
2026-02-11 16:19:12,240 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-15 00:00:00+00:00, run_id=scheduled__2026-01-15T00:00:00+00:00, run_start_date=2026-02-11 08:19:04.023663+00:00, run_end_date=2026-02-11 08:19:12.240797+00:00, run_duration=8.217134, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-15 00:00:00+00:00, data_interval_end=2026-01-16 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:19:12,244 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-16 00:00:00+00:00, run_after=2026-01-17 00:00:00+00:00
2026-02-11 16:19:12,256 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-16T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:12,257 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:19:12,258 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:19:12,258 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-16T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-16T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:12,261 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:12,261 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:12,263 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:12,263 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:12,264 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-16T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:12,265 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:12,266 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:16,846 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-16T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:21,693 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-16T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:21,696 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-16T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:21,707 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-16T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:19:20.561785+00:00, run_end_date=2026-02-11 08:19:20.983555+00:00, run_duration=0.42177, state=success, executor_state=success, try_number=1, max_tries=1, job_id=55, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:12.259792+00:00, queued_by_job_id=17, pid=14429
2026-02-11 16:19:21,708 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-16T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:19:16.013693+00:00, run_end_date=2026-02-11 08:19:16.204040+00:00, run_duration=0.190347, state=success, executor_state=success, try_number=1, max_tries=1, job_id=54, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:12.259792+00:00, queued_by_job_id=17, pid=14426
2026-02-11 16:19:24,725 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-17 00:00:00+00:00, run_after=2026-01-18 00:00:00+00:00
2026-02-11 16:19:24,734 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-18 00:00:00+00:00, run_after=2026-01-19 00:00:00+00:00
2026-02-11 16:19:24,757 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-16 00:00:00+00:00: scheduled__2026-01-16T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:12.205642+00:00. externally triggered: False> successful
2026-02-11 16:19:24,758 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-16 00:00:00+00:00, run_id=scheduled__2026-01-16T00:00:00+00:00, run_start_date=2026-02-11 08:19:12.222241+00:00, run_end_date=2026-02-11 08:19:24.757983+00:00, run_duration=12.535742, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-16 00:00:00+00:00, data_interval_end=2026-01-17 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:19:24,762 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-17 00:00:00+00:00, run_after=2026-01-18 00:00:00+00:00
2026-02-11 16:19:24,766 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-16 00:00:00+00:00: scheduled__2026-01-16T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:12.198175+00:00. externally triggered: False> successful
2026-02-11 16:19:24,767 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-16 00:00:00+00:00, run_id=scheduled__2026-01-16T00:00:00+00:00, run_start_date=2026-02-11 08:19:12.222964+00:00, run_end_date=2026-02-11 08:19:24.767026+00:00, run_duration=12.544062, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-16 00:00:00+00:00, data_interval_end=2026-01-17 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:19:24,770 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-17 00:00:00+00:00, run_after=2026-01-18 00:00:00+00:00
2026-02-11 16:19:24,781 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-17T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:24,782 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:19:24,782 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-17T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:24,785 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:24,786 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:24,787 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:24,789 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:29,731 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-17T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:29,744 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-17T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:19:28.651192+00:00, run_end_date=2026-02-11 08:19:29.072135+00:00, run_duration=0.420943, state=success, executor_state=success, try_number=1, max_tries=1, job_id=56, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:24.784065+00:00, queued_by_job_id=17, pid=14434
2026-02-11 16:19:29,766 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:19:32,788 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-18 00:00:00+00:00, run_after=2026-01-19 00:00:00+00:00
2026-02-11 16:19:32,790 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-18 00:00:00+00:00, run_after=2026-01-19 00:00:00+00:00
2026-02-11 16:19:32,815 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-17 00:00:00+00:00: scheduled__2026-01-17T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:24.728859+00:00. externally triggered: False> successful
2026-02-11 16:19:32,816 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-17 00:00:00+00:00, run_id=scheduled__2026-01-17T00:00:00+00:00, run_start_date=2026-02-11 08:19:24.742697+00:00, run_end_date=2026-02-11 08:19:32.816342+00:00, run_duration=8.073645, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-17 00:00:00+00:00, data_interval_end=2026-01-18 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:19:32,820 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-18 00:00:00+00:00, run_after=2026-01-19 00:00:00+00:00
2026-02-11 16:19:32,830 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-17T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:32,831 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:19:32,832 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-17T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:32,834 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:32,835 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-17T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:32,835 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:32,837 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-17T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:38,620 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-17T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:38,634 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-17T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:19:37.751081+00:00, run_end_date=2026-02-11 08:19:37.964057+00:00, run_duration=0.212976, state=success, executor_state=success, try_number=1, max_tries=1, job_id=57, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:32.833125+00:00, queued_by_job_id=17, pid=14439
2026-02-11 16:19:41,953 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-19 00:00:00+00:00, run_after=2026-01-20 00:00:00+00:00
2026-02-11 16:19:41,960 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-19 00:00:00+00:00, run_after=2026-01-20 00:00:00+00:00
2026-02-11 16:19:41,989 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-17 00:00:00+00:00: scheduled__2026-01-17T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:32.782990+00:00. externally triggered: False> successful
2026-02-11 16:19:41,990 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-17 00:00:00+00:00, run_id=scheduled__2026-01-17T00:00:00+00:00, run_start_date=2026-02-11 08:19:32.801031+00:00, run_end_date=2026-02-11 08:19:41.990251+00:00, run_duration=9.18922, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-17 00:00:00+00:00, data_interval_end=2026-01-18 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:19:41,994 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-18 00:00:00+00:00, run_after=2026-01-19 00:00:00+00:00
2026-02-11 16:19:42,006 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-18T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:42,007 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:19:42,008 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:19:42,008 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-18T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-18T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:42,012 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:42,013 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:42,014 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:42,015 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:42,015 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-18T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:42,016 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:42,018 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:47,218 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-18T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:52,760 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-18T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:52,765 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-18T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:19:52,790 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-18T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:19:51.306641+00:00, run_end_date=2026-02-11 08:19:51.823840+00:00, run_duration=0.517199, state=success, executor_state=success, try_number=1, max_tries=1, job_id=59, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:42.010024+00:00, queued_by_job_id=17, pid=14455
2026-02-11 16:19:52,792 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-18T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:19:46.327874+00:00, run_end_date=2026-02-11 08:19:46.521321+00:00, run_duration=0.193447, state=success, executor_state=success, try_number=1, max_tries=1, job_id=58, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:42.010024+00:00, queued_by_job_id=17, pid=14450
2026-02-11 16:19:56,070 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-19 00:00:00+00:00, run_after=2026-01-20 00:00:00+00:00
2026-02-11 16:19:56,078 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-20 00:00:00+00:00, run_after=2026-01-21 00:00:00+00:00
2026-02-11 16:19:56,104 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-18 00:00:00+00:00: scheduled__2026-01-18T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:41.955773+00:00. externally triggered: False> successful
2026-02-11 16:19:56,105 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-18 00:00:00+00:00, run_id=scheduled__2026-01-18T00:00:00+00:00, run_start_date=2026-02-11 08:19:41.970304+00:00, run_end_date=2026-02-11 08:19:56.105494+00:00, run_duration=14.13519, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-18 00:00:00+00:00, data_interval_end=2026-01-19 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:19:56,110 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-19 00:00:00+00:00, run_after=2026-01-20 00:00:00+00:00
2026-02-11 16:19:56,113 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-18 00:00:00+00:00: scheduled__2026-01-18T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:41.948024+00:00. externally triggered: False> successful
2026-02-11 16:19:56,114 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-18 00:00:00+00:00, run_id=scheduled__2026-01-18T00:00:00+00:00, run_start_date=2026-02-11 08:19:41.971264+00:00, run_end_date=2026-02-11 08:19:56.114369+00:00, run_duration=14.143105, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-18 00:00:00+00:00, data_interval_end=2026-01-19 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:19:56,118 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-19 00:00:00+00:00, run_after=2026-01-20 00:00:00+00:00
2026-02-11 16:19:56,130 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-19T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:56,131 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:19:56,131 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-19T00:00:00+00:00 [scheduled]>
2026-02-11 16:19:56,134 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:19:56,135 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:19:56,136 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:19:56,138 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:01,248 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-19T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:20:01,262 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-19T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:20:00.105255+00:00, run_end_date=2026-02-11 08:20:00.556792+00:00, run_duration=0.451537, state=success, executor_state=success, try_number=1, max_tries=1, job_id=60, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:19:56.132850+00:00, queued_by_job_id=17, pid=14462
2026-02-11 16:20:04,749 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-20 00:00:00+00:00, run_after=2026-01-21 00:00:00+00:00
2026-02-11 16:20:04,752 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-20 00:00:00+00:00, run_after=2026-01-21 00:00:00+00:00
2026-02-11 16:20:04,781 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-19 00:00:00+00:00: scheduled__2026-01-19T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:19:56.072291+00:00. externally triggered: False> successful
2026-02-11 16:20:04,782 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-19 00:00:00+00:00, run_id=scheduled__2026-01-19T00:00:00+00:00, run_start_date=2026-02-11 08:19:56.088835+00:00, run_end_date=2026-02-11 08:20:04.782479+00:00, run_duration=8.693644, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-19 00:00:00+00:00, data_interval_end=2026-01-20 00:00:00+00:00, dag_hash=786b1512e65069b3a18aabcd41909504
2026-02-11 16:20:04,788 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-20 00:00:00+00:00, run_after=2026-01-21 00:00:00+00:00
2026-02-11 16:20:04,803 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-19T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:04,804 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:20:04,805 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-19T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:04,807 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:20:04,809 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-19T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:20:04,810 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:04,812 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-19T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:10,457 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-19T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:20:10,473 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-19T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:20:09.250730+00:00, run_end_date=2026-02-11 08:20:09.706675+00:00, run_duration=0.455945, state=success, executor_state=success, try_number=1, max_tries=1, job_id=61, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:20:04.806032+00:00, queued_by_job_id=17, pid=14470
2026-02-11 16:20:14,684 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-21 00:00:00+00:00, run_after=2026-01-22 00:00:00+00:00
2026-02-11 16:20:14,689 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-21 00:00:00+00:00, run_after=2026-01-22 00:00:00+00:00
2026-02-11 16:20:14,718 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-19 00:00:00+00:00: scheduled__2026-01-19T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:20:04.743999+00:00. externally triggered: False> successful
2026-02-11 16:20:14,719 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-19 00:00:00+00:00, run_id=scheduled__2026-01-19T00:00:00+00:00, run_start_date=2026-02-11 08:20:04.763068+00:00, run_end_date=2026-02-11 08:20:14.719414+00:00, run_duration=9.956346, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-19 00:00:00+00:00, data_interval_end=2026-01-20 00:00:00+00:00, dag_hash=173eef9cfaeb86d6b1c942f5c29626cb
2026-02-11 16:20:14,723 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-20 00:00:00+00:00, run_after=2026-01-21 00:00:00+00:00
2026-02-11 16:20:14,735 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-20T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:14,736 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:20:14,737 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:20:14,737 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-20T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-20T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:14,740 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:20:14,741 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:20:14,742 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:20:14,744 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:14,744 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-20T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:20:14,745 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:14,748 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:19,779 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-20T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:24,922 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-20T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:20:24,926 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-20T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:20:24,940 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-20T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:20:18.982846+00:00, run_end_date=2026-02-11 08:20:19.178813+00:00, run_duration=0.195967, state=success, executor_state=success, try_number=1, max_tries=1, job_id=62, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:20:14.739051+00:00, queued_by_job_id=17, pid=14485
2026-02-11 16:20:24,941 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-20T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:20:23.915884+00:00, run_end_date=2026-02-11 08:20:24.113260+00:00, run_duration=0.197376, state=success, executor_state=success, try_number=1, max_tries=1, job_id=63, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:20:14.739051+00:00, queued_by_job_id=17, pid=14491
2026-02-11 16:20:29,475 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-25 00:00:00+00:00, run_after=2026-02-01 00:00:00+00:00
2026-02-11 16:20:29,480 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-25 00:00:00+00:00, run_after=2026-02-01 00:00:00+00:00
2026-02-11 16:20:29,499 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-20 00:00:00+00:00: scheduled__2026-01-20T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:20:14.678751+00:00. externally triggered: False> successful
2026-02-11 16:20:29,500 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-20 00:00:00+00:00, run_id=scheduled__2026-01-20T00:00:00+00:00, run_start_date=2026-02-11 08:20:14.699618+00:00, run_end_date=2026-02-11 08:20:29.500344+00:00, run_duration=14.800726, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-20 00:00:00+00:00, data_interval_end=2026-01-21 00:00:00+00:00, dag_hash=e6456c1fada1806526fd4d2f401be87d
2026-02-11 16:20:29,504 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-18 00:00:00+00:00, run_after=2026-01-25 00:00:00+00:00
2026-02-11 16:20:29,510 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-20 00:00:00+00:00: scheduled__2026-01-20T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:20:14.685721+00:00. externally triggered: False> successful
2026-02-11 16:20:29,511 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-20 00:00:00+00:00, run_id=scheduled__2026-01-20T00:00:00+00:00, run_start_date=2026-02-11 08:20:14.700417+00:00, run_end_date=2026-02-11 08:20:29.511375+00:00, run_duration=14.810958, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-20 00:00:00+00:00, data_interval_end=2026-01-21 00:00:00+00:00, dag_hash=f42beef0c58e9d6479b9e689a95ccd00
2026-02-11 16:20:29,515 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-18 00:00:00+00:00, run_after=2026-01-25 00:00:00+00:00
2026-02-11 16:20:32,845 INFO - Setting next_dagrun for test_workflow_2 to 2026-01-25 00:00:00+00:00, run_after=2026-02-01 00:00:00+00:00
2026-02-11 16:20:32,847 INFO - Setting next_dagrun for test_workflow_3 to 2026-01-25 00:00:00+00:00, run_after=2026-02-01 00:00:00+00:00
2026-02-11 16:20:36,816 INFO - Setting next_dagrun for test_workflow_3 to 2026-02-01 00:00:00+00:00, run_after=2026-02-08 00:00:00+00:00
2026-02-11 16:20:36,820 INFO - Setting next_dagrun for test_workflow_2 to 2026-02-01 00:00:00+00:00, run_after=2026-02-08 00:00:00+00:00
2026-02-11 16:20:36,854 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-25T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:36,855 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:20:36,855 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:20:36,856 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_3.data_check scheduled__2026-01-25T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_2.data_check scheduled__2026-01-25T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:36,859 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:20:36,859 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:20:36,860 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:20:36,861 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:36,862 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-25T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:20:36,863 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:36,865 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:41,892 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-01-25T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:47,797 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-01-25T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:20:47,805 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-01-25T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:20:47,818 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-01-25T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:20:46.777290+00:00, run_end_date=2026-02-11 08:20:46.978641+00:00, run_duration=0.201351, state=success, executor_state=success, try_number=1, max_tries=1, job_id=65, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:20:36.858122+00:00, queued_by_job_id=17, pid=14514
2026-02-11 16:20:47,819 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-01-25T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:20:40.811040+00:00, run_end_date=2026-02-11 08:20:41.256889+00:00, run_duration=0.445849, state=success, executor_state=success, try_number=1, max_tries=1, job_id=64, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:20:36.858122+00:00, queued_by_job_id=17, pid=14511
2026-02-11 16:20:51,053 INFO - Setting next_dagrun for test_workflow_2 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:20:51,064 INFO - Setting next_dagrun for test_workflow_3 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:20:51,106 INFO - Marking run <DagRun test_workflow_2 @ 2026-01-25 00:00:00+00:00: scheduled__2026-01-25T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:20:36.817443+00:00. externally triggered: False> successful
2026-02-11 16:20:51,107 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-01-25 00:00:00+00:00, run_id=scheduled__2026-01-25T00:00:00+00:00, run_start_date=2026-02-11 08:20:36.831358+00:00, run_end_date=2026-02-11 08:20:51.107528+00:00, run_duration=14.27617, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-25 00:00:00+00:00, data_interval_end=2026-02-01 00:00:00+00:00, dag_hash=e6456c1fada1806526fd4d2f401be87d
2026-02-11 16:20:51,112 INFO - Setting next_dagrun for test_workflow_2 to 2026-02-01 00:00:00+00:00, run_after=2026-02-08 00:00:00+00:00
2026-02-11 16:20:51,117 INFO - Marking run <DagRun test_workflow_3 @ 2026-01-25 00:00:00+00:00: scheduled__2026-01-25T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:20:36.811531+00:00. externally triggered: False> successful
2026-02-11 16:20:51,117 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-01-25 00:00:00+00:00, run_id=scheduled__2026-01-25T00:00:00+00:00, run_start_date=2026-02-11 08:20:36.831555+00:00, run_end_date=2026-02-11 08:20:51.117881+00:00, run_duration=14.286326, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-01-25 00:00:00+00:00, data_interval_end=2026-02-01 00:00:00+00:00, dag_hash=f42beef0c58e9d6479b9e689a95ccd00
2026-02-11 16:20:51,122 INFO - Setting next_dagrun for test_workflow_3 to 2026-02-01 00:00:00+00:00, run_after=2026-02-08 00:00:00+00:00
2026-02-11 16:20:51,137 INFO - 2 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-02-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-02-01T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:51,138 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:20:51,140 INFO - DAG test_workflow_3 has 0/16 running and queued tasks
2026-02-11 16:20:51,141 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-02-01T00:00:00+00:00 [scheduled]>
	<TaskInstance: test_workflow_3.data_check scheduled__2026-02-01T00:00:00+00:00 [scheduled]>
2026-02-11 16:20:51,144 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:20:51,144 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:20:51,146 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-02-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:20:51,147 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:51,148 INFO - Sending TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-02-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:20:51,149 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:51,151 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:20:56,427 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_3', 'data_check', 'scheduled__2026-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:21:01,466 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-02-01T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:21:01,470 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_3', task_id='data_check', run_id='scheduled__2026-02-01T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:21:01,483 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-02-01T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:20:55.568240+00:00, run_end_date=2026-02-11 08:20:55.809995+00:00, run_duration=0.241755, state=success, executor_state=success, try_number=1, max_tries=1, job_id=66, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:20:51.142678+00:00, queued_by_job_id=17, pid=14518
2026-02-11 16:21:01,484 INFO - TaskInstance Finished: dag_id=test_workflow_3, task_id=data_check, run_id=scheduled__2026-02-01T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:21:00.523172+00:00, run_end_date=2026-02-11 08:21:00.749146+00:00, run_duration=0.225974, state=success, executor_state=success, try_number=1, max_tries=1, job_id=67, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:20:51.142678+00:00, queued_by_job_id=17, pid=14521
2026-02-11 16:21:05,023 INFO - Setting next_dagrun for test_workflow_3 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:21:05,028 INFO - Setting next_dagrun for test_workflow_2 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:21:05,045 INFO - Marking run <DagRun test_workflow_2 @ 2026-02-01 00:00:00+00:00: scheduled__2026-02-01T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:20:51.036057+00:00. externally triggered: False> successful
2026-02-11 16:21:05,046 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-02-01 00:00:00+00:00, run_id=scheduled__2026-02-01T00:00:00+00:00, run_start_date=2026-02-11 08:20:51.079205+00:00, run_end_date=2026-02-11 08:21:05.046658+00:00, run_duration=13.967453, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-01 00:00:00+00:00, data_interval_end=2026-02-08 00:00:00+00:00, dag_hash=e6456c1fada1806526fd4d2f401be87d
2026-02-11 16:21:05,051 INFO - Setting next_dagrun for test_workflow_2 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:21:05,056 INFO - Marking run <DagRun test_workflow_3 @ 2026-02-01 00:00:00+00:00: scheduled__2026-02-01T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:20:51.057996+00:00. externally triggered: False> successful
2026-02-11 16:21:05,057 INFO - DagRun Finished: dag_id=test_workflow_3, execution_date=2026-02-01 00:00:00+00:00, run_id=scheduled__2026-02-01T00:00:00+00:00, run_start_date=2026-02-11 08:20:51.080765+00:00, run_end_date=2026-02-11 08:21:05.057590+00:00, run_duration=13.976825, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-01 00:00:00+00:00, data_interval_end=2026-02-08 00:00:00+00:00, dag_hash=f42beef0c58e9d6479b9e689a95ccd00
2026-02-11 16:21:05,061 INFO - Setting next_dagrun for test_workflow_3 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:21:18,740 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:21:17.875843+00:00 [scheduled]>
2026-02-11 16:21:18,741 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:21:18,741 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:21:17.875843+00:00 [scheduled]>
2026-02-11 16:21:18,744 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:21:18,745 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:21:17.875843+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:21:18,745 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:21:17.875843+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:21:18,747 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:21:17.875843+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:21:24,947 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:21:17.875843+00:00', try_number=1, map_index=-1)
2026-02-11 16:21:24,970 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:21:17.875843+00:00, map_index=-1, run_start_date=2026-02-11 08:21:23.758095+00:00, run_end_date=2026-02-11 08:21:24.146324+00:00, run_duration=0.388229, state=success, executor_state=success, try_number=1, max_tries=0, job_id=68, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:21:18.742730+00:00, queued_by_job_id=17, pid=14533
2026-02-11 16:21:28,225 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:21:17.875843+00:00 [scheduled]>
2026-02-11 16:21:28,225 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:21:28,226 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:21:17.875843+00:00 [scheduled]>
2026-02-11 16:21:28,228 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:21:28,229 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:21:17.875843+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:21:28,230 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:21:17.875843+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:21:28,232 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:21:17.875843+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:21:33,021 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:21:17.875843+00:00', try_number=1, map_index=-1)
2026-02-11 16:21:33,035 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:21:17.875843+00:00, map_index=-1, run_start_date=2026-02-11 08:21:32.060912+00:00, run_end_date=2026-02-11 08:21:32.300165+00:00, run_duration=0.239253, state=success, executor_state=success, try_number=1, max_tries=0, job_id=69, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:21:28.227377+00:00, queued_by_job_id=17, pid=14537
2026-02-11 16:21:36,191 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:21:17.875843+00:00: manual__2026-02-11T08:21:17.875843+00:00, state:running, queued_at: 2026-02-11 08:21:17.902644+00:00. externally triggered: True> successful
2026-02-11 16:21:36,192 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:21:17.875843+00:00, run_id=manual__2026-02-11T08:21:17.875843+00:00, run_start_date=2026-02-11 08:21:18.710684+00:00, run_end_date=2026-02-11 08:21:36.192140+00:00, run_duration=17.481456, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:22:27,737 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:22:25.610413+00:00 [scheduled]>
2026-02-11 16:22:27,738 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:22:27,739 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:22:25.610413+00:00 [scheduled]>
2026-02-11 16:22:27,741 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:22:27,742 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:22:25.610413+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:22:27,743 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:22:25.610413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:22:27,745 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:22:25.610413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:22:33,706 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:22:25.610413+00:00', try_number=1, map_index=-1)
2026-02-11 16:22:33,720 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:22:25.610413+00:00, map_index=-1, run_start_date=2026-02-11 08:22:32.708161+00:00, run_end_date=2026-02-11 08:22:32.933960+00:00, run_duration=0.225799, state=success, executor_state=success, try_number=1, max_tries=0, job_id=70, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:22:27.740574+00:00, queued_by_job_id=17, pid=14599
2026-02-11 16:22:37,036 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:22:25.610413+00:00 [scheduled]>
2026-02-11 16:22:37,037 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:22:37,038 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:22:25.610413+00:00 [scheduled]>
2026-02-11 16:22:37,041 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:22:37,042 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:22:25.610413+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:22:37,043 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:22:25.610413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:22:37,045 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:22:25.610413+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:22:41,778 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:22:25.610413+00:00', try_number=1, map_index=-1)
2026-02-11 16:22:41,792 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:22:25.610413+00:00, map_index=-1, run_start_date=2026-02-11 08:22:40.865311+00:00, run_end_date=2026-02-11 08:22:41.114837+00:00, run_duration=0.249526, state=success, executor_state=success, try_number=1, max_tries=0, job_id=71, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:22:37.040105+00:00, queued_by_job_id=17, pid=14604
2026-02-11 16:22:44,986 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:22:25.610413+00:00: manual__2026-02-11T08:22:25.610413+00:00, state:running, queued_at: 2026-02-11 08:22:25.625851+00:00. externally triggered: True> successful
2026-02-11 16:22:44,988 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:22:25.610413+00:00, run_id=manual__2026-02-11T08:22:25.610413+00:00, run_start_date=2026-02-11 08:22:27.714455+00:00, run_end_date=2026-02-11 08:22:44.988068+00:00, run_duration=17.273613, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:22:49,222 INFO - Setting next_dagrun for test_workflow_2 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:22:49,250 INFO - 1 tasks up for execution:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-02-01T00:00:00+00:00 [scheduled]>
2026-02-11 16:22:49,251 INFO - DAG test_workflow_2 has 0/16 running and queued tasks
2026-02-11 16:22:49,251 INFO - Setting the following tasks to queued state:
	<TaskInstance: test_workflow_2.data_check scheduled__2026-02-01T00:00:00+00:00 [scheduled]>
2026-02-11 16:22:49,254 WARNING - cannot record scheduled_duration for task data_check because previous state change time has not been saved
2026-02-11 16:22:49,255 INFO - Sending TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-02-01T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:22:49,256 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:22:49,258 INFO - Executing command: ['airflow', 'tasks', 'run', 'test_workflow_2', 'data_check', 'scheduled__2026-02-01T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/test_workflow_dag.py']
2026-02-11 16:22:53,955 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='test_workflow_2', task_id='data_check', run_id='scheduled__2026-02-01T00:00:00+00:00', try_number=1, map_index=-1)
2026-02-11 16:22:53,969 INFO - TaskInstance Finished: dag_id=test_workflow_2, task_id=data_check, run_id=scheduled__2026-02-01T00:00:00+00:00, map_index=-1, run_start_date=2026-02-11 08:22:53.040114+00:00, run_end_date=2026-02-11 08:22:53.226433+00:00, run_duration=0.186319, state=success, executor_state=success, try_number=1, max_tries=1, job_id=72, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2026-02-11 08:22:49.253181+00:00, queued_by_job_id=17, pid=14609
2026-02-11 16:22:57,520 INFO - Marking run <DagRun test_workflow_2 @ 2026-02-01 00:00:00+00:00: scheduled__2026-02-01T00:00:00+00:00, state:running, queued_at: 2026-02-11 08:22:49.217246+00:00. externally triggered: False> successful
2026-02-11 16:22:57,522 INFO - DagRun Finished: dag_id=test_workflow_2, execution_date=2026-02-01 00:00:00+00:00, run_id=scheduled__2026-02-01T00:00:00+00:00, run_start_date=2026-02-11 08:22:49.231033+00:00, run_end_date=2026-02-11 08:22:57.522212+00:00, run_duration=8.291179, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2026-02-01 00:00:00+00:00, data_interval_end=2026-02-08 00:00:00+00:00, dag_hash=e6456c1fada1806526fd4d2f401be87d
2026-02-11 16:22:57,537 INFO - Setting next_dagrun for test_workflow_2 to 2026-02-08 00:00:00+00:00, run_after=2026-02-15 00:00:00+00:00
2026-02-11 16:24:32,448 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:25:11,146 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:25:08.734726+00:00 [scheduled]>
2026-02-11 16:25:11,147 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:25:11,148 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:25:08.734726+00:00 [scheduled]>
2026-02-11 16:25:11,150 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:25:11,152 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:25:08.734726+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:25:11,153 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:25:08.734726+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:25:11,155 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:25:08.734726+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:25:15,817 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:25:08.734726+00:00', try_number=1, map_index=-1)
2026-02-11 16:25:15,826 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:25:08.734726+00:00, map_index=-1, run_start_date=2026-02-11 08:25:14.987021+00:00, run_end_date=2026-02-11 08:25:15.182197+00:00, run_duration=0.195176, state=success, executor_state=success, try_number=1, max_tries=0, job_id=73, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:25:11.149247+00:00, queued_by_job_id=17, pid=14780
2026-02-11 16:25:19,513 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:25:08.734726+00:00 [scheduled]>
2026-02-11 16:25:19,514 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:25:19,515 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:25:08.734726+00:00 [scheduled]>
2026-02-11 16:25:19,518 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:25:19,519 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:25:08.734726+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:25:19,520 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:25:08.734726+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:25:19,522 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:25:08.734726+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:25:25,016 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:25:08.734726+00:00', try_number=1, map_index=-1)
2026-02-11 16:25:25,028 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:25:08.734726+00:00, map_index=-1, run_start_date=2026-02-11 08:25:24.082162+00:00, run_end_date=2026-02-11 08:25:24.335264+00:00, run_duration=0.253102, state=success, executor_state=success, try_number=1, max_tries=0, job_id=74, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:25:19.516134+00:00, queued_by_job_id=17, pid=14784
2026-02-11 16:25:28,045 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:25:08.734726+00:00: manual__2026-02-11T08:25:08.734726+00:00, state:running, queued_at: 2026-02-11 08:25:08.755026+00:00. externally triggered: True> successful
2026-02-11 16:25:28,046 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:25:08.734726+00:00, run_id=manual__2026-02-11T08:25:08.734726+00:00, run_start_date=2026-02-11 08:25:11.117941+00:00, run_end_date=2026-02-11 08:25:28.046170+00:00, run_duration=16.928229, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:27:42,550 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:27:41.927230+00:00 [scheduled]>
2026-02-11 16:27:42,551 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:27:42,552 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:27:41.927230+00:00 [scheduled]>
2026-02-11 16:27:42,555 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:27:42,556 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:27:41.927230+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:27:42,558 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:27:41.927230+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:27:42,563 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:27:41.927230+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:27:48,382 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:27:41.927230+00:00', try_number=1, map_index=-1)
2026-02-11 16:27:48,392 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:27:41.927230+00:00, map_index=-1, run_start_date=2026-02-11 08:27:47.342287+00:00, run_end_date=2026-02-11 08:27:47.621045+00:00, run_duration=0.278758, state=success, executor_state=success, try_number=1, max_tries=0, job_id=75, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:27:42.553086+00:00, queued_by_job_id=17, pid=14863
2026-02-11 16:27:51,361 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:27:41.927230+00:00 [scheduled]>
2026-02-11 16:27:51,362 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:27:51,363 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:27:41.927230+00:00 [scheduled]>
2026-02-11 16:27:51,365 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:27:51,366 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:27:41.927230+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:27:51,367 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:27:41.927230+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:27:51,369 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:27:41.927230+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:27:56,208 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:27:41.927230+00:00', try_number=1, map_index=-1)
2026-02-11 16:27:56,218 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:27:41.927230+00:00, map_index=-1, run_start_date=2026-02-11 08:27:55.324436+00:00, run_end_date=2026-02-11 08:27:55.565804+00:00, run_duration=0.241368, state=success, executor_state=success, try_number=1, max_tries=0, job_id=76, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:27:51.364296+00:00, queued_by_job_id=17, pid=14867
2026-02-11 16:27:59,193 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:27:41.927230+00:00: manual__2026-02-11T08:27:41.927230+00:00, state:running, queued_at: 2026-02-11 08:27:41.941588+00:00. externally triggered: True> successful
2026-02-11 16:27:59,194 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:27:41.927230+00:00, run_id=manual__2026-02-11T08:27:41.927230+00:00, run_start_date=2026-02-11 08:27:42.522243+00:00, run_end_date=2026-02-11 08:27:59.194164+00:00, run_duration=16.671921, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:29:35,782 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:32:26,935 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:32:24.586692+00:00 [scheduled]>
2026-02-11 16:32:26,936 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:32:26,937 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:32:24.586692+00:00 [scheduled]>
2026-02-11 16:32:26,939 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:32:26,940 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:32:24.586692+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:32:26,941 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:32:24.586692+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:32:26,943 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:32:24.586692+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:32:31,626 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:32:24.586692+00:00', try_number=1, map_index=-1)
2026-02-11 16:32:31,635 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:32:24.586692+00:00, map_index=-1, run_start_date=2026-02-11 08:32:30.779946+00:00, run_end_date=2026-02-11 08:32:30.970102+00:00, run_duration=0.190156, state=success, executor_state=success, try_number=1, max_tries=0, job_id=77, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:32:26.937988+00:00, queued_by_job_id=17, pid=15245
2026-02-11 16:32:35,354 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:32:24.586692+00:00 [scheduled]>
2026-02-11 16:32:35,356 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:32:35,357 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:32:24.586692+00:00 [scheduled]>
2026-02-11 16:32:35,359 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:32:35,360 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:32:24.586692+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:32:35,361 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:32:24.586692+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:32:35,363 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:32:24.586692+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:32:40,205 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:32:24.586692+00:00', try_number=1, map_index=-1)
2026-02-11 16:32:40,215 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:32:24.586692+00:00, map_index=-1, run_start_date=2026-02-11 08:32:39.313427+00:00, run_end_date=2026-02-11 08:32:39.565887+00:00, run_duration=0.25246, state=success, executor_state=success, try_number=1, max_tries=0, job_id=78, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:32:35.358605+00:00, queued_by_job_id=17, pid=15250
2026-02-11 16:32:43,179 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:32:24.586692+00:00: manual__2026-02-11T08:32:24.586692+00:00, state:running, queued_at: 2026-02-11 08:32:24.640884+00:00. externally triggered: True> successful
2026-02-11 16:32:43,180 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:32:24.586692+00:00, run_id=manual__2026-02-11T08:32:24.586692+00:00, run_start_date=2026-02-11 08:32:26.882805+00:00, run_end_date=2026-02-11 08:32:43.180512+00:00, run_duration=16.297707, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:34:36,113 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:39:36,330 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:44:37,582 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:47:04,870 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:47:01.063385+00:00 [scheduled]>
2026-02-11 16:47:04,871 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:47:04,872 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:47:01.063385+00:00 [scheduled]>
2026-02-11 16:47:04,874 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:47:04,875 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:47:01.063385+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:47:04,876 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:47:01.063385+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:47:04,878 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:47:01.063385+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:47:09,876 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:47:01.063385+00:00', try_number=1, map_index=-1)
2026-02-11 16:47:09,888 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:47:01.063385+00:00, map_index=-1, run_start_date=2026-02-11 08:47:08.829141+00:00, run_end_date=2026-02-11 08:47:09.137864+00:00, run_duration=0.308723, state=success, executor_state=success, try_number=1, max_tries=0, job_id=79, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:47:04.873114+00:00, queued_by_job_id=17, pid=16123
2026-02-11 16:47:13,611 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:47:01.063385+00:00 [scheduled]>
2026-02-11 16:47:13,612 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:47:13,613 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:47:01.063385+00:00 [scheduled]>
2026-02-11 16:47:13,616 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:47:13,617 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:47:01.063385+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:47:13,617 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:47:01.063385+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:47:13,620 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:47:01.063385+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:47:18,616 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:47:01.063385+00:00', try_number=1, map_index=-1)
2026-02-11 16:47:18,626 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:47:01.063385+00:00, map_index=-1, run_start_date=2026-02-11 08:47:17.654334+00:00, run_end_date=2026-02-11 08:47:17.914963+00:00, run_duration=0.260629, state=success, executor_state=success, try_number=1, max_tries=0, job_id=80, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:47:13.614770+00:00, queued_by_job_id=17, pid=16128
2026-02-11 16:47:21,837 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:47:01.063385+00:00: manual__2026-02-11T08:47:01.063385+00:00, state:running, queued_at: 2026-02-11 08:47:01.078804+00:00. externally triggered: True> successful
2026-02-11 16:47:21,838 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:47:01.063385+00:00, run_id=manual__2026-02-11T08:47:01.063385+00:00, run_start_date=2026-02-11 08:47:04.847214+00:00, run_end_date=2026-02-11 08:47:21.838833+00:00, run_duration=16.991619, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:49:38,235 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:49:55,970 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:49:53.899884+00:00 [scheduled]>
2026-02-11 16:49:55,971 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:49:55,972 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:49:53.899884+00:00 [scheduled]>
2026-02-11 16:49:55,975 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:49:55,976 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:49:53.899884+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:49:55,977 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:49:53.899884+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:49:55,979 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:49:53.899884+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:50:01,734 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:49:53.899884+00:00', try_number=1, map_index=-1)
2026-02-11 16:50:01,743 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:49:53.899884+00:00, map_index=-1, run_start_date=2026-02-11 08:50:00.883884+00:00, run_end_date=2026-02-11 08:50:01.074978+00:00, run_duration=0.191094, state=success, executor_state=success, try_number=1, max_tries=0, job_id=81, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:49:55.973443+00:00, queued_by_job_id=17, pid=16324
2026-02-11 16:50:04,821 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:49:53.899884+00:00 [scheduled]>
2026-02-11 16:50:04,823 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:50:04,824 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:49:53.899884+00:00 [scheduled]>
2026-02-11 16:50:04,826 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:50:04,827 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:49:53.899884+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:50:04,828 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:49:53.899884+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:50:04,831 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:49:53.899884+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:50:09,799 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:49:53.899884+00:00', try_number=1, map_index=-1)
2026-02-11 16:50:09,808 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:49:53.899884+00:00, map_index=-1, run_start_date=2026-02-11 08:50:08.876502+00:00, run_end_date=2026-02-11 08:50:09.125551+00:00, run_duration=0.249049, state=success, executor_state=success, try_number=1, max_tries=0, job_id=82, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:50:04.825036+00:00, queued_by_job_id=17, pid=16328
2026-02-11 16:50:12,748 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:49:53.899884+00:00: manual__2026-02-11T08:49:53.899884+00:00, state:running, queued_at: 2026-02-11 08:49:53.914480+00:00. externally triggered: True> successful
2026-02-11 16:50:12,749 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:49:53.899884+00:00, run_id=manual__2026-02-11T08:49:53.899884+00:00, run_start_date=2026-02-11 08:49:55.940941+00:00, run_end_date=2026-02-11 08:50:12.749656+00:00, run_duration=16.808715, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:50:46,881 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:50:45.001490+00:00 [scheduled]>
2026-02-11 16:50:46,882 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:50:46,882 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:50:45.001490+00:00 [scheduled]>
2026-02-11 16:50:46,885 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:50:46,886 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:50:45.001490+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:50:46,886 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:50:45.001490+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:50:46,888 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:50:45.001490+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:50:51,986 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:50:45.001490+00:00', try_number=1, map_index=-1)
2026-02-11 16:50:51,995 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:50:45.001490+00:00, map_index=-1, run_start_date=2026-02-11 08:50:51.131500+00:00, run_end_date=2026-02-11 08:50:51.313371+00:00, run_duration=0.181871, state=success, executor_state=success, try_number=1, max_tries=0, job_id=83, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:50:46.883783+00:00, queued_by_job_id=17, pid=16362
2026-02-11 16:50:54,987 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:50:45.001490+00:00 [scheduled]>
2026-02-11 16:50:54,988 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:50:54,989 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:50:45.001490+00:00 [scheduled]>
2026-02-11 16:50:54,991 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:50:54,992 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:50:45.001490+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:50:54,992 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:50:45.001490+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:50:54,995 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:50:45.001490+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:51:03,078 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:50:45.001490+00:00', try_number=1, map_index=-1)
2026-02-11 16:51:03,091 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:50:45.001490+00:00, map_index=-1, run_start_date=2026-02-11 08:50:59.671902+00:00, run_end_date=2026-02-11 08:51:02.375633+00:00, run_duration=2.703731, state=success, executor_state=success, try_number=1, max_tries=0, job_id=84, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:50:54.989871+00:00, queued_by_job_id=17, pid=16368
2026-02-11 16:51:06,322 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:50:45.001490+00:00: manual__2026-02-11T08:50:45.001490+00:00, state:running, queued_at: 2026-02-11 08:50:45.023371+00:00. externally triggered: True> successful
2026-02-11 16:51:06,323 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:50:45.001490+00:00, run_id=manual__2026-02-11T08:50:45.001490+00:00, run_start_date=2026-02-11 08:50:46.856358+00:00, run_end_date=2026-02-11 08:51:06.323272+00:00, run_duration=19.466914, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:53:43,211 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:53:41.610702+00:00 [scheduled]>
2026-02-11 16:53:43,212 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:53:43,213 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T08:53:41.610702+00:00 [scheduled]>
2026-02-11 16:53:43,215 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 16:53:43,216 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:53:41.610702+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 16:53:43,217 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:53:41.610702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:53:43,219 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T08:53:41.610702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:53:48,513 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T08:53:41.610702+00:00', try_number=1, map_index=-1)
2026-02-11 16:53:48,524 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T08:53:41.610702+00:00, map_index=-1, run_start_date=2026-02-11 08:53:47.654036+00:00, run_end_date=2026-02-11 08:53:47.851721+00:00, run_duration=0.197685, state=success, executor_state=success, try_number=1, max_tries=0, job_id=85, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 08:53:43.214149+00:00, queued_by_job_id=17, pid=16480
2026-02-11 16:53:52,748 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:53:41.610702+00:00 [scheduled]>
2026-02-11 16:53:52,749 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 16:53:52,750 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T08:53:41.610702+00:00 [scheduled]>
2026-02-11 16:53:52,753 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 16:53:52,754 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:53:41.610702+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 16:53:52,754 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:53:41.610702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:53:52,757 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T08:53:41.610702+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 16:54:00,077 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T08:53:41.610702+00:00', try_number=1, map_index=-1)
2026-02-11 16:54:00,090 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T08:53:41.610702+00:00, map_index=-1, run_start_date=2026-02-11 08:53:56.938201+00:00, run_end_date=2026-02-11 08:53:59.436258+00:00, run_duration=2.498057, state=success, executor_state=success, try_number=1, max_tries=0, job_id=86, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 08:53:52.751450+00:00, queued_by_job_id=17, pid=16491
2026-02-11 16:54:03,393 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 08:53:41.610702+00:00: manual__2026-02-11T08:53:41.610702+00:00, state:running, queued_at: 2026-02-11 08:53:41.624481+00:00. externally triggered: True> successful
2026-02-11 16:54:03,394 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 08:53:41.610702+00:00, run_id=manual__2026-02-11T08:53:41.610702+00:00, run_start_date=2026-02-11 08:53:43.182253+00:00, run_end_date=2026-02-11 08:54:03.394283+00:00, run_duration=20.21203, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 16:54:39,069 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 16:59:41,374 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:00:25,070 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T09:00:23.032126+00:00 [scheduled]>
2026-02-11 17:00:25,071 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 17:00:25,072 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T09:00:23.032126+00:00 [scheduled]>
2026-02-11 17:00:25,074 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 17:00:25,075 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T09:00:23.032126+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 17:00:25,077 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T09:00:23.032126+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:00:25,079 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T09:00:23.032126+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:00:30,434 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T09:00:23.032126+00:00', try_number=1, map_index=-1)
2026-02-11 17:00:30,445 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T09:00:23.032126+00:00, map_index=-1, run_start_date=2026-02-11 09:00:29.566355+00:00, run_end_date=2026-02-11 09:00:29.782841+00:00, run_duration=0.216486, state=success, executor_state=success, try_number=1, max_tries=0, job_id=87, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 09:00:25.073432+00:00, queued_by_job_id=17, pid=16717
2026-02-11 17:00:33,805 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T09:00:23.032126+00:00 [scheduled]>
2026-02-11 17:00:33,806 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 17:00:33,807 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T09:00:23.032126+00:00 [scheduled]>
2026-02-11 17:00:33,809 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 17:00:33,810 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T09:00:23.032126+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 17:00:33,811 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T09:00:23.032126+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:00:33,813 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T09:00:23.032126+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:00:41,512 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T09:00:23.032126+00:00', try_number=1, map_index=-1)
2026-02-11 17:00:41,522 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T09:00:23.032126+00:00, map_index=-1, run_start_date=2026-02-11 09:00:38.360739+00:00, run_end_date=2026-02-11 09:00:40.857586+00:00, run_duration=2.496847, state=success, executor_state=success, try_number=1, max_tries=0, job_id=88, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 09:00:33.808122+00:00, queued_by_job_id=17, pid=16721
2026-02-11 17:00:44,888 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 09:00:23.032126+00:00: manual__2026-02-11T09:00:23.032126+00:00, state:running, queued_at: 2026-02-11 09:00:23.046249+00:00. externally triggered: True> successful
2026-02-11 17:00:44,890 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 09:00:23.032126+00:00, run_id=manual__2026-02-11T09:00:23.032126+00:00, run_start_date=2026-02-11 09:00:25.046869+00:00, run_end_date=2026-02-11 09:00:44.890070+00:00, run_duration=19.843201, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 17:01:56,956 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T09:01:55.682358+00:00 [scheduled]>
2026-02-11 17:01:56,959 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 17:01:56,961 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T09:01:55.682358+00:00 [scheduled]>
2026-02-11 17:01:56,971 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 17:01:56,972 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T09:01:55.682358+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 17:01:56,975 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T09:01:55.682358+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:01:56,991 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T09:01:55.682358+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:02:02,471 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T09:01:55.682358+00:00', try_number=1, map_index=-1)
2026-02-11 17:02:02,482 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T09:01:55.682358+00:00, map_index=-1, run_start_date=2026-02-11 09:02:01.578233+00:00, run_end_date=2026-02-11 09:02:01.763419+00:00, run_duration=0.185186, state=success, executor_state=success, try_number=1, max_tries=0, job_id=89, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 09:01:56.967261+00:00, queued_by_job_id=17, pid=16817
2026-02-11 17:02:06,509 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T09:01:55.682358+00:00 [scheduled]>
2026-02-11 17:02:06,509 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 17:02:06,510 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T09:01:55.682358+00:00 [scheduled]>
2026-02-11 17:02:06,513 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 17:02:06,514 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T09:01:55.682358+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 17:02:06,514 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T09:01:55.682358+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:02:06,517 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T09:01:55.682358+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:02:13,807 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T09:01:55.682358+00:00', try_number=1, map_index=-1)
2026-02-11 17:02:13,816 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T09:01:55.682358+00:00, map_index=-1, run_start_date=2026-02-11 09:02:10.627316+00:00, run_end_date=2026-02-11 09:02:13.120316+00:00, run_duration=2.493, state=success, executor_state=success, try_number=1, max_tries=0, job_id=90, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 09:02:06.511791+00:00, queued_by_job_id=17, pid=16821
2026-02-11 17:02:17,260 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 09:01:55.682358+00:00: manual__2026-02-11T09:01:55.682358+00:00, state:running, queued_at: 2026-02-11 09:01:55.700669+00:00. externally triggered: True> successful
2026-02-11 17:02:17,261 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 09:01:55.682358+00:00, run_id=manual__2026-02-11T09:01:55.682358+00:00, run_start_date=2026-02-11 09:01:56.931656+00:00, run_end_date=2026-02-11 09:02:17.261699+00:00, run_duration=20.330043, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 17:04:41,776 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:06:37,120 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T09:06:35.236247+00:00 [scheduled]>
2026-02-11 17:06:37,121 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 17:06:37,121 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T09:06:35.236247+00:00 [scheduled]>
2026-02-11 17:06:37,124 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 17:06:37,125 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T09:06:35.236247+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 17:06:37,125 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T09:06:35.236247+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:06:37,128 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T09:06:35.236247+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:06:42,727 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T09:06:35.236247+00:00', try_number=1, map_index=-1)
2026-02-11 17:06:42,737 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T09:06:35.236247+00:00, map_index=-1, run_start_date=2026-02-11 09:06:41.938664+00:00, run_end_date=2026-02-11 09:06:42.134075+00:00, run_duration=0.195411, state=success, executor_state=success, try_number=1, max_tries=0, job_id=91, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 09:06:37.122916+00:00, queued_by_job_id=17, pid=17005
2026-02-11 17:06:45,796 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T09:06:35.236247+00:00 [scheduled]>
2026-02-11 17:06:45,797 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 17:06:45,798 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T09:06:35.236247+00:00 [scheduled]>
2026-02-11 17:06:45,800 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 17:06:45,801 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T09:06:35.236247+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 17:06:45,802 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T09:06:35.236247+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:06:45,804 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T09:06:35.236247+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 17:14:13,896 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T09:06:35.236247+00:00', try_number=1, map_index=-1)
2026-02-11 17:14:13,909 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T09:06:35.236247+00:00, map_index=-1, run_start_date=2026-02-11 09:06:49.644482+00:00, run_end_date=2026-02-11 09:14:13.133820+00:00, run_duration=443.489338, state=success, executor_state=success, try_number=1, max_tries=0, job_id=92, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 09:06:45.799522+00:00, queued_by_job_id=17, pid=17009
2026-02-11 17:14:13,921 ERROR - DagFileProcessorManager (PID=14149) last sent a heartbeat 448.17 seconds ago! Restarting it
2026-02-11 17:14:13,933 INFO - Sending Signals.SIGTERM to group 14149. PIDs of all processes in the group: [14149]
2026-02-11 17:14:13,934 INFO - Sending the signal Signals.SIGTERM to group 14149
2026-02-11 17:14:14,794 INFO - Process psutil.Process(pid=14149, status='terminated', exitcode=0, started='16:14:23') (14149) terminated with exit code 0
2026-02-11 17:14:14,804 INFO - Launched DagFileProcessorManager with pid: 17672
2026-02-11 17:14:14,842 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:14:21,169 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 09:06:35.236247+00:00: manual__2026-02-11T09:06:35.236247+00:00, state:running, queued_at: 2026-02-11 09:06:35.263951+00:00. externally triggered: True> successful
2026-02-11 17:14:21,170 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 09:06:35.236247+00:00, run_id=manual__2026-02-11T09:06:35.236247+00:00, run_start_date=2026-02-11 09:06:37.097530+00:00, run_end_date=2026-02-11 09:14:21.170266+00:00, run_duration=464.072736, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 17:19:17,521 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:24:18,412 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:29:18,998 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:34:22,144 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:39:25,872 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:44:26,544 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:49:27,565 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:54:30,379 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 17:59:33,575 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 18:04:34,279 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 18:06:04,033 INFO - Exiting gracefully upon receiving signal 15
2026-02-11 18:06:05,077 INFO - Sending Signals.SIGTERM to group 17672. PIDs of all processes in the group: [17672]
2026-02-11 18:06:05,078 INFO - Sending the signal Signals.SIGTERM to group 17672
2026-02-11 18:06:05,106 INFO - Process psutil.Process(pid=17672, status='terminated', exitcode=<Negsignal.SIGTERM: -15>, started='17:14:14') (17672) terminated with exit code Negsignal.SIGTERM
2026-02-11 18:06:05,119 INFO - Sending Signals.SIGTERM to group 17672. PIDs of all processes in the group: []
2026-02-11 18:06:05,120 INFO - Sending the signal Signals.SIGTERM to group 17672
2026-02-11 18:06:05,121 INFO - Sending the signal Signals.SIGTERM to process 17672 as process group is missing.
2026-02-11 18:06:05,122 INFO - Exited execute loop
2026-02-11 19:49:47,099 INFO - Task context logging is enabled
2026-02-11 19:49:47,103 INFO - Loaded executor: SequentialExecutor
2026-02-11 19:49:47,187 INFO - Starting the scheduler
2026-02-11 19:49:47,188 INFO - Processing each file at most -1 times
2026-02-11 19:49:47,195 INFO - Launched DagFileProcessorManager with pid: 1103
2026-02-11 19:49:47,202 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 19:50:47,209 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>
2026-02-11 19:50:47,210 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 19:50:47,211 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>
2026-02-11 19:50:47,213 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 19:50:47,214 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 19:50:47,215 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 19:50:47,217 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 19:50:53,631 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1)
2026-02-11 19:50:53,649 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T11:50:44.236059+00:00, map_index=-1, run_start_date=2026-02-11 11:50:51.638132+00:00, run_end_date=2026-02-11 11:50:52.437203+00:00, run_duration=0.799071, state=success, executor_state=success, try_number=1, max_tries=0, job_id=94, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 11:50:47.211969+00:00, queued_by_job_id=93, pid=1149
2026-02-11 19:50:57,049 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>
2026-02-11 19:50:57,050 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 19:50:57,051 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T11:50:44.236059+00:00 [scheduled]>
2026-02-11 19:50:57,053 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 19:50:57,054 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 19:50:57,056 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 19:50:57,058 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T11:50:44.236059+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 19:51:18,050 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T11:50:44.236059+00:00', try_number=1, map_index=-1)
2026-02-11 19:51:18,069 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T11:50:44.236059+00:00, map_index=-1, run_start_date=2026-02-11 11:51:01.651825+00:00, run_end_date=2026-02-11 11:51:17.206445+00:00, run_duration=15.55462, state=success, executor_state=success, try_number=1, max_tries=0, job_id=95, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 11:50:57.052619+00:00, queued_by_job_id=93, pid=1156
2026-02-11 19:51:21,889 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 11:50:44.236059+00:00: manual__2026-02-11T11:50:44.236059+00:00, state:running, queued_at: 2026-02-11 11:50:44.272227+00:00. externally triggered: True> successful
2026-02-11 19:51:21,891 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 11:50:44.236059+00:00, run_id=manual__2026-02-11T11:50:44.236059+00:00, run_start_date=2026-02-11 11:50:47.163710+00:00, run_end_date=2026-02-11 11:51:21.891202+00:00, run_duration=34.727492, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 19:54:48,303 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 20:59:51,203 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:04:53,801 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:05:06,008 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>
2026-02-11 21:05:06,009 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:05:06,009 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>
2026-02-11 21:05:06,011 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:05:06,012 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:05:06,013 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:05:06,015 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:05:10,757 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1)
2026-02-11 21:05:10,770 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:05:02.341510+00:00, map_index=-1, run_start_date=2026-02-11 13:05:09.926357+00:00, run_end_date=2026-02-11 13:05:10.132033+00:00, run_duration=0.205676, state=success, executor_state=success, try_number=1, max_tries=0, job_id=96, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:05:06.010785+00:00, queued_by_job_id=93, pid=2031
2026-02-11 21:05:14,139 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>
2026-02-11 21:05:14,140 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:05:14,140 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:05:02.341510+00:00 [scheduled]>
2026-02-11 21:05:14,142 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:05:14,144 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:05:14,144 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:05:14,147 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:05:02.341510+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:05:25,851 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:05:02.341510+00:00', try_number=1, map_index=-1)
2026-02-11 21:05:25,862 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:05:02.341510+00:00, map_index=-1, run_start_date=2026-02-11 13:05:18.016573+00:00, run_end_date=2026-02-11 13:05:25.202756+00:00, run_duration=7.186183, state=success, executor_state=success, try_number=1, max_tries=0, job_id=97, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:05:14.141781+00:00, queued_by_job_id=93, pid=2035
2026-02-11 21:05:29,454 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:05:02.341510+00:00: manual__2026-02-11T13:05:02.341510+00:00, state:running, queued_at: 2026-02-11 13:05:02.372774+00:00. externally triggered: True> successful
2026-02-11 21:05:29,455 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:05:02.341510+00:00, run_id=manual__2026-02-11T13:05:02.341510+00:00, run_start_date=2026-02-11 13:05:05.989542+00:00, run_end_date=2026-02-11 13:05:29.455430+00:00, run_duration=23.465888, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:09:55,171 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:14:04,705 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>
2026-02-11 21:14:04,706 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:14:04,706 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>
2026-02-11 21:14:04,709 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:14:04,711 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:14:04,712 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:14:04,714 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:14:10,193 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1)
2026-02-11 21:14:10,207 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:14:02.480310+00:00, map_index=-1, run_start_date=2026-02-11 13:14:09.371338+00:00, run_end_date=2026-02-11 13:14:09.551631+00:00, run_duration=0.180293, state=success, executor_state=success, try_number=1, max_tries=0, job_id=98, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:14:04.707798+00:00, queued_by_job_id=93, pid=2627
2026-02-11 21:14:13,294 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>
2026-02-11 21:14:13,294 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:14:13,295 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:14:02.480310+00:00 [scheduled]>
2026-02-11 21:14:13,298 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:14:13,299 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:14:13,299 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:14:13,302 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:14:02.480310+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:14:19,874 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:14:02.480310+00:00', try_number=1, map_index=-1)
2026-02-11 21:14:19,888 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:14:02.480310+00:00, map_index=-1, run_start_date=2026-02-11 13:14:16.970903+00:00, run_end_date=2026-02-11 13:14:19.194837+00:00, run_duration=2.223934, state=success, executor_state=success, try_number=1, max_tries=0, job_id=99, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:14:13.297008+00:00, queued_by_job_id=93, pid=2631
2026-02-11 21:14:22,887 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:14:02.480310+00:00: manual__2026-02-11T13:14:02.480310+00:00, state:running, queued_at: 2026-02-11 13:14:02.506343+00:00. externally triggered: True> successful
2026-02-11 21:14:22,887 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:14:02.480310+00:00, run_id=manual__2026-02-11T13:14:02.480310+00:00, run_start_date=2026-02-11 13:14:04.682347+00:00, run_end_date=2026-02-11 13:14:22.887842+00:00, run_duration=18.205495, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:14:55,634 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:19:06,197 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>
2026-02-11 21:19:06,198 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:19:06,199 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>
2026-02-11 21:19:06,201 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:19:06,202 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:19:06,202 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:19:06,204 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:19:11,264 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1)
2026-02-11 21:19:11,273 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:19:03.976200+00:00, map_index=-1, run_start_date=2026-02-11 13:19:10.406433+00:00, run_end_date=2026-02-11 13:19:10.583585+00:00, run_duration=0.177152, state=success, executor_state=success, try_number=1, max_tries=0, job_id=100, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:19:06.199988+00:00, queued_by_job_id=93, pid=2899
2026-02-11 21:19:14,153 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>
2026-02-11 21:19:14,154 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:19:14,155 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:19:03.976200+00:00 [scheduled]>
2026-02-11 21:19:14,157 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:19:14,158 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:19:14,158 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:19:14,161 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:19:03.976200+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:19:20,505 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:19:03.976200+00:00', try_number=1, map_index=-1)
2026-02-11 21:19:20,514 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:19:03.976200+00:00, map_index=-1, run_start_date=2026-02-11 13:19:17.872533+00:00, run_end_date=2026-02-11 13:19:19.856529+00:00, run_duration=1.983996, state=success, executor_state=success, try_number=1, max_tries=0, job_id=101, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:19:14.156003+00:00, queued_by_job_id=93, pid=2905
2026-02-11 21:19:23,508 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:19:03.976200+00:00: manual__2026-02-11T13:19:03.976200+00:00, state:running, queued_at: 2026-02-11 13:19:03.996122+00:00. externally triggered: True> successful
2026-02-11 21:19:23,509 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:19:03.976200+00:00, run_id=manual__2026-02-11T13:19:03.976200+00:00, run_start_date=2026-02-11 13:19:06.175764+00:00, run_end_date=2026-02-11 13:19:23.509103+00:00, run_duration=17.333339, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:19:58,070 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:23:25,767 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>
2026-02-11 21:23:25,768 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:23:25,769 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>
2026-02-11 21:23:25,771 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:23:25,772 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:23:25,772 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:23:25,774 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:23:30,828 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1)
2026-02-11 21:23:30,840 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:23:22.474344+00:00, map_index=-1, run_start_date=2026-02-11 13:23:29.878014+00:00, run_end_date=2026-02-11 13:23:30.055923+00:00, run_duration=0.177909, state=success, executor_state=success, try_number=1, max_tries=0, job_id=102, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:23:25.770124+00:00, queued_by_job_id=93, pid=3165
2026-02-11 21:23:34,057 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>
2026-02-11 21:23:34,059 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:23:34,060 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:23:22.474344+00:00 [scheduled]>
2026-02-11 21:23:34,062 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:23:34,063 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:23:34,064 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:23:34,066 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:23:22.474344+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:23:41,294 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:23:22.474344+00:00', try_number=1, map_index=-1)
2026-02-11 21:23:41,303 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:23:22.474344+00:00, map_index=-1, run_start_date=2026-02-11 13:23:38.253564+00:00, run_end_date=2026-02-11 13:23:40.613808+00:00, run_duration=2.360244, state=success, executor_state=success, try_number=1, max_tries=0, job_id=103, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:23:34.061620+00:00, queued_by_job_id=93, pid=3175
2026-02-11 21:23:44,486 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:23:22.474344+00:00: manual__2026-02-11T13:23:22.474344+00:00, state:running, queued_at: 2026-02-11 13:23:22.486240+00:00. externally triggered: True> successful
2026-02-11 21:23:44,487 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:23:22.474344+00:00, run_id=manual__2026-02-11T13:23:22.474344+00:00, run_start_date=2026-02-11 13:23:25.749502+00:00, run_end_date=2026-02-11 13:23:44.487725+00:00, run_duration=18.738223, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:25:00,407 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:30:01,937 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:34:40,014 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>
2026-02-11 21:34:40,015 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:34:40,016 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>
2026-02-11 21:34:40,019 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:34:40,020 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:34:40,020 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:34:40,023 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:34:45,188 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1)
2026-02-11 21:34:45,196 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:34:36.593158+00:00, map_index=-1, run_start_date=2026-02-11 13:34:44.379490+00:00, run_end_date=2026-02-11 13:34:44.568175+00:00, run_duration=0.188685, state=success, executor_state=success, try_number=1, max_tries=0, job_id=104, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:34:40.017800+00:00, queued_by_job_id=93, pid=3765
2026-02-11 21:34:48,071 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>
2026-02-11 21:34:48,072 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:34:48,073 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:34:36.593158+00:00 [scheduled]>
2026-02-11 21:34:48,075 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:34:48,076 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:34:48,077 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:34:48,079 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:34:36.593158+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:34:54,368 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:34:36.593158+00:00', try_number=1, map_index=-1)
2026-02-11 21:34:54,377 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:34:36.593158+00:00, map_index=-1, run_start_date=2026-02-11 13:34:51.657620+00:00, run_end_date=2026-02-11 13:34:53.677940+00:00, run_duration=2.02032, state=success, executor_state=success, try_number=1, max_tries=0, job_id=105, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:34:48.074138+00:00, queued_by_job_id=93, pid=3769
2026-02-11 21:34:57,421 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:34:36.593158+00:00: manual__2026-02-11T13:34:36.593158+00:00, state:running, queued_at: 2026-02-11 13:34:36.605715+00:00. externally triggered: True> successful
2026-02-11 21:34:57,422 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:34:36.593158+00:00, run_id=manual__2026-02-11T13:34:36.593158+00:00, run_start_date=2026-02-11 13:34:39.990771+00:00, run_end_date=2026-02-11 13:34:57.422034+00:00, run_duration=17.431263, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:35:04,605 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:37:37,320 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>
2026-02-11 21:37:37,323 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:37:37,325 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>
2026-02-11 21:37:37,328 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:37:37,329 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:37:37,329 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:37:37,332 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:37:42,734 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1)
2026-02-11 21:37:42,746 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:37:36.537391+00:00, map_index=-1, run_start_date=2026-02-11 13:37:41.882286+00:00, run_end_date=2026-02-11 13:37:42.065775+00:00, run_duration=0.183489, state=success, executor_state=success, try_number=1, max_tries=0, job_id=106, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:37:37.326976+00:00, queued_by_job_id=93, pid=3943
2026-02-11 21:37:45,656 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>
2026-02-11 21:37:45,656 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:37:45,658 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:37:36.537391+00:00 [scheduled]>
2026-02-11 21:37:45,660 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:37:45,661 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:37:45,661 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:37:45,663 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:37:36.537391+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:37:51,986 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:37:36.537391+00:00', try_number=1, map_index=-1)
2026-02-11 21:37:51,995 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:37:36.537391+00:00, map_index=-1, run_start_date=2026-02-11 13:37:49.300973+00:00, run_end_date=2026-02-11 13:37:51.291899+00:00, run_duration=1.990926, state=success, executor_state=success, try_number=1, max_tries=0, job_id=107, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:37:45.659179+00:00, queued_by_job_id=93, pid=3947
2026-02-11 21:37:54,897 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:37:36.537391+00:00: manual__2026-02-11T13:37:36.537391+00:00, state:running, queued_at: 2026-02-11 13:37:36.548199+00:00. externally triggered: True> successful
2026-02-11 21:37:54,898 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:37:36.537391+00:00, run_id=manual__2026-02-11T13:37:36.537391+00:00, run_start_date=2026-02-11 13:37:37.280574+00:00, run_end_date=2026-02-11 13:37:54.898275+00:00, run_duration=17.617701, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:40:05,432 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:42:10,068 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>
2026-02-11 21:42:10,069 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:42:10,070 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>
2026-02-11 21:42:10,072 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:42:10,073 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:42:10,074 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:42:10,076 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:42:16,009 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1)
2026-02-11 21:42:16,021 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:42:06.098390+00:00, map_index=-1, run_start_date=2026-02-11 13:42:14.977714+00:00, run_end_date=2026-02-11 13:42:15.202350+00:00, run_duration=0.224636, state=success, executor_state=success, try_number=1, max_tries=0, job_id=108, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:42:10.071255+00:00, queued_by_job_id=93, pid=4261
2026-02-11 21:42:19,036 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>
2026-02-11 21:42:19,037 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:42:19,038 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:42:06.098390+00:00 [scheduled]>
2026-02-11 21:42:19,040 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:42:19,041 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:42:19,042 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:42:19,044 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:42:06.098390+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:42:26,033 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:42:06.098390+00:00', try_number=1, map_index=-1)
2026-02-11 21:42:26,044 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:42:06.098390+00:00, map_index=-1, run_start_date=2026-02-11 13:42:23.050722+00:00, run_end_date=2026-02-11 13:42:25.358396+00:00, run_duration=2.307674, state=success, executor_state=success, try_number=1, max_tries=0, job_id=109, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:42:19.039312+00:00, queued_by_job_id=93, pid=4265
2026-02-11 21:42:28,890 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:42:06.098390+00:00: manual__2026-02-11T13:42:06.098390+00:00, state:running, queued_at: 2026-02-11 13:42:06.109305+00:00. externally triggered: True> successful
2026-02-11 21:42:28,891 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:42:06.098390+00:00, run_id=manual__2026-02-11T13:42:06.098390+00:00, run_start_date=2026-02-11 13:42:10.043511+00:00, run_end_date=2026-02-11 13:42:28.891156+00:00, run_duration=18.847645, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:45:08,342 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:45:12,598 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>
2026-02-11 21:45:12,599 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:45:12,600 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>
2026-02-11 21:45:12,602 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:45:12,602 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:45:12,603 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:45:12,605 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:45:17,971 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1)
2026-02-11 21:45:17,979 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:45:11.332773+00:00, map_index=-1, run_start_date=2026-02-11 13:45:17.144642+00:00, run_end_date=2026-02-11 13:45:17.320385+00:00, run_duration=0.175743, state=success, executor_state=success, try_number=1, max_tries=0, job_id=110, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:45:12.601087+00:00, queued_by_job_id=93, pid=4445
2026-02-11 21:45:21,124 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>
2026-02-11 21:45:21,125 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:45:21,125 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:45:11.332773+00:00 [scheduled]>
2026-02-11 21:45:21,127 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:45:21,128 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:45:21,129 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:45:21,131 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:45:11.332773+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:45:27,542 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:45:11.332773+00:00', try_number=1, map_index=-1)
2026-02-11 21:45:27,552 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:45:11.332773+00:00, map_index=-1, run_start_date=2026-02-11 13:45:24.808986+00:00, run_end_date=2026-02-11 13:45:26.932855+00:00, run_duration=2.123869, state=success, executor_state=success, try_number=1, max_tries=0, job_id=111, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:45:21.126531+00:00, queued_by_job_id=93, pid=4457
2026-02-11 21:45:30,711 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:45:11.332773+00:00: manual__2026-02-11T13:45:11.332773+00:00, state:running, queued_at: 2026-02-11 13:45:11.343680+00:00. externally triggered: True> successful
2026-02-11 21:45:30,712 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:45:11.332773+00:00, run_id=manual__2026-02-11T13:45:11.332773+00:00, run_start_date=2026-02-11 13:45:12.576379+00:00, run_end_date=2026-02-11 13:45:30.712285+00:00, run_duration=18.135906, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:50:09,151 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:51:54,565 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>
2026-02-11 21:51:54,565 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:51:54,566 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>
2026-02-11 21:51:54,568 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:51:54,569 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:51:54,570 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:51:54,572 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:51:59,756 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1)
2026-02-11 21:51:59,765 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:51:53.606280+00:00, map_index=-1, run_start_date=2026-02-11 13:51:58.929545+00:00, run_end_date=2026-02-11 13:51:59.116235+00:00, run_duration=0.18669, state=success, executor_state=success, try_number=1, max_tries=0, job_id=112, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:51:54.567627+00:00, queued_by_job_id=93, pid=4778
2026-02-11 21:52:02,577 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>
2026-02-11 21:52:02,578 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:52:02,579 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:51:53.606280+00:00 [scheduled]>
2026-02-11 21:52:02,581 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:52:02,582 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:52:02,583 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:52:02,585 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:51:53.606280+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:52:08,971 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:51:53.606280+00:00', try_number=1, map_index=-1)
2026-02-11 21:52:08,983 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:51:53.606280+00:00, map_index=-1, run_start_date=2026-02-11 13:52:06.165166+00:00, run_end_date=2026-02-11 13:52:08.284392+00:00, run_duration=2.119226, state=success, executor_state=success, try_number=1, max_tries=0, job_id=113, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:52:02.580306+00:00, queued_by_job_id=93, pid=4785
2026-02-11 21:52:11,769 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:51:53.606280+00:00: manual__2026-02-11T13:51:53.606280+00:00, state:running, queued_at: 2026-02-11 13:51:53.626641+00:00. externally triggered: True> successful
2026-02-11 21:52:11,770 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:51:53.606280+00:00, run_id=manual__2026-02-11T13:51:53.606280+00:00, run_start_date=2026-02-11 13:51:54.542967+00:00, run_end_date=2026-02-11 13:52:11.770204+00:00, run_duration=17.227237, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 21:55:10,944 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 21:57:48,651 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>
2026-02-11 21:57:48,652 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:57:48,652 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>
2026-02-11 21:57:48,654 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 21:57:48,655 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 21:57:48,655 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:57:48,657 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:57:53,551 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1)
2026-02-11 21:57:53,561 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T13:57:45.161908+00:00, map_index=-1, run_start_date=2026-02-11 13:57:52.568219+00:00, run_end_date=2026-02-11 13:57:52.798058+00:00, run_duration=0.229839, state=success, executor_state=success, try_number=1, max_tries=0, job_id=114, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 13:57:48.653419+00:00, queued_by_job_id=93, pid=5020
2026-02-11 21:57:56,795 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>
2026-02-11 21:57:56,796 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 21:57:56,797 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T13:57:45.161908+00:00 [scheduled]>
2026-02-11 21:57:56,799 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 21:57:56,800 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 21:57:56,801 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:57:56,803 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T13:57:45.161908+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 21:58:03,725 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T13:57:45.161908+00:00', try_number=1, map_index=-1)
2026-02-11 21:58:03,734 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T13:57:45.161908+00:00, map_index=-1, run_start_date=2026-02-11 13:58:00.613029+00:00, run_end_date=2026-02-11 13:58:03.051725+00:00, run_duration=2.438696, state=success, executor_state=success, try_number=1, max_tries=0, job_id=115, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 13:57:56.798111+00:00, queued_by_job_id=93, pid=5024
2026-02-11 21:58:07,370 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 13:57:45.161908+00:00: manual__2026-02-11T13:57:45.161908+00:00, state:running, queued_at: 2026-02-11 13:57:45.173955+00:00. externally triggered: True> successful
2026-02-11 21:58:07,371 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 13:57:45.161908+00:00, run_id=manual__2026-02-11T13:57:45.161908+00:00, run_start_date=2026-02-11 13:57:48.626749+00:00, run_end_date=2026-02-11 13:58:07.371771+00:00, run_duration=18.745022, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:00:14,735 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:05:16,671 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:10:18,039 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:15:20,563 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:20:21,200 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:22:08,516 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>
2026-02-11 22:22:08,517 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:22:08,517 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>
2026-02-11 22:22:08,519 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:22:08,520 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:22:08,521 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:22:08,523 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:22:13,028 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1)
2026-02-11 22:22:13,043 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:22:04.982000+00:00, map_index=-1, run_start_date=2026-02-11 14:22:12.100972+00:00, run_end_date=2026-02-11 14:22:12.285802+00:00, run_duration=0.18483, state=success, executor_state=success, try_number=1, max_tries=0, job_id=116, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:22:08.518390+00:00, queued_by_job_id=93, pid=5877
2026-02-11 22:22:16,335 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>
2026-02-11 22:22:16,336 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:22:16,337 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:22:04.982000+00:00 [scheduled]>
2026-02-11 22:22:16,339 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:22:16,340 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:22:16,341 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:22:16,343 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:22:04.982000+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:22:22,992 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:22:04.982000+00:00', try_number=1, map_index=-1)
2026-02-11 22:22:23,007 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:22:04.982000+00:00, map_index=-1, run_start_date=2026-02-11 14:22:20.001092+00:00, run_end_date=2026-02-11 14:22:22.310501+00:00, run_duration=2.309409, state=success, executor_state=success, try_number=1, max_tries=0, job_id=117, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:22:16.338146+00:00, queued_by_job_id=93, pid=5885
2026-02-11 22:22:25,813 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:22:04.982000+00:00: manual__2026-02-11T14:22:04.982000+00:00, state:running, queued_at: 2026-02-11 14:22:04.994901+00:00. externally triggered: True> successful
2026-02-11 22:22:25,815 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:22:04.982000+00:00, run_id=manual__2026-02-11T14:22:04.982000+00:00, run_start_date=2026-02-11 14:22:08.496444+00:00, run_end_date=2026-02-11 14:22:25.815010+00:00, run_duration=17.318566, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:23:26,305 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>
2026-02-11 22:23:26,306 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:23:26,307 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>
2026-02-11 22:23:26,309 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:23:26,310 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:23:26,311 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:23:26,313 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:23:30,784 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1)
2026-02-11 22:23:30,801 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:23:22.716575+00:00, map_index=-1, run_start_date=2026-02-11 14:23:29.865013+00:00, run_end_date=2026-02-11 14:23:30.047501+00:00, run_duration=0.182488, state=success, executor_state=success, try_number=1, max_tries=0, job_id=118, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:23:26.308389+00:00, queued_by_job_id=93, pid=5957
2026-02-11 22:23:33,958 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>
2026-02-11 22:23:33,959 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:23:33,960 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:23:22.716575+00:00 [scheduled]>
2026-02-11 22:23:33,962 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:23:33,963 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:23:33,964 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:23:33,966 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:23:22.716575+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:23:40,305 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:23:22.716575+00:00', try_number=1, map_index=-1)
2026-02-11 22:23:40,317 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:23:22.716575+00:00, map_index=-1, run_start_date=2026-02-11 14:23:37.607422+00:00, run_end_date=2026-02-11 14:23:39.643012+00:00, run_duration=2.03559, state=success, executor_state=success, try_number=1, max_tries=0, job_id=119, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:23:33.961121+00:00, queued_by_job_id=93, pid=5963
2026-02-11 22:23:43,251 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:23:22.716575+00:00: manual__2026-02-11T14:23:22.716575+00:00, state:running, queued_at: 2026-02-11 14:23:22.728972+00:00. externally triggered: True> successful
2026-02-11 22:23:43,252 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:23:22.716575+00:00, run_id=manual__2026-02-11T14:23:22.716575+00:00, run_start_date=2026-02-11 14:23:26.284947+00:00, run_end_date=2026-02-11 14:23:43.252408+00:00, run_duration=16.967461, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:24:29,057 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>
2026-02-11 22:24:29,057 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:24:29,058 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>
2026-02-11 22:24:29,060 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:24:29,061 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:24:29,062 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:24:29,064 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:24:33,769 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1)
2026-02-11 22:24:33,783 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:24:25.278535+00:00, map_index=-1, run_start_date=2026-02-11 14:24:32.782183+00:00, run_end_date=2026-02-11 14:24:33.018163+00:00, run_duration=0.23598, state=success, executor_state=success, try_number=1, max_tries=0, job_id=120, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:24:29.059208+00:00, queued_by_job_id=93, pid=6025
2026-02-11 22:24:36,878 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>
2026-02-11 22:24:36,879 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:24:36,880 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:24:25.278535+00:00 [scheduled]>
2026-02-11 22:24:36,882 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:24:36,883 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:24:36,885 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:24:36,887 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:24:25.278535+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:24:43,353 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:24:25.278535+00:00', try_number=1, map_index=-1)
2026-02-11 22:24:43,366 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:24:25.278535+00:00, map_index=-1, run_start_date=2026-02-11 14:24:40.756154+00:00, run_end_date=2026-02-11 14:24:42.651397+00:00, run_duration=1.895243, state=success, executor_state=success, try_number=1, max_tries=0, job_id=121, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:24:36.880987+00:00, queued_by_job_id=93, pid=6031
2026-02-11 22:24:46,377 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:24:25.278535+00:00: manual__2026-02-11T14:24:25.278535+00:00, state:running, queued_at: 2026-02-11 14:24:25.290518+00:00. externally triggered: True> successful
2026-02-11 22:24:46,378 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:24:25.278535+00:00, run_id=manual__2026-02-11T14:24:25.278535+00:00, run_start_date=2026-02-11 14:24:29.036943+00:00, run_end_date=2026-02-11 14:24:46.378445+00:00, run_duration=17.341502, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:25:23,044 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:30:25,624 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:34:02,793 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>
2026-02-11 22:34:02,794 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:34:02,795 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>
2026-02-11 22:34:02,796 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:34:02,797 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:34:02,798 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:34:02,800 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:34:07,660 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1)
2026-02-11 22:34:07,671 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:34:01.458331+00:00, map_index=-1, run_start_date=2026-02-11 14:34:06.817026+00:00, run_end_date=2026-02-11 14:34:06.984005+00:00, run_duration=0.166979, state=success, executor_state=success, try_number=1, max_tries=0, job_id=122, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:34:02.795914+00:00, queued_by_job_id=93, pid=6356
2026-02-11 22:34:10,882 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>
2026-02-11 22:34:10,884 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:34:10,886 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:34:01.458331+00:00 [scheduled]>
2026-02-11 22:34:10,891 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:34:10,894 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:34:10,896 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:34:10,899 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:34:01.458331+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:34:18,330 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:34:01.458331+00:00', try_number=1, map_index=-1)
2026-02-11 22:34:18,345 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:34:01.458331+00:00, map_index=-1, run_start_date=2026-02-11 14:34:15.274814+00:00, run_end_date=2026-02-11 14:34:17.650822+00:00, run_duration=2.376008, state=success, executor_state=success, try_number=1, max_tries=0, job_id=123, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:34:10.889656+00:00, queued_by_job_id=93, pid=6360
2026-02-11 22:34:21,201 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:34:01.458331+00:00: manual__2026-02-11T14:34:01.458331+00:00, state:running, queued_at: 2026-02-11 14:34:01.472530+00:00. externally triggered: True> successful
2026-02-11 22:34:21,202 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:34:01.458331+00:00, run_id=manual__2026-02-11T14:34:01.458331+00:00, run_start_date=2026-02-11 14:34:02.771449+00:00, run_end_date=2026-02-11 14:34:21.202514+00:00, run_duration=18.431065, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:35:26,556 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:35:30,842 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>
2026-02-11 22:35:30,843 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:35:30,844 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>
2026-02-11 22:35:30,846 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:35:30,847 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:35:30,847 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:35:30,849 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:35:35,306 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1)
2026-02-11 22:35:35,318 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:35:28.256387+00:00, map_index=-1, run_start_date=2026-02-11 14:35:34.456559+00:00, run_end_date=2026-02-11 14:35:34.622624+00:00, run_duration=0.166065, state=success, executor_state=success, try_number=1, max_tries=0, job_id=124, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:35:30.845075+00:00, queued_by_job_id=93, pid=6417
2026-02-11 22:35:38,456 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>
2026-02-11 22:35:38,457 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:35:38,457 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:35:28.256387+00:00 [scheduled]>
2026-02-11 22:35:38,460 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:35:38,461 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:35:38,462 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:35:38,464 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:35:28.256387+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:35:45,438 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:35:28.256387+00:00', try_number=1, map_index=-1)
2026-02-11 22:35:45,451 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:35:28.256387+00:00, map_index=-1, run_start_date=2026-02-11 14:35:42.466015+00:00, run_end_date=2026-02-11 14:35:44.750256+00:00, run_duration=2.284241, state=success, executor_state=success, try_number=1, max_tries=0, job_id=125, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:35:38.458848+00:00, queued_by_job_id=93, pid=6421
2026-02-11 22:35:48,467 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:35:28.256387+00:00: manual__2026-02-11T14:35:28.256387+00:00, state:running, queued_at: 2026-02-11 14:35:28.271560+00:00. externally triggered: True> successful
2026-02-11 22:35:48,468 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:35:28.256387+00:00, run_id=manual__2026-02-11T14:35:28.256387+00:00, run_start_date=2026-02-11 14:35:30.823267+00:00, run_end_date=2026-02-11 14:35:48.468835+00:00, run_duration=17.645568, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:38:38,682 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>
2026-02-11 22:38:38,683 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:38:38,684 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>
2026-02-11 22:38:38,686 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:38:38,687 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:38:38,687 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:38:38,689 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:38:43,329 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1)
2026-02-11 22:38:43,340 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:38:36.954264+00:00, map_index=-1, run_start_date=2026-02-11 14:38:42.458616+00:00, run_end_date=2026-02-11 14:38:42.631193+00:00, run_duration=0.172577, state=success, executor_state=success, try_number=1, max_tries=0, job_id=126, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:38:38.685059+00:00, queued_by_job_id=93, pid=6547
2026-02-11 22:38:46,501 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>
2026-02-11 22:38:46,502 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:38:46,503 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:38:36.954264+00:00 [scheduled]>
2026-02-11 22:38:46,505 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:38:46,506 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:38:46,506 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:38:46,508 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:38:36.954264+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:38:53,514 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:38:36.954264+00:00', try_number=1, map_index=-1)
2026-02-11 22:38:53,527 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:38:36.954264+00:00, map_index=-1, run_start_date=2026-02-11 14:38:50.527365+00:00, run_end_date=2026-02-11 14:38:52.875238+00:00, run_duration=2.347873, state=success, executor_state=success, try_number=1, max_tries=0, job_id=127, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:38:46.503916+00:00, queued_by_job_id=93, pid=6551
2026-02-11 22:38:56,730 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:38:36.954264+00:00: manual__2026-02-11T14:38:36.954264+00:00, state:running, queued_at: 2026-02-11 14:38:36.966597+00:00. externally triggered: True> successful
2026-02-11 22:38:56,731 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:38:36.954264+00:00, run_id=manual__2026-02-11T14:38:36.954264+00:00, run_start_date=2026-02-11 14:38:38.662196+00:00, run_end_date=2026-02-11 14:38:56.731846+00:00, run_duration=18.06965, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:40:29,125 INFO - Adopting or resetting orphaned tasks for active dag runs
2026-02-11 22:40:45,697 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>
2026-02-11 22:40:45,698 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:40:45,699 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>
2026-02-11 22:40:45,700 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:40:45,701 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:40:45,702 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:40:45,704 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:40:50,410 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1)
2026-02-11 22:40:50,421 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:40:42.202549+00:00, map_index=-1, run_start_date=2026-02-11 14:40:49.471193+00:00, run_end_date=2026-02-11 14:40:49.735819+00:00, run_duration=0.264626, state=success, executor_state=success, try_number=1, max_tries=0, job_id=128, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:40:45.699818+00:00, queued_by_job_id=93, pid=6647
2026-02-11 22:40:53,334 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>
2026-02-11 22:40:53,334 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:40:53,335 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:40:42.202549+00:00 [scheduled]>
2026-02-11 22:40:53,337 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:40:53,338 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:40:53,339 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:40:53,341 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:40:42.202549+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:41:00,181 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:40:42.202549+00:00', try_number=1, map_index=-1)
2026-02-11 22:41:00,192 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:40:42.202549+00:00, map_index=-1, run_start_date=2026-02-11 14:40:57.367827+00:00, run_end_date=2026-02-11 14:40:59.471165+00:00, run_duration=2.103338, state=success, executor_state=success, try_number=1, max_tries=0, job_id=129, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:40:53.336536+00:00, queued_by_job_id=93, pid=6656
2026-02-11 22:41:03,073 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:40:42.202549+00:00: manual__2026-02-11T14:40:42.202549+00:00, state:running, queued_at: 2026-02-11 14:40:42.219959+00:00. externally triggered: True> successful
2026-02-11 22:41:03,075 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:40:42.202549+00:00, run_id=manual__2026-02-11T14:40:42.202549+00:00, run_start_date=2026-02-11 14:40:45.676527+00:00, run_end_date=2026-02-11 14:41:03.075445+00:00, run_duration=17.398918, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
2026-02-11 22:41:53,592 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>
2026-02-11 22:41:53,593 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:41:53,594 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.sync_order_data manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>
2026-02-11 22:41:53,596 WARNING - cannot record scheduled_duration for task sync_order_data because previous state change time has not been saved
2026-02-11 22:41:53,597 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default
2026-02-11 22:41:53,597 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:41:53,599 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'sync_order_data', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:41:57,839 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='sync_order_data', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1)
2026-02-11 22:41:57,879 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=sync_order_data, run_id=manual__2026-02-11T14:41:50.369709+00:00, map_index=-1, run_start_date=2026-02-11 14:41:56.916014+00:00, run_end_date=2026-02-11 14:41:57.108020+00:00, run_duration=0.192006, state=success, executor_state=success, try_number=1, max_tries=0, job_id=130, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2026-02-11 14:41:53.595162+00:00, queued_by_job_id=93, pid=6695
2026-02-11 22:42:01,095 INFO - 1 tasks up for execution:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>
2026-02-11 22:42:01,096 INFO - DAG dw_order_sync has 0/16 running and queued tasks
2026-02-11 22:42:01,097 INFO - Setting the following tasks to queued state:
	<TaskInstance: dw_order_sync.run_automation_test manual__2026-02-11T14:41:50.369709+00:00 [scheduled]>
2026-02-11 22:42:01,099 WARNING - cannot record scheduled_duration for task run_automation_test because previous state change time has not been saved
2026-02-11 22:42:01,100 INFO - Sending TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default
2026-02-11 22:42:01,101 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:42:01,103 INFO - Executing command: ['airflow', 'tasks', 'run', 'dw_order_sync', 'run_automation_test', 'manual__2026-02-11T14:41:50.369709+00:00', '--local', '--subdir', 'DAGS_FOLDER/tag_data_warehouse/dw_order_sync.py']
2026-02-11 22:42:19,015 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='dw_order_sync', task_id='run_automation_test', run_id='manual__2026-02-11T14:41:50.369709+00:00', try_number=1, map_index=-1)
2026-02-11 22:42:19,029 INFO - TaskInstance Finished: dag_id=dw_order_sync, task_id=run_automation_test, run_id=manual__2026-02-11T14:41:50.369709+00:00, map_index=-1, run_start_date=2026-02-11 14:42:04.706372+00:00, run_end_date=2026-02-11 14:42:18.347317+00:00, run_duration=13.640945, state=success, executor_state=success, try_number=1, max_tries=0, job_id=131, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2026-02-11 14:42:01.098519+00:00, queued_by_job_id=93, pid=6702
2026-02-11 22:42:22,898 INFO - Marking run <DagRun dw_order_sync @ 2026-02-11 14:41:50.369709+00:00: manual__2026-02-11T14:41:50.369709+00:00, state:running, queued_at: 2026-02-11 14:41:50.381954+00:00. externally triggered: True> successful
2026-02-11 22:42:22,899 INFO - DagRun Finished: dag_id=dw_order_sync, execution_date=2026-02-11 14:41:50.369709+00:00, run_id=manual__2026-02-11T14:41:50.369709+00:00, run_start_date=2026-02-11 14:41:53.571963+00:00, run_end_date=2026-02-11 14:42:22.899708+00:00, run_duration=29.327745, state=success, external_trigger=True, run_type=manual, data_interval_start=2026-02-10 00:00:00+00:00, data_interval_end=2026-02-11 00:00:00+00:00, dag_hash=18b6485188fd364812e8cde73c6c3d20
