# -*- coding: utf-8 -*-
# *****************************************************************
# Author     : John
# Date       : 2025-04-20
# Description: è·å–æŸè‚¡ç¥¨æŸæ—¥çš„æ”¶ç›˜ä»·ï¼Œå¼€ç›˜ä»·ï¼Œæˆäº¤é‡
# éœ€æ±‚ï¼Œæ‰“å¼€all.xlsx è·å–ä¸Šæµ·è‚¡ç¥¨ä»£ç ï¼Œéå†è·å–ä¸Šä¸€æ—¥å’Œå½“å¤©çš„æ”¶ç›˜ä»·ï¼Œå¼€ç›˜ä»·ï¼Œæˆäº¤é‡ï¼Œ
# åˆ¤æ–­ï¼Œå½“å¤©æ”¶ç›˜ä»· å¤§äº ä¸Šä¸€æ—¥çš„å¼€ç›˜ä»·ï¼Œä¸”æˆäº¤é‡å°äºä¸Šä¸€æ—¥çš„ç¥¨ã€‚
# *****************************************************************
import requests
import pandas as pd
import time
import random
from urllib3.exceptions import ProxyError, MaxRetryError

# --------------- æ™ºèƒ½é…ç½®ä¸­å¿ƒ ---------------
CONFIG = {
    # åŸºç¡€é…ç½®
    'BASE_URL': 'https://9.push2.eastmoney.com/api/qt/clist/get',
    'MARKET': {'fs': 'm:1', 'name': 'ä¸Šäº¤æ‰€'},  # ä¸Šäº¤æ‰€æ ‡è¯†
    'HEADERS_TEMPLATES': [  # éšæœºUser-Agentæ± 
        'Mozilla/5.0 (Windows NT 10.0; rv:109.0) Gecko/20100101 Firefox/118.0',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'
    ],
    # å®¹é”™é…ç½®
    'MAX_RETRIES': 5,
    'RETRY_DELAY': [1, 2, 4, 8, 16],  # æŒ‡æ•°é€€é¿æ—¶é—´ï¼ˆç§’ï¼‰
    'TIMEOUT': 15,
    'PROXY_ENABLED': False,  # å¯ç”¨ä»£ç†ï¼ˆéœ€é…ç½®ä¸‹æ–¹PROXIESï¼‰
    'PROXIES': {
        # 'http': 'http://user:pass@proxy.com:8080',
        # 'https': 'https://user:pass@proxy.com:8080'
    }
}


def fetch_with_retry(params, attempt=0):
    """æ™ºèƒ½é‡è¯•æœºåˆ¶ï¼ˆå«ç½‘ç»œè¯Šæ–­ï¼‰"""
    if attempt >= CONFIG['MAX_RETRIES']:
        return None

    # åŠ¨æ€ç”Ÿæˆè¯·æ±‚å¤´
    headers = {
        'User-Agent': random.choice(CONFIG['HEADERS_TEMPLATES']),
        'Referer': 'http://quote.eastmoney.com/',
        'Accept-Encoding': 'gzip'
    }

    try:
        print(f"[Attempt {attempt + 1}] æ­£åœ¨è¯·æ±‚ç¬¬{params['pn']}é¡µ...")
        response = requests.get(
            CONFIG['BASE_URL'],
            params=params,
            headers=headers,
            proxies=CONFIG['PROXIES'] if CONFIG['PROXY_ENABLED'] else None,
            timeout=CONFIG['TIMEOUT']
        )
        response.raise_for_status()  # æŠ›å‡ºHTTPé”™è¯¯

        data = response.json()
        if data['code'] != 0:
            raise ValueError(f"APIé”™è¯¯ç ï¼š{data['code']}ï¼Œä¿¡æ¯ï¼š{data.get('msg', 'æœªçŸ¥é”™è¯¯')}")

        if data['data']['total'] == 0:
            print("âš ï¸ æ¥å£è¿”å›total=0ï¼Œå¯èƒ½æ— æ•°æ®æˆ–æƒé™é—®é¢˜")
            return data

        return data

    except (requests.exceptions.HTTPError, ProxyError, MaxRetryError) as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥ï¼š{str(e)}")
        time.sleep(CONFIG['RETRY_DELAY'][attempt])
        return fetch_with_retry(params, attempt + 1)
    except Exception as e:
        print(f"âŒ æ„å¤–é”™è¯¯ï¼š{str(e)}")
        return None


def parse_robust(data):
    """æ•°æ®å¥å£®æ€§è§£æï¼ˆå«å­—æ®µæ ¡éªŒï¼‰"""
    if not data or 'data' not in data:
        return None, "å“åº”æ•°æ®æ ¼å¼é”™è¯¯"

    meta = data['data']
    if meta.get('diff') is None:
        return None, "ç¼ºå°‘å…³é”®æ•°æ®å­—æ®µ'diff'"

    valid_rows = []
    for item in meta['diff']:
        # åŸºç¡€å­—æ®µæ ¡éªŒ
        if not all(key in item for key in ['f12', 'f14', 'f39', 'f41']):
            continue

        # å¸‚ç›ˆç‡æœ‰æ•ˆæ€§æ£€æŸ¥ï¼ˆæ’é™¤è´Ÿå€¼å’Œç‰¹æ®Šç¬¦å·ï¼‰
        try:
            pe_lyr = float(item['f39']) if item['f39'] != '-' else None
            pe_ttm = float(item['f41']) if item['f41'] != '-' else None
            if pe_lyr is None or pe_ttm is None or pe_lyr <= 0 or pe_ttm <= 0:
                continue
        except ValueError:
            continue

        valid_rows.append({
            'è‚¡ç¥¨ä»£ç ': item['f12'],
            'è‚¡ç¥¨åç§°': item['f14'],
            'é™æ€å¸‚ç›ˆ(PE)': pe_lyr,
            'åŠ¨æ€å¸‚ç›ˆ(PE_TTM)': pe_ttm
        })

    if not valid_rows:
        return None, "æ— æœ‰æ•ˆæ•°æ®ï¼ˆå¯èƒ½æ‰€æœ‰å¸‚ç›ˆä¸ºè´Ÿ/æ— æ•ˆï¼‰"
    return pd.DataFrame(valid_rows), None


def diagnose_failure(params, last_response):
    """æ·±åº¦æ•…éšœè¯Šæ–­"""
    print("\nğŸš‘ è¿›å…¥æ·±åº¦è¯Šæ–­æ¨¡å¼ï¼š")
    print(f"  1. æœ€åè¯·æ±‚URLï¼š{CONFIG['BASE_URL']}?{requests.compat.urlencode(params)}")

    if last_response:
        print("  2. å“åº”å†…å®¹æ‘˜è¦ï¼š")
        print(f"     - çŠ¶æ€ç ï¼š{last_response.status_code}")
        print(f"     - å“åº”å¤´ï¼š{dict(last_response.headers)['Content-Type']}")
        print(f"     - æ•°æ®é•¿åº¦ï¼š{len(last_response.text)}å­—èŠ‚")

        try:
            json_data = last_response.json()
            print(
                f"     - APIè¿”å›ï¼šcode={json_data.get('code', 'N/A')}, total={json_data.get('data', {}).get('total', 0)}")
        except:
            print("     - éJSONå“åº”ï¼ˆå¯èƒ½è¢«åçˆ¬æ‹¦æˆªï¼‰")

    print("\n  3. å»ºè®®æ’æŸ¥æ­¥éª¤ï¼š")
    print("     â–¶ æ‰‹åŠ¨éªŒè¯æ¥å£ï¼šå¤åˆ¶URLåˆ°æµè§ˆå™¨ï¼Œæ£€æŸ¥æ˜¯å¦è¿”å›æ•°æ®")
    print("     â–¶ æ£€æŸ¥å¸‚åœºä»£ç ï¼šç¡®ä¿fs=m:1ï¼ˆä¸Šäº¤æ‰€ï¼‰ï¼Œfs=m:0ä¸ºæ·±äº¤æ‰€")
    print("     â–¶ å¯ç”¨ä»£ç†ï¼šè®¾ç½®PROXY_ENABLED=Trueå¹¶é…ç½®æœ‰æ•ˆä»£ç†")
    print("     â–¶ æ›´æ¢utå‚æ•°ï¼šè®¿é—®ä¸œæ–¹è´¢å¯Œç½‘é¡µï¼ŒæŠ“åŒ…è·å–æœ€æ–°utå€¼")
    print("     â–¶ æ£€æŸ¥äº¤æ˜“æ—¶æ®µï¼šéäº¤æ˜“æ—¥å¯èƒ½æ— æ•°æ®ï¼ˆ9:30-15:00ï¼‰")


def main():
    all_stocks = []
    params = CONFIG['MARKET'].copy()
    params.update({
        'pn': 1,
        'pz': 200,
        'fields': 'f12,f14,f39,f41',
        'ut': 'bd1d9ddb04089700cf9c27f6f7426281'  # æœ€æ–°utå€¼ï¼ˆ2025å¹´4æœˆæœ‰æ•ˆï¼‰
    })

    last_response = None
    while True:
        data = fetch_with_retry(params)
        last_response = data.response if data else last_response

        if not data:
            diagnose_failure(params, last_response)
            return

        df, err = parse_robust(data)
        if err:
            print(f"âš ï¸ æ•°æ®è§£æå¤±è´¥ï¼š{err}")
            if params['pn'] == 1:  # é¦–é¡µæ— æ•°æ®ï¼Œç»ˆæ­¢æµç¨‹
                diagnose_failure(params, last_response)
                return
            break  # åç»­é¡µæ— æ•°æ®ï¼Œè§†ä¸ºæ­£å¸¸ç»“æŸ

        all_stocks.extend(df.to_dict('records'))
        print(f"âœ… ç¬¬{params['pn']}é¡µè·å–{len(df)}æ¡æœ‰æ•ˆæ•°æ®")

        if params['pn'] * 200 >= data['data']['total']:
            break
        params['pn'] += 1
        time.sleep(random.uniform(0.3, 0.8))  # éšæœºå»¶è¿Ÿé˜²åçˆ¬

    if all_stocks:
        result = pd.DataFrame(all_stocks).drop_duplicates('è‚¡ç¥¨ä»£ç ')
        print(f"\nğŸ‰ æˆåŠŸè·å–{len(result)}åªè‚¡ç¥¨ï¼š")
        print(result[['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'é™æ€å¸‚ç›ˆ(PE)', 'åŠ¨æ€å¸‚ç›ˆ(PE_TTM)']].head())
        return result
    print("âŒ æ‰€æœ‰é¡µé¢å‡æ— æœ‰æ•ˆæ•°æ®ï¼Œå¯èƒ½å¸‚åœºæ— äº¤æ˜“æˆ–ä»£ç é”™è¯¯")


if __name__ == "__main__":
    main()